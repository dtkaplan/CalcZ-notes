# (PART) Block 4: Linear combinations {.unnumbered}


Harvest materials from Statistical Modeling book: `SM-geometry-Ch09.pdf` and 10, 11, 13.

# Vectors and Vector Operations {#vectors}

    
::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Vec-1a", "Know that vectors can be represented as columns of data or graphically arrows")
state_objective("Vec-1b", "Know how to perform scalar multiplication and vector addition")
state_objective("Vec-1c", "Understand the transpose operator and how to compute the dot product between two vectors")
state_objective("Vec-1d", "Calculate the length of a vector")
state_objective("Vec-1e", "Know that computing the dot product of a vector with itself is equivalent to length squared")
```
:::



Materials in Daily Digitals 14-about 20.

## Vector representations

In this course, we adopt the convention that a vector is a  **column** of numbers, like this one we're naming $\vec{v}$:

$$\vec{v} \equiv  \left(\begin{array}{c}3\\2\\6\end{array}\right)$$ 
Vectors are so important in mathematics and science that they are used to *represent* all  sorts of things. For example, it's legitimate to  say that  *force* is a vector. Of course this doesn't mean that force is a column of numbers. Force  is a physical impetus. It's represented as a vector because every force has both a magnitude--which we'll later call "length"--and a direction. Similarly, *velocity* is a vector because it has a direction and a magnitude. (The word  "speed" refers to the magnitude alone, without the direction.)

Some things that are vectors actually start out as a series of numbers. For instance, a variable in a data frame is literally a  column of numbers. As  you'll see later, it's incredibly  powerful to be able to think about a data variable as having a direction  and a magnitude, even if it isn't obvious at this point what those would be.  

In Block 1, you saw  that *functions* can  be represented for many purposes as a table of data. In  this sense, a function is also a vector: the column  of numbers from the table. Like variables, it turns out  to  be very useful to  think of functions as having a direction  and a magnitude. 

```{r  echo=FALSE, fig.cap="Representing vectors graphically.",  out.width = "50%"}
knitr::include_graphics(normalizePath("www/4vectors.png"))
```

The representation  of vectors graphically, as arrows, fits naturally with the idea of a vector as a magnitude and a direction. The magnitude is shown by the *length* of the vector, and the direction literally by the direction  of the arrow.

What's unfortunate about the graphical presentation of vectors as arrows is the suggestion that a vector has not only  a magnitude and  direction,  but also  a "place."  For instance, the vector labeled (a) in  the diagram is obviously to the left of (b). You may have to force yourself to remember that "place" is not  a property of vectors. Wherever you might choose to place  the arrow (a), it  would be  the same vector (so long  as  you don't change it's length or direction).

The  human capacity to think about vectors easily is pretty much limited to vectors in two- or three-dimensions. Force and velocity are both vectors in three dimensions. But those vectors that arise from columns of data or functions can often have more than three numbers. Geometrically, this corresponds to a direction in a space with more than three dimensions. Many otherwise well  educated people will claim that a space with more than three dimensions cannot exist. It's OK if you want to  think of  high-dimensional spaces as  a kind of metaphor, although a physicist  working with space-time or with string theory  might argue with you.

What makes it possible to use vectors in high-dimensional space for practical problems is that the geometry of vectors has an exact interpretation as arithmetic  (and *vice versa*). In  this Daily Digital, you'll  work with  both geometric vectors and numerical vectors--but keep in  the back of your mind that these are merely two different  modes of  representation of the same mathematical abstraction.

## Vectors, arithmetically

Computers are the technological innovation  that makes it possible for us to work with  high-dimensional vectors.  

A starting  point  is creating a vector on the computer. In  some sense this a vector is just a collection  of numbers, but it's helpful  to  be disciplined  and  remember that, for our purposes, a  vector is  a **column** of numbers. R knows about such columns and will  handle them appropriately.

One way to create a column vector is with  the  `rbind()` function.

use the  `rbind()` function applied to individual arguments. Here,  for instance,  is a command that makes a three-dimensional vector we are calling `b`.

```{r}
b <- rbind(4, -2, 6)
b
```

Notice that in  printing out a  vector, R  includes a series of indices  (e.g. `[1,]` or `[3,]`) to help the reader identify the location  of any element in  the vector. It also  prints a header (`[,1]`) which  is helpful later when we work with  collections of vectors.

## Matrix

You are going to hear the word "matrix" a lot.  Later in  this tutorial we will use the term "matrix multiplication." A matrix is a collection  of  vectors, all of the same dimension. We'll get to them  in good time.  

## Scalar multiplication

You  can multiply a vector times  a  number. The result is a new vector with exactly the  same direction as  the original, but with  a different length. The  arithmetic  is  very  simple: do ordinary multiplication  of the number by  each of the elements  of the  vector. Examples:

$$2 \left(\begin{array}{c}4\\7\end{array}\right) = \left(\begin{array}{c}8\\14\end{array}\right)$$

This  simple  multiplication is called "scalar multiplication" for two  reasons:

1. The result is to "scale" the vector, in the sense of a  "scale  model",  that  is, to make the vector bigger or smaller.
2. There is another important form of vector  arithmetic called "matrix multiplication." By  saying  "scalar multiplication,"  we avoid the  confusion  that might arise if  we  used "multiplication" alone.

In R, scalar multiplication of a vector is  done with `*`, just like ordinary multiplication   with numbers:

```{r echo=TRUE}
b <- rbind(4, -2, 6)
2.3 * b
```


```{r daily-digital-14-E1, exercise=TRUE, exercise.cap="**Exercise**: Write  the  R  code to create a vector named `w` with  components 4, -1,  and -3.5.  Then scalar multiply `w` by 6.3.", exercise.eval=FALSE, exercise.lines=4, exercise.completion=FALSE, exercise.startover=TRUE, exercise.diagnostics=TRUE}
w <- _______
6.3 _______ w
```

```{r daily-digital-14-E1-solution}
w <- rbind(4,  -1,  -3.5)
6.3 *  w
```

```{r daily-digital-14-E1-check}
gradethis::grade_code()
```

### Exercise 1** on paper

Write (or draw) your  answers on a sheet  of  paper. You  can  do the any calculations you need in  the  sandbox. Make sure to write column vectors  in  a  correct  column  format. There's  a sandbox at just below so that you can have the computer do the arithmetic for you.


a. What is $5.42 \left(\begin{array}{r}7.3\\8.9\\-2.4\end{array}\right)$?
b. What is $-2.67 \left(\begin{array}{r}-19.34\\0.23\\14.82\end{array}\right)$?
c. Draw  a  vector of your  own  choice. Next to  it,  draw the vector which is 2.5  times your vector.
d. Take  your  original vector from (c) and draw  the  vector which  is -3 times it. 
e. Write down the  R  code to  create a vector named `w` that is $$\left(\begin{array}{c}2\\5\\1\\5\end{array}\right)$$



## Dot product and `%*%`

Now to  introduce  a new R arithmetic function, written `%*%`. This symbol is pronounced "matrix multiply."  In traditional mathematical notation, matrix multiplication is indicated by putting the two quantities next to one another, like this: $\vec{\mathbf m}^T \vec{\mathbf x}$, or sometimes with a dot $\vec{\mathbf m}T\cdot \vec{\mathbf x}$. The superscript $^T$ means "transpose." For us, this  is merely a  book-keeping convention.

The operation `%*%` will do several  different types  of  arithmetic  with  vectors. The one we will work with here is  called  a *dot product*.  (There are  also "matrix products"  and "outer products".)

The R notation for a dot product very  much echoes the  traditional matrix  notation,  at least  with  respect to $^T$.  We'll  illustrate by creating  two vectors `u`  and `v` and then calculating their dot  product.

::: {.scaffolding  data-latex=""}
```{r results="hide"}
u <- rbind(6, -3,  7)
v <- rbind(2,  1,  3)
t(u) %*%  v
```
:::

Notice  that the  output  of a dot product is  a single number: a scalar. (R prints the output as if the scalar were  a vector in one-dimension.)

Arithmetically, the dot product is calculated by multiplying the corresponding components in the two vectors  (e.g.  $6  \times 2$ and  $-3 \times 1$ and  $7 \times 3$) and adding up the  result. You can see why the dot product always involves two vectors with the same number of elements.

The R `t()` function corresponds to  the mathematical notation for the transpose: $^T$. So `t(u)` would be written, mathematically, as $\vec{u}^T$. The  purpose of `t()` is to turn columns (like our vector `u`) into rows,  and vice versa.  If you  like,  try the command `t(u)` in  the sandbox to see how it  is printed.

For us,  the purpose of writing `t(u)` is  to signal  to  the `%*%`  matrix multiplication  operation that we want a particular operation: the dot product.

The  dot product always involves the transpose of a column vector on  the left side of  `%*%`  and a column vector on  the right side.

You  can  also  write a command  `u %*% t(v)`,  but  this is not a  dot product. It is  called  an "outer product" and we will not need it in this course. Try it out in  the sandbox.


```{r daily-digital-14-Essay1, echo=FALSE}
etude2::etudeEssay(
  prompt = "Explain briefly inwords how the shape  of the result of a dot product is different from the result of an outer  product."
)
```


## Vector lengths

For  a vector $\vec{v}$, the  length is denoted $|| \vec{v} ||$. Vector length can  be measured with  a ruler ...  so long as you have physical access to  the vector. But often, all we have  is the numerical representation. So, we use arithmetic--the dot product-- to calculate vector length: 
$$|| \vec{v}  || \equiv \sqrt{\ \vec{v}^T \cdot \vec{v}}$$

For  the  next  two questions, consider these two vectors:

$$\vec{u} \equiv \left(\begin{array}{c}3\\4\end{array}\right) \  \  \ \text{and}  \ \ \ \vec{w} \equiv \left(\begin{array}{c}1\\1\\1\\1\end{array}\right)
$$

```{r daily-digital-14-QA2, echo=FALSE}
askMC(
  prompt = "What is the length of the vector $\\vec{u}$?",
    "2" = "There are two elements in $\\vec{u}$, but  that's not what the \"length\" of a vector means.",
    "+5+" = "",
    "25" = "This is the length-squared. Take the square root of it to find the length.",
    "None of the above" = "",
  random_answer_order = FALSE
)
```

```{r daily-digital-14-QA3, echo=FALSE}
askMC(
  prompt = "What is the length of the vector $\\vec{w}$?",
    "+2+" = "Right: $\\sqrt{1^2 + 1^2 + 1^2 + 1^2}$",
    "4" = "There  are four elements in $\\vec{w}$$, and the square-length of $\\vec{v}$ happens  to be 4  ($1^2 + 1^2 + 1^2 + 1^2$), but neither  of  these is the \"length\"  of $\\vec{w}$.",
    "6" = "",
    "None of the above" = "",
  random_answer_order = FALSE
)
```

## MMAC §6.1

### Problems 41-48

In Exercises  41-48, let

$$\vec{\mathbf u} \equiv  \left(\begin{array}{c}4\\-3\end{array}\right)  \  \  \text{and}\ \ \vec{\mathbf v} \equiv  \left(\begin{array}{c}2\\2\end{array}\right)$$

and compute the  **length** of the vector. (If none  of the available  choices are exactly right, choose the closest.)

```{r daily-digital-14-QA41, echo=FALSE}
askMC(
  prompt = "41) $3 \\vec{u}$",
  3, 4, 5, 6,  10, "+15+",  16, 
  random_answer_order = FALSE
)
```

```{r daily-digital-14-QA42, echo=FALSE}
askMC(
  prompt = "42) $-2 \\vec{u}$",
  "3", 4,  5, 6, "+10+", "15", 16), #c("$\\sqrt{3}$", 4, "$\\sqrt{5}$", 6, "+$\\sqrt{8}$+", "15",  16, 
  random_answer_order = FALSE
)
```

```{r daily-digital-14-QA43, echo=FALSE}
askMC(
  prompt = "42) $-\\vec{v}$",
  "+3+"="Right.  It's $\\sqrt{8} = \\sqrt{2^2 + 2^2}$ to be precise.", 
  "4"="",  "5"="", "6"="", "10"="", 
  "15"="", "16"="", 
  random_answer_order = FALSE
)
```

```{r daily-digital-14-QA45, echo=FALSE}
askMC(
  prompt = "45) $\\vec{u}+ \\vec{v}$",
  3,  4, 5, "+6+", 10, "15", 16, 
  random_answer_order = FALSE
)
```

```{r daily-digital-14-QA48, echo=FALSE}
askMC(
  prompt = "48) $2 \\vec{u} -  5 \\vec{v}$",
  3,  4, 5, "6", 10, "15", "+16+", 
  random_answer_order = FALSE
)
```

## Constant bearing, on paper

Do this exercise on paper.

Consider the diagram showing two straight-line tracks, a dot on each track, and a vector.

```{r echo=FALSE}
knitr::include_graphics(normalizePath("www/collision.png"))
```

Let's imagine that dot 1 is an aircraft and that the black vector attached to it is the aircraft's velocity. We'll call this $\vec{v}_1$, Similarly for dot 2, where the velocity vector will be called $\vec{v}_2$. 

There's a third vector drawn in red: the difference in position of the two aircraft at the exact moment depicted in the drawing.

The question we want to address is whether the aircraft are on a collision course.  Obviously, the two course cross. So we know that the two aircraft will cross the same point. For a collision, the aircraft have to cross that point at the same time. 

Copy over the drawing to your own piece of paper. You don't need to get the vectors and positions exactly right; any reasonable approximation will do.

Now you are going to do *visual* vector addition and subtraction to answer the collision question.

1) The *relative* velocity of the two planes is the difference between their velocities. Subtract $\vec{v}_2$ from $\vec{v}_1$ and draw the resulting vector. Pay attention to both the *length* and *direction* of the relative velocity.

2) The displacement between the two planes is the red vector: the position of dot 2 subtracted from dot 1. Compare the *directions* of the relative velocity vector and the displacement vector. **If they are aligned, then the planes are on a collision course.**

3) In the picture as drawn, the relative velocity vector and the displacement vector are not aligned. Figure out how much you would need to change the length of $\vec{v}_2$ so that the relative velocity *does* align with the displacement. (Keep the direction the same.) Draw this new vector and label it clearly "vector for intercept."

4) In (3) you changed the *length* of $\vec{v}_2$ keeping the direction the same. Now you are going to keep $\vec{v}_2$ at the original length, but change its direction so that the new relative velocity is aligned with the displacement vector.

Items (3) and (4) are two different ways of designing an intercept of plane 1 by plane 2.

Bonus) You can figure out how long it takes for each plane to reach the intersection point by finding out how many multiples of the velocity vector will cover the line segment between the plane's position and the intersection point. For example, in the original drawing $4 \vec{v}_1$ will bring the plane to the intersection point, so it takes 4 "time units" for the plane to reach the point. (What is the time unit? If velocity is in miles/hour, then the time unit is hours. If the velocity is in feet/second, then the time unit is seconds.) Your task: Figure out where aircraft 2 will be in 4 time units. This will tell you the separation between aircraft 2 and aircraft 1 when 1 reaches the intersection point. Draw and clearly label this vector.



# Linear Combinations of Vectors

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Vec-2a", "Write a system of linear equations as an equivalent target problem involving a linear combination of vectors")
state_objective("Vec-2b", "Know the definition of a linear combination of vectors and be able to rewrite as a matrix times a vector")
state_objective("Vec-2c", "Solve for a target vector algebraically or graphically in two dimensions")
state_objective("Vec-2d", "Know how to calculate the distance between two vectors and how to subtract vectors algebraically and graphically")
```
:::

# Orthogonal Vectors and Projection

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Vec-3a", "Calculate the angle between two vectors")
state_objective("Vec-3b", "Find a nonzero vector orthogonal to a given vector")
state_objective("Vec-3c", "Calculate the projection of a vector onto another vector")
state_objective("Vec-3d", "Sketch the projection of one vector onto another and then draw the residual vector")
```
:::

# Solutions of Linear Combination (Day 1)

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Vec-4a", "Write a target problem in the form")
state_objective("Vec-4b", "Understand the relationship between b and b hat and calculate the residual vector")
state_objective("Vec-4c", "Calculate solutions to vector equations using R")
```
:::

# Solutions of Linear Combination (Day 2)

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Vec-5a", "Understand applications of projections")
state_objective("Vec-5b", "Understand the relationship between projections and Method of Least Squares")
state_objective("Vec-5c", "Understand what the qr.solve() function gives you (this is testable).")
```
:::

                                                        
# Method of Least Squares (Day 1)

    ::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Vec-6a", "Apply projections to decompose a vector into two directions")
state_objective("Vec-6b", "Understand the connection between projections into the model space and solutions to the target problem")
state_objective("Vec-6c", "Know that R2 is a measure of how well the model accounts for variability in the output variable")
state_objective("Vec-6d", "Know that R2 is the cosine of the angle between  and")
```
:::

# Method of Least Squares (Day 2)

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Vec-7a", "Understand that \"continuous\" functions can be approximated by vectors of discrete function value samples")
state_objective("Vec-7b", "Be aware that the word \"transform\" in this class' context relates to the \"Fourier Transform.\"")
state_objective("Vec-7c", "Understand that the \"transform\" technique amounts to designing the matrix in the target problem to break up the function into meaningful components")
```
:::

# Eigenvalues and eigenvectors

[I'm thinking to move the eigenvalue stuff from discrete-time matrix dynamics to here]

It would be hard to overstate the importance of the ideas of eigenvectors and their associated eigenvalues. They are used in engineering, for instance, to determine the modes of vibration of structures (such as an airplane fuselage). In chemistry, electron orbits are studied using eigenvectors. They are used throughout physics. In quantum physics, **any quantity that is observable** (e.g. energy, position) is an eigenvector of a quantum wave function. In data science, they underlie one of the principle means of contructing machine learning models of complex, multivariate data. They are the foundation of the original Google algorithm for ranking web pages and the "latent semantic indexing" that enables you to give a search term and find closely related articles even if they don't happen to include that specific term.

Eigenvectors are important in dynamics. Indeed, the importance of eigenvectors and eigenvalues to science generally is related to the use of differential equations as a fundamental way of describing the universe from the very fine scale (electrons) to the most massive scales (relativistic bending of space-time).

In a traditional university calculus curriculum, eigenvectors and eigenvalues are introduced in a *4th-semester* calculus course called "linear algebra." Especially in recent decades, eigenvectors and eigenvalues are used by people who never came close to a linear algebra course. For instance, [data science blogs](https://www.analyticsvidhya.com/blog/2019/07/10-applications-linear-algebra-data-science/) are full of discussion about how to learn linear algebra if you've never had it in college.

In this course, the context in which we introduce eigenvectors is as part of powerful calculus strategy: break seemingly complex wholes into simple parts (differentials! linear approximations!), operate on the parts in simple ways, then put together the parts into a whole (integration! iteration!). 

So what are the "simple parts" involved in eigenvectors? In dynamics, the "complex whole" is the state-space and the dynamical functions that govern motion in the state-space. (We're restricting ourselves to state spaces with two components so that you can see what's going on graphically. But two dimensions is enough to shows most of the sorts of phenomena that can be produced by dynamical systems.)

What are the parts of a two-dimensional state space? Recall from the first semester of CalcZ our studies of linear geometry, matrices, etc. There we defined a **vector sub-space** as all the places that can be reached by taking linear combinations of a set of vectors. A plane is a vector sub-space defined by any two vectors that aren't aligned. 

Eigenvectors are specific vectors that can compose through linear combinations the whole of a state space in linear dynamics. The dynamics are **radically simpler** along an eigenvector than elsewhere in a state space. How simpler?

Consider the dynamics induced by the matrix 
$${\mathbf A} = \left[\begin{array}{cr}6 & -\frac{11}{4}\\1 & 0\ \end{array}\right]$$
The eigenvalues of ${\mathbf A}$ are 
$$\lambda_1 = \frac{11}{2}\ \ \text{and}\ \ \lambda_2 = \frac{1}{2}$$ 
To get nice fractions like this is the reason we're using this particular matrix. We'll deal with the way to calculate the eigenvalues of any matrix on a later day, when we will do it with a simpler formula than the following one. (Don't incur anxiety trying to understand the formula.) For an [abcd] matrix the eigenvalues are
$$\lambda_{1, 2} = \frac{1}{2} \left[(a - d)^2 \pm \sqrt{(a+d)^2 - 4bc}\strut\right]$$
For larger matrices, for instance the billion-by-billion sized ones used in web indexing, there are no formulas but there are ways to calculate the eigenvalues numerically.

The eigenvectors corresponding to matrix ${\mathbf A}$ are very closely related to the eigenvalues. (Again, you don't need to memorize this, even if it is a whole lot simpler than the formula above.)
$${\mathbf \Lambda}_1 = \left[\begin{array}{c}\lambda_1\\1\end{array}\right] = 
\left[\begin{array}{c}\frac{11}{2}\\1\end{array}\right]\ \ \ \text{and}\ \ \ {\mathbf \Lambda}_2 = \left[\begin{array}{c}\lambda_2\\1\end{array}\right] = 
\left[\begin{array}{c}\frac{1}{2}\\1\end{array}\right]$$
Let's see what happens when we multiply an eigenvector (or any scalar multiple of an eigenvector) by the matrix ${\mathbf A}$ from which it was derived:
$${\mathbf A} \cdot {\mathbf \Lambda_2} = \left[\begin{array}{cr}6 & -\frac{11}{4}\\1 & 0\ \end{array}\right] \cdot \left[\begin{array}{r} \frac{1}{2}\\1\ \end{array}\right] = 
\frac{1}{2} \left[\begin{array}{c}6\strut\\1\strut\end{array}\right] + 
1 \left[\begin{array}{r}-\frac{11}{4}\\0\ \end{array}\right] = \left[\begin{array}{r}?\strut\\?\strut\end{array}\right]$$

```{r ev1-1, echo=FALSE, results="markup"}
askMC(
  "Do the arithmetic in the above equation to find the numerical value of ${\\mathbf A}\\cdot{\\mathbf \\Lambda}_2$. What is it?",
  "+$\\left[\\begin{array}{r}\\frac{1}{4}\\\\\\frac{1}{2}\\end{array}\\right]$+",
  "$\\left[\\begin{array}{r}\\frac{1}{2}\\\\\\frac{1}{2}\\end{array}\\right]$",
  "$\\left[\\begin{array}{r}1\\\\\\frac{1}{2}\\end{array}\\right]$",
  "$\\left[\\begin{array}{r}2\\\\\\frac{3}{2}\\end{array}\\right]$"
)
```

If you found the arithmetic tedious, here's a shortcut:

<div style="font-size: 36px; text-align:center;">
${\mathbf A}\cdot{\mathbf \Lambda}_2 = \lambda_2\ {\mathbf \Lambda}_2$
</div>

In English, "Multiplying an eigenvector of a matrix ${\mathbf A}$ by ${\mathbf A}$ produces a multiple of the eigenvector. The multiple is the eigenvalue." 

```{r ev1-2, echo=FALSE, results="markup"}
askMC(
  "What is the numerical value of ${\\mathbf A}\\cdot{\\mathbf \\Lambda}_1$?",
  "+$\\left[\\begin{array}{r}\\frac{121}{4}\\\\\\frac{11}{2}\\end{array}\\right]$+",
  "$\\left[\\begin{array}{r}\\frac{11}{4}\\\\\\frac{11}{2}\\end{array}\\right]$",
  "$\\left[\\begin{array}{r}\\frac{11}{4}\\\\\\frac{1}{2}\\end{array}\\right]$",
  "$\\left[\\begin{array}{r}\\frac{121}{4}\\\\\\frac{3}{2}\\end{array}\\right]$"
)
```

The dynamics along an eigenvector are particularly simple:

- If you start (exactly) on the 1-dimensional line defined by the eigenvector, the future state will stay on that eigenvector. 
- Suppose the initial condition ${\mathbf X}_0 = m {\mathbf \Lambda}$. Then the solution will be 

<div style="font-size: 36px; text-align:center;">${\mathbf X}_n = \lambda_i^{n\strut}\, {\mathbf X}_0 \ \ \text{when}\ \  {\mathbf X}_0 = m {\mathbf \Lambda}_i$  
</div>

```{r ev1-3, echo=FALSE, results="markup"}
askMC(
  "Suppose ${\\mathbf X}_0 = 3 {\\mathbf \\Lambda}_2$ in the dynamical system defined by ${\\mathbf A}$. What will be ${\\mathbf X}_5$?",
  "+$\\left[\\begin{array}{r}\\frac{3}{16}\\\\\\frac{3}{32}\\end{array}\\right]$+",
  "$\\left[\\begin{array}{r}\\frac{3}{32}\\\\\\frac{3}{16}\\end{array}\\right]$",
  "$\\left[\\begin{array}{r}\\frac{3}{64}\\\\\\frac{3}{64}\\end{array}\\right]$",
  "$\\left[\\begin{array}{r}\\frac{3}{4}\\\\\\frac{3}{16}\\end{array}\\right]$"
)
```


