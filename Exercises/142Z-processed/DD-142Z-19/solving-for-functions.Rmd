---
title: "Solving for functions"
author: "Daniel Kaplan"
runtime: shiny_prerendered
---

```{r include=FALSE}
library(etude2)
library(mosaicCalc)
```

A familiar task from high-school math is to "solve" an equation. For instance, if given the equation $a x^2 + b x + c = 0$ and asked to "solve for $x$," you might remember to invoke some procedure such as the quadratic formula:$$x = \frac{1}{2a}\left[-b \pm \sqrt{\strut b^2 - 4 a c}\right]$$ From experience, you would know that $x$ will be a number (although the situation gets a little sketchy when $4ac > b^2$). 

In CalcZ, rather than emphasize "equations," we've built on the notion of **functions**. For instance, in the language of calculus, we would define a function such as $f(x) \equiv a x^2 + b x + c$. The task of "solving" is re-framed as "finding a zero of $f(x)$," that is, finding a value $x_0$ for which $f(x_0) = 0$. A similar sort of task is "finding an *argmax* of $f(x)$." This means to find an $x^\star$ such that $f(x^\star) \geq f(x)$ for all $x$. We have used several notations, e.g. $x_0$, $x^\star$, etc., to indicate that a task is to find a specific numerical value that, when put as an input to a function, gives an output that has some specified property, e.g. the output is zero or the output is maximized.

We have also studied operators that, when given a *function* as input, produce as output *another function*. The most famous of these are *differentiation* and *anti-differentiation*. 

With finite-difference equations, we have returned to mathematical objects in the form of *equations*, and to the task of *solving*. For instance, a one-dimensional finite-difference equation looks like $$x_{n+1} = f(x_n)$$ The equation sets the relationship between the future ($n+1$) state and the present ($n$) state. To find a *solution* to the finite-difference equation does not mean finding a numerical value for $x$. Instead, it means finding a *function*  $x_n$ that satisfies the relationship specified by the equation. 

Calling $x_n$ a "function" drops (for good reason) some conventions we have used throughout the course:

1. We have used *parentheses* rather than subscripts, so $x(n)$ instead of $x_n$.
2. We have used names like $f()$ and $g()$ and $\exp()$ and $\sin()$ for functions, and used names like $x$ and $y$ and $t$ for *numerical inputs to functions*.
3. We have been concerned with functions where the input can be varied continuously, say $\infty < x < \infty$ rather than functions where the input is discrete, e.g. $n=0, 1, 2, \ldots$. 

Differential equations---as opposed to *difference equations*---also involve an equation. As we start out, that equation will involve **three** different functions, typically a function of time $g(t)$, the derivative $\partial_t g(t)$ of that function with respect to time and still another function $\text{dynamic}()$. So a differential equation might look like $$\underbrace{\partial_t g(t)}_\text{function 3} = \underbrace{\text{dynamic}}_\text{function 2}(\ \underbrace{g(t)}_\text{function 1}\ )$$ 

The equation mandates a particular relationship between the functions $g(t)$ and $\partial_t g(t)$. To *solve* this equation means to find a particular function $g(t)$ that is faithful to the mandate set by the equation. And, of course, whatever $g(t)$ is, $\partial_t g(t)$ is its derivative with respect to time.

As a form of contrast, consider this equation: $$\partial_t g(t) = \sin(\omega\, t)$$
We already learned a technique to solve such an equation, namely take the anti-derivative with respect to time of both sides:
$$g(t) + C \equiv \int \partial_t g(t) dt = \int \sin(\omega t) dt \equiv - \frac{1}{\omega} \cos(\omega\, t) + D$$

Notice that I've used $\equiv$ in two places in the above line. To say $\partial_t g(t) = \sin(\omega t)$ is to impose a mandate. This won't be true for any $g(t)$ that comes along, the equation is giving specific information about what kind of function $g(t)$ has to be. One the other hand, $g(t) - C \equiv \int \partial_t g(t) dt$ is something that has to be true for *any* $g(t)$ that someone happens to provide. Similarly, $\int \sin(\omega t)dt \equiv - \frac{1}{\omega} \cos(\omega\, t) + D$ is a mathematical *fact*, not a modeling statement about the world.

In a differential equation, the unknown function $g(t)$ appears on *both* sides of the equation, once in the form of $\partial_t g(t)$ ("function 3") and once as $g(t)$ ("function 1"). Although it's tempting to apply anti-differentiation, that will not do the job of finding $g(t)$, since $g(t)$ itself appears as part of the broader function $\text{dynamics}(\ g(t)\ )$ to which we're tempted to apply anti-differentiation. 

We will need other approaches to *solve* the differential equation for $g(t)$. We will use two good approaches, one that always works (for any function $\text{dynamics}()$ and the second that only works sometimes.

1. A numerical method that approximates the differential equation with a finite-difference equation, enabling it to be solved simply by *iteration*. This is Euler's method.
2. A algebraic method that works only if we already know the functional form of the solution. As you'll see, for many differential equations important in modeling, there is such an *ansatz*: a function we already know where all we have to do is fill in the details.

Interestingly, traditionally calculus courses have featured a third method for solving differential equations:

3. An algebraic method that sometimes allows the solver to translate the differential equation into a form that looks like this: $h(g(t)) = \int f(t) dt$ and enables standard anti-differentiation of $f(t)$ to be the central step. We won't dwell on this because it only works sometimes, often requires an algebraic superpower that not all students possess, and, in the cases most commonly encountered in modeling has already been done giving us an *ansatz* that we can use in method (2). 

```{r sff1, echo=FALSE, results="markup"}
askMC(
  "Consider the differential equation $$\\partial_t g(t) = 0.2 g(t) \\left(1 - g(t)/200\\right)$$ Which of these is the function $\\text{dynamics}()$ in the differential equation?",
  "+$\\text{dynamics}(x) \\equiv 0.2 x (1 - x/200)$+" = "When you give as input the function $g(t)$ you get the right-hand side of the differential equation.",
  "$\\text{dynamics}(t) \\equiv 0.2 g(t) (1-g(t)/200)$" = "The input to dynamics() should be the function $g(t)$, not the whole right side of the differential equation.",
  "$\\text{dynamics}(x) \\equiv 0.2 x$",
  "$\\text{dynamics}(x) \\equiv 1 - x/200$"
)
```

Differential equations are often written in a kind of shorthand which makes it easier for those in the know but can be confusing to newcomers. We're going to use that shorthand *since you will encounter it in your downstream courses*. But we want to lay it out in parallel with the highly explicit notation we have been using thus far.

The differential equation in the previous exercise is
$$\partial_t g(t) = 0.2 g(t) \left(1 - g(t)/200\right)$$
The shorthand makes some substitutions:

i. The function $g(t)$ is written simply $x$. You will need to force yourself to remember that $x$ is really $x(t)$: a function of time.
ii. The derivative notation $\partial_t g(t)$ is replaced with $\dot{x}$. That tiny dot over the $x$ is entirely equivalent to $\partial_t$.

Let's write it a little bigger to be sure you can spot it:

<div style="font-size: 45px; text-align:center;">$$\dot{x}$$</div>

In the shorthand the equation is rendered 

<div style="font-size: 30px; text-align:center;">$$\dot{x} = 0.2\, x\ (1-x/200)$$</div> Although we've saved having to write $(t)$ multiple times and having to write $\partial_t$ at all, until you get used to it you will forget that $t$ has anything to do with $\dot{x} = 0.2\, x\ (1-x/200)$. Keep your eyes out for that little speck of a dot, $\dot{\ }$, because it is the only thing to remind you about the essential role of $t$ as the input to the sought-after $x(t)$.

```{r sff2, echo=FALSE, results="markup"}
askMC(
  "Which of the following is the x-shorthand for the differential equation $$\\partial_t g(t) = a g(t) + b \\ \\text{?}$$",
  "+$\\dot{x} = a x + b$+",
  "$x = a \\dot{x} + b$" = "Dot on the wrong side.",
  "$\\dot{x} = a \\dot{x} + b$" = "Too many dots.",
  "$\\dot{x}(t) = a x(t) + b$" = "Remember, the $t$ is implicit in the dot."
)
```

```{r sff3, echo=FALSE, results="markup"}
askMC(
  "What is the function dynamics() in $\\dot{x} = a x + b$?",
  "+dynamics$(x) \\equiv a x + b$+",
  "dynamics$(t) \\equiv a x + b$" = "Don't put a $t$ where it's not needed.",
  "dynamics$(x) \\equiv x + b$",
  "dynamics$(x) \\equiv a x$"
)
```

