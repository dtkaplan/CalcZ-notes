# Change relationships

The questions that started it all had to do with motion. There were words to describe speed: fast and slow. There were words to describe force: strong and weak, heavy and light. And there were words to describe location and distance: far and near, long and short, here and there. But what were the relationships among these things? And how did time fit in, an intangible quantity that had aspects of location (long and short) and of speed (quick and slow)? `r mark(2000)`

Galileo (1564-1642) started the ball rolling. As the son of a musician and music theorist, he had a sense of musical time, a steady beat of intervals. When a student of medicine in Pisa, he noted that swinging pendulums kept reliable time, regardless of the amplitude of their swing. After accidentally attending a lecture on geometry, he turned to mathematics and natural philosophy. Inventing the telescope, his observations put him on a collision course with the accepted classical truth about the nature of the planets. Seeking to understand gravity, he built an apparatus that enabled him to measure accurately the position in time of a ball rolling down a straight ramp. The belled gates he set up to mark the ball's passage were spaced arithmetically in musical time: 1, 2, 3, 4, .... But the distance between the gates was geometric: 1, 4, 9, 16, .... Thus he established a mathematical relationship between increments in time and increments in position. Time advanced as 1, 1, 1, 1, ... and position as 1, 3, 5, 7, .... He observed that the ***second*** increments of position, the increments of the increments 1, 3, 5, 7, ..., were themselves evenly spaced: 2, 2, 2, .... `r mark(2005)`

Putting these observations in tabular form, and adding columns for the 

- first increment  $y(t) \equiv x(t+1) - x(t)$ and the
- second increment $y(t+1) - y(t)$

$t$ | $x(t)$ | first increment | second increment
----|--------|-----------------|---------------
0   | 0      | 1        | 2
1   | 1      | 3        | 2
2   | 4      | 5        | 2
3   | 9      | 7        | 
4   | 16     |          |


Galileo had neither the mathematics nor the equipment to measure motion continuously in time. So what might be obvious to us now, that position is a function of time $x(t)$, would have had little practical significance to him. But we discover in his first increments of $x$ something very much like the ***slope function*** in Chapter \@ref(slope-function).  `r mark(2010)`

$${\cal D}_t\, x(t) \equiv \frac{x(t + 1) - x(t)}{1}$$
From his data, he observed that ${\cal D}_t\, x(t)$ increases linearly in $t$: $${\cal D}_t x(t) = 2 t + 1$$

Calculating the second increments of $x$ is done by the "slope function of the slope function," which we can call ${\cal D}_{tt}$:
$${\cal D}_{tt} x \equiv {\cal D}_t \left[{\cal D}_t x(t)\right] = 2(t+1) + 1 - (2 t + 1) = 2$$

## Continuous time

Newton considered the problem for continuous time rather than Galileo's discrete time. He reframed the slope function from the big increments of the slope operator ${\cal D}_t$ to imagined vanishingly small increments of a operator that we shall denote $\partial_t$ and call ***differentiation***. `r mark(2015)`

The kind of question for which Newton wanted to be able to calculate the answer was, "How to find the function $x(t)$ whose second increment, $\partial_{tt} x(t) = 2$?" His approach, which he called the "method of fluxions," became so important that its name became, simply, "Calculus." `r mark(2020)`

Over the next three centuries, calculus evolved from a set of techniques for describing motion into the general-purpose mathematics of change. Applying calculus in the real world involves understanding change relationships between quantities. To give some examples: `r mark(2025)`

- Electrical power is the change with respect to time of electrical energy.
- Birth rate is one component of the change with respect to time of population.
- Interest, as in bank interest or credit card interest, is the change with repect to time of assets. 
- Inflation is the change with respect to time of prices.
- Disease incidence is one component of the change with respect to time of disease prevalence.
- Force is the change with respect to position of energy.

`r insert_calcZ_exercise("XX.XX", "slwdkw", "Exercises/Diff/kid-mean-table.Rmd")`

## Slopes and motion

Chapter \@ref(instantaneous-rate-of-change) introduced the idea of a ***slope function***: a function $g(t)$ whose value at each instant gives the instantaneous rate of change of a partner function $f(t)$. To keep easier track of the relationship between the function and it's slope function, we use the ${\cal D}$ notation:
$${\cal}D_t f(t)$$ is the slope function of $f(t)$ with respect to $t$. 

To illustrate, imagine a graph of the position of a car along a road as in Figure \@ref(fig:stop-and-go2).  Over the course of an hour, the car traveled about 25 miles. In other words, the ***average*** speed is 25 miles/hour: the *slope* of the tan line segment. Given the traffic, sometimes the car was stopped (time C), sometimes crawling (time D) and sometimes much faster than average (time B).   `r mark(2030)`

```{r stop-and-go2, echo=FALSE, fig.cap="The position of an imagined car over an hour of time. (black) The tan line shows what the position would have been if the car had travelled steadily at the average speed for the hour."}
f <- rfun(~ t, seed=105, n=5)
raw <- function(t) 
        f(t) - t - 30*dnorm(t, 0, 3) + 60*dnorm(t,7,1)
speed <- function(t) {
    pmax(4*raw(20*(t-.5)), 0)
}
position <- antiD(speed(t) ~ t)
Pts <- tibble::tibble(
    t = c(0, 0.19, 0.4, 0.54, 0.65, 1),
    y = position(t) + 2,
    label=c("", "A", "B", "C", "D", "")
)
Intervals <- tibble::tribble(
    ~t0, ~ t1, ~color,
    0, 1, "orange3",
    # .54, .65, "orange",
    # .19, .4, "green",
    # .4, .54, "brown",
) %>%
    mutate(y0=position(t0), y1=position(t1))
slice_plot(position(t) ~ t, domain(t = c(0, 1)), size=2) %>%
    gf_labs(y = "f(t): distance traveled (miles)",
            x = "Time since start (hours)") %>%
    gf_text(0 ~ t, data = Pts, label=~label, color="dodgerblue") %>%
    gf_segment(2 + y ~ t + t, data = Pts[-6,], color="dodgerblue") %>%
    gf_segment(y0 + y1 ~ t0 + t1, data = Intervals, color=~color, alpha=0.5, size=3) %>%
    gf_refine(scale_color_identity())
```

Of course, when you're driving you are aware of the car's speed at any instant. You need only look at the speedometer to read off the value (in miles per hour). Speedometers don't show the average speed for the entire trip. The average speed is the slope of the tan line in Figure \@ref(fig:stop-and-go2), 25 miles in one hour, usually stated 25 miles-per-hour. `r mark(2035)`

In terms of Figure \@ref(fig:stop-and-go2), the speedometer reading is the **slope** of $f(t)$ at the given instant. You can see from the Figure that at instant A the speed is very close to the average speed for the entire trip. At instant B the car is going faster; the slope is much steeper. On the other hand, at instant C the car is at a standstill; its position doesn't change at all. `r mark(2040)`

The car's speedometer shows the speed at each moment---or ***instant***---of the trip. As you can see in Figure \@ref{fig:stop-and-go}, the speed varies and is sometimes less than the average speed, sometimes greater, and occasionally equal to the average speed over the trip.  `r mark(2045)`

Although you can easily judge whether the instantaneous speed is faster or slower than the average speed, quantifying the speed requires some work: calculating the slope of the tangent line.

Far easier to have this job done for us. The means to do so is to compute the slope function of $f()$, that is, ${\cal D}_tf()$. Figure \@ref(fig:instant-speed) shows ${\cal D}_tf()$ directly.

You can read off the speed from the graph at any instant simply by reference to the vertical axis.

```{r instant-speed, echo=FALSE, fig.cap="The ***instantaneous*** velocity of the car whose position vs time is shown in Figure \\@ref(fig:stop-and-go2)."}
f <- rfun(~ t, seed=105, n=5)
raw <- function(t) 
        f(t) - t - 30*dnorm(t, 0, 3) + 60*dnorm(t,7,1)
speed <- function(t) {
    pmax(4*raw(20*(t-.5)), 0)
}
Pts <- tibble::tibble(
    t = c(0, 0.19, 0.4, 0.56, 0.65, 1),
    y = speed(t) + 5,
    label=c("", "A", "B", "C", "D", "")
)
slice_plot(speed(t) ~ t, domain(t=c(0,1)), npts=500) %>%
    gf_labs(y = "Instantaneous speed (miles/hour)", 
           x = "Time since start of trip.") %>%
    gf_text(2 ~ t, data = Pts, label=~label, color="dodgerblue") %>%
    gf_segment(5 + y ~ t + t, data = Pts[-1,], color="dodgerblue")
```
The two graphs in Figures \@ref(fig:stop-and-go) and \@ref(fig:instant-speed) show exactly the same car trip. The presentation of the data in the different graphs makes it easy to see some things and hard to see others. For instance, figuring out when the car is at a stand-still is harder in the position-vs-time graph than in the speed-vs-time graph. `r mark(2050)`

Having worked out a theory of slope functions, Newton was ready to express the laws of motion in continuous time. He did this by denoting position as $x(t)$. The familiar concepts of velocity and force could then be defined in terms of slope functions of position and the "quantity of matter," which we call "mass."  `r mark(2055)`

- Velocity is the slope function of position: $v(t) \equiv {\cal D}_t x(t)$.
- Net force is the slope function of velocity times mass: $F(t) \equiv m {\cal D}_t v(t)$

To take mass out of the formulation, we give a name specifically to the slope function of velocity; we call it ***acceleration***. 

- Acceleration is the slope function of velocity: $a(t) \equiv {\cal D}_t v(t)$.

With acceleration as a concept, we can define net force as mass times acceleration. This is better known as ***Newton's Second Law of Motion***.

::: {.why}
We used **net force** as the quantity we related to mass and the slope function of velocity. There are different sources of forces which add up and can cancel out. Famously, Newton formulated the ***law of universal gravitation*** which ascribed the force between masses as proportional to the product of the two masses and inversely proportional to the square of the distance between them. But a mass on a table has no net force on it, since the table pushes back (push = force) on the mass to cancel out the force due to gravity. "Net force" takes such cancellation into account. `r mark(2060)`
:::


## Differentiation


Two central operations in calculus are:

1. Given a function $f(t)$, find the function $\partial_t\,f(t)$ giving the instantaneous rate of change of $f()$. This process of deriving $\partial_t\, (t)$ from $f(t)$ is called ***differentiation***.
2. Given a function $\partial_t\,(t)$, find the $f(t)$ of which $\partial_t\,f(t)$ is the instantaneous rate of change. This process of finding $f()$ given $\partial_t\,f()$ is called ***anti-differentiation***. `r mark(2065)`


Notice that in (1) and (2) above we didn't use the ${\cal D}_t$ notation. It's time to switch away from that. What prompts the change is the nuisance of the constant 0.1 in the definition of the slope function:
$${\cal D}_t f(t) \equiv \frac{f(t+0.1) - f(t)}{0.1}$$

Whereas the slope function ${\cal D}_t f(t)$ gives an approximation to the instantaneous rate of change, $\partial_t f(t)$ refers to the instantaneous rate of change **exactly**. 

We'll come back to the relationship between ${\cal D}_t$ and $\partial_t$ in Chapter \@ref(evanescent-h). It's a subject of particular interest to mathematicians, hence a central part of traditional calculus texts (which are mostly written by mathematicians). For modeling and other applications of calculus, it is something of a side issue. `r mark(2070)`

As an intermediate step on the path between ${\cal D}_t$ and $\partial_t$, let's redefine the slope function to eliminate the 0.1 and replace it with a parameter $h$: $${\cal D}_x f(x) \equiv \frac{f(x+h) - f(x)}{h}$$
This way of writing the slope function will enable us to consider how the slope function changes as $h$ gets smaller and smaller.


## Notations for differentiation

There are several traditional notations for differentiation of a function named $f()$. For instance:

- Leibnitz: $\frac{df}{dx}$
- Partial: $\frac{\partial f}{\partial x}$
- Euler: $D_x f$
- One-line: $\partial_x f$ (a hybrid of partial and Euler notation.)
- Newton (or "dot"): $\dot{f}$
- Lagrange (or "prime"): $f'$

In this book, we will mainly use the one-line notation, $\partial_x f$, but it means exactly the same as the Leibnitz and Partial notations, which are much more widely used in textbooks. 

If you've studied calculus before, you have likely seen the $f'$ notation. This is admirably concise but is only viable in a narrow circumstance: functions that take a single input. What $f'$ leaves out is a means to specify a crucial aspect of differentiation, the **with-respect-to variable**. The general situation for differentiation involves functions of one or more variables, for example, $g(x, y, z)$. For such functions, you need to specify which is the with-respect-to variable. For instance, we can differentiate $g()$ three different ways, each way incrementing one or another of the three inputs: `r mark(2075)`

$$\partial_z g(x, y, z) \equiv \frac{g(x, y, z+h) - g(x, y, z)}{h}\\ 
\ \\
\partial_x g(x, y, z) \equiv \frac{g(x+h, y, z) - g(x, y, z)}{h}\\ 
\ \\
\partial_y g(x, y, z) \equiv \frac{g(x, y+h, z) - g(x, y, z)}{h}$$

At this point in your studies, you haven't seen why you might choose to differentiate a function with respect to one variable or another. That will come in time. But we want to set you up with notation that won't narrow your options. `r mark(2080)`

Both the Leibnitz and Partial notations are explicit in identifying the function and the with-respect-to-variable. For example, using the Partial differentiation notation, the three ways of differentiating our example function $g(x, y, z)$ are labeled : `r mark(2085)`

$$\frac{\partial f}{\partial x},\ \ \ \frac{\partial f}{\partial y},\ \ \text{and}\ \ \frac{\partial f}{\partial z}$$

Our R/mosaic computer differentiation is longer but explicit:
```r
dx_g <- D(g(x, y, z) ~ x)
dy_g <- D(g(x, y, z) ~ y)
dz_g <- D(g(x, y, z) ~ z)
```
The names being used here are arbitrary; you can use any names you like. What's nice about `dx_g` and the others is that it mimics the math notation $\partial_x g()$.

Notice that the R/mosaic operator for differentiation is named `D()` and that it is a function. It follows the same pattern as `makeFun()` or `slice_plot()` or `contour_plot()`: the first argument is a tilde expression, for instance `g(x, y, z) ~ x`, which identifies the mathematical function to work with (`g()`) and the name of the with-respect-to input to that function. The R/mosaic notation makes it clear that differentiation is an ***operation*** on a function. The `D()` operator takes a function as input and produces as output **another function**. We've seen similar behavior with, say, `slice_plot()`, which takes a function as input and produces graphics as output. Both `D()` and `slice_plot()` need to know the identity of the with-respect-to variable as well as the function to work with. What's why both pieces of input are packaged into a tilde expression. `r mark(2090)`

::: {.why}
We're calling `D()` an ***operator*** rather than a ***function***. The reason is purely for communication with other people. There are so many "functions" in a calculus course that we thought it would be helpful to distinguish between the kinds of functions that take quantities as input and produce a quantity as output, and the functions that take a *function* as input and produce a *function* as output. Both sorts are called "functions" in R terminology. But a sentence like, "Differentiation is a function that takes a function as input and produces a function as output," true though it be, is dizzying. `r mark(2095)`
:::

::: {.intheworld}
It is a fact of mathematical and scientific life that a variety of notations are used for differentiation. To some extent, this reflects historical precedence and, to be honest, nationalistic European politics of the 18th century. To make sense of mathematical writing in the many areas in which calculus is used, you have to recognize all of them for what they are. Your skill will be enhanced if you also memorize the names of the different styles. It's not all that different from the pattern in English of having multiple words for the same sort of object, for instance: car, automobile, junker, ride, wheels, crate, jalopy, limo, motor car, horseless carriage.  `r mark(2100)`

In the days when carriages where pulled by horses, the phrase "horseless carriage" made a useful distinction. Today, when horses are rarely seen on the road, it make sense to trim down the notation to its essentials: ~~horseless~~ **car**~~iage~~. Think of $\partial_x$ as this sort of minification of older notations.^[Yes, ["minification" is a word!](https://en.wikipedia.org/wiki/Minification_(programming))]   
:::

`r insert_calcZ_exercise("XX.XX", "eodlt", "Exercises/Diff/pine-lead-car.Rmd")`

`r insert_calcZ_exercise("XX.XX", "iclcws", "Exercises/Diff/robin-row-boat.Rmd")`


`r insert_calcZ_exercise("XX.XX", "helxs", "Exercises/Diff/deer-pitch-saw.Rmd")`



## Visualizing the slope function {#slope-fun-visualization}

The function produced by the differencing operation
$${\cal D}_x f(x) \equiv \frac{f(x+h) - f(x)}{h}$$ is in every way an ordinary function that takes an input and produces an output.

Ordinarily, we visualize functions of one variable by drawing a ***graph***. This technique is every bit as applicable to functions produced by $\diff{x}$ as to any other function.

The input to a slope function $\diff{x} f(x)$ is exactly the same as the input to the mother function $f(x)$. So a graph of the slope function will have the same **horizontal axis** as a graph of the mother function. However, the output of $\diff{x} f(x)$ is a different kind of thing than the output of $f(x)$.  `r mark(2115)`

Suppose, for instance, that we have a mother function $T(x)$ giving atmospheric temperature at a location on Earth as a function of altitude $x$. The output of $T(x)$ has, as you would expect, the dimension of temperature with units of, say, degrees C. But the output of $\diff{x} T(x)$ has a different dimension: temperature divided by altitude with units of, say, degrees C per km. `r mark(2120)`

The different dimensions of the output of a function and the output of its slope fun means that the **vertical axis** for graphing $\diff{x} f(x)$ must be different from the vertical axis used for graphing $f(x)$. Thus, in general, $\diff{x} f(x)$ and $f(x)$ cannot be graphed in the same frame. `r mark(2125)`

This requirement to use different graphics frames for $f(x)$ and $\diff{x}f(x)$ makes it somewhat difficult to visualize the relationship between $f(x)$ and $\diff{x}f(x)$. 

Let's explore a non-standard way to visualize $\diff{x}f(x)$ that can be shown in the same graphics frame as the graph of $f(x)$. Perhaps this non-standard visualization will give you a better way to understand slope functions. If so, good. The ultimate benefit of a way to show $\diff{x} f(x)$ and $f(x)$ in the same frame will come when we introduce the operation of ***anti-differentiation***. `r mark(2130)`

Recall that the ***basic model of change*** in Calculus is the straight-line function $\line(x) \equiv a x + b$. The slope $a$ of $\line(x)$ tells how the output changes for a unit change in input. In differentiation, we  `r mark(2135)`

i. approximate the mother function $f(x)$ as a series of local line segments.
ii. extract the **slope** of each line segment as the value of the slope function at each input $x$. 

Figure \@ref(fig:segment-approx) shows the segment by segment approximation around each of several input values (marked in green).  The ***slope function visualization*** is constructed by throwing away the vertical offset of each of the line segments and plotting them horizontally adjacent to one another. `r mark(2140)`

```{r segment-approx, echo=FALSE, fig.cap="A function $f(x)$ shown along with the tangent line segment touching $f()$ at each of the green points. For the slope function visualization, the tangent line segments are moved down to the horizontal axis."}

Segs <- segments(sin(x) ~ x, domain(x=c(-.1,pi)), nsegs=10)
gf_segment(yf + yfend ~ x + xend, data = Segs, 
           color=~slope,size=2, alpha=.9) %>%
    gf_refine(scale_color_continuous(type="gradient")) %>%
    slice_plot(sin(x) ~ x, color="orange3", domain(x=c(0, pi)),
               alpha = 0.5, size=1, inherit=FALSE) %>%
    gf_point(offset ~ start, size=1, color="green") %>%
    gf_segment(y + yend ~ x + xend, data = Segs, 
           color=~slope,size=1.3, lineend="round") %>%
    gf_point(0 ~ start, size=1, color="green")
    
```

Figure \@ref(fig:slope-visualization-examples) shows several examples of the slope function visualization.

```{r slope-visualization-examples, echo=FALSE, fig.cap="Slope-function visualizations of several pattern-book functions.", fig.height=3, fig.width=7, fig.show="hold", out.width="50%"}
Segs <- segments(exp(x) ~ x, domain(x=c(-pi,pi)), nsegs=30)
slice_plot(exp(x) ~ x, domain(x=c(-pi, pi))) %>%
    gf_labs(title="exp(x)")
gf_segment(y + yend ~ x + xend, data = Segs, 
           color=~slope,size=1.3, lineend="round") %>%
  gf_point(0 ~ start, size=1, color="green") %>%
    gf_labs(title="exp(x) slope-function visualization")
Segs <- segments(log(x) ~ x, domain(x=c(.2,pi)), nsegs=30)
slice_plot(log(x) ~ x, domain(x=c(.2, pi))) %>%
    gf_labs(title="og(x)")
gf_segment(y + yend ~ x + xend, data = Segs, 
           color=~slope,size=1.3, lineend="round") %>%
  gf_point(0 ~ start, size=1, color="green") %>%
    gf_labs(title="log(x) slope-function visualization")
Segs <- segments(x^2 ~ x, domain(x=c(-pi,pi)), nsegs=30)
slice_plot(x^2 ~ x, domain(x=c(-pi, pi))) %>%
    gf_labs(title=expression(x^2))
gf_segment(y + yend ~ x + xend, data = Segs, 
           color=~slope,size=1.3, lineend="round") %>%
  gf_point(0 ~ start, size=1, color="green") %>%
    gf_labs(title=expression(paste("x^2 slope-function visualization")))
Segs <- segments(2*x -4 ~ x, domain(x=c(-pi,pi)), nsegs=30)
slice_plot(2*x - 4 ~ x, domain(x=c(-pi, pi))) %>%
    gf_labs(title="2x - 4")
gf_segment(y + yend ~ x + xend, data = Segs, 
           color=~slope,size=1.3, lineend="round") %>%
  gf_point(0 ~ start, size=1, color="green") %>%
    gf_labs(title="line(x) = 2 x - 4 slope-function visualization") %>%
    gf_lims(y=c(-1,1))
```


::: {.intheworld}
Calculus and the *Wealth of Nations*

1776 can be reckoned as the birth year of two revolutions: the American *Declaration of Independence* and Adam Smith's publication of the *Wealth of Nations*.

Smith, considered the intellectual father of free-market economics, explored the origins of the supply and demand of commodities, labor, and money. A key figure of the Scottish Enlightenment, Smith would have been well aware of Newton, his work, and the many advances enabled by the creation of calculus. And *Wealth of Nations* lays out dozens of relationships between different quantities --- wages, labor, stock, interest, prices, profits, and coinage among others. Yet *Wealth of Nations* does not use the concepts or language of calculus. Lacking this, Smith's arguments, sophisticated though they be, are based on the Aristotelian notions of tendency toward a "natural" resting place.^[For more discussion, see Tony Aspromourgos (2007) "Adam Smith's treatment of market prices and their relationship to <<supply>> and <<demand>>" *History of Economic Ideas* , 2007, Vol. 15, No. 3 (2007), pp. 27-57 [Link](https://www.jstor.org/stable/23723287)]

Consider this characteristic statement in *Wealth of Nations*:

>  *The market price of every particular commodity is regulated by the proportion between the quantity which is actually brought to market, and the demand of those who are willing to pay the natural price of the commodity... Such people may be called the effectual demanders, and their demand the effectual demand.*

Smith's "natural price" and "effectual demand" are fixed quantities. But Smith lived near the end of a centuries-long period of ***static*** economies. Transportation, agriculture, manufacture, population were all much as they had been for the past 500 years or longer.^[Smith commented on the difference between "demand" and "effectual demand:" "A very poor man may be said, in some sense, to have a demand for a coach and six [a carriage pulled by six horses]; he might like to have it; but his demand is not an effectual demand, as the commodity can never be brought to market in order to satisfy it." In today's economy, of course, transportation superior to a coach and six is readily demanded and supplied.] Calculus was invented to deal with ***dynamics***: how things change.

It took the industrial revolution and nearly a century of intellectual development before economics was seen dynamically. In this dynamical view, supply and demand are not seen as mere quantities, but as ***functions*** of which price is the major input. The tradition in economics is to use the word "curve" instead of "function," giving us the phrases "supply curve" and "demand curve." Many students starting out in economics can easily see supply and demand as quantities. Making the transition from quantity to function, that is, between a single amount and a relationship between amounts is a core challenge to those learning economics. 

Once this transition is accomplished, economics students are taught essential concepts of calculus---particularly first and second derivatives, the subjects of this Block---although the names used are peculiar to economics, for instance, "elasticity", "marginal returns" and "diminishing marginal returns."

```{r cournot-demand, echo=FALSE, fig.cap="Demand as a *function* of price, as first published by Antoine-Augustin Cournot in 1836."}
knitr::include_graphics("www/cournot-demand-curve.png")
```

:::

## Dimension of derivatives

Recall that the differencing operator takes as input a function and returns as output another function that takes the same kind of input, but produces a different kind of output. 

For instance, suppose the function `pressure()` takes an altitude as input (in km) and returns as output a pressure (in kPa, "kiloPascal"^[Air pressure at sea level is about 100 kiloPascal.]).

The derivative function, let's call it `d_pressure()`, also takes an input in km, but produces an output in kPA per km: a rate.

You can see this by examining the differencing operator itself:

$${\cal D}_x f(x) \equiv \frac{f(x+h) - f(x)}{h}$$

Remember the notation for dimensions. A quantity $x$ has dimensions denoted as $[x]$. (This is nothing more than saying, "Pronounce $[x]$ as 'the dimensions of $x$'.")
The input to $f()$ has dimension $[x]$. The output from $f()$ has dimension $[f(x)]$.

What is the dimension of $h$? (We could write this question more simply, "What is $[h]$?) Since the operator adds $x + h$, it must be that $[h] = [x]$. Otherwise, addition wouldn't be a viable operation to combine the two quantities. `r mark(2105)`

What is the dimension of $f(x + h) - f(x)$? (Again, we could ask this more simply, "What is $[f(x+h) - f(x)]$?") Since we're subtracting two quantities, the two quantities must have the same dimension and the result is also that dimension. So $[f(x+h) - f(x)] = [f(x)]$. `r mark(2110)`

The output of the function $df(x)$ produced by $\mbox{Diff}(f)$ therefore has dimension $[f(x)] / [x]$.

`r insert_calcZ_exercise("17.1", "eyded", "Exercises/Diff/kitten-put-kayak.Rmd")`

`r insert_calcZ_exercise("17.2", "elclvd", "Exercises/Diff/rat-take-fork.Rmd")`

`r insert_calcZ_exercise("17.3", "nsmx8w3", "Exercises/Diff/SIR-dimensions.Rmd")`



