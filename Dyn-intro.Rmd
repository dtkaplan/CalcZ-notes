# (PART) Block 5: Dynamical systems {.unnumbered}




# States, Dynamics, Trajectory
    
::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-1a", "Understand the difference between state, dynamics, trajectory")
state_objective("Dyn-1b", "Understand the difference between continuous and discrete time")
state_objective("Dyn-1c", "Recognize the form of a differential or finite-difference equation")
```
:::


A **trajectory** is a sequence of successive states. For example, here is a trajectory of six successive states: $$\{ {\mathbf S_0}, {\mathbf S_1},  {\mathbf S_2}, {\mathbf S_3}, {\mathbf S_4}, {\mathbf S_5}\}$$

It's conventional to call ${\mathbf S}_0$ the "initial state" or, more often, the **initial condition**.

Usually, we calculate a trajectory one step at a time:
$$\left\{ {\mathbf S_0},\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\ {\mathbf S_1}=g({\mathbf S_0}),\\ {\mathbf S_2} = g({\mathbf S_1}),\\ {\mathbf S_3} = g({\mathbf S_2}),\\ {\mathbf S_4} = g({\mathbf S_3}),\\ \ \ \ \ \ {\mathbf S_5} = g({\mathbf S_4}))\ \ \ \right\}$$
NOTE: We've written the above on several lines just to make it more readable. It could just as well have been written on one line.

-----


One common mathematical task in using finite-difference equations is **iteration**. In iterating a finite-difference equation, you are running a machine to construct the "future state" from the "present state." In iteration, you repeatedly do this. By plugging in the "future state" into the machine, you generate a state further in the future. 

It can be helpful to think of "future" and "present" state in terms of a series of days. The system's state **today** is the present state. The system's state **tomorrow** is the next future state.  The system's state on the **day after tomorrow** is the future state after tomorrows's state. 

A finite-difference equation is a statement about how tomorrow's state is a function of today's state. We could write this in the form
$$\mbox{state}_{\small\mbox{tomorrow}} = g( \mbox{state}_{\small\mbox{ today}})$$
This notation is wordy and hard to read. So we simplify it. 

- Today is day $n$
- Tomorrow is day $n+1$
- The state on day $n$ is written $\mathbf S_n$. 
- The state on day $n+1$ is written $\mathbf S_{n+1}$
- The dynamics are represented by a function, say, $g({\mathbf S})$.
- To remind us of the role played by $g()$, we write $${\mathbf S}_{n+1} = g({\mathbf S}_n)$$

(Exercises: DtLAhm, mJRDLy)

The ingredients for calculating a trajectory are:

a. A function $g(S)$
b. An initial condition ${\mathbf S}_0$.
c. A choice of how many steps to take.

<!--

There are two basic styles to computing trajectories on the computer. The first is a **calculator style* series of commands. For instance, the code in the sandbox computes a trajectory of length 6 from the given $g()$ and initial condition.

```{r fdec1, exercise=TRUE, exercise.cap="Calculator style", exercise.nline=10, eval=FALSE}
g <- makeFun(5 + x/2 ~ x)
x0 <- 7
x1 <- g(x0)
x2 <- g(x1)
x3 <- g(x2)
x4 <- g(x3)
x5 <- g(x4)
x6 <- g(x5)

```

Computer programmers learn that his is a bad style for several reasons.

i. The information about all these closely related things `x0`, `x1`, `x2` and so on is spread out over a bunch of different names. Most programming language provide no easy way to handle these as a group. An example of "handling as a group" is to plot out the trajectory versus $n$.  
ii. The statements are highly repetitive. Some people like this, because it gives them a sense of order. But programmers learn (through hard experience) that it is difficult for a human reader to confirm that every line is repeating exactly the same pattern. For instance, `x5 <- g(x3)` is a perfectly valid computer statement, but inconsistent with the dynamics that are supposed to be calculated.

A more effective style of programming is illustrated in the next sandbox which uses an "iteration operator":

-->

To facilitate calculating a trajectory, use the `Iterate()` operator. 

```{r fdec3-2, exercise=TRUE, exercise.cap="An iteration operator", exercise.nlines=8, eval=FALSE}
g <- makeFun(5 + x/2 ~ x)
Traj <- Iterate(g, x0 = 7, n = 6)
Traj
```

```{r fdec3-2-solution, echo=FALSE}
g <- makeFun(-0.8*x + 2 ~ x)
Traj <- Iterate(g, x0=10, 50) 
gf_point(x ~ n, data = Traj) %>%
  gf_line(alpha=0.2)
```

The `Iterate()` operator takes as a first argument the dynamics in the form of the name of a function or a tilde-expression of the sort accepted by `makeFun()`. The next argument is the initial condition. (This argument is named `x0` regardless of the name used in the dynamics).  The third argument is the number of steps to iterate.

`Iterate()` returns a data frame with two (or more) columns. The first, named `n`, is the step number. The second is given the same name as the variable used in the dynamical function. Because the output of `Iterate()` is in the form of a data frame, you can employ any function set up to accept a data frame. `gf_point()` is particularly useful for plotting the trajectory as a function of $n$.  

`Iterate()` is for finite-difference equations in discrete time, so $n$ will always be an integer and the trajectory is appropriately plotted as a series of isolated points. Even so, it can be helpful to the human viewer to connect the points faintly with straight lines. This makes it a bit easier to see the sequence. For instance:

```{r eval=FALSE}
# Make the Traj then ...
gf_point(x ~ n, data = Traj) %>%
  gf_line(alpha=0.2)
```

(Exercises: DzIhgb)

You can use the `Iterate()` function to compute the trajectory of any finite-difference system from any initial condition. Each trajectory is a sequence of numbers $\{x_n\}$ for $n=0, 1, 2, \ldots$.

Sometimes it's possible to find an algebraic formula for a trajectory. Such a formula is unfortunately called a "solution," an over-used word in mathematics. In the days before computers were readily available, students of dynamics tended to study only those systems for which an algebraic solution could be found. A more modern style is to put the modeling setting first and foremost and not hesitate to use numerical methods like `Iterate()` instead of relying on algebra.

Because the word "solution" appears so often in textbooks it's helpful to know what they look like and how they are different from dynamics.

i. Arithmetic sequences    
    - Dynamics: $x_{n+1} = x_n + b$
    - Solution: $x_n = x_0 + n b$
ii. Geometric sequences    
    - Dynamics: $x_{n+1} = \alpha\, x_n$
    - Solution: $x_n = x_0\, \alpha^n$
iii. Combined sequences   
    - Dynamics: $x_{n+1} = \alpha\, x_n + b$   <br> 
    - Solution: $x_n = \left(x_0 - b/\alpha\right) \alpha^n + b/\alpha$
    
The dynamics of a discrete-time system write tomorrow's state as a function of today's state. In contrast, the *solution* gives a formula for $x_n$ directly in terms of $n$, the initial condition $x_0$, and any parameters of the system (such as $\alpha$ and $b$ in the above examples).

As you can see, even for dynamics as simple as for the combined sequences, the solution is fairly complicated. Because solutions can be so complicated, they can be extremely hard to find and hard to use. The only ones we will use extensively will be composed of relatively simple terms like $(-1)^n$ and $\alpha^n$. The analogs of these for continuous time systems are $\sin(\omega t)$ and $e^{-kt}$. 

(Exercises: 9mSE8t)

## 142Z Day 15 exercises

`r insert_calcZ_exercise("XX.XX", "DtLAhm", "Exercises/Dynamics/kitten-mean-tv.Rmd")`

`r insert_calcZ_exercise("XX.XX", "mJRDLy", "Exercises/Dynamics/rat-lend-piano.Rmd")`

`r insert_calcZ_exercise("XX.XX", "DzIhgb", "Exercises/Dynamics/ape-leave-shirt.Rmd")`

`r insert_calcZ_exercise("XX.XX", "9mSE8t", "Exercises/Dynamics/lobster-become-sofa.Rmd")`

`r insert_calcZ_exercise("XX.XX", "FUIt1Q", "Exercises/Dynamics/spider-find-book.Rmd")`


::: {.takenote}
We will be using a handful of Greek letters in our mathematical notation. You should learn these by heart:

* $\alpha$  : alpha (lowercase)
* $\beta$  : beta (lowercase)
* $\lambda$  : lambda (lowercase)
* $\Lambda$  : lambda (uppercase)
* $\omega$  : omega (lowercase)
* $\xi$  : xi (lowercase), pronounced "ex-eee"
* $\eta$  : eta (lowercase)

The last two of these, $\xi$ and $\eta$ are the Greek equivalents to the familiar $x$ and $y$. We'll see $\xi$ and $\eta$ as arguments to functions that we will quickly be re-scaling and renaming $x$ and $y$.
:::


# Difference equations in 1 dimension

    Objectives:")
::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-2a", "Understand how discrete time operates and what a step is ")
state_objective("Dyn-2b", "Define a fixed point in discrete time and determine whether the fixed point is stable or unstable")
state_objective("Dyn-2c", "Understand the relationship between oscillations and stability as we step through discrete time")
```
:::

An important strategy in creating and understanding models of dynamics involves **fixed points**.  A fixed point is a value of the state which the dynamics leave untouched. For finite-difference equation dynamics, $${\mathbf X}_{n+1} = g({\mathbf X}_n)$$

At a fixed point, "tomorrow's" value is the same as "today": ${\mathbf X}_{n+1} = {\mathbf X}_n$; the state doesn't change with $n$. 

A fixed point ${\mathbf X}^\star$ satisfies 
$${\mathbf X}^\star = g({\mathbf X}^\star)\ \ \ \mbox{or, said another way,}\ \ \ g({\mathbf X}^\star) - {\mathbf x^\star} = 0$$
"Fixed point" is a mathematical term. In the sciences, you will hear the term "equilibrium state," "steady state," "resting point," or "balance point." For example, chemistry has a concept of [chemical equilibrium](https://en.wikipedia.org/wiki/Chemical_equilibrium), a state where the concentration of reactants and products doesn't change. Finding such equilibria is an important task in many areas of science and engineering.

Some dynamical systems don't display any fixed points, e.g. the orbit of the Earth around the Sun. Others have one or more. We're going to treat them mathematically by analysis of the function $g()$ that governs the dynamics.

There are several ways to find fixed points. 

1. If you have a simple algebraic form for $g()$ you can solve $g(x) = x$ for $x$. For instance, suppose $g(x) \equiv 4 x (1-x)$. Then the fixed points satisfy $$x^\star = 4x^\star (1-x^\star)$$  This has two solutions: one at $x^\star = 0$ and the other at $x^\star = 3/4$.  (Exercise: dBCKD6)

2. Numerical solving. If solving $g(x)=x$ is not so easy, then we can instead create a new function $h(x)\equiv g(x)-x$ and then solve for the zeros of $h()$.  The point of setting up the helper function $h()$ is that computer algorithms for finding zeros generally take a *function* as their input rather than an *equation*.  (Exercise: RLdGHh )

3. Graphically. Plot out the function $g(x) - x$ versus $x$. Find values of $x$ where the graph crosses zero. Each of these values is a fixed point $x^\star$.

For instance:
```{r eval=FALSE}
dom <- domain(x = c(0,10))
g <- makeFun(x + sin(x) ~ x) 
slice_plot(g(x) - x ~ x, dom) 
```

4. By iteration. Sometimes you can identify a fixed point by iterating the dynamics starting from different initial conditions. The following sandbox iterates a system for 100 steps. The `tail(5)` function returns just the last 5 rows of the data table, making it easier to see where the state ended up after many iterations.

```{r eval=FALSE}
g <- makeFun(x + sin(x) ~ x)
Iterate(g, x0=.872, 100) %>% tail(5)
```
You can look for different fixed points by trying different values for $x0$. 

(Exercise: Iw4IJW)

------

A tree provides a simple example of equilibrium. A living tree grows slowly, with essentially no change from day to day. The tree is usually in equilibrium with its surroundings. But there are disruptions that can place the tree out of equilibrium. The wind is a familiar disruption, changing the dynamics so that the tree no longer stands straight and still; it sways in the wind. A severe storm or a chain saw creates an opportunity for bigger disruption, removing the fixed point of upright posture and replacing it with an entirely different sort of fixed point. The steady, slow process of rot can weaken the equilibrium to the point where it no longer exists or is too weak to withstand the wind. The tree falls.

Mathematics provides several concepts for thinking about equilibrium and the loss of equilibrium. The idea of a **fixed point** is at the center of things. The idea of disruption also has a mathematical equivalent called "forcing." The slow change (as in the rot of a tree) leading to a dramatic, sometimes sudden, collapse is represented by a "bifurcation." We'll explore forcing and bifurcation later, when we've developed better tools and ways of thinking to understand dynamics.

Here we will examine the important topic of "stability." The word has a variety of related meanings in everyday life: a patient is stable when his or her condition is not worsening (or getting better), a chair is stable when it won't fall over, a stable personal relationship is much preferred to an unstable one, a person who is stable does not get upset or disturbed by a trivial incident.

In mathematics, "stability" is a property of dynamics near a fixed point. A fixed point is stable when an initial trajectory close enough to the fixed point leads to a trajectory that continues to get closer to the fixed point. A fixed point is unstable when initial conditions close to the fixed point lead to trajectories that tend away from the fixed point. 

In everyday life, we think about stability as a matter of how hard you can push something before it falls over. A coin standing on edge is not very stable in this sense, any palpable disturbance will cause it to fall over. But mathematically, stability is just about the response to infinitesimal disturbances. The coin standing on edge is mathematically stable. Large disturbances may lead to the state of a system leaving even a stable fixed point. Stability of mathematical fixed points is about *local* dynamics. The response to large disturbances is non-local or *global* dynamics, a much harder topic.

Use a `r sandbox_link()` to explore stability via iteration.

```{r eval=FALSE}
g <- makeFun(5*sin(x)^2 ~ x)
findZeros(g(x) - x ~ x)
Iterate(g, x0 = 0.0001, n=10)
```

[Exercise: YsZp7T]

[Advanced exercise: AvXzzY, eMT6Zn]

-----

Previously, we examined the stability of fixed points by using iteration: start at an initial condition arbitrarily close (but not exactly on!) a fixed point and see if the trajectory tends toward or away from the fixed point.

Now we'll look at stability another way, by considering the shape of of the dynamical function near a fixed point. At this point in CalcZ, you're aware that "near" suggests local, and that we routinely model (continuous) functions in terms of the value at a point, the value of the derivative at the point, and the value of the 2nd derivative at the point.

The stability of a fixed point is determined in all but very special situations by the slope of the function at the fixed point. Here's the rule: 

> In the dynamical system $x_{n+1} = g(x_n)$ with a fixed point at $x^\star$, the stability of that fixed point depends only on the magnitude of $\left| \partial_x g(x^\star) \right|$. The rule is: 

> If $\left| \partial_x g(x^\star) \right| > 1$, the fixed point at $x^\star$ is **unstable**.

> If $\left| \partial_x g(x^\star) \right| < 1$, the fixed point at $x^\star$ is **stable**.

Notice that it doesn't matter what is the **sign** of $\partial_x g(x^\star)$; the fixed point will be stable or not depending just on the magnitude of the derivative.

```{r eval=FALSE}
g <- makeFun(sin(x)^2 + 1 ~ x)
fixed_points <- findZeros(g(x) - x ~ x)
dg <- D(g(x) ~ x)

## Now, apply dg() to the fixed point(s)
dg(fixed_points)
```

[Exercise: 61zaad, F0nHmq, VesZTL, z7CO1o]


## Day 16 Exercises

`r insert_calcZ_exercise("XX.XX", "dBCKD6", "Exercises/Dynamics/snake-drive-socks.Rmd")`

`r insert_calcZ_exercise("XX.XX", "RLdGHh", "Exercises/Dynamics/spruce-type-chair.Rmd")`

`r insert_calcZ_exercise("XX.XX", "Iw4IJW", "Exercises/Dynamics/titmouse-drive-pantry.Rmd")`

`r insert_calcZ_exercise("XX.XX", "YsZp7T", "Exercises/Dynamics/calf-fly-boat.Rmd")`

`r insert_calcZ_exercise("XX.XX", "61zaad", "Exercises/Dynamics/calf-dive-pot.Rmd")`

`r insert_calcZ_exercise("XX.XX", "F0nHmq", "Exercises/Dynamics/turtle-become-magnet.Rmd")`

`r insert_calcZ_exercise("XX.XX", "VesZTL", "Exercises/Dynamics/titmouse-see-jacket.Rmd")`

`r insert_calcZ_exercise("XX.XX", "z7CO1o", "Exercises/Dynamics/finch-make-door.Rmd")`

`r insert_calcZ_exercise("XX.XX", "AvXzzY", "Exercises/Dynamics/crow-know-scarf.Rmd")`

`r insert_calcZ_exercise("XX.XX", "eMT6Zn", "Exercises/Dynamics/spider-dive-sheet.Rmd")`



# Difference equations in 2 dimensions

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-3a", "Learn how to construct future states of a dynamical system in two dimensions given the dynamical rule and the two-dimensional initial condition.")
state_objective("Dyn-3b", "Appreciate that global dynamics can be complicated, potentially with many fixed points, learn how to identify the locations of the fixed points.")
state_objective("Dyn-3c", "Understand how local dynamics near a fixed point are comparatively simple and can be meaningfully approximated by a matrix.")
state_objective("Dyn-3d", "Review the mechanics of matrix arithmetic and iterate a dynamical system written in terms of a matrix.")
```
:::

```{r echo=FALSE}
source("Exercises/Dynamics/draw_flow.R", local=TRUE)
```

We will be using finite-difference equations mainly for modeling physical processes. It turns out that the way forward is **not** to make the function $g(x)$ more complicated in $x_{n+1} = g(x_n)$ but instead to add more state variables. In this course, we'll deal with states with two quantities, $(x, y)$, which can be called a *two-dimensional* state. The systems we will study will involve two dynamical functions, each of which takes both $x$ and $y$ as arguments. That is:
$$x_{n+1} = f(x_n, y_n)\\
y_{n+1} = g(x_n, y_n)$$

For instance, here is one such system:
```{r echo=FALSE, out.width="100%", message=FALSE}
draw_flow()
```
The functions $f(x,y)$ and $g(x,y)$ are represented by short line segments with a tiny dot at one end. Each line segment connects $(x_n, y_n)$ to $(x_{n+1}, y_{n+1})$, with the dot at the $n+1$ end. 

Consider the line segment that starts at $(0,0)$. The end of the line segment is at about $(-0.101, -0.163)$. (You can't see such precision from the graph, but the author can!) This is just to say that for the particular $f()$ and $g()$ being displayed, $$f(0, 0) = -0.101\ \ \ \mbox{and}\ \ \ g(0,0) = -0.163$$ The result of the dynamics is to take a state of $(0,0)$ a bit to the "southwest," to $(-0.101, -0.163)$. From there you can take the next step, then the one after that, and so on to approximate the trajectory. It's very much like the state was being blown around in the wind, with the line segments indicating the direction and speed of the wind at any point.

```{r 2d1-1, echo=FALSE, results="markup"}
askMC(
  "Consider the line segments near $(2.5, 2.5)$. Which of these best describes the functions at that point?",
  "$f(2.5, 2.5) \\approx 0$ and $g(2.5.,2.5) < 0$",
  "+$f(2.5, 2.5) < 0$ and $g(2.5.,2.5) \\approx 0$+",
  "$f(2.5, 2.5) > 0$ and $g(2.5.,2.5) < 0$",
  "$f(2.5, 2.5) \\approx 0$ and $g(2.5.,2.5) > 0$"
)
```

The blue and red contour lines are added to the picture to help the viewer spot fixed points. The blue contour line is the zero contour of $f(x,y) - x$. Similarly, the red contour line is the zero contour of $g(x,y) - y$.

The left panel below shows the dynamics of $x$: that is $x_{n+1} = f(x_n,y_n)$. The right panel shows the $y$ dynamics: $y_{n+1} = g(x_n,y_n)$.

```{r echo=FALSE, out.width="50%", fig.show="hold", message=FALSE}
draw_flow(dy=0, center = c(-2,3), width=3, 
          ngrid=11, dx=0.2, arrow=2) %>%
  gf_labs(title = expression(x[n+1] == f(x[n],y[n])))  
draw_flow(dx=0, center = c(-2,3), width=3, 
          ngrid=11, dy=0.2, arrow=3) %>%
  gf_labs(title = expression(y[n+1] == g(x[n],y[n]))) %>%
  gf_refine(coord_fixed(xlim=c(-5, 1), ylim=c(-0.5, 5.5), clip="on"))
```

Note that in the x-dynamics plot, we're only seeing the change in $x$. That's why the line segments are all horizontal: they connect $x_n$ to $x_{n+1}$. The blue contour shows the points where $x_{n+1} = x_n$: The line segment is just a dot. For this particular $f(x,y)$ the segments starting at places to the right of the contour point to the left; the segments starting to the left of the contour point to the right. At the contour, the segments point neither left nor right: they are fixed points with respect to $x$. 

The right panel is similar, but shows the dynamics of $y$. Since the plot shows only the change in $y$, the segments are all oriented in the $y$ direction. For this particular $g(x,y)$, segments above the contour point upward, segments below the contour point downward, and segments on the contour show no change in $y$.

The original graph shows both the $x$ and $y$ dynamics simultaneously. Where the blue and red contours cross, there is a fixed point in both $x$ and $y$. You can see 3 such fixed points (with a fourth suggested near the top of the graph). 

[Exercises: KzgT1c, 3A3pMv]

-----


Consider a tuning fork as an example of a dynamical system. Ordinarily it's in equilibrium: silent. But after you tap it, it rings, the ringing dying out over time. The design and use of a turning fork is all about the transient vibrations as the fork returns to equilibrium, its fixed point. 

We are going to focus on a small but important part of dynamics: the behavior **near** a fixed point. Up until now, we've considered only stability or instability. But now we want to know a bit more, about the behavior of the transient approaching **near** a stable fixed point or the escape from **near** an unstable one.

We're going to use an approach that's familiar in calculus: zoom in on the region very close to fixed points.

"Very close" can mean different things to different people. In calculus, *very close* is often taken to mean, "so close that the system is well approximated as a linear system." That is, instead of looking at general, nonlinear functions of the dynamics, we're going to look only at dynamics involving linear functions. The system we are going to study will be this one:
$$\xi_{n+1} = \mu + \alpha\, \xi_n + \beta\, \eta_n\\
\eta_{n+1} = \nu + \gamma\, \xi_n + \delta\, \eta_n$$

Where $\alpha, \beta, \gamma, \delta, \nu, \mu$ are all constant scalars, and $\xi$ ("ex-eee", Greek for x) and $\eta$ ("ay-tah", Greek for $y$). 

There is a lot of Greek in the above equation, but don't let it worry you. That's because we're going to simplify things even more.

Since we're interested in behavior **near** a fixed point $(\xi^\star, \eta^\star)$, we'll define new state variables that are centered on the fixed point:
$$x = \xi - \xi^\star\\
y = \eta - \eta^\star$$
In terms of $x$ and $y$, the fixed point is at $(0,0)$.

The dynamics **near** this stable fixed point now become:
$$x_{n+1} = a x_n + b y_n\\
y_{n+1} = c x_n + d y_n$$

We don't need terms like $\mu$ and $\nu$ in the $(\xi, \eta)$ system, because when $(x_n = 0, y_n=0)$ both $x_{n+1}$ and $y_{n+1}$ will be zero: a fixed point at $(0,0)$! 


It's just the four parameters $a, b, c$, and $d$ that shape the dynamics. It can be handy to adopt a vector/matrix notation to highlight the role of the four parameters without distracting from all the $x_n$ and $y_n$ notation. Do do this, we'll put $x_n$ and $y_n$ into a single vector, which we'll call ${\mathbf X}_n$. (Note the boldface **x** to signify that it is a vector, rather than a scalar wich is written unbolded, $x$.)
$$
\left[ \begin{array}{c}x_{n+1}\\y_{n+1}\end{array} \right] \equiv\ \ \ \ {\mathbf X}_{n+1} = 
\left[ \begin{array}{cc}a & b\\c & d\end{array} \right] 
{\mathbf X}_n \ \ \ \ \equiv 
\left[ \begin{array}{c}a x_{n} + by_n\\c x_n + d y_{n}\end{array} \right]
$$
It's important to remember that writing the dynamics as 
$${\mathbf X}_{n+1} = 
\left[ \begin{array}{cc}a & b\\c & d\end{array} \right] 
{\mathbf X}_n$$ 
doesn't change anything about the dynamics, it's just a more compact notation. 

We could simplify even more by giving a name to the [abcd] matrix, like this:
$${\mathbf X}_{n+1} = {\mathbf A}\cdot {\mathbf X}_n$$
But we'll be wanting to look at the role played by each of the four parameters $a, b, c$, and $d$, so we'll continue to write out the matrix components. 


The price we pay for limiting ourselves to linear dynamics is that we can't necessarily describe the global behavior of dynamics, just the behavior in a small locale. It turns out in science and engineering that this is often all that we need. (We'll look at some dynamical models that rely on nonlinearity in future days.)

-----

Recall some of the concepts we used in exploring *linear combinations*.

- a **vector** is a mathematical object with two properties: magnitude (length) and direction. We wrote vectors as a column of numbers, for instance $${\mathbf v} = \left[\begin{array}{r}3\\-1\\8\end{array}\right]\ \ \ \mbox{or}\ \ \ {\mathbf u} =\left[\begin{array}{r}2\\-3\end{array}\right]$$ The dimension of a vector is the count of numbers used in its representation: 3 for $\mathbf v$ and 2 for $\mathbf u$.
- a **matrix** is a collection of vectors, all of which have the same dimension. For instance: 

$${\mathbf M} =\left[\begin{array}{rrr}3 & 1 & 0\\-1 & 4 & -2\\8 & 0 & 12\end{array}\right]\ \ \ \mbox{or}\ \ \ {\mathbf P} =\left[\begin{array}{rr}-1 & 2\\7 & 0\end{array}\right]$$

- **multiplying** a matrix times a vector produces a new vector which is a *linear combination* of the vectors in the matrix. For instance:

$${\mathbf P}\cdot{\mathbf u} = \left[\begin{array}{rr}-1 & 2\\7 & 0\end{array}\right] \cdot \left[\begin{array}{r}2\\-3\end{array}\right] =
2 \left[\begin{array}{r}-1\\7\end{array}\right] + -3 \left[\begin{array}{r}2\\0\end{array}\right] = \left[\begin{array}{r}-7\\14\end{array}\right]$$

There's a simplification of the [abcd]-style matrix that is particularly important in the way dynamics are written in physics and related disciplines. That matrix has the form $$\left[\begin{array}{cc}a & b\\1 & 0\end{array}\right]$$
We'll call this an [ab10]-format matrix.

It's worth emphasizing the special form of the equations corresponding to an [ab10] matrix:

$$\underbrace{\left[\begin{array}{c}x_{n+1}\\y_{n+1}\end{array}\right]}_\mbox{next state} =  
\underbrace{\left[\begin{array}{rr}a & b\\1 & 0\end{array}\right]}_\mbox{[ab10] format matrix} \cdot\underbrace{\left[\begin{array}{c}x_n\\y_n\end{array}\right]}_\mbox{current state} = 
\left[\begin{array}{rcr}a\, x_n & + & b\, y_n \\x_n & & \end{array}\right]$$
Since both $x_n$ and $y_n$ are numerical quantities, you'll often work with the system like this:

$$\underbrace{\left[\begin{array}{c}x_{n+1}\\y_{n+1}\end{array}\right]}_\mbox{next state} =  
\underbrace{\left[\begin{array}{rr}a & b\\1 & 0\end{array}\right]}_\mbox{[ab10] format matrix} \cdot\underbrace{\left[\begin{array}{r}3\\-1\end{array}\right]}_\mbox{current state} = 
\left[\begin{array}{rcr}3 a & + & (-1)b \\3 & & \end{array}\right]$$

[Exercise: j2ettP ]








## Day 17 Exercises


`r insert_calcZ_exercise("XX.XX", "KzgT1c", "Exercises/Dynamics/crow-find-sofa.Rmd")`

`r insert_calcZ_exercise("XX.XX", "on164B", "Exercises/Dynamics/seaweed-bite-shoe.Rmd")`

`r insert_calcZ_exercise("XX.XX", "3A3pMv", "Exercises/Dynamics/bee-wake-bottle.Rmd")`

`r insert_calcZ_exercise("XX.XX", "j2ettP", "Exercises/Dynamics/shark-understand-saw.Rmd")`

`r insert_calcZ_exercise("XX.XX", "PTn8Yk", "Exercises/Dynamics/aspen-take-cotton.Rmd")`

`r insert_calcZ_exercise("XX.XX", "JcqzZA", "Exercises/Dynamics/camel-dig-fridge.Rmd")`



# Wrap-up Discrete Time difference equations

  

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-4a", "Understand how eigenvalues can describe the properties of difference equations in discrete time")
state_objective("Dyn-4b", "Understand sequences as steps through discrete time")
```
:::

We're focusing now on the behavior of discrete-time dynamical systems near fixed points. Recall that we've defined $x$ and $y$ scales that have the fixed point at (0, 0) and that the dynamics can be approximated by linear functions which we write with a matrix. We'll call the matrix ${\mathbf A}$ and use ${\mathbf X}_n$ to denote the two-dimensional state at time $n$.  So the dynamics are: $${\mathbf X}_{n+1} = {\mathbf A}\, {\mathbf X}_n\ \ \ \mbox{where}\ \ {\mathbf A} = \left[\begin{array}{cc}a & b\\c & d\end{array}\right]\  \mbox{for instance}\ \ \left[\begin{array}{rr}1.1 & -0.4\\0.3 & 0.9\end{array}\right]$$
This is all just a matter of arithmetic. Suppose we start at the initial condition ${\mathbf X}_0 = \left[\begin{array}{r}1.3\\0.5\end{array}\right]$. Using the example matrix from above, the value of ${\mathbf X}_{1}$ will be ${\mathbf A}\, {\mathbf X}_0$, or
$$
{\mathbf X}_1 = \underbrace{\left[\begin{array}{rr}1.1 & -0.4\\0.3 & 0.9\end{array}\right]}_{\mathbf A} \cdot \underbrace{\left[\begin{array}{r}1.3\\0.5\end{array}\right]}_{{\mathbf X}_0} = 1.3 \left[\begin{array}{r}1.1\\0.3\end{array}\right] + 0.5 \left[\begin{array}{r}-0.4\\0.9\end{array}\right] = \left[\begin{array}{r}1.23\\0.84\end{array}\right]
$$
Over the next few class sessions, you'll see why such systems are important in practice. For now, however, we want to see the behavior of such systems as they are iterated to higher $n$. We can obviously construct an infinite number of make-work exercises about matrix arithmetic. And we could have you push off the arithmetic labor onto the computer. But instead, we take heed of a famous epigram that's painted onto the wall in the Math Department offices (by the window overlooking the chapel):

> *The purpose of computing is insight, not numbers.* --- Richard Hamming

If we were to have you calculate and display numerically sequences of vectors, it would be hard to extract insight into the patterns of matrix iteration. Instead, we'll use a graphical display, actually two:

1. The trajectory as it moves from step to step through state space, that is, the space $y$ versus $x$.
2. The "time series" for the variable $y$, that is, $y_n$ versus $n$. Think of this as a graph of $y$ versus time, while the state-space graph is $y$ versus $x$.

We'll let the computer do the arithmetic and graphing. Your job is to experiment with various matrices, explore the patterns of motion they produce, and gain some insight. Click on the picture of the app to bring it up in another tab of your browser, then arrange that tab and this one side by side.

<a href="https://maa-statprep.shinyapps.io/142Z-Matrix-iteration/" target="_blank"><img src="www/app-snapshot.png" width="70%"></a>

**Slow and fast motion**

Each trajectory consists of a series of dots. The dots are connected with a thin line to help you see easily consecutive points, but these are discrete-time dynamics so only the dots are "real."

The spacing between consecutive dots is something like the "speed" of the motion, but perhaps "distance jumped" is a better metaphor to correspond to discrete time. For convenience, we'll say the motion is "slow" when consecutive dots are close together and "fast" when they are far apart.

One general pattern seen in linear dynamics near a fixed point is that the motion is slow near the fixed point and fast far from it. 

Sometimes the speed of motion is systematically faster for trajectories heading in some directions and slower for trajectories in other directions. But on any one trajectory, the motion will be faster far from the fixed point and slower near to it. Of course, the speed of motion is zero right at the fixed point: it's fixed!


**The saddle** Start with the matrix $${\mathbf A} = \left[\begin{array}{rr}0.90 & 0.05\\0.05 & 1.01\end{array}\right]$$
Set the number of iterations to, say, 100. Then click in the graph to start trajectories for many places near the perimeter of the graphic frame. You can just do this randomly at first, but then clear the graph and do it systematically to make the pattern of motion clear.

This pattern is called a "saddle," because the dynamics are analogous to the movement of a drop of water rolling down a horse saddle.

```{r sts-1, echo=FALSE, results="markup"}
askMC(
  "From initial conditions in a particular direction from the origin (that is, the fixed point), the trajectories head in straight to the origin. What direction is that? (Use the notation of the clock. So 6:00 is straight down, 9:00 is to the left, and so on.) Hint: Use the y versus n graph to determine where the trajectory started.",
  "+4:00 & 10:00+",
  "2:00 & 8:00",
  "6:00 & 12:00",
  "1:00 & 7:00",
  random_answer_order = TRUE
)
```

```{r sts-2, echo=FALSE, results="markup"}
askMC(
  "The trajectories that head in almost straight to the fixed point, turn left or right and head away from the fixed point in another direction. What direction is that? Hint: Use the y versus n graph to determine where the trajectory started.",
  "4:00 & 10:00",
  "2:00 & 8:00",
  "6:00 & 12:00",
  "+1:00 & 7:00+",
  random_answer_order = TRUE
)
```

The two directions you found in the previous two questions are called "characteristic directions," or, more generally, **characteristic vectors**. But in mathematics and the sciences, these are usually called **eigenvectors**. We denote the eigenvectors as ${\mathbf \Lambda}_1$ and ${\mathbf \Lambda}_2$, pronouced "lambda-one" and "lambda-two." Perhaps one way to remember that the ${\mathbf \Lambda}$s are each telling part of the story of the A matrix is to see that ${\mathbf \Lambda}$ is only part of A.

Associated with each eigenvector is a number called a **characteristic value** or **eigenvalue**. The two eigenvalues are displayed as $\lambda_1$ and $\lambda_2$ underneath the matrix. We'll defer for the present how these are calculated.

The dynamics have an extremely simple solution when they start on an eigenvector: motion right along that eigenvector. Suppose the initial condition is $m {\mathbf \Lambda}_1$
The solution is $${\mathbf X}_n = \lambda_1^n\ \  m {\mathbf \Lambda}_1$$ with the same for $\lambda_2$ and ${\mathbf \Lambda}_2$. 
Such motion is either stable ($|\lambda | < 1$) or unstable ($|\lambda| > 1$).

```{r sts-3, echo=FALSE, results="markup"}
askMC(
  "Which is the eigenvalue corresponding to the direction of stable motion?",
  "+0.88+",
   "0.9",
  "1.01",
  "1.03",
  random_answer_order = FALSE
)
```

```{r sts-4, echo=FALSE, results="markup"}
askMC(
  "Which is the eigenvalue corresponding to the direction of **unstable** motion?",
  "0.88",
   "0.9",
  "1.01",
  "+1.03+",
  random_answer_order = FALSE
)
```

The saddle behavior is "generic" in the sense that a small change to the numbers composing the matrix will still produce saddle motion.

**The source** In the app, change the matrix to $${\mathbf A} = \left[\begin{array}{rr}1.1 & 0.05\\0.05 & 1.1\end{array}\right]$$ and construct trajectories starting from all around the fixed point.

```{r sts-5, echo=FALSE, results="markup"}
askMC(
  "Which is the **stable** eigenvector?",
  "${\\mathbf \\Lambda}_1$",
  "${\\mathbf \\Lambda}_2$",
  "Both ${\\mathbf \\Lambda}_1$ and ${\\mathbf \\Lambda}_2$",
  "+There is no stable direction.+",
  random_answer_order = FALSE
)
```

```{r sts-6, echo=FALSE, results="markup"}
askMC(
  "Which is the **unstable** eigenvector?",
  "${\\mathbf \\Lambda}_1$",
  "${\\mathbf \\Lambda}_2$",
  "+Both ${\\mathbf \\Lambda}_1$ and ${\\mathbf \\Lambda}_2$+",
  "There is no stable direction.",
  random_answer_order = FALSE
)
```

```{r sts-7, echo=FALSE, results="markup"}
askMC(
  "Since motion along both eigenvectors is unstable, the trajectory moves away from the origin. Motion along one of the eigenvectors is relatively \"fast\" and motion along the other is \"slow\". (You can see the speed by looking at the spacing between dots on a trajectory) What is the eigenvalue for the **slow** direction?",
  "0.95",
  "+1.05+",
  "1.15",
  "1.25",
  random_answer_order = FALSE
)
```

```{r sts-8, echo=FALSE, results="markup"}
askMC(
  "Which direction does the \"slow\" eigenvector point in? (You may need to create many trajectories before you find one that is straight.)",
  "+4:30 - 10:30+",
  "1:30 - 7:30",
  "2:30 - 8:30",
  "There is no slow eigenvector.",
  random_answer_order = TRUE
)
```

**The spiral node** In the app, change the matrix to $${\mathbf A} = \left[\begin{array}{rr}1.0 & -0.5\\0.5 & 0.9\end{array}\right]$$ and construct a single trajectory of 100 or so steps starting near the fixed point. (Why a single trajectory? You'll see.)

```{r sts-9, echo=FALSE, results="markup"}
askMC(
  "What phrase best describes the trajectory?",
  "Clockwise spiral toward the fixed point",
  "Clockwise spiral away from the fixed point",
  "Counter-clockwise spiral toward the fixed point",
  "+Counter-clockwise spiral away from the fixed point+",
  random_answer_order = FALSE
)
```

```{r sts-10, echo=FALSE, results="markup"}
askMC(
  "What phrase best describes the time series $y_n$ versus $n$?",
  "exponential growth",
  "a sinusoid",
  "+a sinusoid whose amplitude grows exponentially+",
  "a sinusoid whose baseline is shifted away from zero",
  random_answer_order = FALSE
)
```

```{r sts-11, echo=FALSE, results="markup"}
askMC(
  "The eigenvalues have a different form in the spiral motion than they did in the saddle or source. What's that difference?",
  "They are negative numbers.",
  "They are integers.",
  "They are real numbers.",
  "They are rational numbers (e.g. 15/32).",
  "They are irrational numbers (e.g, $\\pi$).",
  "+They are complex numbers.+" = "Numbers written like 0.3i are called \"imaginary\". Numbers with both a real and an imaginary part are called \"complex\" numbers." 
)  
```

**String art** This isn't an actual term in dynamics, but it is an apt description of the sorts of trajectories seen when one or both of the diagonal elements of the ${\mathbf A}$ matrix are negative. For instance, set the matrix in the app to $${\mathbf A} = \left[\begin{array}{rr}-1.00 & -0.02\\-0.01 & -1.00\end{array}\right]$$ and construct a trajectory with 100 or more steps. 

The trajectories are pretty complicated looking, but the time series of an individual component are not.

```{r sts-12, echo=FALSE, results="markup"}
askMC(
  "Which of these phrases best describes the **time series** $y_n$ versus $n$?",
  "exponential growth",
  "exponential decay", 
  "+exponential growth but alternating signs+",
  "exponential decay but alternating signs",
  random_answer_order = FALSE
)  
```

**Curved trajectories and curved time series** It's tempting---**but wrong**--- to look at the curves in trajectories as something like exponential growth. But keep in mind that the growth is exponential only in the time series. When a trajectory is sharply curved that corresponds to the motion starting in the direction of the slow eigenvector and then curving onto the fast eigenvector. Often this appears in the trajectory as an down-then-up kind of graph.



`r insert_calcZ_exercise("XX.XX", "pbnVGt", "Exercises/Dynamics/wolf-meet-screen.Rmd")`


`r insert_calcZ_exercise("XX.XX", "3D9C7d", "Exercises/Dynamics/maple-think-ring.Rmd")`






# Continuous-Time differential equation in 1 dimension

We are now switching over to another formalism for describing dynamics: differential equations. Differential equations are used to describe dynamics that take place in continuous time or space, as opposed to the one-step-at-a-time, discrete-time situation for finite-difference equations. 

It may help, even before getting into differential equations, to highlight some of the similarities and differences from discrete-time dynamics.

. | Differential Equations | Difference Equations
--|------------------------|---------------------
Trajectory | continuous functions $x(t)$ | discrete sets of numbers ${x_0, x_1, x_2, \ldots}$
Dynamics | instantaneous change is a function of current state | state at next step is a function of previous state.

Difference equations are analogous to football and baseball. In both these sports, action takes place in discrete steps: one down at a time in football, one batter at a time in baseball. (Base stealing is the exception in baseball, since that can happen at any time.)

Differential equations are like soccer or ice hockey or basketball: the play proceeds continually (although interrupted by goals and penalties).

We are going to start with differential equation systems where the *state space* is a wire-like number line: a single quantity.  The state at any instant (the "instantaneous state") can be well imagined as a bead sliding along the wire. 

Newcomers understandably endow this bead-on-wire analogy with other familiar properties of the real world. For instance, a real-world wire has friction which needs to be overcome by applying a force. A real-world bead has momentum which prolongs motion even after force has been applied. As you will see, a differential equation system that involves force and momentum requires a two-dimensional (or higher) state space.

An exact physical analogy to a one-dimensional differential equation system will always be somewhat artificial, since the physical laws of motion can't be implemented with a one-dimensional state. Here's one such contrived analogy:

> The state space is represented by a road, the instantaneous state being the location of a car along that road. But instead of the car's motion being set by the accelerator and brakes, the velocity of the car is strictly dictated by an authoritarian government law: no exceptions. When the dictated speed is zero, the car will stand still and cannot start moving again. Ultimately, depending on the shape of the law, the car will head off to infinity or come to an eternal standstill at a stable fixed point. Two different cars can never collide on this road: if the cars are close together, they must be travelling at similar velocities. Cars can't pass one another in different directions. Passing requires that the two cars have opposite velocities: one positive and one negative.  If the mandated velocity at a point along the road is positive, every car that comes to that point must have the same positive velocity.

The diagram shows such a road as a grey line. The red numbers are mile-markers alongside the road. The curve shows the mandated speed at any point: you can read off the numerical value of the mandated speed on the y-axis.

```{r echo=FALSE, warning=FALSE}
f <- rfun( ~ x, seed=999)
xpts <- seq(-5,5,length=500)
offset <- mean(f(xpts))
scale <- sd(xpts)
speed  <- function(x) 20*(f(x-10) - offset)/scale
Signs <- tibble::tibble(
  x = seq(0,20, by=2),
  y = 13,
  label = paste("Mile", x),
  angle = -sign(x - 9)*90
)
slice_plot(speed(x) ~ x, domain(x=c(0,20)), color="blue") %>%
  gf_text(y ~ x, label = ~ label, color="red", data = Signs, angle=~ angle) %>%
  gf_text(-30 ~ 1, label=c("West"), inherit=FALSE ) %>%
  gf_text(30 ~ 19, label=c("East"), inherit=FALSE ) %>%
  gf_hline(yintercept=0, color="black", alpha=0.3, size=3) %>%
  gf_labs(y = "Mandated speed (mph)", x="", title="County Road B") %>%
  gf_theme(panel.grid = element_blank(), axis.text.x = element_blank())
```


```{r drive1-1, echo=FALSE, results="markup"}
askMC(
  "At mile marker 4, which way is the car going?",
  "+West+" = "A negative velocity means heading west.",
  "East",
  "At a standstill"
)
```

```{r drive1-2, echo=FALSE, results="markup"}
askMC(
  "How long will it take for the car to go from mile marker 4 to mile marker 0? (Choose the closest answer.)",
  "5 minutes",
  "15 minutes",
  "+25 minutes+" = "The velocity is about -10 mph over that segment of the road. To go 4 miles at 10 mph takes 24 minutes.", 
  "45 minutes",
  "Can't be done.",
  random_answer_order = FALSE
)
```

```{r drive1-3, echo=FALSE, results="markup"}
askMC(
  "A car starts at mile marker 8. Where will it end up?",
  "+All the way west+",
  "About mile 9",
  "About mile 10",
  "About mile 13",
  "All the way east",
  random_answer_order = FALSE
)
```

```{r drive1-4, echo=FALSE, results="markup"}
askMC(
  "A car starts at mile marker 10. Where will it end up?",
  "All the way west",
  "About mile 9",
  "About mile 10",
  "+About mile 13+",
  "All the way east",
  random_answer_order = FALSE
)
```


```{r drive1-5, echo=FALSE, results="markup"}
askMC(
  "You and your friend plan to bike along the road. (Bikes are not covered by the speed mandate.) You'll stop at a point where you can sell snacks to motorists through their car windows. What's the most profitable point for you to set up your business.",
  "All the way west",
  "About mile 9",
  "About mile 10",
  "+About mile 13+",
  "All the way east",
  random_answer_order = FALSE
)
```

A government commission is exploring ways to improve road use by changing the speed mandate. They will add a constant to the existing speed mandate. 

```{r drive1-6, echo=FALSE, results="markup"}
askMC(
  "One group of citizens wants to facilitate east-to-west travel. Which of these would be a suitable value of the constant to add to the speed mandate?",
  "+-75 mph+",
  "-25 mph",
  "15 mph",
  "35 mph",
  "60 mph",
  random_answer_order = FALSE
)
```

```{r drive1-7, echo=FALSE, results="markup"}
askMC(
  "Another group of citizens wants to facilitate west-to-east travel. Which of these would be a suitable value of the constant to add to the speed mandate?",
  "-75 mph",
  "-25 mph",
  "15 mph",
  "35 mph",
  "+60 mph+",
  random_answer_order = FALSE
)
```

```{r drive1-8, echo=FALSE, results="markup"}
askMC(
  "An angry chef has a road-side hamburger stand at mile 5. His business has been non-existent since the current speed mandate was implemented. To give his stand the best chance at success, which policy should he advocate?",
  "-75 mph",
  "-25 mph",
  "+15 mph+",
  "35 mph",
  "60 mph",
  random_answer_order = FALSE
)
```


-----



A familiar task from high-school math is to "solve" an equation. For instance, if given the equation $a x^2 + b x + c = 0$ and asked to "solve for $x$," you might remember to invoke some procedure such as the quadratic formula:$$x = \frac{1}{2a}\left[-b \pm \sqrt{\strut b^2 - 4 a c}\right]$$ From experience, you would know that $x$ will be a number (although the situation gets a little sketchy when $4ac > b^2$). 

In CalcZ, rather than emphasize "equations," we've built on the notion of **functions**. For instance, in the language of calculus, we would define a function such as $f(x) \equiv a x^2 + b x + c$. The task of "solving" is re-framed as "finding a zero of $f(x)$," that is, finding a value $x_0$ for which $f(x_0) = 0$. A similar sort of task is "finding an *argmax* of $f(x)$." This means to find an $x^\star$ such that $f(x^\star) \geq f(x)$ for all $x$. We have used several notations, e.g. $x_0$, $x^\star$, etc., to indicate that a task is to find a specific numerical value that, when put as an input to a function, gives an output that has some specified property, e.g. the output is zero or the output is maximized.

We have also studied operators that, when given a *function* as input, produce as output *another function*. The most famous of these are *differentiation* and *anti-differentiation*. 

With finite-difference equations, we have returned to mathematical objects in the form of *equations*, and to the task of *solving*. For instance, a one-dimensional finite-difference equation looks like $$x_{n+1} = f(x_n)$$ The equation sets the relationship between the future ($n+1$) state and the present ($n$) state. To find a *solution* to the finite-difference equation does not mean finding a numerical value for $x$. Instead, it means finding a *function*  $x_n$ that satisfies the relationship specified by the equation. 

Calling $x_n$ a "function" drops (for good reason) some conventions we have used throughout the course:

1. We have used *parentheses* rather than subscripts, so $x(n)$ instead of $x_n$.
2. We have used names like $f()$ and $g()$ and $\exp()$ and $\sin()$ for functions, and used names like $x$ and $y$ and $t$ for *numerical inputs to functions*.
3. We have been concerned with functions where the input can be varied continuously, say $\infty < x < \infty$ rather than functions where the input is discrete, e.g. $n=0, 1, 2, \ldots$. 

Differential equations---as opposed to *difference equations*---also involve an equation. As we start out, that equation will involve **three** different functions, typically a function of time $g(t)$, the derivative $\partial_t g(t)$ of that function with respect to time and still another function $\mbox{dynamic}()$. So a differential equation might look like $$\underbrace{\partial_t g(t)}_\mbox{function 3} = \underbrace{\mbox{dynamic}}_\mbox{function 2}(\ \underbrace{g(t)}_\mbox{function 1}\ )$$ 

The equation mandates a particular relationship between the functions $g(t)$ and $\partial_t g(t)$. To *solve* this equation means to find a particular function $g(t)$ that is faithful to the mandate set by the equation. And, of course, whatever $g(t)$ is, $\partial_t g(t)$ is its derivative with respect to time.

As a form of contrast, consider this equation: $$\partial_t g(t) = \sin(\omega\, t)$$
We already learned a technique to solve such an equation, namely take the anti-derivative with respect to time of both sides:
$$g(t) + C \equiv \int \partial_t g(t) dt = \int \sin(\omega t) dt \equiv - \frac{1}{\omega} \cos(\omega\, t) + D$$

Notice that I've used $\equiv$ in two places in the above line. To say $\partial_t g(t) = \sin(\omega t)$ is to impose a mandate. This won't be true for any $g(t)$ that comes along, the equation is giving specific information about what kind of function $g(t)$ has to be. One the other hand, $g(t) - C \equiv \int \partial_t g(t) dt$ is something that has to be true for *any* $g(t)$ that someone happens to provide. Similarly, $\int \sin(\omega t)dt \equiv - \frac{1}{\omega} \cos(\omega\, t) + D$ is a mathematical *fact*, not a modeling statement about the world.

In a differential equation, the unknown function $g(t)$ appears on *both* sides of the equation, once in the form of $\partial_t g(t)$ ("function 3") and once as $g(t)$ ("function 1"). Although it's tempting to apply anti-differentiation, that will not do the job of finding $g(t)$, since $g(t)$ itself appears as part of the broader function $\mbox{dynamics}(\ g(t)\ )$ to which we're tempted to apply anti-differentiation. 

We will need other approaches to *solve* the differential equation for $g(t)$. We will use two good approaches, one that always works (for any function $\mbox{dynamics}()$ and the second that only works sometimes.

1. A numerical method that approximates the differential equation with a finite-difference equation, enabling it to be solved simply by *iteration*. This is Euler's method.
2. A algebraic method that works only if we already know the functional form of the solution. As you'll see, for many differential equations important in modeling, there is such an *ansatz*: a function we already know where all we have to do is fill in the details.

Interestingly, traditionally calculus courses have featured a third method for solving differential equations:

3. An algebraic method that sometimes allows the solver to translate the differential equation into a form that looks like this: $h(g(t)) = \int f(t) dt$ and enables standard anti-differentiation of $f(t)$ to be the central step. We won't dwell on this because it only works sometimes, often requires an algebraic superpower that not all students possess, and, in the cases most commonly encountered in modeling has already been done giving us an *ansatz* that we can use in method (2). 

```{r sff1, echo=FALSE, results="markup"}
askMC(
  "Consider the differential equation $$\\partial_t g(t) = 0.2 g(t) \\left(1 - g(t)/200\\right)$$ Which of these is the function $\\mbox{dynamics}()$ in the differential equation?",
  "+$\\mbox{dynamics}(x) \\equiv 0.2 x (1 - x/200)$+" = "When you give as input the function $g(t)$ you get the right-hand side of the differential equation.",
  "$\\mbox{dynamics}(t) \\equiv 0.2 g(t) (1-g(t)/200)$" = "The input to dynamics() should be the function $g(t)$, not the whole right side of the differential equation.",
  "$\\mbox{dynamics}(x) \\equiv 0.2 x$",
  "$\\mbox{dynamics}(x) \\equiv 1 - x/200$"
)
```

Differential equations are often written in a kind of shorthand which makes it easier for those in the know but can be confusing to newcomers. We're going to use that shorthand *since you will encounter it in your downstream courses*. But we want to lay it out in parallel with the highly explicit notation we have been using thus far.

The differential equation in the previous exercise is
$$\partial_t g(t) = 0.2 g(t) \left(1 - g(t)/200\right)$$
The shorthand makes some substitutions:

i. The function $g(t)$ is written simply $x$. You will need to force yourself to remember that $x$ is really $x(t)$: a function of time.
ii. The derivative notation $\partial_t g(t)$ is replaced with $\dot{x}$. That tiny dot over the $x$ is entirely equivalent to $\partial_t$.

Let's write it a little bigger to be sure you can spot it:

<div style="font-size: 45px; text-align:center;">$$\dot{x}$$</div>

In the shorthand the equation is rendered 

<div style="font-size: 30px; text-align:center;">$$\dot{x} = 0.2\, x\ (1-x/200)$$</div> Although we've saved having to write $(t)$ multiple times and having to write $\partial_t$ at all, until you get used to it you will forget that $t$ has anything to do with $\dot{x} = 0.2\, x\ (1-x/200)$. Keep your eyes out for that little speck of a dot, $\dot{\ }$, because it is the only thing to remind you about the essential role of $t$ as the input to the sought-after $x(t)$.

```{r sff2, echo=FALSE, results="markup"}
askMC(
  "Which of the following is the x-shorthand for the differential equation $$\\partial_t g(t) = a g(t) + b \\ \\mbox{?}$$",
  "+$\\dot{x} = a x + b$+",
  "$x = a \\dot{x} + b$" = "Dot on the wrong side.",
  "$\\dot{x} = a \\dot{x} + b$" = "Too many dots.",
  "$\\dot{x}(t) = a x(t) + b$" = "Remember, the $t$ is implicit in the dot."
)
```

```{r sff3, echo=FALSE, results="markup"}
askMC(
  "What is the function dynamics() in $\\dot{x} = a x + b$?",
  "+dynamics$(x) \\equiv a x + b$+",
  "dynamics$(t) \\equiv a x + b$" = "Don't put a $t$ where it's not needed.",
  "dynamics$(x) \\equiv x + b$",
  "dynamics$(x) \\equiv a x$"
)
```


-----

There are a few differential-equation forms that show up again and again in modeling problems. We're going to introduce them to you here and, later, show you the solutions.

**The proportional growth/decay model**: $\dot{x} = a x$

* Simple population growth. The population is a function of time: $x(t)$. Growth at any instant is proportional to the instantaneous population. For instance a population growing at 3% per year will have $a \approx 0.03$ with units 1/year.
* Radioactive decay. The amount of the radioactive substance is a function of time: $x(t)$. For example, phosphorus-32 (that is, $^{32}$P) has a half life of 14 days. The differential equation is $\dot{x} = -a x$ with $a \approx 0.049$ with units 1/day.

**Change proportional to  difference**: $\dot{x} = - a (x - x_\mbox{fixed})$

* Newton's Law of Cooling is about how a hot (or cold) object comes into equilibrium with the ambient temperature. For instance, you might have a cup of coffee at $200^\circ$F in a room at $70^\circ$F. Unless you drink it, the coffee will cool with time until it reaches the room's temperature. In this setting, $x_\mbox{fixed} = 70^\circ$F. The value of $a$ depends on how insulated the cup is (and details of evaporation, etc.). But if the coffee reaches very near to room temperature in 60 minutes, $a \approx 0.5$ with units 1/minute.


```{r basic2a, echo=FALSE, results="markup"}
askMC(
  "What are the units of the output of $x(t)$?",
  "degrees F per minute",
  "+degrees F+",
  "1/minute",
  "1/degrees F"
)
```

```{r basic2b, echo=FALSE, results="markup"}
askMC(
  "What are the units of $\\dot{x}$?",
  "+degrees F per minute+",
  "degrees F",
  "1/minute",
  "1/degrees F"
)
```

```{r basic2c, echo=FALSE, results="markup"}
askMC(
  "What is $x$?",
  "the room temperature",
  "the initial temperature of the coffee",
  "+the instantaneous coffee temperature as a function of time+",
  "the fixed rate at which the coffee cools",
  "the instantaneous rate at which the coffee cools as a function of time"
)
```

```{r basic2d, echo=FALSE, results="markup"}
askMC(
  "What is $\\dot{x}$?",
  "the room temperature",
  "the initial temperature of the coffee",
  "the instantaneous coffee temperature as a function of time",
  "+the instantaneous rate at which the coffee cools as a function of time+"
)
```

**Limited growth**, e.g. $\dot{x} = r x (1-x/k)$

The proportional-growth model will lead to $x(t)$ increasing without limit. Sometimes that's a good model over short times, before $x(t)$ has a chance to get unrealistically big. But over long periods of time, something's gotta give.

* Population with a "carrying capacity." For $t$ when $x(t)$ is very small, the population growth is well approximated by the usual proportion-growth model.  For intermediate $t$, the population has grown to a large enough size that it is consuming a substantial fraction of the available resources and population growth slows. When the population reaches the "carrying capacity" the growth stops (e.g. birth rate = death rate).

```{r basic3a, echo=FALSE, results="markup"}
askMC(
  "If the units of $x(t)$ is, say, rabbits, what is the units of $k$?",
  "+rabbits+",
  "rabbits per day",
  "rabbits per week",
  "rabbits per year"
)
```

```{r basic3b, echo=FALSE, results="markup"}
askMC(
  "Suppose the units of $\\dot{x}$ is, rabbits per month, what is the units of $r$?",
  "+1/month+",
  "rabbits per month",
  "months per rabbit", 
  "rabbits per month-squared"
)
```

```{r basic3c, echo=FALSE, results="markup"}
askMC(
  "Even without finding the full solution $x(t)$ to the differential equation, you can figure out how big the population will be when growth falls to zero. How big?",
  "+$k$+",
  "$k/r$",
  "$r/k$", 
  "$1/r$"
)
```



`r insert_calcZ_exercise("XX.XX", "5DVPWG", "Exercises/Dynamics/spruce-make-lamp.Rmd")`

`r insert_calcZ_exercise("XX.XX", "L6hTUu", "Exercises/Dynamics/pine-win-oven.Rmd")`

`r insert_calcZ_exercise("XX.XX", "VCWRBs", "Exercises/Dynamics/seal-fly-socks.Rmd")`



::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-5a", "Using slope fields, understand that a differential equation has a family of solutions")
state_objective("Dyn-5b", "Determine a particular solution to a differential equation in one dimension")
state_objective("Dyn-5c", "Determine end behavior of a differential equation graphically")
state_objective("Dyn-5d", "Describe a scenario using proportional or inversely proportional growth with a differential equation")
```
:::

# Continuous-Time differential equation in 2 dimensions


::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn6-lost", "Determine a particular solution to a differential equation in two dimensions")
state_objective("Dyn-6a", "Describe a scenario using logistics growth with a differential equation")
state_objective("Dyn-6b", "Understand the three types of dynamics stable, instable, and saddle points and how lambda values can clearly show which one is which")
```
:::

# Catch-up: Review Day

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-7a", "Understand the benefits of using the exponential function as an educated guess for a solution to a differential equation")
state_objective("Dyn-7b", "Comprehend how solutions to differential equations can have complex eigenvalues")
state_objective("Dyn-7c", "Understand how complex eigenvalues are related to oscillations")
```
:::

 Force-balance equation

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-8a", "Damped harmonic oscillator example")
state_objective("Dyn-8b", "Translate eigenvalues into the description of qualitative dynamics")
state_objective("Dyn-8c", "Understand eigenvectors and their connection to flow fields")
```
:::

Nonlinear phase plane and systems of nonlinear differential equations

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-9a", "Interpret phase plane diagrams, flow field diagrams, and time series plots of nonlinear systems of differential equations")
state_objective("Dyn-9b", "Be able to interpret individual terms in a dynamical function that describes specific relationships among real-world objects")
state_objective("Dyn-9c", "Predator-prey model")
state_objective("Dyn-9d", "Attrition model")
```
:::

Complex Eigenvalues

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-10a", "Understand the benefits of using the exponential function as an educated guess for a solution to a differential equation")
state_objective("Dyn-10b", "Comprehend how solutions to differential equations can have complex eigenvalues")
state_objective("Dyn-10c", "Understand how complex eigenvalues are related to oscillations")
```
:::
