# (PART) Block 5: Dynamical systems {.unnumbered}




# States, Dynamics, Trajectory
    
::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-1a", "Understand the difference between state, dynamics, trajectory")
state_objective("Dyn-1b", "Understand the difference between continuous and discrete time")
state_objective("Dyn-1c", "Recognize the form of a differential or finite-difference equation")
```
:::


A **trajectory** is a sequence of successive states. For example, here is a trajectory of six successive states: $$\{ {\mathbf S_0}, {\mathbf S_1},  {\mathbf S_2}, {\mathbf S_3}, {\mathbf S_4}, {\mathbf S_5}\}$$

It's conventional to call ${\mathbf S}_0$ the "initial state" or, more often, the **initial condition**.

Usually, we calculate a trajectory one step at a time:
$$\left\{ {\mathbf S_0},\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\ {\mathbf S_1}=g({\mathbf S_0}),\\ {\mathbf S_2} = g({\mathbf S_1}),\\ {\mathbf S_3} = g({\mathbf S_2}),\\ {\mathbf S_4} = g({\mathbf S_3}),\\ \ \ \ \ \ {\mathbf S_5} = g({\mathbf S_4}))\ \ \ \right\}$$
NOTE: We've written the above on several lines just to make it more readable. It could just as well have been written on one line.

-----


One common mathematical task in using finite-difference equations is **iteration**. In iterating a finite-difference equation, you are running a machine to construct the "future state" from the "present state." In iteration, you repeatedly do this. By plugging in the "future state" into the machine, you generate a state further in the future. 

It can be helpful to think of "future" and "present" state in terms of a series of days. The system's state **today** is the present state. The system's state **tomorrow** is the next future state.  The system's state on the **day after tomorrow** is the future state after tomorrows's state. 

A finite-difference equation is a statement about how tomorrow's state is a function of today's state. We could write this in the form
$$\mbox{state}_{\small\mbox{tomorrow}} = g( \mbox{state}_{\small\mbox{ today}})$$
This notation is wordy and hard to read. So we simplify it. 

- Today is day $n$
- Tomorrow is day $n+1$
- The state on day $n$ is written $\mathbf S_n$. 
- The state on day $n+1$ is written $\mathbf S_{n+1}$
- The dynamics are represented by a function, say, $g({\mathbf S})$.
- To remind us of the role played by $g()$, we write $${\mathbf S}_{n+1} = g({\mathbf S}_n)$$

(Exercises: DtLAhm, mJRDLy)

The ingredients for calculating a trajectory are:

a. A function $g(S)$
b. An initial condition ${\mathbf S}_0$.
c. A choice of how many steps to take.

<!--

There are two basic styles to computing trajectories on the computer. The first is a **calculator style* series of commands. For instance, the code in the sandbox computes a trajectory of length 6 from the given $g()$ and initial condition.

```{r fdec1, exercise=TRUE, exercise.cap="Calculator style", exercise.nline=10, eval=FALSE}
g <- makeFun(5 + x/2 ~ x)
x0 <- 7
x1 <- g(x0)
x2 <- g(x1)
x3 <- g(x2)
x4 <- g(x3)
x5 <- g(x4)
x6 <- g(x5)

```

Computer programmers learn that his is a bad style for several reasons.

i. The information about all these closely related things `x0`, `x1`, `x2` and so on is spread out over a bunch of different names. Most programming language provide no easy way to handle these as a group. An example of "handling as a group" is to plot out the trajectory versus $n$.  
ii. The statements are highly repetitive. Some people like this, because it gives them a sense of order. But programmers learn (through hard experience) that it is difficult for a human reader to confirm that every line is repeating exactly the same pattern. For instance, `x5 <- g(x3)` is a perfectly valid computer statement, but inconsistent with the dynamics that are supposed to be calculated.

A more effective style of programming is illustrated in the next sandbox which uses an "iteration operator":

-->

To facilitate calculating a trajectory, use the `Iterate()` operator. 

```{r fdec3-2, exercise=TRUE, exercise.cap="An iteration operator", exercise.nlines=8, eval=FALSE}
g <- makeFun(5 + x/2 ~ x)
Traj <- Iterate(g, x0 = 7, n = 6)
Traj
```

```{r fdec3-2-solution, echo=FALSE}
g <- makeFun(-0.8*x + 2 ~ x)
Traj <- Iterate(g, x0=10, 50) 
gf_point(x ~ n, data = Traj) %>%
  gf_line(alpha=0.2)
```

The `Iterate()` operator takes as a first argument the dynamics in the form of the name of a function or a tilde-expression of the sort accepted by `makeFun()`. The next argument is the initial condition. (This argument is named `x0` regardless of the name used in the dynamics).  The third argument is the number of steps to iterate.

`Iterate()` returns a data frame with two (or more) columns. The first, named `n`, is the step number. The second is given the same name as the variable used in the dynamical function. Because the output of `Iterate()` is in the form of a data frame, you can employ any function set up to accept a data frame. `gf_point()` is particularly useful for plotting the trajectory as a function of $n$.  

`Iterate()` is for finite-difference equations in discrete time, so $n$ will always be an integer and the trajectory is appropriately plotted as a series of isolated points. Even so, it can be helpful to the human viewer to connect the points faintly with straight lines. This makes it a bit easier to see the sequence. For instance:

```{r eval=FALSE}
# Make the Traj then ...
gf_point(x ~ n, data = Traj) %>%
  gf_line(alpha=0.2)
```

(Exercises: DzIhgb)

You can use the `Iterate()` function to compute the trajectory of any finite-difference system from any initial condition. Each trajectory is a sequence of numbers $\{x_n\}$ for $n=0, 1, 2, \ldots$.

Sometimes it's possible to find an algebraic formula for a trajectory. Such a formula is unfortunately called a "solution," an over-used word in mathematics. In the days before computers were readily available, students of dynamics tended to study only those systems for which an algebraic solution could be found. A more modern style is to put the modeling setting first and foremost and not hesitate to use numerical methods like `Iterate()` instead of relying on algebra.

Because the word "solution" appears so often in textbooks it's helpful to know what they look like and how they are different from dynamics.

i. Arithmetic sequences    
    - Dynamics: $x_{n+1} = x_n + b$
    - Solution: $x_n = x_0 + n b$
ii. Geometric sequences    
    - Dynamics: $x_{n+1} = \alpha\, x_n$
    - Solution: $x_n = x_0\, \alpha^n$
iii. Combined sequences   
    - Dynamics: $x_{n+1} = \alpha\, x_n + b$   <br> 
    - Solution: $x_n = \left(x_0 - b/\alpha\right) \alpha^n + b/\alpha$
    
The dynamics of a discrete-time system write tomorrow's state as a function of today's state. In contrast, the *solution* gives a formula for $x_n$ directly in terms of $n$, the initial condition $x_0$, and any parameters of the system (such as $\alpha$ and $b$ in the above examples).

As you can see, even for dynamics as simple as for the combined sequences, the solution is fairly complicated. Because solutions can be so complicated, they can be extremely hard to find and hard to use. The only ones we will use extensively will be composed of relatively simple terms like $(-1)^n$ and $\alpha^n$. The analogs of these for continuous time systems are $\sin(\omega t)$ and $e^{-kt}$. 

(Exercises: 9mSE8t)

## 142Z Day 15 exercises

`r insert_calcZ_exercise("XX.XX", "DtLAhm", "Exercises/Dynamics/kitten-mean-tv.Rmd")`

`r insert_calcZ_exercise("XX.XX", "mJRDLy", "Exercises/Dynamics/rat-lend-piano.Rmd")`

`r insert_calcZ_exercise("XX.XX", "DzIhgb", "Exercises/Dynamics/ape-leave-shirt.Rmd")`

`r insert_calcZ_exercise("XX.XX", "9mSE8t", "Exercises/Dynamics/lobster-become-sofa.Rmd")`

`r insert_calcZ_exercise("XX.XX", "FUIt1Q", "Exercises/Dynamics/spider-find-book.Rmd")`


::: {.takenote}
We will be using a handful of Greek letters in our mathematical notation. You should learn these by heart:

* $\alpha$  : alpha (lowercase)
* $\beta$  : beta (lowercase)
* $\lambda$  : lambda (lowercase)
* $\Lambda$  : lambda (uppercase)
* $\omega$  : omega (lowercase)
* $\xi$  : xi (lowercase), pronounced "ex-eee"
* $\eta$  : eta (lowercase)

The last two of these, $\xi$ and $\eta$ are the Greek equivalents to the familiar $x$ and $y$. We'll see $\xi$ and $\eta$ as arguments to functions that we will quickly be re-scaling and renaming $x$ and $y$.
:::


# Difference equations in 1 dimension

    Objectives:")
::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-2a", "Understand how discrete time operates and what a step is ")
state_objective("Dyn-2b", "Define a fixed point in discrete time and determine whether the fixed point is stable or unstable")
state_objective("Dyn-2c", "Understand the relationship between oscillations and stability as we step through discrete time")
```
:::

An important strategy in creating and understanding models of dynamics involves **fixed points**.  A fixed point is a value of the state which the dynamics leave untouched. For finite-difference equation dynamics, $${\mathbf X}_{n+1} = g({\mathbf X}_n)$$

At a fixed point, "tomorrow's" value is the same as "today": ${\mathbf X}_{n+1} = {\mathbf X}_n$; the state doesn't change with $n$. 

A fixed point ${\mathbf X}^\star$ satisfies 
$${\mathbf X}^\star = g({\mathbf X}^\star)\ \ \ \mbox{or, said another way,}\ \ \ g({\mathbf X}^\star) - {\mathbf x^\star} = 0$$
"Fixed point" is a mathematical term. In the sciences, you will hear the term "equilibrium state," "steady state," "resting point," or "balance point." For example, chemistry has a concept of [chemical equilibrium](https://en.wikipedia.org/wiki/Chemical_equilibrium), a state where the concentration of reactants and products doesn't change. Finding such equilibria is an important task in many areas of science and engineering.

Some dynamical systems don't display any fixed points, e.g. the orbit of the Earth around the Sun. Others have one or more. We're going to treat them mathematically by analysis of the function $g()$ that governs the dynamics.

There are several ways to find fixed points. 

1. If you have a simple algebraic form for $g()$ you can solve $g(x) = x$ for $x$. For instance, suppose $g(x) \equiv 4 x (1-x)$. Then the fixed points satisfy $$x^\star = 4x^\star (1-x^\star)$$  This has two solutions: one at $x^\star = 0$ and the other at $x^\star = 3/4$.  (Exercise: dBCKD6)

2. Numerical solving. If solving $g(x)=x$ is not so easy, then we can instead create a new function $h(x)\equiv g(x)-x$ and then solve for the zeros of $h()$.  The point of setting up the helper function $h()$ is that computer algorithms for finding zeros generally take a *function* as their input rather than an *equation*.  (Exercise: RLdGHh )

3. Graphically. Plot out the function $g(x) - x$ versus $x$. Find values of $x$ where the graph crosses zero. Each of these values is a fixed point $x^\star$.

For instance:
```{r eval=FALSE}
dom <- domain(x = c(0,10))
g <- makeFun(x + sin(x) ~ x) 
slice_plot(g(x) - x ~ x, dom) 
```

4. By iteration. Sometimes you can identify a fixed point by iterating the dynamics starting from different initial conditions. The following sandbox iterates a system for 100 steps. The `tail(5)` function returns just the last 5 rows of the data table, making it easier to see where the state ended up after many iterations.

```{r eval=FALSE}
g <- makeFun(x + sin(x) ~ x)
Iterate(g, x0=.872, 100) %>% tail(5)
```
You can look for different fixed points by trying different values for $x0$. 

(Exercise: Iw4IJW)

------

A tree provides a simple example of equilibrium. A living tree grows slowly, with essentially no change from day to day. The tree is usually in equilibrium with its surroundings. But there are disruptions that can place the tree out of equilibrium. The wind is a familiar disruption, changing the dynamics so that the tree no longer stands straight and still; it sways in the wind. A severe storm or a chain saw creates an opportunity for bigger disruption, removing the fixed point of upright posture and replacing it with an entirely different sort of fixed point. The steady, slow process of rot can weaken the equilibrium to the point where it no longer exists or is too weak to withstand the wind. The tree falls.

Mathematics provides several concepts for thinking about equilibrium and the loss of equilibrium. The idea of a **fixed point** is at the center of things. The idea of disruption also has a mathematical equivalent called "forcing." The slow change (as in the rot of a tree) leading to a dramatic, sometimes sudden, collapse is represented by a "bifurcation." We'll explore forcing and bifurcation later, when we've developed better tools and ways of thinking to understand dynamics.

Here we will examine the important topic of "stability." The word has a variety of related meanings in everyday life: a patient is stable when his or her condition is not worsening (or getting better), a chair is stable when it won't fall over, a stable personal relationship is much preferred to an unstable one, a person who is stable does not get upset or disturbed by a trivial incident.

In mathematics, "stability" is a property of dynamics near a fixed point. A fixed point is stable when an initial trajectory close enough to the fixed point leads to a trajectory that continues to get closer to the fixed point. A fixed point is unstable when initial conditions close to the fixed point lead to trajectories that tend away from the fixed point. 

In everyday life, we think about stability as a matter of how hard you can push something before it falls over. A coin standing on edge is not very stable in this sense, any palpable disturbance will cause it to fall over. But mathematically, stability is just about the response to infinitesimal disturbances. The coin standing on edge is mathematically stable. Large disturbances may lead to the state of a system leaving even a stable fixed point. Stability of mathematical fixed points is about *local* dynamics. The response to large disturbances is non-local or *global* dynamics, a much harder topic.

Use a `r sandbox_link()` to explore stability via iteration.

```{r eval=FALSE}
g <- makeFun(5*sin(x)^2 ~ x)
findZeros(g(x) - x ~ x)
Iterate(g, x0 = 0.0001, n=10)
```

[Exercise: YsZp7T]

[Advanced exercise: AvXzzY, eMT6Zn]

-----

Previously, we examined the stability of fixed points by using iteration: start at an initial condition arbitrarily close (but not exactly on!) a fixed point and see if the trajectory tends toward or away from the fixed point.

Now we'll look at stability another way, by considering the shape of of the dynamical function near a fixed point. At this point in CalcZ, you're aware that "near" suggests local, and that we routinely model (continuous) functions in terms of the value at a point, the value of the derivative at the point, and the value of the 2nd derivative at the point.

The stability of a fixed point is determined in all but very special situations by the slope of the function at the fixed point. Here's the rule: 

> In the dynamical system $x_{n+1} = g(x_n)$ with a fixed point at $x^\star$, the stability of that fixed point depends only on the magnitude of $\left| \partial_x g(x^\star) \right|$. The rule is: 

> If $\left| \partial_x g(x^\star) \right| > 1$, the fixed point at $x^\star$ is **unstable**.

> If $\left| \partial_x g(x^\star) \right| < 1$, the fixed point at $x^\star$ is **stable**.

Notice that it doesn't matter what is the **sign** of $\partial_x g(x^\star)$; the fixed point will be stable or not depending just on the magnitude of the derivative.

```{r eval=FALSE}
g <- makeFun(sin(x)^2 + 1 ~ x)
fixed_points <- findZeros(g(x) - x ~ x)
dg <- D(g(x) ~ x)

## Now, apply dg() to the fixed point(s)
dg(fixed_points)
```

[Exercise: 61zaad, F0nHmq, VesZTL, z7CO1o]


## Day 16 Exercises

`r insert_calcZ_exercise("XX.XX", "dBCKD6", "Exercises/Dynamics/snake-drive-socks.Rmd")`

`r insert_calcZ_exercise("XX.XX", "RLdGHh", "Exercises/Dynamics/spruce-type-chair.Rmd")`

`r insert_calcZ_exercise("XX.XX", "Iw4IJW", "Exercises/Dynamics/titmouse-drive-pantry.Rmd")`

`r insert_calcZ_exercise("XX.XX", "YsZp7T", "Exercises/Dynamics/calf-fly-boat.Rmd")`

`r insert_calcZ_exercise("XX.XX", "61zaad", "Exercises/Dynamics/calf-dive-pot.Rmd")`

`r insert_calcZ_exercise("XX.XX", "F0nHmq", "Exercises/Dynamics/turtle-become-magnet.Rmd")`

`r insert_calcZ_exercise("XX.XX", "VesZTL", "Exercises/Dynamics/titmouse-see-jacket.Rmd")`

`r insert_calcZ_exercise("XX.XX", "z7CO1o", "Exercises/Dynamics/finch-make-door.Rmd")`

`r insert_calcZ_exercise("XX.XX", "AvXzzY", "Exercises/Dynamics/crow-know-scarf.Rmd")`

`r insert_calcZ_exercise("XX.XX", "eMT6Zn", "Exercises/Dynamics/spider-dive-sheet.Rmd")`



# Difference equations in 2 dimensions

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-3a", "Learn how to construct future states of a dynamical system in two dimensions given the dynamical rule and the two-dimensional initial condition.")
state_objective("Dyn-3b", "Appreciate that global dynamics can be complicated, potentially with many fixed points, learn how to identify the locations of the fixed points.")
state_objective("Dyn-3c", "Understand how local dynamics near a fixed point are comparatively simple and can be meaningfully approximated by a matrix.")
state_objective("Dyn-3d", "Review the mechanics of matrix arithmetic and iterate a dynamical system written in terms of a matrix.")
```
:::

```{r echo=FALSE}
source("Exercises/Dynamics/draw_flow.R", local=TRUE)
```

We will be using finite-difference equations mainly for modeling physical processes. It turns out that the way forward is **not** to make the function $g(x)$ more complicated in $x_{n+1} = g(x_n)$ but instead to add more state variables. In this course, we'll deal with states with two quantities, $(x, y)$, which can be called a *two-dimensional* state. The systems we will study will involve two dynamical functions, each of which takes both $x$ and $y$ as arguments. That is:
$$x_{n+1} = f(x_n, y_n)\\
y_{n+1} = g(x_n, y_n)$$

For instance, here is one such system:
```{r echo=FALSE, out.width="100%", message=FALSE}
draw_flow()
```
The functions $f(x,y)$ and $g(x,y)$ are represented by short line segments with a tiny dot at one end. Each line segment connects $(x_n, y_n)$ to $(x_{n+1}, y_{n+1})$, with the dot at the $n+1$ end. 

Consider the line segment that starts at $(0,0)$. The end of the line segment is at about $(-0.101, -0.163)$. (You can't see such precision from the graph, but the author can!) This is just to say that for the particular $f()$ and $g()$ being displayed, $$f(0, 0) = -0.101\ \ \ \mbox{and}\ \ \ g(0,0) = -0.163$$ The result of the dynamics is to take a state of $(0,0)$ a bit to the "southwest," to $(-0.101, -0.163)$. From there you can take the next step, then the one after that, and so on to approximate the trajectory. It's very much like the state was being blown around in the wind, with the line segments indicating the direction and speed of the wind at any point.

```{r 2d1-1, echo=FALSE, results="markup"}
askMC(
  "Consider the line segments near $(2.5, 2.5)$. Which of these best describes the functions at that point?",
  "$f(2.5, 2.5) \\approx 0$ and $g(2.5.,2.5) < 0$",
  "+$f(2.5, 2.5) < 0$ and $g(2.5.,2.5) \\approx 0$+",
  "$f(2.5, 2.5) > 0$ and $g(2.5.,2.5) < 0$",
  "$f(2.5, 2.5) \\approx 0$ and $g(2.5.,2.5) > 0$"
)
```

The blue and red contour lines are added to the picture to help the viewer spot fixed points. The blue contour line is the zero contour of $f(x,y) - x$. Similarly, the red contour line is the zero contour of $g(x,y) - y$.

The left panel below shows the dynamics of $x$: that is $x_{n+1} = f(x_n,y_n)$. The right panel shows the $y$ dynamics: $y_{n+1} = g(x_n,y_n)$.

```{r echo=FALSE, out.width="50%", fig.show="hold", message=FALSE}
draw_flow(dy=0, center = c(-2,3), width=3, 
          ngrid=11, dx=0.2, arrow=2) %>%
  gf_labs(title = expression(x[n+1] == f(x[n],y[n])))  
draw_flow(dx=0, center = c(-2,3), width=3, 
          ngrid=11, dy=0.2, arrow=3) %>%
  gf_labs(title = expression(y[n+1] == g(x[n],y[n]))) %>%
  gf_refine(coord_fixed(xlim=c(-5, 1), ylim=c(-0.5, 5.5), clip="on"))
```

Note that in the x-dynamics plot, we're only seeing the change in $x$. That's why the line segments are all horizontal: they connect $x_n$ to $x_{n+1}$. The blue contour shows the points where $x_{n+1} = x_n$: The line segment is just a dot. For this particular $f(x,y)$ the segments starting at places to the right of the contour point to the left; the segments starting to the left of the contour point to the right. At the contour, the segments point neither left nor right: they are fixed points with respect to $x$. 

The right panel is similar, but shows the dynamics of $y$. Since the plot shows only the change in $y$, the segments are all oriented in the $y$ direction. For this particular $g(x,y)$, segments above the contour point upward, segments below the contour point downward, and segments on the contour show no change in $y$.

The original graph shows both the $x$ and $y$ dynamics simultaneously. Where the blue and red contours cross, there is a fixed point in both $x$ and $y$. You can see 3 such fixed points (with a fourth suggested near the top of the graph). 

[Exercises: KzgT1c, 3A3pMv]

-----


Consider a tuning fork as an example of a dynamical system. Ordinarily it's in equilibrium: silent. But after you tap it, it rings, the ringing dying out over time. The design and use of a turning fork is all about the transient vibrations as the fork returns to equilibrium, its fixed point. 

We are going to focus on a small but important part of dynamics: the behavior **near** a fixed point. Up until now, we've considered only stability or instability. But now we want to know a bit more, about the behavior of the transient approaching **near** a stable fixed point or the escape from **near** an unstable one.

We're going to use an approach that's familiar in calculus: zoom in on the region very close to fixed points.

"Very close" can mean different things to different people. In calculus, *very close* is often taken to mean, "so close that the system is well approximated as a linear system." That is, instead of looking at general, nonlinear functions of the dynamics, we're going to look only at dynamics involving linear functions. The system we are going to study will be this one:
$$\xi_{n+1} = \mu + \alpha\, \xi_n + \beta\, \eta_n\\
\eta_{n+1} = \nu + \gamma\, \xi_n + \delta\, \eta_n$$

Where $\alpha, \beta, \gamma, \delta, \nu, \mu$ are all constant scalars, and $\xi$ ("ex-eee", Greek for x) and $\eta$ ("ay-tah", Greek for $y$). 

There is a lot of Greek in the above equation, but don't let it worry you. That's because we're going to simplify things even more.

Since we're interested in behavior **near** a fixed point $(\xi^\star, \eta^\star)$, we'll define new state variables that are centered on the fixed point:
$$x = \xi - \xi^\star\\
y = \eta - \eta^\star$$
In terms of $x$ and $y$, the fixed point is at $(0,0)$.

The dynamics **near** this stable fixed point now become:
$$x_{n+1} = a x_n + b y_n\\
y_{n+1} = c x_n + d y_n$$

We don't need terms like $\mu$ and $\nu$ in the $(\xi, \eta)$ system, because when $(x_n = 0, y_n=0)$ both $x_{n+1}$ and $y_{n+1}$ will be zero: a fixed point at $(0,0)$! 


It's just the four parameters $a, b, c$, and $d$ that shape the dynamics. It can be handy to adopt a vector/matrix notation to highlight the role of the four parameters without distracting from all the $x_n$ and $y_n$ notation. Do do this, we'll put $x_n$ and $y_n$ into a single vector, which we'll call ${\mathbf X}_n$. (Note the boldface **x** to signify that it is a vector, rather than a scalar wich is written unbolded, $x$.)
$$
\left[ \begin{array}{c}x_{n+1}\\y_{n+1}\end{array} \right] \equiv\ \ \ \ {\mathbf X}_{n+1} = 
\left[ \begin{array}{cc}a & b\\c & d\end{array} \right] 
{\mathbf X}_n \ \ \ \ \equiv 
\left[ \begin{array}{c}a x_{n} + by_n\\c x_n + d y_{n}\end{array} \right]
$$
It's important to remember that writing the dynamics as 
$${\mathbf X}_{n+1} = 
\left[ \begin{array}{cc}a & b\\c & d\end{array} \right] 
{\mathbf X}_n$$ 
doesn't change anything about the dynamics, it's just a more compact notation. 

We could simplify even more by giving a name to the [abcd] matrix, like this:
$${\mathbf X}_{n+1} = {\mathbf A}\cdot {\mathbf X}_n$$
But we'll be wanting to look at the role played by each of the four parameters $a, b, c$, and $d$, so we'll continue to write out the matrix components. 


The price we pay for limiting ourselves to linear dynamics is that we can't necessarily describe the global behavior of dynamics, just the behavior in a small locale. It turns out in science and engineering that this is often all that we need. (We'll look at some dynamical models that rely on nonlinearity in future days.)

-----

Recall some of the concepts we used in exploring *linear combinations*.

- a **vector** is a mathematical object with two properties: magnitude (length) and direction. We wrote vectors as a column of numbers, for instance $${\mathbf v} = \left[\begin{array}{r}3\\-1\\8\end{array}\right]\ \ \ \mbox{or}\ \ \ {\mathbf u} =\left[\begin{array}{r}2\\-3\end{array}\right]$$ The dimension of a vector is the count of numbers used in its representation: 3 for $\mathbf v$ and 2 for $\mathbf u$.
- a **matrix** is a collection of vectors, all of which have the same dimension. For instance: 

$${\mathbf M} =\left[\begin{array}{rrr}3 & 1 & 0\\-1 & 4 & -2\\8 & 0 & 12\end{array}\right]\ \ \ \mbox{or}\ \ \ {\mathbf P} =\left[\begin{array}{rr}-1 & 2\\7 & 0\end{array}\right]$$

- **multiplying** a matrix times a vector produces a new vector which is a *linear combination* of the vectors in the matrix. For instance:

$${\mathbf P}\cdot{\mathbf u} = \left[\begin{array}{rr}-1 & 2\\7 & 0\end{array}\right] \cdot \left[\begin{array}{r}2\\-3\end{array}\right] =
2 \left[\begin{array}{r}-1\\7\end{array}\right] + -3 \left[\begin{array}{r}2\\0\end{array}\right] = \left[\begin{array}{r}-7\\14\end{array}\right]$$

There's a simplification of the [abcd]-style matrix that is particularly important in the way dynamics are written in physics and related disciplines. That matrix has the form $$\left[\begin{array}{cc}a & b\\1 & 0\end{array}\right]$$
We'll call this an [ab10]-format matrix.

It's worth emphasizing the special form of the equations corresponding to an [ab10] matrix:

$$\underbrace{\left[\begin{array}{c}x_{n+1}\\y_{n+1}\end{array}\right]}_\mbox{next state} =  
\underbrace{\left[\begin{array}{rr}a & b\\1 & 0\end{array}\right]}_\mbox{[ab10] format matrix} \cdot\underbrace{\left[\begin{array}{c}x_n\\y_n\end{array}\right]}_\mbox{current state} = 
\left[\begin{array}{rcr}a\, x_n & + & b\, y_n \\x_n & & \end{array}\right]$$
Since both $x_n$ and $y_n$ are numerical quantities, you'll often work with the system like this:

$$\underbrace{\left[\begin{array}{c}x_{n+1}\\y_{n+1}\end{array}\right]}_\mbox{next state} =  
\underbrace{\left[\begin{array}{rr}a & b\\1 & 0\end{array}\right]}_\mbox{[ab10] format matrix} \cdot\underbrace{\left[\begin{array}{r}3\\-1\end{array}\right]}_\mbox{current state} = 
\left[\begin{array}{rcr}3 a & + & (-1)b \\3 & & \end{array}\right]$$

[Exercise: j2ettP ]








## Day 17 Exercises


`r insert_calcZ_exercise("XX.XX", "KzgT1c", "Exercises/Dynamics/crow-find-sofa.Rmd")`

`r insert_calcZ_exercise("XX.XX", "on164B", "Exercises/Dynamics/seaweed-bite-shoe.Rmd")`

`r insert_calcZ_exercise("XX.XX", "3A3pMv", "Exercises/Dynamics/bee-wake-bottle.Rmd")`

`r insert_calcZ_exercise("XX.XX", "j2ettP", "Exercises/Dynamics/shark-understand-saw.Rmd")`

`r insert_calcZ_exercise("XX.XX", "PTn8Yk", "Exercises/Dynamics/aspen-take-cotton.Rmd")`





# Wrap-up Discrete Time difference equations

  

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-4a", "Understand how eigenvalues can describe the properties of difference equations in discrete time")
state_objective("Dyn-4b", "Understand sequences as steps through discrete time")
```
:::

# Continuous-Time differential equation in 1 dimension


::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-5a", "Using slope fields, understand that a differential equation has a family of solutions")
state_objective("Dyn-5b", "Determine a particular solution to a differential equation in one dimension")
state_objective("Dyn-5c", "Determine end behavior of a differential equation graphically")
state_objective("Dyn-5d", "Describe a scenario using proportional or inversely proportional growth with a differential equation")
```
:::

# Continuous-Time differential equation in 2 dimensions


::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn6-lost", "Determine a particular solution to a differential equation in two dimensions")
state_objective("Dyn-6a", "Describe a scenario using logistics growth with a differential equation")
state_objective("Dyn-6b", "Understand the three types of dynamics stable, instable, and saddle points and how lambda values can clearly show which one is which")
```
:::

# Catch-up: Review Day

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-7a", "Understand the benefits of using the exponential function as an educated guess for a solution to a differential equation")
state_objective("Dyn-7b", "Comprehend how solutions to differential equations can have complex eigenvalues")
state_objective("Dyn-7c", "Understand how complex eigenvalues are related to oscillations")
```
:::

 Force-balance equation

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-8a", "Damped harmonic oscillator example")
state_objective("Dyn-8b", "Translate eigenvalues into the description of qualitative dynamics")
state_objective("Dyn-8c", "Understand eigenvectors and their connection to flow fields")
```
:::

Nonlinear phase plane and systems of nonlinear differential equations

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-9a", "Interpret phase plane diagrams, flow field diagrams, and time series plots of nonlinear systems of differential equations")
state_objective("Dyn-9b", "Be able to interpret individual terms in a dynamical function that describes specific relationships among real-world objects")
state_objective("Dyn-9c", "Predator-prey model")
state_objective("Dyn-9d", "Attrition model")
```
:::

Complex Eigenvalues

::: {.objectives}
```{r echo=FALSE, results="asis"}
state_objective("Dyn-10a", "Understand the benefits of using the exponential function as an educated guess for a solution to a differential equation")
state_objective("Dyn-10b", "Comprehend how solutions to differential equations can have complex eigenvalues")
state_objective("Dyn-10c", "Understand how complex eigenvalues are related to oscillations")
```
:::
