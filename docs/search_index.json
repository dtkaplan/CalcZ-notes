[["index.html", "CalcZ Student Notes Welcome to calculus Computing and apps Exercises and feedback", " CalcZ Student Notes Daniel Kaplan 2021-07-01 Welcome to calculus Calculus is the set of concepts and techniques that provide the main mathematical basis for dealing with motion, growth, decay, and oscillation. The phenomena can be as simple as a ball arcing ballistically through the air or as complex as the airflow over a wing that generates lift. Calculus is used in biology and business, chemistry, physics and engineering. It is the basis for weather prediction, understanding climate change, the algorithms for heart rate and blood oxygen measurement by wristwatches. It is a major part of the language of science, of logistics. The electron orbitals of chemistry, the stresses of bones and beams, and the business cycle of recession and rebound are all understood primarily through calculus. 10 Calculus has been central to science from the very beginnings. It is no coincidence that the scientific method was introduced and the language of calculus was invented by the same small group of people during the historical period known as the Enlightenment. Learning calculus has always been a badge of honor and an entry ticket to professions. Millions of students career ambitions have been enhanced by passing a calculus course or thwarted by lack of access to one. In the 1880s, a hit musical featured “the very model of a modern major general.” One of his claims for modernity: “I’m very good at integral and differential calculus.”1 What was modern in 1880 is not modern anymore. Yet, amazingly, calculus today is every bit as central to science and technology as it ever was, and is much more important to logistics, economics and myriad other fields than ever before. In the last 20 years, calculus has become even more important. The reason is that science, engineering, and society have now fully adopted the computer for almost all aspects of work, study, and life. The amount of data collected and used has exploded. Machine learning has become the way human decision makers interact with such data. Think about what it means to become “computerized.” To take an everyday example, consider video. Over the span of a human life we moved from a system which involved people going to theaters to watch the shadows recorded on cellulose film to the distribution over the airwaves by low-resolution television, to the introduction of high-def broadcast video, to on demand streaming from huge libraries of movies. Just about anyone can record, edit, and distribute their own video. The range of topics (including calculus) on which you can access a video tutorial or demonstration is incredibly vast. All of this recent progress is owed to computers. 20 The “stuff” that computers operate on, transform and transmit is always mathematical representations stored as bits. The creation of mathematical representations of objects and events in the real world is essential to every task of any sort that any computer performs. Calculus is a key component of inventing and using such representations. You may be scratching your head. If calculus is so important, why is it that many of your friends who took calculus came away wondering what it is for? What’s so important about “slopes” and “areas” and how come your high-school teacher couldn’t tell you what calculus is for? The disconnect between the enthusiasm expressed in the preceding paragraphs and the lived experience of students is very real. There are two major reasons for that disconnect, both of which we tackle head-on in this book. First, teachers of mathematics have a deep respect for tradition. Such respect has its merits but the result is that almost all calculus is taught using methods that were appropriate for the era of paper and pencil, but not for the computer era. As you will see, in this book we express the concepts of calculus in a way that carries directly over to the uses of calculus on computers and in genuine work. 30 Second, the uses of calculus are enabled not by the topics of Calc I and Calc II, but the courses for which I/II are a preliminary: linear algebra and dynamics. Only a small fraction of students who start in Calc I ever reach the parts of calculus that are the most useful. Fortunately, there is a large amount of bloat in the standard textbook topics of Calc I/II which can be removed to make room for the genuinely important topics. We try to do that in this book. Computing and apps The text provides two complementary ways to access computing. The most intuitive is designed purely to exercise and visualize mathematical concepts through mouse-driven, graphical apps. To illustrate, here is an app that we’ll use in Block 6. You can click on the snapshot to open the app in your browser. More fundamentally, you will be carrying out computing by composing computer commands and text and having a computer carry out the commands. One good way to do this is in a sandbox, a kind of app which provides a safe place to enter the commands. You’ll open the sandbox (click on the image below) in your browser. Once you’ve entered the computer commands, you press the “Run” button to have the commands carried out.40 You may prefer to install the R and RStudio software on your own laptop. This usually provides a faster response to you and lowers the load on the sandbox cloud servers being used by other students. Experienced R users may even prefer to skip the sandbox entirely and use the standard resources of RStudio to edit and evaluate their computer commands. You’d use exactly the same R commands regardless of whether you use a cloud server or your own laptop. An important technique for teaching and learning computing is to present scaffolding for computer commands. At first, the scaffolding may be complete, correct commands that can be cut-and-paste into a sandbox where the calculation will be carried out. Other times it will be left to the student to fill in some part that’s been left out of the scaffolding. For example, when we introduce drawing graphs of functions and the choice of a domain, you might see a scaffold that has blanks to be filled in: slice_plot( exp(-3*t) ~ t, domain( --fill in domain-- )) You can hardly be expected at this point to make sense of any part of the above command, but soon you will. Exercises and feedback Learning is facilitated by rapid, formative feedback. Many of the exercises in this book are arranged to give this.50 Short answer exercises are often arranged to give immediate feedback that goes beyond right-or-wrong. In other words, when an answer is incorrect, we try to tell you why it is incorrect to provide a hint to guide you to the correct answer. As a frivolous example: Question A What does the word calculus mean literally? A small stone ✓ Such stones were part of an apparatus for doing numerical calculations, back in the days before the pencil was invented. A source of trouble to students. ☹︎ Calculus sometimes has that reputation, but as they say, “No pain, no gain.” Find a better answer. The element calcium. ☹︎ No, but when you get the right answer you’ll realize the two are related in some cases. Some exercises are meant as drill, and provide only right-or-wrong feedback. Still other exercises provide no feedback at all. Typically, these are intended to raise the stakes for graded work, encouraging you to think carefully before choosing an answer. Watch here↩︎ "],["outline-of-block-1.html", "Outline of Block 1", " Outline of Block 1 This section is for development purposes only. It is not to be included in the released text. This outline was that established during the May 17-19, 2021 working sessions at USAFA. It’s copied directly from the Teams document. I’ve made some modifications which are noted in [[square brackets]] for deletions and bold face for additions.. Block 1 Functions and Mathematical Modeling Intro to the course NTI We can make the point about Linear Function is the model for change by drawing pictures or discussing how certain quantities change between two points in time The discussion about Calc Z should not be about “How is Z different,” but “Z is the new Calculus to which USAFA is transitioning; you may see differences between this course and the traditional course that some of your peers are taking.” Oveall goal for day 1 is to build cadet’s confidence that they can be successful. This requires us to show them the systems, resources, philosophy, and expectations (e.g., college \\(\\neq\\) high school) behind the course. Lecture Topics Calculus Z overview and trajectory Course resources and systems Calculus is the study of change Linear Function is the model for “change” because it has “slope” Outcomes Understand than an equation relates quantities, but a function maps inputs to outputs Understand the difference between \\(\\equiv\\) and \\(=\\) Be able to identify a function’s input Readings (assigned M1, skim before, read after) Chapter 1 Additional Resources None Assignments HW01 Feedback01 DD01 Basics of modeling functions NTI Emphasize that functions map inputs to outputs, but the naked functions are (by themselves) not flexible enough for most circumstances Show students graph of 5 naked functions, have them pick which is which Points out that a truly naked straight-line is just \\(x\\), and use that as the introduction to parameterization Show scatter plot of \\(f(x)\\equiv -x+2\\) and explain why \\(f(x)\\equiv x\\) is not a good model to motivate basic modeling function Lecture Topics Naked modeling functions Basic Modeling functions and their behaviors based on their parameters Outcomes Know graphs, domains, ranges, horizonal/veritcal intercepts &amp; asymptotes (if any) for all the naked modeling functions Recognize that functions are a way of modeling relationship in the real-world Given parameters, describe how those parameters affect the shape of the function Readings: Section 3 and Chapter 2 Additional Resources PDF - Exponential Functions Deep Dive Math Insight - Logarithm basics Khan Academy - Properties of Logarithms RESOURCE FOR TRIG VALUES (TRIG TABLE) Assignments DD02 Functions as I/O and Notational Structure of functions (R&lt;&gt;Math) NTI Rewrite \\(y=mx+b\\) as \\(mx-y+b=0\\) to show function notation eliminates ambiguity of IO Break student habit of using “x-axis” or “y-axis”; describe these as “horizontal” or “vertical” axes Break student habit of using “x” and “y”; instead they should say “input” and “output” Explain that parameters scale or shift inputs/outputs. Ex: the \\(C\\) in \\(Ce^{kt}\\) scales the output and the \\(k\\) scales the input Example function without a formula: \\(f:Cadet\\to RoomNumber\\) Topics Functions as Input and Ouptut (IO) Introduce Multi-input functions Function Representations Notation and Conventions Distinguish between mathematical symbols: \\(=\\), \\(\\equiv\\), $, &lt;- See Secton 5.8 Outcomes Understand that a function maps inputs to outputs Given an input, be able to find the output of a function in any one of the five standard forms: Graphs of functions (including contour plots) Tables of inputs and outputs Word descriptions Computer function name Mathematical notation Be able to translate between traditional math notation and R expressions Reading: Chapter 5 &amp; 6 To do: Provide glossary of notation across 6-blocks (+alternate forms) Assignments DD03 Parameterized functions as models NTI Introduce idea that input has meaning, and output has meaning relative to the input Give students a function. Then change the units of input to a different unit (e.g. feet go to Meters) Logarithms are not necessarily used as the end model; they are the lever which seperate power from exponential functions TODO: Think about physical phenomenon that would appropriately be modeled by a Logarithmic function or power with \\(p&lt;1\\) Focus the lesson entirely on finding parameters for Sine, Power, and Exponential Lecture Topics: Modeling phenomenon with the basic modeling functions How to find parameters for basic modeling functions Linear Sine Power Exponential Logarithmic (note) Objectives Given a description of a real-world scenario, be able to identify the appropriate basic modeling function Given data, select parameters of the basic modeling functions that “fit” the data Reading: Chapter 7 [[Combining 2+ functions]] I’ve integrated this with the “Parameterized function” chapter. Examples NTIs Topics Linear Combination (ex: Polynomial) Composition with scaling function (\\(e^{kt}) 1. Gallons/\\) to Liters/Euros Composition (affine shift) 1. Fahrenheit &lt;&gt; Celsius The modeling process Slope function NTI: How do broaden the idea of describing the slope of a line to a general function? No \\(h\\) at this point The slope function is a function \\(s()\\) which is built from a function \\(f()\\) Topics Average rate of change. (Example: Quarterly return of stocks. HW of tree harvesting.) (Example 2: Sine wave with difference around 1 period. Or maybe this becomes low-pass filter example in accumulation.) \\(s(x) \\equiv \\frac{f(x + 0.1) - f(x)}{0.1}\\) Except for linear function, slope function depends on how big \\(h\\) is. So let’s fix \\(h\\) while we figure things out. Every function has a slope function. It’s helpful to name functions so we know where they come from. We’re going to use \\(f&#39;()\\) to stand for the slope function of \\(f()\\) Reading: Chapter 9 Composition Generally NTI: What temperature is it while driving up a mountain? Problem where they are calculating the slope of a sigmoid Topics: Formula for Hump (exponential with a quadratic) Driving up a mountain temperature vs altitude, altitude vs road position, road position vs time Hump is the slope function of Sigmoid Reading: Chapter 11 Multiplication of functions NTIs: Multiplication about Sines, exponential, hump, sigmoid Topics: Multiplying functions of the same inputs gives a function of those inputs. Multiplying functions of different inputs gives a function whose inputs are the union of the inputs to the multiplicands. Be able to reverse engineer these products: sinexp, sinhump, sinsigmoid Reading: Chapter 11 Multivariate functions NTIs: Ask students how they compute the slope of a multi-input function as best they can imagine how (homework?) Build their imagined function (for the slope) and plot the function Outcomes: Be able to read &amp; construct (in R) Contour Plots Be able to read &amp; construct (in R) Surface Plots Be able to read a table w/ 2 inputs Reading: Chapter 12 Piecewise functions [jettison if needed in favor of doing this as homework] Topics Construct and evaluate piecewise functions Demonstrate how to implement in R Outcomes: Be able to identify break(s) of a piecewise function Be able to evaluate a piecewise function at a given input Be able to implement a piecewise function in R Reading: Chapter 13 Iterative Modeling NTI: Examples: Tides Cooling Water Objectives: Describe differences between two models and between a model and data Identify disagreements between the model and data d: Reading: NEED LINK TO CHAPTER Review, GR, Project Days [[Semi-log Log-log plots]] Magnitude and log Topics: Introduce the idea that using logarithms converts a number to its order of magnitude Outcomes: Reading: Chapter 14 Flexible catchup day Dimensional Analysis Reading: Chapter 15 1.5 class days One of our highlighting formats, called ::: {.takenote} is being used as a clear statement of basic skills that a students should master. It might be good to tie quizzes to these and vice versa. "],["change.html", "Chapter 1 Change 1.1 Quantity vs number 1.2 Functions", " Chapter 1 Change Calculus is about change, and change is about relationships. A changing climate is about the relationship between, say, global average temperature and time. It’s also about changing levels of CO2 and methane, both their production and elimination by atmospheric and geological processes. It’s about how burning oil (a change in configuration of the atoms in hydrocarbons) contributes to ocean acidification (the process of change in ocean pH). It’s about a whole complex and intricate network of relationships and how change in one component provokes change in others. 100 This book presents calculus in terms of two simple but central concepts: functions and quantities. Those words have everyday meanings which are, happily, close to the specific mathematical concepts that we will be using over and over again. Close … but not identical. So pay careful attention to the brief descriptions that follow. 1.1 Quantity vs number A mathematical quantity is an amount of “stuff.” The real-world stuff might be mass or time or length. It equally well can be velocity or volume or momentum or corn yield per acre. We live in a world of stuff, some of which is tangible (e.g., corn, mass, force) and some of which is harder to get your hands on and your minds around (acceleration, crop yield, fuel economy). An important use of calculus is helping us conceptualize the abstract kinds of stuff as mathematical compositions of simpler stuff. For example, crop yield incorporates mass with length and time. Later, you’ll see us using the more scientific-sounding term dimension instead of “stuff.” In fact, Chapter 15 is entirely dedicated to the topic of dimensions, but for now it’s sufficient for you to understand that numbers alone are not quantities. Most people are inclined to think “quantity” is the same as “number”; they conflate the two. This is understandable but misguided. By itself a number is meaningless. What meaning does the number 5 have without more context? Quantity, on the other hand, combines a number with the appropriate context to describe some amount of stuff. So, the first thing you need to know about any quantity is the kind of stuff it describes. A “mile” is a kind of stuff: length. A meter is the same kind of stuff: length. A liter is a different kind of stuff: volume. A gallon and an acre-foot are the same kind of stuff: volume. “Stuff,” as we mean it here, is what we measure. As you know, we measure with units. Which units are appropriate depends on the kind of stuff. Meters, miles, microns are all appropriate units of length, even though the actual lengths of these units differ markedly. (A mile is roughly a million microns.) 110 Only after you know the dimension and units does the number have meaning. Thus, a number is only part of specifying a quantity. Here’s the salient difference between number and quantity when it comes to calculus: All sorts of arithmetic and other mathematical operations can be performed to combine numbers: addition, multiplication, square roots, etc. When performing mathematics on quantities, only multiplication and division are universally allowed. For addition and subtraction, square roots, and such, the operation makes sense only if the dimensions are suitable. The mathematics of units and dimension are the equivalent in the technical world of common sense in our everyday world. For instance (and this may not make sense at this point), if someone tells me they are taking the square root of 10 liters, I know immediately that either they are just mistaken or that they haven’t told me essential elements of the situation. It’s just as if someone said, “I swam across the tennis court.” You know that they either used the wrong verb—walk and run would work—or that it wasn’t a tennis court, or that something important was unstated, perhaps, “During the flood, I swam across the tennis court.” 1.2 Functions The other central concept in the book is functions in their mathematical and computing sense; this is the primary topic for Block 1. A function is something that takes one or more inputs and returns an output. In calculus, we’ll deal mainly with functions that take one or more quantities as inputs and return another quantity as output. But sometimes we’ll work with functions that take functions as input and return a quantity as output. And there will even be functions that take a function as inputs and return a function as an output. You’ve almost certainly seen functions expressed in the general form \\(f(x)\\). The function is \\(f()\\), the input is \\(x\\). Perhaps it’s obvious at this point that \\(x\\) is a quantity. \\(f(x)\\) is the operation performed on that quantity. In computing, there are definite, widely used, notations to identify the output of a function. Strangely, in high-school mathematics there is not. This is a major source of confusion both to students learning calculus and professionals using computers to do the work of calculus. 120 It’s possible to present calculus without functions. For instance, Isaac Newton, the inventor of calculus, spoke of “flowing quantities.”2 It’s practically impossible (and generally unwise) to do computing without functions. They are a basic building block of every mainstream modern computer language. Since the operations of calculus in actual practice are performed on the computer, common sense suggests that we should describe calculus in terms of functions. That’s what we will do in this book. For you, this may take a bit of getting used to. The reason is that the notation used in high-school algebra and in almost all calculus texts is not the notation of functions. For example, almost all students have seen a mathematical expression in this form: \\[y = m x + b\\] Using the language of math classes, we can say that the expression “describes a relationship between two variables.” And from your experience, you know that the variables are \\(x\\) and \\(y\\). The other letters, \\(m\\) and \\(b\\), are something else. Many students will reflexively call them the “slope” and “intercept” of the “line.” You are so used to this that you probably don’t see the huge ambiguity involved. For instance, what is a variable? Common sense suggest that it’s a thing that varies. But if we know the value of \\(x\\), is it still a variable? In statistics, a variable is something else entirely: a trait. Since statistics and mathematics are used together, this is bound to bring confusion. 130 Or consider famous famous sentence in high-school mathematics: \\[y = m x + b\\] The notation of equations is a poor substitute for the notation of functions. For instance, what is the input and what is the output? It’s not explicitly stated. If, using the allowed manipulations of algebra, we re-arrange \\[y = m x + b \\ \\ \\text{into}\\ \\ \\ m = \\frac{y-b}{x}\\] do we still have a function? If so, is it the same function as \\(m x + b\\)? Would \\(x\\) be the input or would both \\(x\\) and \\(y\\) be inputs? How about \\(b\\)? And in the re-arrangement, we have a problem if \\(x\\) is zero, a problem we would never encounter in the original \\(y=mx+b\\). The engineers and mathematicians who invented computer languages realized that they had to be explicit in identifying the input, the output, and the function itself; computers demand unambiguous instructions.3 Sorting this out was a difficult process even for those mathematically talented and skilled pioneers of notation. So, you can be forgiven for the occasional confusion you have when dealing with notation that pre-dates computing. 140 In this book we’ll be explicit and consistent in the ways we denote functions so that you can always figure out what are the inputs and how they are being translated into the output. A good start in learning to read the function notation is to see the equivalent of \\(y=m x + b\\) in that notation: \\[g(x) \\equiv m x + b\\] Notice that we’re using \\(\\equiv\\) (with three parallel bars) rather than \\(=\\). And there’s no \\(y\\). The \\(x\\) appears in parentheses on the left side of \\(\\equiv\\) to say explicitly “\\(x\\) stands for the input.” The notation provides a place to state the name of the function, in this case \\(g()\\), so that we can refer to the function unambiguously when we are doing operations on it. Since often we’ll be using many functions at the same time, it’s helpful to have a way to distinguish them by name. The functional notation makes it easy to create many different names: not just \\(y\\) but \\(g_\\star()\\), \\(h_\\text{altitude}()\\), azimuth(), and so on. Try that with \\(y\\) In Newton’s language, a “flowing quantity” was a fluent and the change in a flowing quantity was a fluxion.↩︎ Actually, it’s common to give computers ambiguous instructions. The computer will carry out the instruction in the way it does, which may not be anything like what the programmer expected or intended.↩︎ "],["structure-of-a-function.html", "Chapter 2 Structure of a function 2.1 Inputs to output 2.2 A bureaucratic analogy 2.3 Domain: input space 2.4 Range: output space", " Chapter 2 Structure of a function [F-10] Recognize that functions are a way of representing (storing) what we know and be able to use properly the basic nomenclature of functions). You’re used to mathematical functions being stated as formulas, expressions composed of addition, multiplication, square roots, and so on. The expression \\(m x + b\\) uses a multiplication and an addition. \\(\\sqrt{\\strut 1 - x^2}\\) uses exponentiation (\\(x^2\\)), subtraction and square root. 200 There’s nothing in the mathematical concept of “function” that requires a formula. And computer functions in general are not based on an algebraic formula. The word used to describe the internals of a computer function is algorithm, which is a generalization of “formula” that includes many non-arithmetic operations such as looping and branching. 2.1 Inputs to output We will be using formulas extensively, but best if you can visualize functions generally as something that’s not necessarily a formula. This section gives another perspective on how to describe and think about a function. But remember, functions take inputs and return the corresponding output. Any arrangement that accomplishes this is a function, even if arithmetic is nowhere in sight. A simple and useful framework for organizing what we know is the table, generally set up as an array of rows and columns. For instance, here is a table about a range of internal combustion engines of various sizes: Engine mass BHP RPM bore stroke Webra Speed 20 0.25 0.78 22000 16.5 16 Enya 60-4C 0.61 0.84 11800 24.0 22 Honda 450 34.00 43.00 8500 70.0 58 Jacobs R-775 229.00 225.00 2000 133.0 127 Daimler-Benz 609 1400.00 2450.00 2800 165.0 180 Daimler-Benz 613 1960.00 3120.00 2700 162.0 180 Nordberg 5260.00 3000.00 400 356.0 407 Cooper-Bessemer V-250 13500.00 7250.00 330 457.0 508 Each row of the table reports on one, specific engine. Each column is one attribute of the of an engine. Using such tables can be easy. For example, if asked to report how fast the engine named “Enya 60-4C” spins, you would go down to the Enya 60-4C row and over to the “RPM” column and read off the answer: 11,800 revolutions per minute (RPM). A table like this describes the general relationships between engine attributes. For instance, we might want to understand the relationship (if any) between RPM and engine mass, or relate the diameter (that is, “bore”) and depth (that is, “stroke”) of the cylinders to the power generated by the engine. Any single entry in the table doesn’t tell us about such general relationships; we need to consider the rows and columns as a whole. 210 If you examined the relationship between engine power (BHP) and bore, stroke, and RPM, you will find that (as a rule) the larger the bore, stroke, and RPM, the more powerful the engine. That’s a qualitative description of the relationship. Most educated people are able to understand such a quantitative description. Even if they don’t know exactly what “power” means, they have some rough conception of it. Often, we’re interested in having a quantitative description of a relationship such as the one (bore, stroke, RPM) \\(\\rightarrow\\) power. Remarkably, many otherwise well-educated people are uncomfortable with the idea of using quantitative descriptions of a relationship: what sort of language the description should be written with; how to perform the calculations to use the description; how to translate between data (such as in the table) and a quantitative description; how to translate the quantitative description to address a particular question or make a decision. This course is about constructing and using such quantitative descriptions: that is, mathematical modeling. Skills for modeling are essential for work in engineering and science, and highly valued in many other fields in commerce, management, and government. Often, the work of applying such quantitative skills is called calculation. The name calculus is used to describe the methods that are widely used for undertaking calculations. Functions are a fundamental way of organizing mathematical models and calculations. You have undoubtedly seen them in your previous mathematics education, but it’s worth reviewing them from the basics so that we can share a vocabulary for communicating about them. A function is a transformation from one or more inputs to an output. To keep things simple for now we’ll focus on inputs and outputs that are numeric, but later we’ll need a more nuanced view of “numeric” that takes into account the different kinds of things that are represented by numbers, e.g. length, power, RPM. 2.2 A bureaucratic analogy You’ll have many opportunities to work with functions defined by formulas. Here, I want to emphasize that functions are really just a way of storing a correspondence of inputs to outputs and that formulas need have nothing to do with it except as one way of describing the pattern. Instead of a formula, imagine a long corridor with a sequence of offices, each identified by a room number. The input to the function is the room number. To evaluate the function for that input, you knock on the appropriate door and, in response, you’ll receive a piece of paper with a number to take away with you. That number is the output of the function. 220 This will sound at first too simple to be true, but … In a mathematical function each office gives out exactly the same number every time someone knocks on the door. Obviously, being a worker in such an office is highly tedious and requires no special skill. Every time someone knocks on the worker’s door, he or she writes down the same number on a piece of paper and hands it to the person knocking. What that person will do with the number is of absolutely no concern to the office worker. The utility of such functions depends on the artistry and insight of the person who creates them: the modeler. An important point of this course is to teach you some of that artistry. Hopefully you will learn through that artistry to translate your insight to the creation of functions that are useful in your own work. But even if you just use functions created by others, knowing how functions are built will be helpful in using them properly. In the sort of function just described, all the offices were along a single corridor. Such functions are said to have one input, or, equivalently, to be functions of one variable. To operate the function, you just need one number: the address of the office from which you’ll collect the output. Many functions have more than one input: two, three, four, … tens, hundreds, thousands, millions, …. In this course, we’ll work mainly with functions of two inputs, but the skills you develop will be applicable to functions of more than two inputs. What does a function of two inputs look like in our office metaphor? Imagine that the office building has many parallel corridors, each with a numeric ID. To evaluate the function, you need two numeric inputs: the number of the corridor and the number of the door along that corridor. With those two numbers in hand, you locate the appropriate door, knock on it and receive the output number in return. 230 Three inputs? Think of a building with many floors, each floor having many parallel corridors, each corridor having many offices in sequence. Now you need three numbers to identify a particular office: floor, corridor, and door. Four inputs? A street with many three-input functions along it. Five inputs? A city with many parallel four-input streets. And on and on. Applying inputs to a function in order to receive an output is only a small part of most calculations. Calculations are usually organized as algorithms, which is just to say that algorithms are descriptions of a calculation. The calculation itself is … a function! How does the calculation work? Think of it as a business. People come to your business with one or more inputs. You take the inputs and, following a carefully designed protocol, hand them out to your staff, perhaps duplicating some or doing some simple arithmetic with them to create a new number. Thus equipped with the relevant numbers, each member of staff goes off to evaluate a particular function with those numbers. (That is, the staff member goes to the appropriate street, building, floor, corridor, and door, returning with the number provided at that office.) The staff re-assembles at your roadside stand, you do some sorting out of the numbers they have returned with, again following a strict protocol. Perhaps you combine the new numbers with the ones you were originally given as inputs. In any event, you send your staff out with their new instructions—each person’s instructions consist simply of a set of inputs which they head out to evaluate and return to you. At some point, perhaps after many such cycles, perhaps after just one, you are able to combine the numbers that you’ve assembled into a single result: a number that you return to the person who came to your business in the first place. A calculation might involve just one function evaluation, or involve a chain of them that sends workers buzzing around the city and visiting other businesses that in turn activate their own staff who add to the urban tumult. The reader familiar with floors and corridors and office doors may note that the addresses are discrete. That is, office 321 has offices 320 and 322 as neighbors. Calculus is about continuous functions, so we need a way to accept, say, 321.487… as an input. There is no such office. 240 A slight modification to the procedure will produce a continuous function. It works like this: for an input of 321.487… the messenger goes to both office 321 and 322 and collects their respective outputs. Let’s imagine that they are -14.3 and 12.5 respectively. All that’s needed is a small calculation, which in this case will look like \\[-14.3 \\times (1 - 0.487...) + 12.5 \\times 0.487...\\] This is called linear interpolation and lets us construct continuous functions out of discrete data. In Blocks 2 and 5 we’ll discuss other widely used ways to do this that produce not just continuous functions but smooth functions. Understanding the difference between continuous and smooth will have to wait until we introduce a couple more calculus concepts: derivatives and limits. 2.3 Domain: input space As you know, there is a powerful way of thinking about numbers in terms of space and geometry. For instance, a single number corresponds to a point on a line: the so-called number line. A pair of inputs, say, (x, y) corresponds to a point in a plane, often called the Cartesian coordinate plane. Three numbers corresponds to a point in space, perhaps organized into (x, y, z) of a Cartesian space. There are higher-dimensional spaces, but usually special training is needed to become comfortable with them. If you are having this discomfort, you might prefer to work with the office metaphor. Just for fun, here’s how you can think of a 10-dimensional space: 10 numbers, one telling you which planet, the next specifying the continent on that planet, and so on for country, state, city, street, building, floor, corridor, door. The set of inputs with which the function can be evaluated is called the domain of the function. Sometimes we describe the domain as a space, e.g. the number line, the plane, and so on. Sometimes domains including more restrictions. For instance, a particular input might only meaningfully be positive, with no offices corresponding to negative values for that input. Or, an input might be restricted to be in the interval 0 to 1. Sometimes in calculus, the domain excludes an isolated point. For instance, there may be no office at the door marked 0 but the neighboring doors open into working offices. 250 2.4 Range: output space The range of a function is the set of all the outputs that can be produced. Since at this stage we’re working only with functions that return a single number as output, it’s common to describe the range as all or part of the number line. For instance, some functions only have positive outputs. Other functions’ outputs are always in the interval 0 to 1. (This is the case, for instance, when the function returns a probability as the output.) Exercise 2.3: RLUCX Consider this graph of a function \\(g(x)\\): Question A What is the domain of \\(g(x)\\)? \\(-\\infty &lt; x &lt; \\infty\\) ☹︎ \\(-3 \\leq x \\leq 2\\) ✓ \\(-4 \\leq x \\leq 4\\) ☹︎ This might be called the “graphics” domain, yet the function graph doesn’t extend over that whole interval. $-10 g(x) ☹︎ This is the vertical extent of the graphics frame. \\(-1 \\leq g(x) \\leq 33\\) ☹︎ The domain refers to the horizontal axis. Question B What is the range of \\(g(x)\\)? \\(-\\infty &lt; x &lt; \\infty\\) ☹︎ The range refers output of the function. \\(x\\) is the input. \\(-3 \\leq x \\leq 2\\) ☹︎ The range refers output of the function. \\(x\\) is the input. \\(-4 \\leq y \\leq 4\\) ☹︎ You’re used to calling the function output \\(y\\), but that’s a bad habit. Break it! $-10 g(x) ☹︎ This is the vertical extent of the graphics frame. \\(-1 \\leq g(x) \\leq 33\\) ✓ Weather forecasting by numerical process Weather forecasting by numerical process is a highly influential book, from 1922, by Lewis Fry Richardson. He envisioned a calculation for a weather forecast as a kind of function. The domain for the forecast is the latitude and longitude of a point on the globe, rather than the rectilinear organization of corridor. One fantastic illustration of the idea shows a building constructed in the form of an inside-out globe. At each of many points on the globe, there is a business. (You can see this most clearly in the foreground, which shows several boxes of workers.) 260 Figure 2.1: An artist’s depiction of the organization of calculations for weather forecasting by Richardson’s system. Source Each business might work this way: In each business there is a person who will report the current air pressure at that point on the globe, another person who reports the temperature, another reporting humidity, and so on. To compute the predicted weather for the next day, the business has a staff assigned to visit the neighboring businesses to find out the pressure, temperature, humidity, etc. Still other staffers take the collected output from the neighbors and carry out the arithmetic to translate those outputs into the forecast for tomorrow. For instance, knowing the pressure at neighboring points enables the direction of wind to be calculated, thus the humidity and temperature of air coming in to and out of the region the business handles. In today’s numerical weather prediction models, the globe is divided very finely by latitude, longitude, and altitude, and software handles both the storage of present conditions and the calculation from that of the future a few minutes later. Repeating the process using the forecast enables a prediction to be made for a few minutes after that, and so on. Some of the most important concepts in calculus relate to the process of collecting outputs from neighboring points and combining them: for instance finding the difference or the sum. To illustrate, here is the first set of equations from Richardson’s Weather forecasting … written in the notation of calculus: 270 You can hardly be expected at this point to understand the calculations described by these equations, which involve the physics of air flow, the coriolis force, etc. but it’s worth pointing out some of the notation: The equations are about the momentum of a column of air at a particular latitude (\\(\\phi\\)) and longitude. \\(M_E\\) and \\(M_N\\) are east-west and north-south components of that momentum. \\(\\partial M_E /\\partial t\\) is the amount the east-west momentum will change in the next small interval of time (\\(\\partial t\\)). \\(p_G\\) is the air pressure at ground level from that column of air. \\(\\partial p_G / \\partial n\\) is about the difference between air pressure in the column of air and the columns to the north and south. Calculus provides both the notation for describing the physics of climate and the means to translate this physics into arithmetic calculation. "],["naked-intro.html", "Chapter 3 Naked modeling functions 3.1 The list 3.2 Function shapes 3.3 The power-law family", " Chapter 3 Naked modeling functions Experience allows us to make a short list of mathematical functions that provide a large majority of the tools for representing the real world as a mathematical object. Think of this list as different actors, each of whom is skilled in portraying an archetypical character: hero, outlaw, lover, fool, comic. A play brings together different characters, costumes them, builds on dialog.300 A mathematical modeler is a kind of playwright. She combines mathematical character types to tell a story about relationships. But there is only a handful of archetypical mathematical functions, the analog of the character actors in drama and comedy. We are calling these the naked modeling functions. In writing a mathematical model, you will clothe the actors to suit the era and location and assemble them together in harmony or discord. 3.1 The list Here is a list of our basic, unadorned functions, the naked model function, Update this list to correspond to the one newly developed for the Accum series. Name \\(f(x)\\) exponential \\(e^x\\) logarithm \\(\\ln(x)\\) sinusoid \\(\\sin(x)\\) square \\(x^2\\) proportional \\(x\\) constant \\(1\\) reciprocal \\(1/x\\) or \\(x^{-1}\\) hump \\(\\dnorm(x)\\) sigmoid \\(\\pnorm(x)\\) Exponential \\(e^x\\) Logarithm \\(\\ln(x)\\) Power-law \\(x^p\\) Sinusoid \\(\\sin(x)\\) Straight-line \\(m x + b\\) Hump \\(\\text{dnorm}(x)\\) Sigmoid \\(\\text{pnorm}(x)\\) We’ve written these here in a traditional notation so that you can see the connections to the math you’ve already studied. We’ve used \\(x\\) to stand for the single input to these functions just because that’s traditional. 310 It’s good to refer to the functions by their word name—exponential, logarithm, power-law, sinusoid, straight-line, etc. This helps to avoid the source of common confusion. For example, the mathematical expressions \\(e^x\\) and \\(x^e\\) are easily confused, but they are notation for utterly different patterns. You won’t so easily mistake “exponential” and “power-law.” One important point to make here is that our list of naked modeling functions is very short. You should memorize the names and be able easily to associate each name with the traditional notation. Over the next several chapters, we will introduce several features of functions. Some of our basic modeling functions have these features, some don’t. These features include: monotonicity up or down concavity up or down horizontal asymptotes vertical asymptotes periodicity By the end of Block 1, you should be able to list all seven basic modeling functions and say which of these features are relevant to each. 320 You will also use and see the computer names for these functions. The names can differ somewhat from one computer language to another, but the names in the language we will use, R, are easily recognized by programmers who use any other language. For ease of reference, here’s a table Similarly, update this: Name Traditional notation R expression Exponential \\(e^x\\) exp(x) Logarithm \\(\\ln(x)\\) log(x) Power law \\(x^p\\) x^p Sinusoid \\(\\sin(x)\\) sin(x) Straight-line \\(m x + b\\) m*x+b Hump dnorm(x) Sigmoid pnorm(x) We’ve left out the traditional notation for the hump and sigmoid because there isn’t a standard one. Surprisingly, there is no specific name in R for the Power law or Straight-Line functions, but it’s easy to implement them when needed using the code above. You noticed that the section heading is “The naked modeling functions.” We mean “naked” in a metaphorical sense, and chose the metaphor to make it easy to remember. Think of this list of seven functions as the celebrities of the world of calculus. Unlike human celebrities who appear and wane over the years, and marry and divorce each other frequently, these celebrities have been with us for generations and maintain intimate connections with one another that reflect the nature of mathematics rather than the fads and fancies of celebrities. (Mastering calculus is largely a matter of becoming familiar with the mathematical connections. You’ll see these in due time.) These (basic) celebrity functions appear in many mathematical settings, just as a human celebrity strives to maintain a public image. The human celebrity is a human organism and that organism is naturally naked. In public appearance, however, the celebrity always is clothed in one way or another. (OK … Rarely some of them appear unclothed and the same is true in mathematics.) In other words, in order to interact with the world at large, the celebrities need attire. 330 Similarly, the mathematical functions that appear in real-world applications—as opposed to most math textbooks—always wear clothes, they are adorned with what we call parameters. Parameters help them deal with the units and dimension of quantities. And just as there are standard elements of clothing: shirt, skirt, trousers, … there are standard ways of clothing the naked modeling function. The process of decorating basic modeling functions is called the parameterization of the function, and there are often multiple ways of paremeterizing the same function. Once we dress the naked functions—that is, parameterize them—they will become the superheroes of calculus. We’ll call this league of superheroes the basic modeling functions.. To be consistent, \\(mx + b\\) is not really naked. The naked equivalent is simply \\(x\\). Almost always, the way we will clothe functions is to replace the naked \\(x\\) with \\(mx + b\\) 3.2 Function shapes You are going to be building models by selecting an appropriate function or by putting functions together in various ways. This might remind you of Lego blocks. As you know, these come in different shapes: \\(6\\times 2\\), \\(4\\times 2\\), \\(2\\times 2\\), and so on. Similarly, each of the naked modeling function has a distinctively shaped graph. Knowing the shapes by name will help you when you need to build a model. 340 I didn’t include a graph of the straight-line function, since you already know what that looks like. Instead, I’ll plot two more basic functions, the identity function and the constant function. As you’ll see later, every straight-line function is a “linear combination” of these two. It’s tempting to deny that the constant function is a function. After all, the output does not depend on the input. Still, this situation arises frequently in modeling: you start out supposing that one quantity depends on another but it turns out that it does not. Since functions are our way of representing relationships, it’s helpful to have a function for the situation of “no relationship.” The constant function does the job. 3.3 The power-law family Update this to reference the square and reciprocal naked modeling functions. The power-law “function” is really a set of differently shaped functions. We lump them together under the name “power-law” because they are strongly related, especially when it comes to the calculus operations you will be learning to use. 350 Even within the power-law family, it’s helpful to consider different but overlapping groups: The monomials: \\(m_0(x) \\equiv x^0\\), \\(m_1(x) \\equiv x^1\\), \\(m_2(x) \\equiv x^2\\), \\(\\ldots\\). Of course, \\(m_0()\\) is exactly the same as the constant function, and \\(m_1(x)\\) is the same as the identity function. As for the rest, they have just two general shapes: both arms up (for even powers); one arm up and the other down (for odd powers.) Figure 3.1: Graphs of the monomial functions from order 2 to 5. The negative powers, e.g. \\(f(x) \\equiv x^{-1}\\), \\(g(x) \\equiv x^{-2}\\), \\(h(x) \\equiv x^{-1.5}\\) The non-integer powers, e.g. \\(f(x) = \\sqrt{x}\\), \\(g(x) = x^\\pi\\), and so on. Figure 3.2: The domain of power-law functions with non-integer power is \\(0 \\leq x &lt; \\infty\\). Exercise 3.1: H2eu2 Answer these questions about the naked-modeling functions. You can refer to the graphs in Figures 3.1 through 3.2. Question A Which of these best describes the concavity of the hump function? It’s not concave. ☹︎ If it curves, it’s either concave up or down. It’s concave down. ☹︎ In some places, but not in others. It’s concave down in the center and concave up on both flanks. ✓ It’s concave down on the left and concave up on the right ☹︎ Look again Question B Which of these best describes the concavity of the sigmoid function? It’s not concave. ☹︎ If it curves, it’s either concave up or down. It’s concave down. ☹︎ In some places, but not in others. It’s concave down on the left and concave up on the right. ☹︎ Look again It’s concave up on the left and concave down on the right. ✓ Look again Question C Which of these best describes the concavity of the second-order monomial \\(m_2(x) \\equiv x^2\\)? It’s not concave. ☹︎ If it curves, it’s either concave up or down. It’s concave down. ☹︎ Is it a smile or a frown? It’s concave down on the left and concave up on the right. ☹︎ Look again It’s concave up everywhere in its domain. ✓ Look again We need questions about asymptotes. "],["fun-describing.html", "Chapter 4 Describing functions 4.1 Computer commands 4.2 Tables of inputs and outputs 4.3 Word descriptions 4.4 Computer function names 4.5 Mathematical notation", " Chapter 4 Describing functions We will need to communicate about functions to your fellow humans and to computers. Important modes of communication include: 400 Graphs of functions that show their “shape” Tables of inputs and outputs Word descriptions Computer function name Mathematical notation In this chapter, we’ll illustrate these five different modes using the naked modeling functions. It’s important to become proficient at all five. 4.1 Computer commands We’ll start with computer commands that enable us to draw graphs. To make a graph of a function with one input, use the slice_plot() command, like this: slice_plot(exp(x) ~ x, domain(x=c(-2,2))) You can simply copy-and-paste the command into a sandbox to create the graph. But let’s take apart the command into it’s components to see how R commands are structured. 410 slice_plot( ... ) Commands usually start with the name of the operation to perform. The name is always followed by a pair of parentheses. Those parentheses will contain the arguments of the operation, which you can think of as specifying the details of what is to be done. The slice_plot() operator draws graphs for functions of a single input. exp(x) ~ x is being given as the first argument to the slice_plot() operator. We’ll defer a detailed explanation, just pointing out that we are specifying to the computer that we want a plot of the exponential function and that we are going to use x as the name of the input. domain(x = c(-3,3)) Functions have mathematical domains: the set of valid inputs to the function. The exponential function has the entire number line as the domain. To draw a function graph you need to specify the graphical domain, that is, which part of the function domain to show in the graph. 4.2 Tables of inputs and outputs Another way of describing a function is to give a table of inputs and outputs. Like graphics, a table can only show some of the possible inputs. input output -1.00 0.3678794 -0.75 0.4723666 -0.50 0.6065307 -0.25 0.7788008 0.00 1.0000000 0.25 1.2840254 0.50 1.6487213 Before modern computing, tables were one of the primary means to describe functions. People working with calculus needed a reference collection of books containing tables for the functions they used. 420 With computers, we have better and faster ways to get the output of a function from the input. Still, modelers often use recorded data to construct functions. Tables are perhaps the most widely used method for storing and accessing data, although electronic spreadsheets are used today instead of printed tables. Even today, a table can be a nice way to describe a function when we are interested in the output from only a handful of the possible inputs. Conceptually, it’s helpful to keep in mind that every naked modeling function is just a way of organizing information that could have been stored in a table. 4.3 Word descriptions Knowing and correctly using a handful of phrases goes a long way in being able to communicate with other people about functions with a single input. Often, the words make sense in everyday speech (“steep,” “growing,” “decaying,” “goes up,” “goes down,” \"flat). 430 Sometimes the words are used in everyday speech but the casual person isn’t sure exactly what they mean. For instance, you will often hear the phrase “growing exponentially.” The graph of the exponential function illustrates exactly this sort of growth: flat for small \\(x\\) and growing steadily steeper and steeper as \\(x\\) increases. Still other words are best understood by those who learn calculus. “Concave up,” “concave down,” “approaching 0 asymptotically,” “continuous,” “discontinuous,” “smooth,” “having a minimum at …,” “having a minimum of …,” “approaching \\(\\infty\\) asymptotically,” “having a vertical asymptote.” To illustrate the patterns described by these phrases, consider the three naked modeling functions in Figure 4.1: Figure 4.1: Three of the naked modeling functions: (a) exponential, (b) sinusoid, (c) power-law \\(x^{-1}\\). Concave The exponential is concave up everywhere in its domain. The sinusoid alternates back and forth between concave up and concave down. This particular power law \\(x^{-1}\\) is concave up for \\(x &gt; 0\\) and concave down for \\(x &lt; 0\\). Continuous The exponential is continuous everywhere in its domain. The sinusoid is continuous everywhere in its domain. The power law \\(x^{-1}\\) is discontinuous at \\(x = 0\\) Periodic. Only the sinusoid is periodic, that is, repeating the same shape over and over again. Asymptote. The exponential has a horizontal asymptote of zero as \\(x \\rightarrow -\\infty\\) The sinusoid has neither a vertical nor a horizontal asymptote. The power law \\(x^{-1}\\) has a vertical asymptote of \\(\\infty\\) as \\(x \\rightarrow 0\\) from the right, and of \\(-\\infty\\) as \\(x \\rightarrow 0\\) from the left. Maximum. Only the sinusoid has a maximum, that is, an input for which the output is larger than for any other nearby input. The sinusoid similarly has a minimum. 4.4 Computer function names As you might expect, computer programmers and language developers have written software implementing several of the naked modeling functions: exp(), log(), sin(), dnorm(), and pnorm(). For these functions, the name tells everying, so far as the computer is concerned, that is needed to calculate the output from any given input. 440 Computer notation for the power-law and straight-line functions is different. It will be much easier to understand once you have seen how to create and name your own functions. The reason for this difference is that the power-law and straight-line functions are not quite naked. Both of them have parameters: the exponent in the power-law function and the slope and intercept in the straight-line function. Why do you include the power-law and straight-line functions in the list of naked modeling functions when they are not naked? We’re using the “naked modeling function” list to accomplish two things at the same time: To emphasize that in modeling real-world situations you should always expect that your functions will have parameters. To point out that a large fraction modeling situations can be handled by just a few function “shapes.” To make the list of shapes in (ii) comprehensive, we’ve had to stretch the “naked” metaphor a bit. 4.5 Mathematical notation You have grown up with traditional mathematical notation and have are likely familiar with the notation for several of the naked modeling functions: \\(\\ln x\\), \\(\\sin x\\), \\(e^x\\), \\(x^p\\) (as in \\(x^2\\) where \\(p=2\\) or \\(\\sqrt{x}\\) where \\(p=1/2\\)). 450 Traditional notation mixes up several things that computer notation sensibly keeps separate. From the computer programmer’s point of view, traditional notation is idiosyncratic rather than systematic. If you are interested in these things, three concepts from computing may help you appreciate the the differences: Functional notation In computing, the notation in which a function name is followed by parentheses4 with the inputs inside the parentheses is called “functional notation.” functional notation is part of traditional mathematical notation, although often the parentheses are left out. Infix notation For functions with two inputs, computing languages often support a different arrangement of the function name and the inputs where the name comes between the arguments. You’ve seen this in parts of traditional arithmetic notation, for instance, \\(3 + 5\\) or \\(8/2\\). Infix notation is sometimes used in place of functional notation as in 3^2 or x^3. Markup notation You are undoubtedly familar with word processing and, particularly, a style of word processing called What-you-see-is-what-you-get (WYSIWYG). In WYSIWYG, you can enter plain text just using the keyboard, but if you want to make something boldface or italics, you use the mouse to select the text involved and select a style from a menu. Typically, WYSIWYG mathematical content involves a similar mouse-based process. In contrast, in mainstream computer languages, the mouse is not needed at all. The computer commands are constructed from plain, linear sequences of letters and other characters. Computer programmers helpfully observed that the word-processing process can be constructed as simple plain text input to computer program that interprets the input in well-defined ways and carries out typesetting. To illustrate, consider the next couple of lines. The first shows an ordinary looking word-processor formatted sentence. The second shows the way this was encoded so that a typesetter can produce the formatted content. 460 \\(e^x\\), \\(\\sqrt{x^2}\\) and \\(\\int_0^\\infty \\frac{1}{x^2} dx\\) are examples of traditional notation.5 $e^x$, $\\sqrt{x^2}$ and $\\int_0^\\infty \\frac{1}{x^2} dx$ are examples of *traditional* notation.^[A footnote] Traditional mathematical notation includes features such as superscripts and special symbols that are easily written out with pencil in hand. Often this notation is beautiful and aesthetically cherished by mathematicians. But computer commands in most computer languages are straight sequences of characters using function or infix notation.6 Or sometimes square braces or curly braces or another token, depending on the language.↩︎ A footnote↩︎ Some computer languages use notation where the name of the function is contained inside the parentheses as in (+ 2 3).↩︎ "],["fun-notation.html", "Chapter 5 Notation for functions 5.1 A notation for computing 5.2 Objects and actions 5.3 Formulas and algorithms 5.4 Algorithms without formulas 5.5 Computer notation 5.6 CalcZ naming conventions 5.7 Functions in R 5.8 \\(=\\), \\(\\equiv\\), \\(\\rightarrow\\), &lt;-", " Chapter 5 Notation for functions Part of the difficulty of mathematics for many people is making sense of the nomenclature and notation. What you were taught in high school is a highly idiomatic system that can be mastered only with extensive experience. Mathematicians are undoubtedly skilled in logic, but mathematics itself has an ancient history which has littered the language with synonyms, near synonyms, inconsistencies, diacritical marks, and letters in unfamiliar alphabets. 500 To illustrate the cultural admiration for abstraction in mathematics, consider this famous poem, The Jabberwocky, by a University of Oxford mathematician, Charles Lutwidge Dodgson (1832-1898): ’Twas brillig, and the slithy toves        Did gyre and gimble in the wabe: All mimsy were the borogoves,        And the mome raths outgrabe. Here are some words commonly encountered in traditional mathematics notation. equation, formula, function, variable, unknown, root And here are a few mathematical sentences. \\(y = x\\) \\(y = \\sqrt{x}\\) \\(y^2 = x\\) \\(x^2 = x\\) \\(x = \\sqrt{x}\\) All five sentences are equations. That’s easy, because they each have an equal sign between the two sides. Which are formulas? Which are functions? You’re used to calling \\(x\\) and \\(y\\) variables. When do they become unknowns? Sentence (iv) might be interpreted as describing roots. But sentence (v) says the same thing as (iv) but would not be related to roots.510 5.1 A notation for computing The traditional notation is practically useless for computing. A programmer has to have a deep understanding of what the notation is intended to mean in any given circumstance before she can construct a computer expression that will carry that same meaning in the computer’s work. To illustrate, here are some similar-looking sentences. In math notation, each of them can mean something. In R, one of them is valid and the others invalid. Read each one and try to guess which one is valid and why the others are not. 520 y = x y = sqrt(x) y^2 = 3 y = sqrt(3) y - x = 0 0 = (x+3)(x-2) Once you’ve made your guesses, open a sandbox to see if you got it right. The student who knows how to make sense of math notation will find this not of much help in writing computer notation. It’s like a well educated foreigner trying to make sense of how some of these sentences are meaningful and others not. “Chair a meeting,” but not “seat a meeting.” “Seat a guest,” but not “chair a guest.” “Bush yourself out,” but not “tree yourself out.” “Tree a cat,” but not “bush a cat.” “Table a motion,” but not “desk a motion.” “Bench a player,” but not “couch a player.” “Couch a meaning” but not “bench a meaning.” In this book, we’re going to use a mathematical notation that corresponds to a usable computer notation. The first step is to stop using \\(=\\) to mean so many different things. 530 5.2 Objects and actions [F-30] Identify the structure of function notation when the function is defined by a formula. We’re going to give names to mathematical “objects” and actions. In this introduction, we’ll use boldface for objects and italics for actions. A function is a mathematical object that gives instructions about how to transform one or more inputs into an output. Typically, but not always, we will give names to functions so that we can refer to them. You can think of a function like a recipe: it tells you what to do with the inputs to create the output. You’re used to functions where the recipe is written as a formula using arithmetic and other operators. A more general term for the recipe in a function is algorithm. (Section 5.3 gives a definition of “algorithm” and shows examples that are not formulas.) 540 An argument is a symbol that stands for an input in an algorithm. Applying a function to inputs means to carry out the steps of the function’s algorithm, inserting the appropriate quantity in place of the symbol. Recipes will use symbols like “rice” to describe the algorithm. In cooking, you apply a recipe to the incredients. Where the recipe says, “Add rice to the boiling water” you use the physical rice and the physical boiling water, instead of the symbols. Applying a function to inputs is so fundamental to computing, that you’ll often hear other words for it than “apply”: run the function or evaluate the function or execute the function. To define a function in mathematical notation we will write something like this: \\[g(x) \\equiv 4 x^2 - 7\\] \\(g()\\) is the name of the function. The function takes just one argument, which is being written with the symbol \\(x\\) in the definition. To make double sure that the human reader sees the symbol being used for the argument, we are putting the list of symbols in the parentheses following the function name. The definition of a function with two inputs looks like \\(h(x, y) \\equiv 3y - 5 x^2 + x\\) and functions with more than two inputs follow the same pattern. The algorithm of \\(g()\\) is presented as a formula. The formula in the example, \\(4 x^2 - 7\\) says, \"Take the input quantity. Multiply 4 by the input and then multiply by the input again. Subtract \\(7\\) from that to produce the output of the function. We use \\(\\equiv\\) as the punctuation to distinguish the function name (and argument list) from the algorithm. The algorithm is always on the right of \\(\\equiv\\), the name of the function and argument list are to the left. The command g(3), applies the function named \\(g()\\) to the value 3. Do this by replacing the \\(x\\) in the algorithm by the \\(3\\) and carry out the calculations in the algorithm. For \\(g(3)\\), the output will be 29. In R, a function is defined using a very similar expression. For the \\(g()\\) we defined above, the R definition would be g &lt;- makeFun(4*x^2 - 7 ~ x) The name of the function, without parentheses, is on the left side of the assignment operator &lt;-. We could use the name g to refer to anything, function or not. The R/mosaic operator makeFun() constructs functions and leading a command with g &lt;- gives the output from makeFun() a name. The text in the parentheses of makeFun is also an R expression. We call this sort of expression a tilde expression. (The symbol ~ is called “tilde.”) The tilde character is simply punctuation to separate the expression on the left side, 4*x^2 - 7, from the expression on the right side. The right side of the tilde expression identifies which symbols are the arguments. (In this case, x is the only argument.) The left side of the tilde expression describes the algorithm for the function, using the argument names specified on the right side. 550 To apply the function \\(g()\\) to an argument, we write an R expression with the value for the argument given in the parentheses. For instance, to apply \\(g()\\) to the value 3, we write: g(3) ## [1] 29 5.3 Formulas and algorithms The algorithms for the example functions in the previous section involved only arithmetic. More generally, a formula will involve the invocation of another function. For example: \\(\\sqrt{\\strut m x + b}\\) or \\(\\sin(m x) + \\ln(b)\\). The idea of “algorithm” generalizes that of formulas. A starter definition is: An algorithm is a set of instructions for performing a computation. High-school math typically involves presenting algorithms as formula. You learned, maybe in middle school, how to follow the arithmetic steps involved in algorithms described as formulas. You also have likely used a calculator to perform some of the arithmetic or to evaluate functions such as \\(\\sin()\\) and \\(\\ln()\\) and \\(\\sqrt{\\strut}\\) for which you don’t know how to evaluate using simple arithmetic. The calculator is implementing an algorithm with which its been programmed to enable the calculation of \\(\\sin()\\) and \\(\\ln()\\) and such. A slightly more detailed definition of “algorithm” highlights that algorithms are written in terms of other, simpler algorithms. An algorithm is a set of instructions for performing a computation written in terms of other algorithms that we already know how to perform. For our purposes, the “algorithms that we already know how to perform” will be taken to be arithmetic—addition, subtraction, multiplication, division—as well as the evaluation of the naked modeling functions. Admittedly, people cannot compute logarithms as fluently as they can add numbers, but you already have the R implementations of the basic modeling functions: exp(), log(), sin(), power-law, dnorm(), and pnorm(). The vast majority of functions you will see in this book (and in mathematical modeling in general) can be constructed out of basic arithmetic and the application of the naked modeling functions. 560 5.4 Algorithms without formulas Many functions are described by algorithms that use concepts common in computer programming but unknown to traditional mathematical notation. Some of these have names like iteration or branching and many refer to stored lists of fixed numbers (like the office workers in the street, building, floor, corridor, door image of a function). We’ll deal with some of these things later, but for now … We are going to use the word algorithm to name the kind of expression to the right of \\(\\equiv\\) in a function definition. A formula is a specific kind of algorithm generally written in traditional math notation. Algorithms, including the ones that are formulas, are written in terms of a set of symbols that stand for inputs. This is a high-fallutin’ way of saying something simple: in \\(mx + b\\), the \\(x\\), \\(m\\), and \\(b\\) are the names we give to the quantities being used in the calculation. The notation we are using for function definition lists some of these names in two places, and others in only one place. Again, look at \\[g(x) \\equiv m x + b\\] The \\(x\\) appears both in the algorithm and the list of input name \\((x)\\) to the left of \\(\\equiv\\). The \\(m\\) and \\(b\\) are different; they appear only in the algorithm. The word for such quantities in mathematics is parameter. Eventually, when the algorithm is followed, we’re going to have to put in specific numerical values in place of each parameter. 570 Where will these parameter values come from? This is a subject on which mathematical notation is silent. You have to figure it out from context and experience. This is potentially very confusing, especially when a human is not around to sort things out. 5.5 Computer notation The notation used in computer programming lets us be explicit about which symbols refer to function inputs and which to parameters of the function. Depending on the computer language things can be handled in one way or another. (For experienced computer programmers: This is the issue of scope and can be complex in its own right.) 580 In the software used in CalcZ (R/mosaic, which is the R language augmented with the mosaic package of extensions), we will take a simple-to-use approach. It works like this: All modeling functions we construct with R/mosaic will list parameters formally as arguments to the function. It is as if we wrote in traditional notation \\[g(x, m, b) \\equiv m x + b\\] There is also a way to give default numerical values to parameters so that you can write \\(g(3.5)\\) and the computer will know where to find the parameter values. In writing about formulas using math notation, we’ll extend the traditional notation to write, for instance, \\(g(x, m=2, b=3) \\equiv m x + b\\). In R/mosaic, we would construct a mathematical function like \\(g()\\) using the makeFun() function: g &lt;- makeFun(m*x + b ~ x, m=2, b=3) You could also write g &lt;- makeFun(m*x + b ~ x) but this notation means that you will have to give specific numerical values for the m and b inputs whenever you evaluate g(). There won’t be any default values for the “parameters-as-inputs” m and b. 590 [F-31-R] Identify and create R versions of mathematical functions using makeFun() and tilde expressions. [F-33] Master the conventions used in CalcZ for giving names to functions and for referring to functions with “pronouns.” 5.6 CalcZ naming conventions We’re going to be using a lot of functions in CalcZ. Some of these functions have proper names, usually written using short sequences of letters: for instance the naked modeling functions \\(\\sin()\\), \\(\\ln()\\), \\(\\exp()\\). 600 Other functions will needed just for a sentence or a paragraph or a section, perhaps being used in an example or to lay out the steps of an algorithm. In natural languages such as English, we often use pronouns for such purposes: she, he, it, they, we, I, …. We also will use pronouns for identifying functions. Our policy is this: A pronoun for a function will be named \\(f()\\) or \\(g()\\) or \\(h()\\) or the corresponding upper-case letters \\(F()\\), \\(G()\\), or \\(H()\\). The particular choice of letter f, g, or h has no significance whatsoever. It is just a way to give an unambiguous handle for a function that we are going to be using for a little while. On occasion, we will use subscripts or superscripts on these pronoun letters, for instance \\(f_1()\\) or \\(g^\\star()\\). This is a way to give us many more possible pronouns when we need them. Perhaps this is analogous to words like “sister,” “parent,” “husband,” “cousin,” etc. that allow us to refer, without a proper name, to a specific person. On other occasions, where a function relates to a specific quantity such as position or velocity, we will use the names \\(x()\\), \\(y()\\), \\(z()\\), \\(u()\\), \\(v()\\), \\(w()\\), and such. These letters are, of course, the same ones we frequently use to name the inputs to functions. How do you know whether the letter is meant to refer to an input rather than a function? The parentheses provide the clue: \\(x()\\) is a function name, \\(x\\) is an input name. 610 It can become tedious to give a name to every function, even if it’s not being used again. Consider this sentence as an example: “The functions \\(g(x) \\equiv \\sqrt{\\strut x}\\) and \\(h(x) \\equiv x^3\\) are examples of power-law functions.” Long and awkward. So we’ll feel free to write instead, “\\(\\sqrt{\\strut x}\\) and \\(x^3\\) are examples of power-law functions.” Without the formality provided by “\\(g(x) \\equiv\\)” it can be hard to know whether \\(\\sqrt{\\strut x}\\) means “the square-root function” or \"take the square root of a specific number \\(x\\). The convention we will use is based on the name used in the expression. When standard argument names from the end of the alphabet are being used without any subscript (e.g. \\(x_0\\)) or with a special symbol as a subscript (e.g. \\(t^\\star\\)), we intend the expression to be a function. However, when we want to apply a function to specific values for inputs we will write in any of the following styles: \\[f(x^\\star) \\ \\ \\mbox{or}\\ \\ \\sqrt{\\strut x^\\star}\\ \\ \\mbox{or}\\ \\ \\sqrt{\\strut x=3}\\ \\ \\mbox{or}\\ \\ \\left.\\sqrt{\\strut x}\\right|_{x=3}\\ \\ \\mbox{or}\\ \\ \\left.g(x)\\strut \\right|_{x=3}\\] One of the important techniques of calculus is to take something we often think of as a number and turn it into a function whose output is a number. It will take you time to get used to the calculus notation and to be able to tell at a glance whether something is a function or a number. 620 Here’s an illustration that will only make sense to those who have already studied some calculus: \\[\\int_0^3\\!\\! f(x) dx\\ \\ \\text{is a number, but }\\int_0^x\\!\\! f(x) dx \\ \\ \\text{is a function.}\\ \\ \\] In high-school math notation, it can be hard to tell if an expression is intended to be a function or a number. Careful attention to the CalcZ conventions will make it much easier to figure whether an expression resolves to a function or a number. When you first read a mathematical expression, a good first question to ask is, “What kind of thing is this? A function? A number?” It is essential that you can apply these conventions reflexively. Being able to say what kind of thing a symbol stands for is a key to understanding what a mathematical expression means. Exercise 5.1: TKWEW Use the CalcZ naming conventions to answer these questions. Question A What is \\(h()\\)? The name of a function ✓ Right. Typically we use \\(f()\\), \\(g()\\), \\(h()\\) or something similarly generic to stand for a function that we’re going to be working with for a little while. Think of these as pronouns. Just as we can say, meaningfully, “She gave it to him,” we can say \\(h(x) \\equiv f(x) + g(2*x)\\) The name of an input. ☹︎ Sorry, these will usually be letters like \\(x\\), \\(y\\), \\(t\\). A specific numerical value ☹︎ Sorry, but we’ll use constructions with a subscript like \\(x_0\\) or \\(y_\\star\\) and the like for these. Question B How come we write \\(f()\\) for the name of a function rather than just \\(f\\) or \\(f(x)\\)? No good reason ☹︎ We certainly intend with the empty parentheses to remind the reader that a name refers to a function. If you spot a place where we violate this intention, point it out to us. It’s a reminder that we’re talking about a function with the name “\\(f\\).” ✓ The parentheses are part of the name. ☹︎ Not at all. Names in R never contain parentheses. So f, fbar, fred are all valid names in an R command, but f() is not. We use the parentheses when writing to a human audience as a reminder that the name is referring to a function. The computer doesn’t need any such reminders Question C What sort of thing is denoted by \\(x_0\\) or \\(y_\\star\\) or \\(y_{max}\\)? A particular numerical value ✓ Right. For instance, it might be the particular value for the input to a function which produces an output of zero. Or it might be a particular location in the domain of a function. The name of an input ☹︎ Sorry. We won’t typically use subscripts when referring to an input name. Question D Which of these symbols might stand for the entire domain of a function?     \\(y\\) ✓ Right. Another term to use for a symbol standing for a domain is “name of an input.”        \\(f()\\) ☹︎ No, this is how we write the name of the function called “\\(f\\)”        \\(y_0\\) ☹︎ No. \\(y_0\\) might be used to stand for a single point in the domain. Question E Suppose you come across \\(v(w) \\equiv w + 3\\) in this book. What do \\(v\\) and \\(w\\) stand for? \\(v()\\) is the name of a function and \\(w\\) is the name of the input to that function. ✓ Right. Whenever we write something like “name(another_name) \\(\\equiv\\),” we’re saying explicitly that “name” refers to a function and “another_name” refers to an input. It’s meaningless. ☹︎ We’ll try not to write meaningless mathematical expressions. If we do by mistake, let us know. It’s the same thing as \\(v = w + 3\\). ☹︎ \\(v = w+3\\) is an equation. But \\(v(w) \\equiv w+3\\) is the format for defining a function named \\(v()\\). Question F Are \\(g(x) \\equiv x^2\\) and \\(h(w) \\equiv w^2\\) the same function? Yes, although that function is being given two different names. ✓ The only thing that’s significant about the name of an input is that it be used consistently in the function algorithm. Of course not! ☹︎ Sorry. I suppose you might ask, “What do you mean by the same function?” Remember that a function is a relationship between inputs and the output. \\(g(x) \\equiv x^2\\) and \\(h(w) \\equiv w^2\\) describe exactly the same relationship: the output will be the square of the input. Question G Which of these is the R/mosaic notation for \\(\\equiv\\)?     &lt;- makeFun() ✓        makeFun() ☹︎ Almost right. makeFun() creates a function but doesn’t give it a name.        &lt;- ☹︎ Sorry. In R, this symbol means “give a name to” whatever is on the right side of the &lt;-. The name being given is on the left side of &lt;-. 5.7 Functions in R Any name in the R language can refer to any sort of object. We will use the CalcZ naming conventions in our use of R, so that the ability you develop to read math notation should help reading R and vice versa. 630 R/mosaic provides additional clues to distinguish between numbers and functions. Almost all the time we will create a function using makeFun(). So when you see an R expression starting as name &lt;- makeFun(tilde expression) you know for sure the name refers to a function. As we get deeper into calculus, you will meet additional R operators that generate functions. We’ll introduce these in good time, but for someone reviewing the course, these include D(), antiD(), compose() and iterate(). Some readers may have encountered R previously in a statistics or data science course. Those readers will be wondering what this is with makeFun(). Experienced programmers know that the way you make functions in R is by using the function keyword. For instance: f &lt;- function(x) { 3 + 2*x } That’s a completely correct and legitimate way to define a function in R and in most settings is the universal practice. We developed makeFun() to handle a situation where computers, in their insistence on avoiding ambiguity, will do something that is not what the person familiar with math notation is likely to suspect. The problem comes up in something as simple as g &lt;- function(x) { m*x + b } In traditional math notation, \\(g(x) \\equiv m x + b\\), we are usually silent on where parameters like \\(m\\) and \\(b\\) are coming from. And, to be honest, you don’t have to worry about this until you try to evaluate the function. 630 If you evaluate, say, the command \\(g(3)\\), the R system knows how to find the right values for \\(m\\) and \\(b\\). If there are no such objects in the appropriate places in the R system, an error message will be generated. The rules that computer languages follow in tracking down symbols that aren’t in the argument list are called scoping rules. Scoping is an advanced programming concept and different languages use different rules. That’s a recipe for trouble and confusion for newbies. (And even for experts!) makeFun() is arranged to impose its own scoping system, one that is dead easy and essentially the same in most every computer language. All that makeFun() does is to add any parameters in the function algorithm to the argument list. The makeFun() command creates a function with 3 arguments. makeFun(m*x + b ~ x) ## function (x, m, b) ## m * x + b The point of the ~ x part of the tilde expression is simply to name which arguments should come first. To evaluate the function, you’ll have to provide values for m and b. But some operations on a function—differentiation and anti-differentiation, in particular—can be done without having to specify parameter values. For those of you who know what differentiation or anti-differentiation are, here is an example: D(m*x + b ~ x) ## function (x, m, b) ## m antiD(m*x + b ~ x) ## function (x, C = 0, m, b) ## m * 1/2 * x^2 + b * x + C Sometimes you have particular numerical values in mind for the parameters. For instance, if you are modeling the trajectory of a ball, you will undoubtedly need to make use of gravitational acceleration at the Earth’s surface, which is \\(9.8 \\text{m}/\\text{s}^2\\). You might prefer not to include the specific number 9.8 in your function definitions so that you can use the same functions to model a ball’s trajectory on Mars. But since most balls are thrown on Earth, maybe it’s not worthwhile to insist that the value 9.8 be specified every time the function is used. You can have it both ways by using g as the parameter name and instruct R to set g to 9.8 unless otherwise specified. The function will look like this: 640 ball_velocity &lt;- makeFun(g*t + t0 ~ t, g = 9.8, t0 = 0) # For Earth: falling 3 seconds from a standstill ball_velocity(3) ## [1] 29.4 # For Earth when the ball has an initial upward velocity of 10 m/s ball_velocity(3, t0 = -10) ## [1] 19.4 # For Mars ... ball_velocity(3, t0 = -10, g = 3.711) ## [1] 1.133 5.8 \\(=\\), \\(\\equiv\\), \\(\\rightarrow\\), &lt;- The \\(=\\) sign carries a lot of weight in high-school notation. Too much weight. It is used for several meanings that ought to be distinguished one from another. Combining them all into one symbol leads to confusion and error. Meaning 1: “Is defined to be …” We use \\(\\equiv\\) in mathematical notation and &lt;- in R. The notation in R is a bit simpler than the mathematical notation: it is a way of giving something a name. name &lt;- something If the “something” is a function, you will see that on the left side of &lt;-, for instance by use of the makeFun() operator qw in h &lt;- makeFun(x^2 ~ x). The left side is simply a name. In math notation, the equivalent would be written \\(h(x) \\equiv x^2\\). The left side isn’t exactly a name. It’s a name followed by parentheses in which are the names being used in the algorithm. Keep in mind that in writing about functions, we will generally provide a hint that the name refers to the function, writing \\(h()\\) or h(). The parentheses aren’t part of the name; the name here is \\(h\\). But the parentheses remind us that \\(h\\) is a function. 650 Meaning 2: “Happens to be …” The acceleration due to gravity is often given the name \\(g\\). On Earth’s surface, it happens to be \\(9.8 \\text{m}/\\text{s}^2\\). In our math notation, we will use the equal sign for this narrow meaning, as in \\(g=9.8\\text{m}/\\text{s}^2\\). In R we will use =. Meaning 3: “Gets closer and closer to …” Calculus is about relationships: the connection between two (or more) things. So you will hear phrases like, “As \\(x\\) increases, \\(f(x)\\) decreases.” Or, in everyday experience, “As it gets more humid, the weather becomes more uncomfortable.” Or, “slower is safer,” or “the spicier the better” or “the heavier the blanket, the warmer I’ll be.” (One of the important uses of derivatives in calculus is to represent such statements quantitatively. But that’s a subject for the next Block.) In calculus, sometimes you have to distinguish between “\\(x\\) is zero” and “\\(x\\) gets closer and closer to zero.” We’ll need this when we want to say, “It gets smaller and smaller, but doesn’t disappear entirely.” The symbol for “gets closer and closer to” is \\(\\rightarrow\\), as in \\(x \\rightarrow 0\\) In reading math, take care to notice which of \\(=\\), \\(\\rightarrow\\), or \\(\\equiv\\) is being used. The sign has something important to say and is intended to help you make sense of what you read. Exercise 5.7: LDNE r knitr::knit_child(exercise_file(“02,” “function-notation.Rmd”))` "],["graphs-and-graphics.html", "Chapter 6 Graphics &amp; function graphs 6.1 The graphics frame 6.2 Data graphics: the point plot 6.3 Graphics layers 6.4 Data and functions 6.5 Inputs to output 6.6 Outputs to inputs 6.7 Graphs of functions with two inputs 6.8 Contour plots 6.9 Slice plots", " Chapter 6 Graphics &amp; function graphs [F-20] Understand that a mathematical graph consists of points in a composite space: the input \\(\\times\\) output. Scientific and statistical graphics are visual depictions of information and data. For displaying a function with a single input, mathematicians and other favor a particular style of graphics. This favored style is called a function graph, which has a specific technical meaning in mathematics. Notice that we’re writing “function graph” rather than “function graphic.” A function graph is a particular sort of graphic: there are many other types of graphics some of which we’ll use to display data or features of functions. 700 6.1 The graphics frame Technical graphs are usually drawn in a graphics frame that has several components: The frame is a region on the piece of paper or computer screen that is marked off by a horizontal and a vertical axis. The horizontal axis stands for one quantity. The vertical axis stands for another quantity. Both the horizontal and vertical axes are drawn with a scale that enables you to translate between a numerical value and position. Figure 6.1: An empty graphics frame with scales for both the horizontal and vertical axes. 6.2 Data graphics: the point plot One of the most common uses of a graphics frame is to display visually two columns from a table containing data. For instance, here is a small part of a table about the size of penguins in the Palmer Archipelago in Antarctica. 710 species body_mass flipper_length bill_length Chinstrap 3.600 19.3 4.57 Chinstrap 3.850 19.5 4.76 Adelie 3.300 18.7 3.62 Gentoo 4.300 20.8 4.38 Chinstrap 3.950 21.0 4.90 Chinstrap 2.700 19.2 4.69 Gentoo 5.650 22.4 4.95 Adelie 4.300 19.5 4.15 Adelie 3.325 19.0 3.85 Chinstrap 3.775 19.4 5.17 A point plot displays two columns from the table. Each row in the table is represented by one point in the graphic. For instance: Figure 6.2: Data from 344 penguins on flipper length (cm) and body mass (kg). Each penguin has a specific mass and flipper length. To look at the penguins with a mass of around 4 kg, you can see that the different penguins have a variety of flipper lengths. That’s typical natural variability. A function graph can be constructed in the same way. Start with a table reporting the output of the function for a variety of inputs, like this: input output -3.0 0.0013499 -2.4 0.0081975 -1.8 0.0359303 -1.2 0.1150697 -0.6 0.2742531 0.0 0.5000000 0.6 0.7257469 1.2 0.8849303 1.8 0.9640697 2.4 0.9918025 3.0 0.9986501 Then make a point plot of the two columns in the table: Figure 6.3: A point plot of the table. Typically, when drawing the graph of a function we do not plot individual dots, but lines connecting the dots. It’s very much the same as making a point plot, but use gf_line(). Data are stored in tables called data frames. There are many ways to access data frames and many different ways to store them. This is an important topic in data science. In CalcZ we supply data frames in the simplest possible way: giving them a name that you can use to refer to the data frame. Before you can use gf_point() to plot a pair of columns from a data frame, you have to know the names of the columns. A useful function for this is names(). Similarly, to look at the first few rows, use the head() function. 6.3 Graphics layers You will often want to compare to functions, or compare a function to data, or something more elaborage. You can do this using the ordinary graphics functions, e.g. slice_plot() or gf_point(). Each such command would generates a graphics layer. You can stack layers on top of one another by connecting the commands with a pipe, which is written %&gt;% in R. The pipe token should always come at the end of a line, never at the beginning. The last command in the pipeline should not be followed by %&gt;%. 720 Here is an ugly plot made of three layers, each layer displaying one of the naked modeling functions. When a slice_plot() is the first layer, the domain() must be given explicitly. You’re welcome to do so in the later layers, but if you don’t the original domain() will be passed down the pipeline. slice_plot(dnorm(x) ~ x, domain(x=c(-4,4))) %&gt;% slice_plot(pnorm(x) ~ x, color=&quot;red&quot;, size=2) %&gt;% slice_plot(sin(x) ~ x, color=&quot;green&quot;, size=4, alpha = 0.2) Just to show how these things are done, the functions have been drawn in different colors, different widths (e.g., size=2) and different levels of transparency (e.g. alpha=0.2). 6.4 Data and functions In Figure 6.2, the data point plot of the penguin flipper length vs body mass, there are generally multiple penguins with the same body mass but different flipper lengths. The overall impression is that of a cloud of points. When we construct a function to model the pattern observed in that cloud, we need to respect the mathematical definition of function, part of which is that a function has only one output for any given input. Figure 6.4: The penguin data doesn’t directly describe any sensible mathematical function. (left) We use modeling to create a function that stays close, but not too close, to the data points. (right) To create the model of flipper length as a function of body mass, we used one of a set of techniques called machine learning. That is, we didn’t specify that the form should be an exponential or a hump or a sigmoid or any other particular shape. We simply asked the computer to figure out a smooth function that stays close to the data. The result, as it happens, was a sigmoid. 730 6.5 Inputs to output You can easily evaluate a function for a given input from its graph. As you know, just put your finger at the horizontal coordinate for the input. Then move your finger upward to reach the point on the curve directly above that horizontal coordinate. You read off the value of the function at that input by reference to the scale on the vertical axis. 740 It’s not possible to show with a graph the whole of a function whose domain is \\(-\\infty\\) to \\(\\infty\\). Consequently, when drawing a graph we choose to show only that part of the domain that we expect will be relevant to our needs. Sometimes, the graphic’s domain includes parts that are not in the domain of the function being drawn. In such cases, the function’s graph does not extend into the invalid part of the graphic domain, as in this plot of a function whose domain is only the positive numbers. This function has a range that runs from \\(-\\infty\\) to \\(\\infty\\), but the limits of paper and display mean that we can show only part of this range. With experience, you’ll learn to read the hints in a graph that the underlying function might have a range larger than the one shown in the graphic. 6.6 Outputs to inputs Graphs are relatively modern, coming into mainstream use only in the 1700s. Much of mathematics was developed before graphs were invented. One consequence of this is that function tasks that are easy using a graph might be very hard with the previous ways of implementing functions. This is analogous to the way that arithmetic is pretty easy with Arabic numerals, but really hard with Roman numerals. 750 A function graph makes it easy to evaluate the function inverse. For all the basic modeling functions we have a way to calculate numerically the output for any given input (in the function’s domain). Often, working with a function goes another way: you know the output and you want to find a corresponding input. It’s easy to do this with a graph. Pick the position on the vertical axis that represents the given input. Then trace horizontally to where the ink is. From there, trace vertically to read off the value of an input that would produce the given output. Mathematicians are careful to distinguish between functions where there is a unique input that generates each given output, and functions where there can be more than one input that generates the same output. Functions with a one-to-one relationship between output and input are called “invertible.” Invertible or not, it is a common procedure for working with functions to find an input corresponding to a specific, given output. In high-school algebra, this was called “solving for \\(x\\).” A special case of solving is finding the roots of a polynomial. The name we give to the procedure is zero finding, which correctly points out that we are trying to find an input. 6.7 Graphs of functions with two inputs We can draw graphs of functions with two inputs. Now the points need to be marked in a 3-dimensional space: one axis for each of the two inputs and another axis for the output. Like this: 760 (#fig:fun-1b-1.2)A graph of a function of two inputs is a surface. It is very hard to read a graph of a function with two inputs. Think of the graph as a kind of tent suspended over a domain of ground. The graph itself is a surface. To show the graph on a display, some tricks of the trade are used: color to give an additional scale for the output; computer graphics to let us rotate the surface to look at it from various perspectives, added grid lines and marks on the surface to help us read out the numerical value. 6.8 Contour plots [F-21] Interpret a contour plot of a function of two input variables, to include estimating function values and locations of peaks and valleys. A mathematical graph is just one way to draw a picture of a function with two inputs. There are other ways. One helpful mode of picture is called a contour plot, familiar to many non-mathematicians in the form of topgraphical maps showing landscape elevation as a function of latitude and longitude. Here’s a contour plot of the same function shown in the previous graph: 770 (#fig:Fig-1b-2.1)A contour plot displays the surface in the same manner as a topographical map shows the terrain. This contour plot is a topographical map of the mathematical graph in Figure @ref(fig:fun-1b-1.2) It may take some practice to learn to read contour plots fluently but it is a skill that’s worthwhile to have. Note that the graphics frame is the Cartesian space of the two inputs. The output is presented as contour lines. Each contour line has a label giving the numerical value of the function output. Each of the input value pairs on a given contour line corresponds to an output at the level labeling that contour line. To find the output for an input pair that is not on a contour line, you interpolate between the contours on either side of that point. For example, the input pair (0, 0)—which is at the bottom of the frame, midway from left to right—falls between the contours labeled “20” and “22.” This means that the output corresponding to input (0, 0) is somewhere between 20 and 22. The point is much closer to the contour labeled “20,” so it’s reasonable to see the output value as 20.5. This is, of course, an approximation, but that’s the nature of reading numbers off of graphs. Often, the specific numerical value at a point is not of primary interest. Instead, we may be interested in how steep the function is at a point, which is indicated by the spacing between contours. When contours are closely spaced, the hillside is steep. Where contours are far apart, the hillside is not steep, perhaps even flat. Another common task for interpreting contour plots is to locate the input pair that’s at a local high point or low point: the top of a hill or the bottom of a hollow. Such points are called local argmax or local argmin respectively. The output of the function at a local argmax is called the local maximum; similarly for a local argmin, where the output is called a local minimum. (The word “argmax” is a contraction of “argument of the maximum.” We will tend to use the word “input” instead of “argument,” but it means exactly the same thing to say “the inputs to a function” as to says “the arguments of a function.”) Still other common tasks for reading contour plots are to start at a given input pair and figure out 1) the direction to move which is most steeply uphill, or 2) the direction to move which will keep the function output the same. 780 It can be helpful to look at a contour map and interpret the contours as representing geographical features: hills, valleys, crests, coves, hollows, and so on. Then, for (Fun-1c) translate between a contour plot and a graph of a function with one input. (We can think about this as a function of two inputs, where we hold one of the inputs constant, that is, always the same. ) 6.9 Slice plots [F-23] Know what is meant by a slice of function of two variables. Be able to determine if a function is increasing, decreasing, or constant when moving horizontally or vertically on the contour plot. As mentioned before, mathematical modeling is the process of constructing mathematical representations of situations or phenomena of interest. In CalcZ, we are primarily interested in using functions as such representations. Almost always, when mathematically modeling a real-world situation or phenomenon, we do not try to capture every nuance of every relationship that might exist in the real world. We leave some things out. Such simplifications make modeling problems tractable and encourage us to identify the most important features of the most important relationships. On the other hand, it’s easy to go wrong and leave out something that’s important. To mitigate this risk, many modeling projects involve a modeling cycle where we propose a candidate model, examine the consequence of that model to see if it corresponds well to the parts of reality that are important to us in our task, and modify the model as needed to produce a new and better candidate. 790 In this spirit, it’s useful always to assume that our models are leaving something out and that a more complete model involves a function with more inputs than the present candidate. The present candidate model should be considered as a slice of a more complete model. Our slice leaves out one or more of the variables in a more complete model. To illustrate this, suppose that we have a “more complete model” in the form of a function of two inputs, as shown in the contour plot below. As you become practiced reading contour plots, you might prefer to read this one as a hilltop (shaded yellow) side-by-side with a hollow or bowl (shaded purple), with green, almost level flanks at the left and right edges of the frame. The most common forms of slice involve constructing a simpler function that has one input but not the other. For example, our simpler function might ignore input #2. There are different ways of collapsing the function of two inputs into a function of one input. An especially useful way in calculus is to take the two-input function and set one of the inputs to a constant value. For instance, suppose we set input #2 to the constant value 1.5. This means that we can consider any value of input #1, but input #2 has been replaced by 1.5. In Figure Fig-1c.2, we’ve marked in red the points in the contour plot that give the output of the simplified function. 795 Each point along the red line corresponds to a specific value of input #1. From the contours, we can read the output corresponding to each of those values of input #1. This relationship, output versus input #1 can be drawn as a mathematical graph (to the right of the contour plot). Study that graph until you can see how the rising and falling parts of the graph correspond to the contours being crossed by the red line. Slices can be taken in any direction or even along a curved path! The blue line below the slice constructed by letting input #2 vary and holding input #1 and the constant value 0. Austin has a surface_plot_with_contours() function. Add that in to mosaicCalc. Exercise 6.3: drawing We’ve created a function named \\(\\mbox{twins}(x,y)\\) to help you practice making contour plots. You’ll need to open a sandbox to draw the plot. Here is some scaffolding for the command: twins &lt;- mosaic::rfun(~ x + y, seed = 302, n=5) contour_plot(twins(x, y) ~ x + y, domain(x=c(0,1), y=c(-1,1))) Question A The domain of the plot should be large enough to show a mountain next to a deep hole. Which of these domains will do the job? domain(x=c(-5, 5), y=c(-5, 5) ✓ domain(x=c(1, 5), y=c(1, 5) ☹︎ This shows the mountain, but not the hole. domain(x=c(1,1), y=c(-1,1))) ☹︎ Some of the hole is shown, but none of the mountain. domain(x=c(5,10), y=c(0,10))) ☹︎ There’s hardly anything going on in this domain. The function here is pretty flat except for a dip in the lower left. In a different sandbox (so you can still see the contour plot in the first sandbox), draw a slice through the function along the line \\(y=0\\). Use the same \\(x\\)-domain as in the correct answer to the previous question. twins &lt;- mosaic::rfun(~ x + y, seed = 302, n=5) slice_plot(__tilde-expression__, __domain__) Question B Which of these expressions will accomplish the task? slice_plot(twins(x, y=0) ~ x, domain(x=c(-5,5))) ✓ slice_plot(twins(x) ~ x, domain(y=c(-5, 5))) ☹︎ The domain should be over \\(x\\), not \\(y\\). And twins() takes two inputs, even if one of them is fixed at zero. slice_plot(twins(x, y=0) ~ x, domain(x=c(-5, 5), y=c(-5, 5))) ☹︎ A slice plot has a domain that includes only one input. slice_plot(twins(x, y=0) ~ x + y, domain(x=c(-5, 5), y=c(-5, 5))) ☹︎ A slice plot has only one input on the right side of the tilde expression. Exercise 6.8: daylength Consider this graph of the length of the day at different levels of latitude and different days of the year. Source. First, orient yourself to the graph and what the contours mean. Note the vertical lines indicating the days of the equinoxes and solstices. Question A True or False: There is a place on the equator when the day length is exactly 12 hours at some time of year.     TRUE ☹︎ If there were, the horizontal (dashed) line denoting the equator would cross the 12-hour contour. It doesn’t.        FALSE ✓ Since the dashed equator line no where overlaps with the 12-hour contour line, there is no time of year when the length of day on the equator is exactly 12 hours. Presumably this is because daylight starts somewhat before the sun rises above the horizon and ends somewhat after the sun goes below the horizon. The word “equinox” comes from the Latin for “equal night.” Question B True or False: To judge from the contour plot, on the equinox every latitude has a length of day somewhat longer than the length of night.     TRUE ✓        FALSE ☹︎ Note that neither of the lines for the March or September equinoxes cross the 12-hour length-of-day contour. Question C The USAFA is at latitude 38.9983° N. Reading from the contour plot, roughly what is the length (in hours) of the longest day of the year?     13 ☹︎        14 ☹︎        15 ✓        16 ☹︎        17 ☹︎        18 ☹︎        19 ☹︎ "],["params-intro.html", "Chapter 7 Parameters for functions 7.1 Parallel scales 7.2 Scale the output", " Chapter 7 Parameters for functions The naked modeling functions provide the modeler with a collection of shapes. They are not yet fully suited to represent real-world phenomena. To illustrate, consider Figure 7.1 which shows the number of officially confirmed cases in March 2020. 800 The outbreak was widely described as “exponential,” so alongside the data Figure 7.1 shows the function \\(e^x\\). Figure 7.1: Cumulative confirmed COVID-19 cases during the month of March, 2020. The red curve is \\(e^x\\) There’s an obvious mismatch between the data and the function \\(e^x\\). Does this mean the COVID pattern is not exponential? A hint comes from the formula \\(e^x\\). What is \\(x\\)? Plotted as it is in the graph, \\(x\\) is the calender day in March. But why shouldn’t \\(x\\) be the given in hours or minutes or weeks? If we want the input to \\(\\exp()\\) to be in hours, we can multiply \\(x\\) by 24. If the input is to be in weeks, the multiplier should be \\(\\frac{1}{7} = 0.1429\\). In both cases, the function will be \\(e^{kx}\\), where \\(k\\) would be 24 for hours or 0.1429 for weeks. Exploring a bit, we found that \\(0.3 \\leq k &lt; 0.5\\) will produce functions graphs that match the data much better than naked \\(e^x\\). 810 Figure 7.2: COVID-19 data compared to the exponential functions \\(e^{kt}\\). A variety of possible numerical values for \\(k\\) is shown. The multiplier \\(k\\) in \\(e^{kx}\\) is called a parameter of the function: a number that we can use to set the scale of the input. To use the exponential function to model COVID, we’ve had to stretch out the red curve in Figure 7.2 by clothing naked \\(x\\) as \\(k x\\). Perhaps it’s a matter of personal choice which size of \\(k\\) will be best suited to model the data. My personal choice is \\(k=0.30\\). My reasoning? The orange curve parallels the COVID data. The flaw with \\(k=0.30\\) is that the curve lags several the data by several days. But we can fix this by pulling the \\(k=0.30\\) curve to the left. Mathematically this can be accomplished by subtracting a few days from \\(x\\) before multiplying by \\(k\\), that is, using the function \\[f(x) \\equiv e^{k(x-s)}\\] where \\(s\\) stands for the shift. Figure 7.3 shows the orange curve after pulling it 10 days to the left. It’s now a pretty good match to the data. Figure 7.3: COVID-19 data compared to the exponential functions \\(e^{k(t-s)}\\). Note that once we’ve aligned the orange curve horizontally, it seems to curve too much. The green curve does much better. It has a much gentler curve, \\(k=0.19\\) and is pulled about a little more than a month to the left. 820 By parameterizing the exponential function as \\(e^{k(x-s)}\\) and finding suitable values for \\(k\\) and \\(s\\), we get a good match to the March data. But models can sometimes tell us more. For the green curve in Figure 7.3 the value of \\(s\\) is -32 days. 32 days before March 1 is in late January. And even though we didn’t have any January or February data to base the green curve on, late January 2020 is regarded as the very beginning of the outbreak. 7.1 Parallel scales The graphical format we have been using to display functions of one variable places the input on the horizontal axis and the output on the vertical axis. This is not the only way to draw a function. Consider these everyday objects: a thermometer and a ruler.       Each object presents a read-out of what’s being measured—temperature or length—on two different scales. At the same time, the objects provide a way to convert one scale to another. A function gives the output for any given input. We represent the input value as a position on a number line—which we call an “axis”—and the output as a position on another output line, almost always drawn perpendicular to one another. But the two number lines can just as well be parallel to one another. To evaluate the function, find the input value on the input scale and read off the corresponding output. The inverse function can be evaluated just as easily: switch the roles of the input and output scales. 830 Taking the traditional unit scale as the input and the metric scale as the output, the two functions implemented on the objects are: \\[\\underbrace{C(F) = \\frac{5}{9}(F-32)}_\\mbox{Fahrenheit to Celcius}\\ \\ \\ \\text{and}\\ \\ \\ \\ \\underbrace{\\text{cm(inches)} = 2.54 \\times (\\text{inches}-0}_\\mbox{inches to cm})\\] These are very simple, straight-line functions, but they play an important role in modeling. Each conversion function can be written in the form \\(h(x) \\equiv m (x - x_0)\\). Of course, if you multiply the \\(m\\) through both terms in parentheses, you get \\(h(x) = m x - m x_0\\) which can be written even more simply as \\(mx + b\\) by setting \\(b\\equiv m x_0\\). So the conversion function is simply the straight-line function. \\(m\\) and \\(x_0\\) are the parameters of the straight-line function. In terms of the graph of a straight-line function, they are the slope and x-intercept respectively. Often, functions can be parameterized in other ways. For instance, you likely learned the parameterization \\(m x + b\\), in which \\(m\\) is (still) the slope of the graph but \\(b\\) is now the y-intercept. We can call \\(m(x - x_0)\\) the “x-intercept parameterization” and \\(m x + b\\) the \"y-intercept parameterization. They are equivalent and equally good ways of parameterizing the straight line. There are still other ways of parameterizing, each style reflecting its own format for specifying the two points that make up a line. To turn a naked modeling function into a basic modeling function all we do is use \\(h()\\) to convert the input before applying the naked function. 840 Basic modeling function7 formula Exponential \\(e^{h(x)}\\) Power-law \\(\\left[h(x)\\right]^p\\) Sinusoid \\(\\sin(h(x))\\) Hump \\(\\text{dnorm}(h(x))\\) Sigmoid \\(\\text{pnorm}(h(x))\\) Straight-line \\(h(x())\\) As you can see, the straight-line function is a fundamental part of modeling. To illustrate the link between basic modeling functions and their naked progenitors, Figure 7.4 shows the model we fit to the COVID-19 data: Figure 7.4: A graph of the naked modeling exponential with an additional scale displayed (red) to match it to the COVID-19 data The function being drawn is simply \\(e^x\\): naked. The black horizontal scale shows \\(x\\). To match the function to the data, that is, to show the basic modeling function, we simply add a new scale that translates \\(x\\) to “day in March.” That’s the red scale. So, on March 22, there were about 25,000 COVID cases to date. The naked modeling function does not give a good model of the COVID case numbers. But if we scale the input before applying the naked function, we are effectively laying a new axis, stretched and shifted from the original, that let’s us read off the number of cases. Input scaling empowers the naked modeling functions to model a huge variety of phenomena. There’s just one exponential function and it always looks exactly the same. But there is a huge variety of ways to scale the input. With input scaling, the naked modeling function puts on clothes and becomes one of our basic modeling functions. \\[\\underbrace{e^x}_\\mbox{naked modeling function}\\ \\ \\ \\underbrace{e^{k(x-x_0)}}_\\mbox{basic modeling function}\\] The straight-line function \\(h()\\) is being written here as \\(k(x-x_0)\\) rather than \\(m(x-x_0)\\). It’s traditional to to write some of the basic modeling functions You may have noticed that the above uses \\(k\\) instead of \\(m\\) as the multiplier in the straight-line function in the exponent. Of course, you can use whatever name you wish for a parameter. The idiom of mathematical notation has several conventions. Knowing these will help you read mathematics more fluently. 850 The table shows a few of them. Often, there are multiple parameterizations. Function Written form Parameter 1 Parameter 2 Exponential \\(e^{kt}\\) \\(k\\) “exponential constant”8 Not used Exponential \\(e^{t/\\tau}\\) \\(\\tau\\) “time constant”9 Not used Exponential \\(2^{t/\\tau_2}\\) \\(\\tau_2\\) “doubling time”10 Not used Power-law \\([x - x_0]^p\\) \\(x_0\\) “center” Not used Sinusoid \\(\\sin\\left(\\frac{2 \\pi}{P} (t-t_0)\\right)\\) \\(P\\) “period” \\(t_0\\) “time shift” Sinusoid \\(\\sin(\\omega t + \\phi)\\) \\(\\omega\\) “angular frequency” \\(\\phi\\) “phase shift” Sinusoid \\(\\sin(2 \\pi \\omega t + \\phi)\\) \\(\\omega\\) “frequency” \\(\\phi\\) “phase shift” Hump dnorm(x, mn, sd) mn “mean” sd “standard deviation” Sigmoid pnorm(x, mn, sd) mn “mean” sd “standard deviation” Straight-line \\(mx + b\\) \\(m\\) “slope” \\(b\\) “y-intercept” Straight-line \\(m (x-x_0)\\) \\(m\\) “slope” \\(x_0\\) “center” 7.2 Scale the output Just as the natural input usually needs to be scaled before it reaches the naked modeling function, so the output from the naked function may need to be scaled before it presents a result suited for interpreting in the real world. Figure 7.5: Natural quantities must be scaled to pure numbers before being suited to the naked modeling functions. The output is a pure number which is scaled to the natural quantity of interest. The overall result of input and output scaling is a smartly dressed modeling function ready to engage the real world. 860 Name Naked form Dressed for action exponential \\(e^x\\) \\(A e^{kx} + C\\) sinusoid \\(\\sin(x)\\) \\(A \\sin(\\frac{2 \\pi}{P} x) + C\\) straight-line \\(a x + b\\) \\(a x + b\\) The parameter \\(C\\) is often called the baseline or the offset. Statisticians call it the “intercept,” because it plays the same role as \\(b\\) in the straight-line function. When working with sinusoids, parameter \\(A\\) is called the amplitude. Of course, you’re already familiar with \\(a\\) and \\(b\\): the slope and intercept of a straight line. Figure 7.6: Baseline (blue), amplitude (red), and period (green) for the sinusoid. Figure 7.7: The baseline for the exponential is the horizontal asymptote. The straight-line function is like a penguin: even when it’s naked, it’s still fully dressed! Now we can let you in on a little secret. All along, the straight-line function has been dressed, not naked. The actual naked form is so simple that it can be confusing: \\[\\text{identity}(x) \\equiv x\\] Clothing the identity function by scaling looks like this: \\[ x \\underbrace{\\longrightarrow}_\\mbox{input scaling} k x + c \\underbrace{\\longrightarrow}_\\mbox{output scaling} A(kx + c) + C\\] A little bit of algebra transforms the scaled function into a more concise form: \\[A(kx + c) + C \\longrightarrow \\underbrace{Ak}_ax + \\underbrace{Ac + C}_b \\longrightarrow ax + b\\] Most students have thoroughly explored the straight-line function in their high-school studies, so we thought it ill-advised to start out with the identity function. Exercise 7.3: uKCIE Each of the graphs shows two horizontal scales and one of the basic modeling functions. Which horizontal scale (black or red) corresponds to the naked modeling function? Question A For graph (A), which scale corresponds to the naked modeling function?     black ✓        red ☹︎        neither ☹︎        both ☹︎ It can’t be both. There’s only one naked function. When you scale the input, it becomes a “basic modeling function.” Question B For graph (B), which scale corresponds to the naked modeling function?     black ☹︎        red ✓ Right. The naked modeling function has an output of 1/2 when the output is zero. That’s what the red scale shows.        neither ☹︎        both ☹︎ It can’t be both. There’s only one naked function. When you scale the input, it becomes a “basic modeling function.” Question C For graph (C), which scale corresponds to the naked modeling function?     black ☹︎        red ✓ The naked sinusoid has a positive-going zero crossing at \\(x=0\\). That’s the red scale.        neither ☹︎        both ☹︎ It can’t be both. There’s only one naked function. When you scale the input, it becomes a “basic modeling function.” Exercise 7.7: BLECL Find the straight-line function that will give the value on the red scale for each point on the black scale. Each graph shows a basic modeling function written in this style: \\(\\sin(r(t-t_0))\\). Your job is to estimate \\(t_0\\) and \\(r\\). We’re leaving the log function out of the list, simply because it’s rarely used with \\(h()\\).↩︎ \\(-\\tau_2\\) is sometimes called the “half life.”↩︎ "],["process-of-modeling.html", "Chapter 8 Process of modeling 8.1 Variations from scaling 8.2 Curve fitting an exponential function 8.3 Curve fitting a periodic function 8.4 Curve fitting a power-law function 8.5 Hump and sigmoid functions 8.6 The modeling cycle", " Chapter 8 Process of modeling Seen very abstractly, a mathematical model, as we are using the term, is a set of functions that represent the relationships between inputs and outputs. 900 At the most simple level, building a model can be a short process: Develop an understanding of the relationship you want to model. Often, part of this “understanding” is the pattern seen in data. Choose a function type—e.g. exponential, sinusoidal, sigmoid—that you think would be a good match to the relationship. Find parameters that scales your function to be able to accept real-world inputs and generate real-world outputs. It’s important to distinguish between two basic types of model: Empirical models which are rooted in observation and data. Mechanistic models such as those created by applying fundamental laws of physics, chemistry, and such. We are going to put off mechanistic models for a while, for two reasons. First, the “fundamental laws of physics, chemistry, and such” are often expressed with the concepts and methods of calculus. We are heading there, but at this point you don’t yet know the core concepts and methods of calculus. Second, most students don’t make a careful study of the “fundamental laws of physics, chemistry, and such” until after they have studied calculus. So examples of mechanistic models will be a bit hollow at this point. The process of constructing a model that is a good match for data is called curve fitting, or, more generally, fitting a model. 8.1 Variations from scaling A good place to start building a model is to pick one of the basic modeling functions. This works surprisingly often. To remind you, here are our seven basic modeling functions: 910 straight-line exponential power-law logarithm sinusoid hump sigmoid It helps in making the selection to have ready to mind the basic shape of each of these function families. To review, revisit Section 3.2. Remember also that, in general, we scale the inputs and scale the output. This means that in choose a model family, we don’t have to worry at first about the numbers on the axes. (Of course, those numbers will be critically important later on in the process!) The scaling does, however, allow us to consider some variations on the shapes of the modeling functions. In particular, the input scaling lets us flip the shape right-for-left. And the output scaling lets us flip the shape top-for-bottom. \\(f(t)\\), basic shape \\(f(-t)\\), flipped right-for-left \\(-f(t)\\), flipped top-for-bottom \\(-f(-t)\\), flipped both top-for-bottom and right-for-left For functions such as the sinusoid, flipping is not much use, since the flipped sinusoid curve is still a sinusoid. Similarly, a right-for-left flipped hump function has the same shape as the original. For the straight-line function, flipping of either sort accomplishes the same thing: changing the sign of the slope. For the exponential function, the two possible types of flipping—right-for-left and top-for-bottom—produce four different curves, all of which are exponential, shown in Figure 8.1. Figure 8.1: Four variations of the exponential functions. Exercise 8.3: ds4e7 These three expressions \\[e^{kt}\\ \\ \\ \\ \\ 10^{t/d} \\ \\ \\ \\ \\ 2^{t/h}\\] produce the same value if \\(k\\), \\(d\\) and \\(h\\) have corresponding numerical values. The scaffolding has an expression for plotting out \\(2^{t/h}\\) for \\(-4 \\leq t \\leq 12\\) where \\(h = 4\\). It also plots out \\(e^{kt}\\) and \\(10^{t/d}\\) fa &lt;- makeFun(2^(t/h) ~ t, h = 4) fb &lt;- makeFun(10^(t/d) ~ t, d = 10) fc &lt;- makeFun(exp(k*t) ~ t, k = 0.1) slice_plot(fa(t) ~ t, domain(t = c(-4, 12))) %&gt;% slice_plot(fb(t) ~ t, color=&quot;blue&quot;) %&gt;% slice_plot(fc(t) ~ t, color = &quot;red&quot;) %&gt;% gf_lims(y = c(0, 8)) Your task is to modify the values of d and k such that all three curves lie on top of one another. (Leave h at the value 4.) You can find the appropriate values of d and k to accomplish this by any means you like, say, by using the algebra of exponents or by using trial and error. (Trial and error is a perfectly valid strategy regardless of what your high-school math teachers might have said about “guess and check.” The trick is to make each new guess systematically based on your previous ones and observation of how those previous ones performed.) After you have found values of k and d that are suited to the task … Essay question tmp-1: Enter the numerical value of your best estimate of k. Essay question tmp-2: Enter the numerical value of your beat estimate of d. 8.2 Curve fitting an exponential function The exponential function is particularly useful when the quantity we want to model shows constant proportional increase. Many quantities in everyday life are this way. For instance, an increase in salary is typically presented in a format like “a 3% increase.” The population growth of a country is often presented as “percent per year.” Inflation in the price of goods is similarly described in percent per year. Interest on money in a bank savings account is also described as percent per year. But if you have the bad fortune to owe money to a loan shark, the proportional increase might be described as “percent per month” or “percent per week.” 920 When you know the “percent increase per time” of a quantity whose initial value is \\(A\\), the exponential function is easy to write down: \\[f(t) = A (1+r)^t\\] The number \\(r\\) is often called the interest rate or discount rate and is given in percent. Regrettably, it’s extremely easy amd common to forget the rules for addition with percent. If \\(r = 5\\%\\), then \\((1+r) = 1.05\\), not 6. Always keep in mind that \\(5\\%\\) means \\(\\frac{5}{100}\\). Another source of error stems from the tradition in mathematics of using the number \\(e=2.718282\\) as the “natural” base of the exponential function, whereas in \\(f(t) = A (1+r)^t\\) the base is \\(1+r\\). You can translate an exponential \\(b^t\\) in any base \\(b\\) to the “natural” base. This is just a matter of calculating the appropriate parameter \\(k\\) such that \\(e^k = b\\). Using logarithms, \\[e^k = b\\ \\ \\implies \\ \\ k=\\ln(b)\\] For instance, if \\(r=5\\%\\) per year, we’ll have \\(k = \\ln(1+r) = \\ln(1.05) = 0.488\\) per year. Almost everybody is happier doing arithmetic with numbers like 2 and 10 rather than \\(e=2.718282\\). For this reason, you may see formulations of the exponential function as \\(g(t) \\equiv 2^{a t}\\) or \\(h(t) \\equiv 10^{c t}\\). Remember that \\(2^{a t}\\) and \\(e^{at}\\), although both exponential functions, are quantitatively different. If you want to write \\(2^{at}\\) using the “natural” base, it will be \\(e^{\\ln(2) a\\, t }\\). Similarly, \\(10^{ct} = e^{\\ln(10) c\\, t}\\). Exponential functions also describe decrease or decay. Just replace \\(t\\) with \\(-t\\). That is, a movie of a decreasing quantity is just the movie of an increasing quantity played backwards in time! 930 Figure 8.2 shows some data collected by Prof. Stan Wagon to support his making a detailed mechanistic model of an everyday phenomenon: The cooling of a mug of hot beverage to room temperature. The mug started at room temperature, which was measured at 26 degrees C. At time 0 he poured in boiling water from a kettle and measured the temperature of the water over the next few hours. Figure 8.2: Stan’s data Our task is to translate this data into the form of a function that takes time as input and returns temperature as output. Such a model would be useful for, say, filling in the gaps of the data. For instance, we might want to find the temperature of the water immediately after being poured from the kettle into the mug. Looking at the data, one sees that the temperature decreases along a curve: cooling fast at first and then more slowly. This is the pattern of the flipped right-for-left exponential. (Figure 8.1(B)) We can imagine then that an exponential, \\(A e^{kt} + C\\) will be a suitable model form for the cooling water. What remains is to find the parameters \\(A\\), \\(k\\), and \\(C\\). Here is a general process for curve-fitting an exponential. Later, we’ll apply this process specifically to the water-cooling situation. General process for curve-fitting an exponential Step 0: Check that the data show an exponential pattern in one of its variations, namely a smooth increase or decrease and leveling out beyond some value of \\(t\\). If this isn’t true, reconsider whether you should be using an exponential function in the first place. Step 1 Do the data show exponential growth or exponential decay? If it’s exponential growth, then the flat region in Step 0 will be to the left and \\(k\\) will be positive. If exponential decay, the flat region will be to the right and \\(k\\) will be negative. Notice that the question of “growth or decay” depends only on the sign of the parameter \\(k\\). You can have an exponentially decaying process that’s increasing. Consider, for instance, the speed of a car as it merges onto a highway from a slow speed on the entrance ramp. The car’s velocity is increasing, but as you approach highway speed the rate of increase gets smaller. That’s exponential decay. Step 2 Where is the baseline? We’re going to put aside \\(k\\) for the moment and find the value of the output that is being approached asymptotically, that is, the height of the level zone of the data. This height is the coefficient \\(A\\) in the linear combination. Step 3 Once you know the baseline, you’re set to find a numerical value for the parameter \\(k\\). Pick a point in the data far from the baseline. Call the input \\(t_1\\). Scan forward or backward in time to find a point in the data that’s vertically half way from the original point toward the baseline. Call the input at that point \\(t_{1/2}\\). The difference between these, \\(t_1 - t_{1/2}\\) is called the half-life or halving-time if it’s negative and the doubling time if it’s positive. The parameter \\(k\\) is \\(0.693 / (t_1 - t_{1/2})\\). Double check the sign of \\(k\\) to make sure it’s consistent with what you saw in Step 1. (Incidently, \\(0.693 = \\ln(2)\\). The 2 is the same as the 2 in doubling or halving.) Step 4 Now that you have numerical values for the baseline \\(A\\) and the parameter \\(k\\), calculating the value of \\(B\\) is straightforward. i. Pick a \\(t_0\\) that’s reasonably well represented in your data. Find the vertical coordinate represented by the data near that \\(t_0\\). Call that \\({\\cal D}\\). ii. Solve with respect to \\(B\\) the equation \\(A + B e^{k t_0} = {\\cal D}\\). Things are particularly easy if you can use \\(t_0 = 0\\). Then you just straight off calculate \\(B = {\\cal D} - A\\). Step 5 Plot the function \\(A + B e^{k t}\\) using the values for \\(A\\), \\(B\\), and \\(t\\) that you just found. If you are not satisfied, tweak the parameters a bit until you are. Exponential curve fitting applied to the water-cooling data Let’s illustrate the general process on the water-cooling data, redrawn in Figure 8.3. 950 Figure 8.3: The cooling-water data, repeated here for convenience. Step 0: The data indicate a smooth curve. As \\(t\\) gets large, the curve approaches a constant. So an exponential model is reasonable. Step 1: The flat zone of the data is to the right. So we’ve got exponential decay and \\(k &lt; 0\\). Step 2: The curve looks like it’s leveling out at a temperature of about 25 degrees C for large \\(t\\). So \\(A \\approx 25^{\\circ} \\text{C}\\). Step 3: The point furthest from the baseline is located at \\(t_1 = 15 \\text{sec}\\) with a value \\({\\cal D} \\approx 80^\\circ\\text{C}\\). This if \\(55^\\circ\\text{C}\\) from the baseline. We want to find the value of \\(t_1\\) where the temperature will be half way from 80 to the baseline. That’s a temperature of about \\(80 - 55/2 = 53.5\\). Scanning over to the right, the function that I can imagine going through the data crossed \\(53^\\circ\\) at about \\(t_{1/2} = 40\\). Thus, the half-life is estimated at 25s. The parameter \\(k\\) is therefore $k\\(0.693 / \\mbox{half-life}) = - 0.63 / 25 = -0.0277\\). Since we identified in Step 1 that exponential decay is involved, we expect \\(k\\) to be negative. It is. Step 4. We know \\(A \\approx 25\\) and \\(k \\approx -0.0277\\). We also now that for \\(t=15\\) the function output is about \\({\\cal D} = 80^\\circ\\). This means \\(25^\\circ + B e^{- 0.0277 \\times 15} \\approx 80^\\circ = 25 + 0.66 B\\). Solving for \\(B\\) gives \\(B = (80 - 25)/0.66 = 83.3\\) Step 5. Graph the function over the data. Figure 8.4: An exponential function that roughly aligns with the data. Exercise 8.7: vkwl4 The Bargain Basement store wants to sell its goods quickly. Consequently, they reduce each product’s price \\(P\\) by 5% per day. Question A If a jacket costs $80 today, how much will it cost in \\(t\\) days? \\(P = 80 - 5t\\) ☹︎ Remember, 5 percent is exactly the same as 0.05 \\(P = 80 - 4t\\) ☹︎ Remember, 4 percent is exactly the same as 0.04 \\(P = 80 - 0.05t\\) ☹︎ This would be a decrease in price by 5 cents every day. \\(P = 80 (0.05)^t\\) ☹︎ Each day’s price would be only 5% that of the previous day’s price. \\(P = 80 (0.95)^t\\) ✓ You’ll need to open a sandbox for the next question. You’re on your own here! Remember, to raise a number to a power, you can use an expression like `0.95^7$. Question B You decided that you like the $80 jacket, but you have a budget of only $60. How long should you wait before coming back to the Bargain Basement store.?     3 days ☹︎ On day 3 the price will be \\(0.95 imes 0.95 imes 0.95 imes 80\\). That’s above your budget.        4 days ☹︎ On day 4 the price will be \\(80 \\times 0.95^4\\)= $65.16. Too much!        5 days ☹︎ On day 5 the price will be \\(80 \\times 0.95^5\\)= $61.90. Close, but still higher than your budget.        6 days ✓ Exercise 8.11: asevss The Wikipedia entry on “Common Misconceptions” used to contain this item: Some cooks believe that food items cooked with wine or liquor will be non-alcoholic, because alcohol’s low boiling point causes it to evaporate quickly when heated. However, a study found that some of the alcohol remains: 25% after 1 hour of baking or simmering, and 10% after 2 hours. The modeler’s go-to function type for events like the evaporation of alcohol is exponential: The amount of alcohol that evaporates would, under constant conditions (e.g. an oven’s heat), be proportional to the amount of alcohol that hasn’t yet evaporated. Question A A) Assume that 25% of the alcohol remains after 1 hour? If the process were exponential, how much would remain after 2 hours?     10% ☹︎ That’s what the study is reported to have found, but that’s not consistent with an exponential process that decays to 25% after one hour        25% ☹︎ Exponentials decay to zero eventually, so don’t expect things to stay still after one hour.        25% of 25% ✓ We know that 75% is eliminated over 1 hour, leaving 25%. The continuing exponential process will, over the next hour eliminate 75% of the amount at the start of that hour. So after hour 2 we’ll have 25% of the amount we had at hour 1, which was 25% of the original amount.        75% ☹︎ That’s how much was eliminated in the first hour, not how much remains after 2 hours.        75% of 75% ☹︎ In an exponential process, at any moment the rate of decay (e.g. 75% per hour) is a constant proportion of the amount that is still there. After one hour, there is 25% of the alcohol remaining. That will decay at a rate of 75% per hour. Over the next hour, we’ll lose 75% of the original 25%, giving us 25% of the original amount. Question B B) What is the half-life of an exponential process that decays to 25% after one hour? 15 minutes ☹︎ This provides time for four halvings in one hour, which would leave \\(\\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} = 1/16\\) of the original not 1/4. 30 minutes ✓ This gives time for two halvings in one hour, bringing us to 25% as observed. 45 minutes ☹︎ Two halvings bring us down to 25%. At this rate, it would take 90 minutes to get down to 25%, not 60 minutes as observed. none of the above ☹︎ Let’s change pace and think about the “10% after 2 hours” observation. First, recall that the amount left after \\(n\\) halvings is \\(\\mbox{amount_left}(n) \\equiv \\frac{1}{2}^n\\) This is an exponential function with base 1/2. You’re going to carry out a guess-and-check procedure to find a zero of the function \\(\\text{amount_left}(n) - 0.10\\) that is, you’ll find what \\(n\\) will generate the stated output value (e.g. 10%). Open a sandbox and copy over the scaffolding, which include the definition of the amount_left() function. and a “guess” for the input. Change the guess until you get the output 10%. amount_left &lt;- makeFun((1/2)^n ~ n) amount_left(0) ## [1] 1 Question C C) Use amount_left() to figure out how many halvings it takes to bring something down to 10% of the original amount.     2.58 ☹︎        3.32 ✓        3.62 ☹︎        3.94 ☹︎        4.12 ☹︎ Another way to find the input \\(n\\) that generates an output of 10% is to construct the inverse function to \\(\\text{amount_left}()\\). The computer already provides you with inverse functions for \\(2^n\\) and \\(e^n\\) and \\(10^n\\). Their names are log2(), log(), and log10() repectively. Using log2(), write a function named log_half() that gives the inverse function to \\((1/2)^n\\). Remember, the input to the inverse function corresponds to 10%; the output to the \\(n\\). log_half &lt;- makeFun( log2(...your stuff here ...) ~ x) Question D The answer you got in part C) is the number of halvings needed to reach 10%. If this number occurs in 2 hours (that is, 120 minutes), what is the half life stated in minutes.     30 ☹︎        35 ☹︎        36 ✓        38 ☹︎        42 ☹︎        47 ☹︎ Suppose you compromise between the half-life needed to reach 25% after one hour and the half-life needed to reach 10% after two hours. Use, say, 33 minutes as the compromise half life. Using the sandbox below, calculate how much would be left after 1 hour for this compromise half life, and how much left after 2 hours. Question E How much is left after 1 hour and after 2 hours when the half life is 33 minutes? 28% and 8% ✓ 31% and 4% ☹︎ 30% and 9% ☹︎ 27% and 9% ☹︎ Exercise 8.15: j3xe You have likely heard the phrase “exponential growth” used to describe the COVID-19 pandemic. Let’s explore this idea using actual data. The COVID-19 Data Hub is a collaborative effort of universities, government agencies, and NGOs to provide up-to-date information about the pandemic. We’re going to use the data about the US at the whole-country level. (There’s also data at state and county levels.) Perhaps the simplest display is to show the number of cumulative cases (the confirmed variable) and deaths as a function of time. You can see the documentation for the dataset at the COVID-19 Data Hub Open a sandbox and make the plot. We’re going to plot confirmed cases in blue and deaths in red. gf_point(confirmed ~ date, data = Covid_US, color = &quot;blue&quot;) %&gt;% gf_point(deaths ~ date, color = &quot;red&quot;) Question A As of mid July, about how many confirmed cases were there? (Note that the labeled tick marks refer to the beginning of the month, so the point labeled Feb is February 1.) about 300,000 ☹︎ The number 1e6 means 1,000,000, that is, six zeros following the one. about 350,000 ☹︎ The number 1e6 means 1,000,000, that is, six zeros following the one. about 400,000 ☹︎ The number 1e6 means 1,000,000, that is, six zeros following the one. about 3,000,000 ☹︎ Mid July is the tick mark after the one labelled Jul. about 3,500,000 ✓ about 4,000,000 ☹︎ Mid July is the tick mark after the one labelled Jul. We’re going to do something to make the graph more informative. (At least, more informative if you understand about logarithms and exponentials!) Here’s the same graphic as above, but taking the logarithm of the number of cases (that is, confirmed) and of the number of deaths. Since we’re taking the logarithm of only the y-variable, this is called a “semi-log” plot. gf_point(log(confirmed) ~ date, data = Covid_US, color = &quot;blue&quot;) %&gt;% gf_point(log(deaths) ~ date, color = &quot;red&quot;) Up through the beginning of March in the US, it is thought that most US cases were in people travelling into the US from hot spots such as China and Italy and the US, as opposed to contagion between people within the US. (Such contagion is called “community spread.”) So let’s focus on the data from the start of March onward. Exponential growth appears as a straight-line pattern on a semi-log plot. Obviously, the overall pattern of the curves is not a straight line. The explanation for this is that the exponential growth rate changes over time, perhaps due to public health measures (like business closing, masks, etc.) The first (official) US death from Covid-19 was recorded was recorded on Feb. 29, 2020. Five more deaths occurred two days later, bringing the cumulative number to 6. Question B The red data points for Feb 29/March 1 show up at zero on the vertical scale. The red data point for March 2 is at around 2 on the vertical scale. Is this consistent with the facts stated above? No. The data contradict the facts. ☹︎ Think about what it means to be 0 on the vertical scale. Yes. The vertical scale is in log units, so 0 corresponds to 1 death, since \\(\\ln 1 = 0\\). ✓ No. The vertical scale doesn’t mean anything. ☹︎ You can see from the plotting command what the quantity on the vertical axis is: log(confirmed) for the blue dots and log(deaths) for the red. One of the purposes of making a semi-log plot is to enable you to compare very large numbers with very small numbers on the same graph. For instance, in the semi-log plot, you can easily see when the first death occurred, a fact that is invisible in the plot of the raw counts (the first plot in this exercise). Another feature of semi-log plots is that they preserve proportionality. Look at the plot of raw counts and note that the curve for the number of deaths is much shallower than the curve for the number of (confirmed) cases. Yet on the semi-log plot, the two curves are practically parallel. On a semi-log plot, the arithmetic difference between the two curves tells you what the proportion is between those curves. The parallel curves mean that the proportion is practically constant. Calculate what the proportion between deaths and cases was in the month of May. Here’s a mathematical hint: \\(\\ln \\frac{a}{b} == \\ln a - \\ln b\\). We are interested in \\(\\frac{a}{b}\\). Question C What is the proportion of deaths to cases during the month of May? about 0.2% ☹︎ Remember, it’s the natural logarithm that’s being plotted, so the inverse function is exp(). about 1% ☹︎ This would correspond to a (vertical) difference between the curves of about 4.6 log units. Is it really that big? about 2% ☹︎ This would correspond to a (vertical) difference between the curves of about 4 log units. Is it really that big? about 6% ✓ Good. You calculated exp(log(deaths) - log(cases)) which gives an answer around 0.06, or 6%. about 25% ☹︎ I’m not really sure what could lead you to this answer. You’re making a mistake that I didn’t anticipate. more than 50% ☹︎ It’s true that in May log(deaths) is about 12, and log(cases) is about 14, and 12/14 is indeed greater than 50%. But, on a log scale, the proportion relates to the difference between logs, not the ratio. In many applications, people use semi-log plots to see whether a pattern is exponential or to compare very small and very large numbers. Often, people find it easier if the vertical scale is written in the original units rather than the log units. To accomplish both, the vertical scale can be ruled with raw units spaced logarithmically, like this: gf_point(confirmed ~ date, data = Covid_US, color = &quot;blue&quot;) %&gt;% gf_point(deaths ~ date, color = &quot;red&quot;) %&gt;% gf_refine(scale_y_log10()) ## Warning: Transformation introduced infinite values in continuous y-axis ## Warning: Transformation introduced infinite values in continuous y-axis The labels on the vertical axis show the raw numbers, while the position shows the logarithm of those numbers. The next question has to do with the meaning of the interval between grid lines on the vertical axis. Note that on the horizontal axis, the spacing between adjacent grid lines is half a month. Question D What is the numerical spacing (in terms of raw counts) between adjacent grid lines on the vertical axis? \\(10^1\\) ☹︎ If this were true, moving up from the lowest label (1e+01, that is, 10) the next grid line would be at 20, then 30, then 40. \\(10^2\\) ☹︎ If this were true, moving up from the lowest label (1e+01) the next grid line would be at 110, then 210, then 310. A factor of 10. ✓ Right. Every time you move up by one grid line, the raw number increases ten-fold, so 10, 100, 1000, 10,000, and so on. The phrase a factor of 10 means to multiply by 10, not to add 10. A factor of 100. ☹︎ You’re thinking along the right lines, but this is the difference between every second grid line, not adjacent grid lines. 8.3 Curve fitting a periodic function Figure 8.5 shows the tide level in Providence, Rhode Island, starting at midnight on April 1, 2020 and recorded every minute for four and a half days. (These data were collected by the US National Oceanic and Atmospheric Administration. Link) 960 Figure 8.5: About four days of tide-level data from Providence, Rhode Island It’s not too hard to see what’s going on. The tide rises and falls about every 12 hours. The difference between high tide and low tide is a little more than one meter. The tide gauge is calibrated so that a typical reading is 1 meter, although we don’t know what that is respect to. (Certainly not sea level, since then the typical reading would be around zero.) This simple description tells almost everything needed to construct an A/B model of the tide level using a sinusoid, that is, a function of the form \\[A + B \\sin(2\\pi t/P)\\] The procedure is straightforward: Step 0: Determine whether a sinusoid model is appropriate. As you know, sinusoids oscillate up and down repeatedly with a steady period. That certainly seems the case here. But sinusoids are also steady in the peak and trough values for each cycle. That’s only approximately true in the Providence data. Models inevitably involve approximation. We’ll have to keep an eye on whether the fixed amplitude feature of sinusoids Step 1: Choose a sensible value to represent the low point repeatedly reached. 0.5 m seems appropriate here, but obviously the exact position of the trough of each cycle varies over the 4.5 day duration of the data. Similarly, the peak is near 1.6 m. Parameter \\(A\\) is the mean of the peak and trough values: \\(\\frac{1.6 + 0.5}{2} = 1.05\\) m here. Parameter \\(B\\) is half the difference between the peak and trough values: \\(\\frac{1.6 - 0.5}{2} = 0.55\\). Parameter \\(A\\) is called the baseline of the sinusoid. Paramter \\(B\\) is the amplitude. (Note that by convention, the amplitude is always half the high-to-low range of the sinusoid.) Step 2: Estimate the period \\(P\\) of the sinusoid. This can be done with a ruler: the horizontal duration of a complete cycle. I like to use the time between peaks, but the time between troughs would work just as well. Another good choice is the time between positive sloping crossings of the baseline. (But be careful. The time between successive baseline crossings, one positive sloping and the other negative, give just half the period.) On the scale of the above plot, it’s hard to read off the time of the first peak. So, zoom in until it becomes more obvious. Figure 8.6: Zooming in on the start of the data (left) and on the last part of the data (right). The left panel in Figure 8.6 shows about 24 hours at the start of the record. The first peak is at about 7 hours, the second at about 18 hours. That indicates that the period is 18 - 7 = 11 hours. Step 3 Plot out the model over the data. Replacing the symbols \\(A\\), \\(B\\), and \\(P\\) with our estimates, the model is \\[\\require{color} {\\color{green}\\mbox{tide}(t) \\equiv 1.05 + 0.55 \\sin(2\\pi t/11)}\\] Figure 8.7 shows this model in \\(\\color{green}\\mbox{green}\\). Figure 8.7: The sinusoid fails to align with the timing of peaks and troughs. Exercise 8.19: YELXG A person breathes in and out every three seconds. The volume \\(V\\) of air in the person’s lungs varies between a minimum of \\(2\\) liters and a maximum of \\(4\\) liters. Assume time \\(t\\) is measured in seconds. Remember that a full cycle of the sine wave \\(\\sin(x)\\) involves \\(x\\) going from its starting value to that value plus \\(2 \\pi\\). Question A Which of the following is the most appropriate of these models for \\(V(t)\\)? \\(V(t) \\equiv 2 + 2 \\sin \\left( \\frac{\\pi}{3} t \\right)\\) ☹︎ This varies between a minimum of 0 and a maximum of 2. \\(V(t) \\equiv 3 + \\sin \\left( \\frac{2\\pi}{3} t \\right)\\) ✓ Good. In this class, we generally write the sine function like \\(\\sin(2 \\pi t/P)\\) which means that the overall argument to the sine function will go from 0 to \\(2 \\pi\\) when \\(t\\) goes from 0 to \\(P\\). \\(V(t) \\equiv 2 + 2 \\sin \\left( \\frac{2\\pi}{3} t \\right)\\) ☹︎ This varies between a minimum of 0 and a maximum of 2. \\(V(t) \\equiv 3 + \\sin \\left( \\frac{\\pi}{3} t \\right)\\) ☹︎ Right amplitude and baseline: the minimum will be 2 liters and the maximum 4 liters. But the period is wrong. Going from \\(t=0\\) to \\(t=3\\) should produce a full cycle of the sine function. But here the argument would go only from 0 to $ 3 = \\(\\pi\\). After 3 seconds, only half a cycle has been completed. Question B Given a respiratory period of 3 seconds/breath, what is the respiratory frequency in units of breaths/minute? 20 breaths/minute ✓ Right. Each breath takes 1/20th of a minute, which is 3 seconds, the period specified in the question. 3 breaths/minute ☹︎ If this were true, each breath would take 20 seconds to complete. 1/3 breath per minute ☹︎ With breaths completed every three seconds, 1/3 of a breath is completed each second. But the problem asked for breaths per minute. 20 seconds per breath ☹︎ The period is in the units of seconds per breath, but the frequency will have units of breaths per second. Frequency is the reciprocal of period (and vice versa). A respiratory cycle can be divided into two parts: inspiration and expiration. Please do an experiment. Using a clock or watch, breath with a total period of 3 seconds/breath, that is, complete one breath every three seconds. Once you have practiced this and can do it without forcing either phase of breathing, make a rough estimate of what fraction of the cycle is inspiration and what fraction is expiration. (The “correct/incorrect” answers here are right for most people. Your natural respiration might be different.) Question C Which is true? Inspiration lasts longer than expiration ✓ Expiration lasts longer than inspiration ☹︎ Maybe it is for you, but not for most people. Try breathing in while counting 1-2-3 then exhaling while counting 1-2-3-4-5-6. Likely, that’s not a very natural pattern for you. Inspiration and expiration each consume about the same fraction of the complete cycle. ☹︎ People can do this consciously by counting 1-2-3 for inspiration and another 1-2-3 for expiration. This usually feels forced and unnatural. Exercise 8.23: VBWD The graph below shows a recording from a “spirometer,” an instrument for recording respiration. Like many old instruments, the trace from this spirometer is made by a pen at the end of a swinging arm with paper moving steadily beneath it. The arm is not exactly aligned with the horizontal axis. Nonetheless, you should be able to estimate an appropriate amplitude and period for the trace. (dm\\(^3\\) is cubic-decimeters: a tenth of a meter cubed. This is the same as a liter.) Question A What are appropriate estimates for the period and amplitude of the respiration trace? About \\(\\pm 1\\) liter and 3 seconds. ☹︎ If this were true, over the 120 seconds of the recording you would expect to see 40 cycles of respiration. About \\(\\pm 1\\) liter and 5 seconds. ✓ About \\(\\pm 1\\) liter and 7.5 seconds. ☹︎ If this were true, you would expect to see about 16 cycles of respiration over 120 seconds of recording. 8.4 Curve fitting a power-law function You have been using power-law functions from early in your math and science education. Some examples: 970 Setting Function formula exponent Circumference of a circle \\(C(r) = 2 \\pi r\\) 1 Area of a circle \\(A(r) = \\pi r^2\\) 2 Volume of a sphere \\(V(r) = \\frac{4}{3} \\pi r^3\\) 3 Distance traveled by a falling object \\(d(t) = \\frac{1}{2} g t^2\\) 2 Gas pressure versus volume \\(P(V) = \\frac{n R T}{V}\\) \\(-1\\) … perhaps less familiar … Distance traveled by a diffusing gas \\(X(t) = D \\sqrt{ \\strut t}\\) \\(1/2\\) Animal lifespan (in the wild) versus body mass $L(M) = a M^{0.25} 0.25 Blood flow versus body mass \\(F(M) = b M^{0.75}\\) 0.75 The reason why power-law functions have their important role in science have to do with the logic of physical quantities such as length, mass, time, area, volume, force, power, and so on. We’ll discuss this at length later in the course and the principles will appear throughout calculus. As for finding the power law \\(f(x) \\equiv A x^p\\) that provides a good match to data, we’ll need some additional tools to be introduced in Chapter 14. 8.5 Hump and sigmoid functions Our last two basic modeling functions express an important idea in modeling: localness. To put this in concrete terms, imagine creating a function to depict the elevation above sea level of a long road as a function of distance in miles, \\(x\\), from the start of the road. If the road were level at 1200 feet elevation, a sensible model would be \\(\\mbox{elevation}(x) = 1200 \\text{ft}\\). If the road were gently sloping, a better model would be \\(\\mbox{elevation}(x) = 1200 + 3 x\\). 980 Now let’s add a bump to the road. A bump is a local feature, often only a few feet wide. Or, perhaps the road is crossing a mountain range. That’s also a local feature, but unlike a bump in the road a mountain range extends for many miles. The basic modeling function suited to represent bumps in the road, or potholes, or mountain ranges is called a hump function. A hump function has two parameters: the location of the hump, which we’ll call the center parameter, and the sideways extent of the hump, which we’ll call the spread. Figure ?? shows a few hump functions with different parameters. It’s easy to read off the center parameter from a graph of a hump. It’s the location of the top of the hump. (We mentioned before that a mathematical word for “the location of the top” is argmax; the value for the input of the function that produces the maximum output.) The spread parameter is also pretty straightforward, but you first have to become familiar with an unusual feature of the hump function. The output of the hump function far from the center is practically zero. But it is not exactly zero. You can see from the graphs that the hump function has long flanks which approach zero output more or less in the manner of an exponential function. This means that we can’t measure the spread of the hump function by the distance between the zeros on either side of the peak. Instead, we need a convention that will allow us to be precise in quantifying what is admittedly a vague concept of width. A simple convention is that the spread is the “half-width at half-height.” Come down half-way from the peak of the hump. Panel (c) of Figure ?? marks that elevation with a thin, red, horizontal line. Along that line, measure the width of the hump, as marked by the thick red line in Panel (c). The spread parameter is half the width of the hump measured in this way. 990 If you have a keen eye, you’ll notice that the red line is not exactly half-way down from the peak. It’s down 39.35% from the peak. The official definition of width of a hump is not actually half-width at half-height, but that simple formulation will do for us for the present. Another seeming oddity about the hump function is the value of the maximum. It would have seemed natural to define this as 1, so-called “unit height.” The way it actually works is different: the maximum height is set so that the area under the hump function is 1. This business with the area will make more sense when you’ve learned some calculus tools, specifically “differentation” and “integration.” For now though … Consider another road feature, a local change from one elevation to another as you might accomplish with a ramp. The basic modeling function corresponding to a local change from one level to another is the sigmoid function. Figure ?? shows three sigmoid functions. The name “sigmoid” comes from vague resemblance of the graph to the letter S (which is “sigma” in Greek: ς). The parameters of the sigmoid function are the same as for the hump function: center and width. The center is easy to estimate from a graph. It’s the value of the input that produces an output of 0.5, half-way between the max and min of the sigmoid. As with the hump function, the width is measured according to a convention. The width is the change in input needed to go from an output of 0.5 to an output of 0.8413. This use of 0.8413 must seem loony at first exposure, but there is a reason. We’ll need more calculus tools before it can make sense. Hump functions and sigmoid functions with the same center and width parameters have a very close relationship. The slope of the sigmoid function is the corresponding hump function. Figures ?? and ?? show corresponding hump and sigmoid functions. To the very far left, the sigmoid function is effectively flat: a slope near zero. Moving toward the center the sigmoid has a gentle slope: a low number. In the center, the sigmoid is steepest: a higher number. Then the slope of the sigmoid becomes gentle again before gradually falling off to zero. Near zero, then low, then higher, then low again, then falling off to zero: that’s also the description of a hump function! In R, the name of the sigmoid function is pnorm(). The hump is dnorm(). The parameters that specify center and spread are named mean and sd. The word “mean” accurately conveys the idea of “center.” It would be nice to be able to say that sd comes from spread, but in fact sd is short for standard deviation, a old-fashioned term familiar to students of statistics. 1000 “Standard deviation” is off-putting to many people and it really should be replaced with something less weird, perhaps typical spread. The “standard” can be interpreted as “widely used convention.” What about “deviation?” The hump function first appeared two-hundred years ago as part of a theory of measurement error. In the context of “error,” “deviation” might have made sense. But the theory of measurement error long ago became a more general theory of variation. Errors are just one source of variation. Exercise 8.25: IELWV The hump function that we mainly use in CalcZ is implemented in R with dnorm(x, mean, sd). The input called mean corresponds to the center of the hump. The input called sd gives the width of the hump. In a sandbox, make a slice plot of dnorm(x, mean=0, sd=1). By varying the value of width, figure out how you could read that value directly from the graph. slice_plot(dnorm(x, mean=0, sd=1) ~ x, domain(x = c(-4, 4))) In the plot below, one of the double-headed arrows represents the width parameter. The others are misleading. Question A Which arrow shows correctly the width parameter of the hump function in the graph with arrows?     top ✓        middle ☹︎        bottom ☹︎        none of them ☹︎ Question B What is the value of center in the graph with arrows?     -2 ☹︎ The center parameter is the argmax of the function.        -1 ☹︎ The center parameter is the argmax of the function.        -0.5 ☹︎ The center parameter is the argmax of the function.        0 ☹︎ The center parameter is the argmax of the function.        0.5 ✓        1 ☹︎ The center parameter is the argmax of the function.        2 ☹︎ The center parameter is the argmax of the function. Exercise 8.29: CKSLE Hump functions and sigmoidal functions come in pairs. For every possible sigmoid, there is a corresponding hump that gives, for each value of the input, the slope of the sigmoid. Each of the following graphs shows a sigmoid and a hump function. The two might or might not correspond to one another. That is, the output of the hump might be the slope of the sigmoid, or the hump might correspond to some other sigmoid. Remember, you’re comparing the output of the hump to the slope of the sigmoid. For each graph, say whether the hump and the sigmoid correspond to one another. If not, choose one of the reasons why not. Question A Graph (A) The hump and sigmoid correspond. ✓ The peak of the hump does not occur at the same value of \\(x\\) at which the sigmoid is steepest. ☹︎ For what \\(x\\) is the sigmoid the steepest? For what \\(x\\) is the hump the highest? The numerical value of the output of the hump function is, for all \\(x\\), much larger than the numerical value of the slope of the sigmoid. ☹︎ Did you calculate the numerical value of the slope of the sigmoid? Question B Graph (B) The hump and sigmoid correspond. ☹︎ The peak of the hump does not occur at the same value of \\(x\\) at which the sigmoid is steepest. ✓ The hump peaks at about \\(x=2\\) while the steepest part of the sigmoid is at about \\(x=4\\) The numerical value of the output of the hump function is much larger than the numerical value of the slope of the sigmoid. ☹︎ Did you calculate the numerical value of the slope of the sigmoid? Question C Graph (C) The hump and sigmoid correspond. ✓ The peak of the hump does not occur at the same value of \\(x\\) at which the sigmoid is steepest. ☹︎ For what \\(x\\) is the sigmoid the steepest? For what \\(x\\) is the hump the highest? The numerical value of the output of the hump function is, for all \\(x\\), much larger than the numerical value of the slope of the sigmoid. ☹︎ Did you calculate the numerical value of the slope of the sigmoid? In the graph D, there are several hump functions shown, only one of which corresponds to the sigmoid. Question D Which hump corresponds to the sigmoid?     A ☹︎ The value of the hump output is much larger than the slope of the sigmoid.        B ✓ Right! The hump is centered on the steepest part of the sigmoid and falls to zero where the sigmoid levels out.        C ☹︎ The hump is too narrow.        D ☹︎ The hump is too broad and shifted to the left. Exercise 8.33: bllKR Have in mind a hump function and a sigmoid function that form a corresponding pair. Question A Which of these stories is consistent with the relationship between a hump and its corresponding sigmoid? The hump is the amount of water in a bathtub while the sigmoid is the time you spend in the bath. ☹︎ The hump is the amount of water in the bathtub while the sigmoid is the rate at which water flows from the tap. ☹︎ You turn the tap on and off after a while. That’s not what the sigmoid looks like. The hump is the rate at which water flows from the tap and the sigmoid is the amount of water in the bathtub. ✓ The hump indicates the amount the drain is open and the sigmoid is the amount of water in the bathtub. ☹︎ Shouldn’t the amount of water go down when the drain is open? Exercise 8.37: EKCIE A data frame named EbolaSierraLeone11 records the cumulative number of Ebola cases in Sierra Leone from May 1, 2014 to December 16, 2015. Let’s find how well a sigmoidal function models the data. gf_point(Cases ~ Day, data = MMAC::EbolaSierraLeone) It’s straightforward to estimate the values of the parameters from data that have a sigmoidal form. To walk you through the process, the next plot shows simulated data from a genuine sigmoid function. Sketch in a S-shaped curve that smoothly follows the data. Find the top plateau of the S-curve. This is indicated by the red line in the graph above. The parameter A is simply the height of the plateau, in this case \\(y \\approx 15\\). Come down half way from the plateau. Here, that’s 15/2 or 7.5, indicated by the horizontal blue line segment. Find the inverse of the S-curve from that half-way point onto the horizontal-axis. Here, that gives \\(t \\approx 5\\). The parameter center is that value. From the center of the S-shaped curve, follow the curve upward about 2/3 of the way to the plateau. In the diagram, that point is marked with a green line at \\(t \\approx 7\\). The width is the distance along the horizontal axis from the blue centerline to the green line. Here, that’s \\(7 - 5\\) giving 2 as the width. You might also want to trace the S-curve downward from the centerline about 2/3 of the way to zero. That’s indicated by the left green line. In the standard sigmoid, the two green lines will be equally spaced around the centerline. Of course the data may not be in the shape of the standard sigmoid, so you might find the two green lines are not equally spaced from the center. Put aside for the moment that the Ebola data doesn’t look exactly like the standard sigmoid function. Follow the above procedure, nevertheless. Question A Where is the top plateau? About Day 600. ☹︎ Measure the height of the plateau, not where it starts horizontally. About 14,000 cases ✓ About 20,000 cases ☹︎ Read the vertical axis markings more carefully. None of the above ☹︎ One of the above answers is pretty good. Question B Where is the centerline? Near Day 200 ✓ Near Day 300 ☹︎ That’s the center of the vertical scale, not the day at which the curve reaches half-way to the eventual plateau. At about 7000 cases ☹︎ That’s half-way up to the plateau, but the answer you want is the day at which the curve reaches that point. Question C Now to find the width parameter. The curve looks more classically sigmoidal to the left of the centerline than to the right, so follow the curve downward as in Step 4 of the algorithm to find the parameters. What’s a good estimate for width? About 50 days ✓ About 100 days ☹︎ Too wide! About 10 days ☹︎ Too small About 2500 cases ☹︎ The width is measured along the horizontal axis, not the vertical Open a sandbox and use the following commands to plot the Ebola data along with the sigmoid that you matched to the data by eye. The commands also generate and plot a more “refined” estimate found with fitModel() starting with your by-eye parameters. (Note: You’ll need to fill in the blanks at the start of the scaffolding with your by-eye parameters before running the code.) A_estimate &lt;- _____ center_estimate &lt;- _____ width_estimate &lt;- ______ guessed_fun &lt;- makeFun(A* pnorm(Day, center, width) ~ Day, A = A_estimate, center = center_estimate, width = width_estimate) refined_fun &lt;- fitModel(Cases ~ A * pnorm(Day, center, width), data = EbolaSierraLeone, start = list(A=A_estimate, center=center_estimate, width=width_estimate)) gf_point(Cases ~ Day, data = MMAC::EbolaSierraLeone) %&gt;% slice_plot(guessed_fun(Day) ~ Day, color=&quot;red&quot;) %&gt;% slice_plot(refined_fun(Day) ~ Day, color=&quot;blue&quot;) I can’t predict what you see in your graph, since it depends on what starting estimates you used for A, center and width. Essay question tmp-3: Write down the estimates you made by eye for A, center and width. Then explain in words any major systematic deviations of the ‘refined’ model from the data. This idea of fitting a sigmoidal curve globally to data that are only roughly sigmoidal might be forgiven since it’s just a textbook exercise. But if this were a real-world problem, there are three rookie mistakes in the approach, despite its technical sophistication. A model is built for a purpose. There’s no statement in the exercise about what the purpose is. The data themselves are a good enough representation of the historical pattern. There’s no need to adorn them with a fitted curve. The mathematical processes that would justify the expectation that a sigmoid curve could be useful are based on the idea that the underlying mechanism for the phenomenon is unchanging. For an epidemic, that mechanism is contagion. By saying the “mechanism is unchanging,” we mean that person-to-person transmission of the Ebola virus happens in the same way at the beginning of the epidemic as it does in the middle and in the end. But strong public health interventions were introduced to control the epidemic. That’s a change in mechanism. 8.6 The modeling cycle Effective modelers treat models with skepticism. They look for ways in which models failure to capture salient features of the real world. They have an eye out for deviations between what their models show and what they believe they know about the system being modeled. They consider ways in which the models might not serve the purpose for which they were developed. 1010 When modelers spot a failure or deviation or lack of proper utility, they might discard the model but more often they make a series of small adjustments, tuning up the model until is successfully serves the purposes for which it is intended. Thus, modeling is a cyclic process of creating a model, assessing the model, and revising the model. The process comes to a sort of preliminary end when the model serves its purposes. But even then, models are often revised to check whether the results are sensitive to some factor that was not included or to check whether some component that was deemed essential really is so. 8.6.1 Example: Cooling water Looking back on the exponential fitted to the cooling water data in Section 8.2, it looks like our original estimate of the half-life is a bit too small; the data doesn’t seem to decay at the rate implied by \\(k = -0.0277\\). Perhaps we should try a somewhat slower decay, say \\(k = -0.2\\) and see if that improves things. In the cooling water example, we’re using only a subset of the data collected by Prof. Wagon. The next commands re-create that subset so that you can work with it. They also plot the data and an exponential model. 1020 # reconstruct the sample set.seed(101) Stans_data &lt;- CoolingWater %&gt;% sample_n(20) # Plot the sample and overlay a model gf_point(temp ~ time, data=Stans_data) %&gt;% gf_lims(y = c(20, NA)) %&gt;% slice_plot(25 + 83.3*exp(-.0277*time) ~ time, color=&quot;blue&quot;) See if \\(k=-0.02\\) provides a better fit to the model. (You can add another slice_plot() to be able to compare the original and \\(k=-0.02\\) models.) Later in CalcZ, we’ll study optimization. There are optimization techniques for directing the computer to refine the parameters to best match the data. Just to illustrate, here’s what we get: refined_params &lt;- fitModel(temp ~ A + B*exp(k*time), data = Stans_data, start = list(A = 25, B = 83.3, k = -0.0277)) coef(refined_params) ## A B k ## 25.92628463 60.69255269 -0.01892572 new_f &lt;- makeFun(refined_params) gf_point(temp ~ time, data = Stans_data) %&gt;% slice_plot(new_f(time) ~ time, color=&quot;blue&quot;) Figure 8.8: Polishing the fit using the rough model as a starting point. The refined parameters give a much better fit to the data than our original rough estimates by eye. We had two rounds of the modeling cycle. First, choice of an A/B expontential model and a rough estimate of the parameters A, B, and \\(k\\). Second, refinement of those parameters using the computer. Looking at the results of the second round, the experienced modeler can see some disturbing discrepancies. First, the estimated baseline appears to be too high. Related, the initial decay of the model function doesn’t seem to be fast enough and the decay of the model function for large \\(t\\) appears to be too slow. Prof. Stan Wagon noticed this. He used additional data to fill in the gaps for small \\(t\\) and refined his model further by changing the basis functions in the linear combination. He hypothesized that there are at least two different cooling processes. First, the newly poured water raises the temperature of the mug itself. Since the water and mug are in direct contact, this is a fast process. Then, the complete water/mug unit comes slowly into equilibrium with the room temperature. 1030 The newly refined model was a even better match to the data. But nothing’s perfect and Prof. Wagon saw an opportunity for additional refinement based on the idea that there is a third physical mechanism of cooling: evaporation from the surface of the hot water. Prof. Wagon’s additional circuits of the modeling cycle were appropriate to his purpose, which was to develop a detailed understanding of the process of cooling. For other purposes, such as demonstrating the appropriateness of an exponential process or interpolating between the data points, earlier cycles might have sufficed. Here’s a graph of the model Prof. Wagon constructed to match the data. Figure 8.9: A model that combines three exponentials provides an excellent fit. This is an excellent match to the data. But … matching the data isn’t always the only goal of modeling. Prof. Wagon wanted to make sure the model was physically plausible. And looking at the refined parameters, which include two exponential processes with parameters \\(k_1\\) and \\(k_2\\), he saw something wrong: But what can we make of \\(k_1\\), whose [positive value] violates the laws of thermodynamics by suggesting that the water gets hotter by virtue of its presence in the cool air? The most likely problem is that our simple model (the proportionality assumption) is not adequate near the boiling point. There are many complicated factors that affect heat transportation, such as air movement, boundary layer dissipation, and diffusion, and our use of a single linear relationship appears to be inadequate. In the next section [of our paper] we suggest some further experiments, but we also hope that our experiments might inspire readers to come up with a better mathematical model. The modeling cycle can go round and round! 8.6.2 Example: The tides Step 4: Evaluate and refine. The green model would make poor predictions. The model says “high tide” when the data say otherwise. What’s missing is the phase of the sinusoid. A model that incorporates the phase is 1040 \\[{\\color{blue}{\\mbox{tide}(t)} \\equiv 1.05 + 0.55 \\sin(2\\pi (t - t_0)/11)}\\] The new parameter, \\(t_0\\), should be set to be the time of a positive-going crossing of the baseline. There’s such a crossing at about time = 17. Happily, changing the phase does not itself necessitate re-estimating the other parameters: baseline, amplitude, period. This model, incorporating the phase, has been graphed in \\(\\color{blue}\\mbox{blue}\\). Figure 8.10: Shifting the phase of the sinusoid gives the flexibility needed to align the peaks and troughs of the model with the data. Performing this alignment for one peak makes it clear that the period is wrong. For some modeling purposes, such as prediction of future tides, the phase information is impossible. For others, say, description of the amplitude of the tides, not. But getting the phase roughly right can help point out other problems. For instance, having the blue sinusoid for comparison makes it clear that the estimated period of 11 hours is too short. Maybe 13 hours would be better. Better still, since at \\(t=t_0 = 17\\) the model is a close match to the data, let’s use that as the estimate of the start of a cycle. But then, let’s move much further along in the data to find another baseline crossing. To judge from the right panel, there is a baseline crossing at \\(t=103\\). The difference between these two times is \\(103 - 17 = 86\\) hours. Of course, the period is not 86 hours. Looking back at the whole set of data we can see 7 complete cycles between \\(t=17\\) and \\(t=103\\). So our new estimate of the period is \\(86/7 = 12.3\\) hours. With this refinement the model is \\[{\\color{green}{\\mbox{tide}(t)} \\equiv 1.05 + 0.55 \\sin(2\\pi (t - 17)/12.3)}\\] Figure 8.11: With the phase about right, a better estimate can be made of the period: 12.3 hours. That’s a pretty good match to the data! We might call it quits at that. First, let’s polish up the parameter estimates, letting the computer do the tedious work of trying little tweaks to see if it can improve the fit. tide_mod &lt;- fitModel(level ~ A + B*sin(2*pi*(hour-hzero)/P), data = RI_tide, start=list(A=1.05, B=0.55, hzero=17, P=12.3)) coef(tide_mod) ## A B hzero P ## 1.0220540 0.4998367 15.3899905 12.5593556 Figure 8.12: Polishing the parameters of the sinusoid This last model seems capable of making reasonable predictions, so if we collected up-to-date data we might be able to fit a new model to predict the tide level pretty accurately a few days ahead of time. Also, the excellent alignment of the model peaks with the data tell us that the cyclic tide has a period that constant, at least so far as well can tell. 1050 With the period estimate \\(P=12.56\\) hours, we can go looking for other phenomena that might account for the tides. The period of the day-night cycle is, of course 24 hours. So the tides in Providence come in and out twice a day. But not exactly. Something else must be going on. Isaac Newton was the first to propose that the tides were caused by the gravitational attraction of the Moon. A complete cycle of the Moon—moon rise to moon rise—takes about 50 minutes longer than a full day: the Earth revolves once every 24 hours, but in that time the Moon has moved a bit further on in its orbit of the Earth. So the Moon’s period, seen from a fixed place on Earth is about 24.8 hours. Half of this, 12.4 hours, is awfully close to our estimate of the tidal period: 12.56 hours. The difference in periods, 8 minutes a day, might be hard to observe over only 4 days. Maybe with more data we’d get a better match between the tides and the moon. This is the modeling cycle at work: Propose a model form (A/B model with sinusoid), adjust parameters to match what we know (the Providence tide record), compare the model to the data, observe discrepancies, propose a refined model. You can stop the model when it is giving you what you need. The period 12.56 hour model seems good enough to make a prediction of the tide level a few days ahead, and is certainly better than the “two tides a day” model. But our model is not yet able to implicate precisely the Moon’s orbit in in tidal oscillations. Discrepancies between a model and data play two roles: they help us decide if the model is fit for the purpose we have in mind and they can point the way to improved models. That the tidal data deviates from the steady amplitude of our model can be a clue for where to look next. It’s not always obvious where this will lead. Historically, careful analysis of tides led to a highly detailed, highly accurate model: a linear combination of sinusoids with diurnal periods 12.42, 12.00, 12.66, and 11.97 hours as well components with period 23.93, 25.82, 24.07, 26.87, and 24.00 hours. A tide-prediction model is constructed by finding the coefficients of the linear combination; these differ from locale to locale. 1060 Exercise 8.39: GSEww The data frame SunsetLA records the number of minutes after 4 pm until the sun sets in Los Angeles, CA over a 4-year interval from January 2010 (month 1) through December 2013 (month 48). Open a sandbox and make a plot of sunset time versus month. gf_point(Minutes ~ Month, data = SunsetLA) %&gt;% gf_line() We’re using both gf_point() and gf_line(). With data that oscillates up and down, connecting the data points with lines makes it easier to see the pattern. Question A What is the range of the number of minutes until sunset over the whole 4-year period? 40 to 190 minutes ✓ 120 minutes ☹︎ A range is an interval spanned by two numbers. 40 to 180 minutes ☹︎ The largest values are half a tick mark up from 180. Tick marks are spaced by 20 minutes. 0 to 48 months ☹︎ That’s the domain. The range is along the vertical axis. Question B The data fall nicely on a sine-shaped curve. What is the period of that sine?     6 months ☹︎ Look at the number of months from one peak to another.        11 months ☹︎ Look more carefully. And remember that the change in length of day is an annual phenomenon.        12 months ✓        12 minutes ☹︎ Period refers to an interval on the domain of the function, not the range. The function \\[\\mbox{sunset}(\\mbox{Month}) \\equiv A \\sin(2 \\pi\\, \\mbox{Month} / 12) + C\\] is a linear combination of two functions: The constant function one(Month) The sine function sin(2*pi*Month/12) The two functions are scaled by \\(C\\) and \\(A\\), respectively. You can estimate \\(C\\) by the mid-point of the range (in minutes) of the data. You can estimate \\(A\\) as half the length of the range (that is, half the max minus the min.) Make rough but reasonable numeric estimates for \\(C\\) and \\(A\\) from the data. Then, in the sandbox, define the sunset() function using the numerical estimates in the linear combination. Plot your function as a layer on top of the data. (Pipe the gf_point() layer to slice_plot().) sunset &lt;- makeFun(A + C*sin(2*pi*(Month - offset)/12), A = __your estimate__, C = __your estimate__, offset=0) gf_point(Minutes ~ Month, data = SunsetLA) %&gt;% gf_line() %&gt;% slice_plot(sunset(Month) ~ Month) The domain for slice_plot() is inherited to that implied by the SunsetLA data. Notice that the input name in slice_plot() corresponds to that established in gf_point(). Question C Your sunset() function should be a pretty good match to the data except for one thing. What is that thing? The sunset() function has a completely different range than the data. ☹︎ This won’t be the case if you have estimated \\(C\\) and \\(A\\) correctly. The period of the sunset() function doesn’t match the data. ☹︎ Did you use sin(2*pi*Month/12)? If so, the period should be right. There is a horizontal time shift between sunset() and the data. ✓ We’re going to fix the problem with sunset() by defining a time offset to use as a reference. For a sine function, a suitable time offset is the value along the horizontal axis when the phenomenon being modeled crosses \\(C\\) with a positive slope. There are 4 such points along the horizontal axis readily identifiable in the data. (They may not be at an integer value of Month.) Question D Which of these is a suitable value for the time offset?     0 months ☹︎ That’s not a time when the data suggest that \\(C\\) is being crossed.        19 months ☹︎ That’s a maximum, not a crossing of \\(C\\).        21.5 months ☹︎ That’s a crossing of \\(C\\), but not one with a positive slope.        15.5 months ✓ This is a good rough value. Since the period is 12 months, you could equally well have said the offset is 3.5 months. In the original scaffolding, the value of offset was zero. Change that to match your answer to the previous question. Plot out the modified sunset() function and confirm that it is a much better match to the data than the original (that is, the one without the time offset). You can “tune” your function by tweaking the numerical values of the \\(A\\), \\(C\\), and \\(offset\\) parameters until you get a solid match. Alternatively, you can use fitModel() to do the tuning for you. Plug in your estimates (a.k.a. “guesses”) for the parameters in place of the ___ in the following. Then run the code. You’ll see your estimate of the function compared to the result of having the computer refine your estimate. Chances are, the computer does a better job of stringing the function through the data. ## rough estimates from graph rough_A &lt;- __estimated_A__ rough_C &lt;- __estimated_C__ rough_offset &lt;- __estimated_offset___ guessed_fun &lt;- makeFun(A*sin(2*pi*(Month - offset)/12) + C ~ Month, A = rough_A, C = rough_D, offset = rough_offset) tuned_fun &lt;- fitModel(Minutes ~ A*sin(2*pi*(Month - offset)/12) + C, data = SunsetLA, start = list(A = rough_A, C = rough_C, offset = rough_offset) ) gf_point(Minutes ~ Month, data = SunsetLA) %&gt;% gf_line(color = &quot;blue&quot;) %&gt;% slice_plot(tuned_fun(Month) ~ Month) %&gt;% slice_plot(guessed_fun(Month) ~ Month, color = &quot;red&quot;) Perhaps you were expecting the tuned sine function to match the data exactly. It does not. One reason for this is that the Earth’s orbit around the Sun is not exactly circular. The sine function is only a model of the phenomenon, good for some purposes and not for others. For a more complete explanation, see this article on Wikipedia. (Thomas Swalm contributed to this exercise.) From the {MMAC} R package↩︎ "],["fun-slopes.html", "Chapter 9 Slope function 9.1 Change and slope 9.2 Continuous change 9.3 Slope 9.4 The fitted line 9.5 Average rate of change 9.6 Instantaneous rate of change", " Chapter 9 Slope function For our purposes, the definition of calculus is 1100 The use of functions to model and explore continuous change The agenda of this chapter is to give specific mathematical meaning to the word “change.” 9.1 Change and slope You have an solid, intuitive sense of what “change” means. In mathematics, and especially the mathematics of functions, change has a very simple meaning that you have already touched on in your previous math education. The word that encapsulates “change” in high-school math is slope. For instance, you’ve undoubtedly had to calculate the slope of a straight line in a graph. You learned about “rise” and “run” and how to read them from a graph or from a formula. The slope is the ratio: rise over run. Slope is a lovely metaphor for change, since everyone has a intuitive sense of the slope of a road or of a hillside. You learned to apply this intuition to reading graphs and the slope of a line. We’ll exploit the intuitive ability to read a landscape in order to introduce abstract mathematical ideas in a down-to-earth setting. It’s a very effective pedagogical strategy. But not everything that changes has a “slope.” For instance, the population of a country can change, as can the number of new cases of an epidemic disease, the temperature of a cup of coffee, or the distance from Earth of a spacecraft. A major part of learning calculus is generalizing and abstracting the mathematical concept of which “slope” is an example and becoming proficient with mathematical procedures for working with change. 9.2 Continuous change Most people are comfortable with the ideas of daily changes in temperature or monthly changes in credit-card debt or quarterly changes in the unemployment rate or annual changes in the height of a child. Such things are easy to record in, say, a spreadsheet. For example, as I write, the weather forecast for the next several days (in southeastern Colorado in mid-May) is 1110 Day High Low Description Thursday 73 43 sunny Friday 72 48 windy Saturday 66 48 thunderstorms Sunday 68 43 windy Monday 70 39 sunny Tuesday 70 43 sunny Wednesday 66 45 partly cloudy Such data is said to be discrete. The day is listed, but not the time of day. The high temperature is forecast, but not the time of that high. The “description” is also discrete, one of the several words that are used to summarize the quality of the weather, as opposed to the quantity of rain. Calculus is about continuous change. For instance, if the weather bureau provide a web interface that let me enter the date and time to the nearest fraction of a second, they would be giving a way to track the change continuously. Many physical processes are intrinsically continuous, for instance the motion (change in position) of a spacecraft or the height of the tide or the stress on a tree as a function of wind velocity. Finding a language to describe continuous change—famously, the position of the moon or planets in their orbit, or the speed of a ball rolling down a ramp—was central to the emergence of what historians call the “Age of Enlightenment” or “modern scientific method.” The first complete presentation of that language was published by Isaac Newton based on his work in the 1660s. As you might guess, the name of the language is “calculus.” 9.3 Slope You already know pretty much everything there is to know about the straight-line function, Formula: \\(f(x) \\equiv a x + b\\). The parameters \\(a\\) and \\(b\\) are the “slope” and “intercept” respectively. (More precisely, \\(b\\) is the “y-intercept.” But in statistics and modeling, it’s just the “intercept.”) Reading parameters from a graph: You learned several ways to do this which are all equivalent. Maybe the easiest is the read the y-intercept off the graph. That’s \\(b\\). Then choose some non-zero \\(x_1\\) and read off from the graph the value of \\(f(x_1)\\). The slope is simply \\[\\frac{f(x_1) - b}{x_0}\\] The y-intercept method is a special case of a more general method, the two-point method, that you can use even if the y-intercept isn’t shown on the graph. Pick two specific values of \\(x\\), which we’ll call \\(x_0\\) and \\(x_1\\). Evalate the function at these input values and compute the rise over run: \\[\\mbox{rise over run} \\equiv \\frac{f(x_1) - f(x_0)}{x_1 - x_0}\\] The rise over run is the slope of the straight line. The y-intercept method is exactly the same as the two-point method with \\(x_0 = 0\\). Matching a straight-line function to data: You might not have been taught this formally, but the basic process is easy to imitate. The process is called line fitting or, in statistics and other fields, linear regression. 1120 9.4 The fitted line [Fun-4-a-1] Construct a straight-line model that fits data. To illustrate line fitting, let’s return to the cooling mug of water. Figure 9.1 shows the data along with a dozen candidate straight line functions, each one drawn in its own color. Figure 9.1: Some candidate straight-line function models plotted on top of the cooling water data. Which one(s) would you pick as good matches to the data? Some of the straight-line models are a much better match to the data than others. The blue-shaded functions are pretty good fits, the greenish functions are maybe OK but a little sketchy, and the purple-shaded functions are just horrible. Now that you know what a reasonable straight-line model looks like, you will find it pretty easy to draw one on data graphics that even remotely show a straight-line pattern. Step 1: Draw a reasonable straight-line through the data points. Step 2: Find the parameters that correspond to the line you drew. 9.5 Average rate of change Since the slope is our standard way of representing a relationship of change, we will often use it as a way of summarizing a function. To illustrate, consider the exponential model we constructed to match the cooling-water data: 1130 water &lt;- makeFun(60.7*exp(-0.019*t) + 25.93 ~ t) Figure 9.2: The exponential function that was previously matched to the cooling-water data. The slope of the straight line connecting two points on the function graph is the average rate of change during the interval. During the interval \\([t_0, t_1]\\) the rate at which the water cools is higher at first and lower at the end. The average rate of change is a single number that summarizes the whole interval. For all except straight-line models, the average rate of change depends on the interval chosen. Exercise 9.3: KEWIX We will be working extensively with the change in output value of a function when the input value changes. The change in the output value of a function \\(f()\\) when the input changes from \\(x = a\\) to \\(x = b\\) is \\[f(x=b) - f(x=a)\\] Notice that when we talk about the change from \\(x=a\\) to \\(x=b\\) we subtract \\(f(x=a)\\) from \\(f(x=b)\\). That change is sometimes called the rise in the value of the function. Rise always compares (by subtraction) the two output values corresponding to two specific input values. Remember that \\(a\\) and \\(b\\) stand for specific numbers. Corresponding with the idea of the change in output being \\(f(x=b) - f(x=a)\\) the change in the input value to a function is \\(b - a\\). This is often called the run in the value of the input. Each point on the graph of a function has Cartesian coordinates \\((a, f(x=a))\\). For example, the graph of the function \\(f()\\) shown in Graph I includes points such as \\((1.0, 4.0)\\), and \\((3.5, 3.0)\\). The second coordinate is the output value when we provide the first coordinate as an input value. The nature of the \\(f()\\) function (as defined by the graph) is such that \\(f(x=1) \\equiv 4\\) and \\(f(x=3.5) \\equiv 3\\). Question A True or false: In Graph I, the rise from a to b is positive.     TRUE ☹︎ \\(f(x=a) &gt; f(x=b)\\), so the rise \\(f(x=b) - f(x=a)\\) is negative.        FALSE ✓ Question B True or false: In Graph I, the run from \\(x=a\\) to \\(x=b\\) is positive.     TRUE ✓        FALSE ☹︎ The run is about the relative positions of \\(x=a\\) and \\(x=b\\) on the x-axis. Since \\(a &lt; b\\), the run from \\(x=a\\) to \\(x=b\\) is positive. Question C True or false: In Graph II, the run from a to b is positive.     TRUE ✓        FALSE ☹︎ The run is about the relative positions of a and b on the x-axis. Since a is to the left of b, the run from a to b is positive. Question D True or false: In Graph II, the rise from a to b is positive.     TRUE ☹︎ Remember, the rise from \\(x=a\\) to \\(x=b\\) is \\(f(x=b) - f(x=a)\\)        FALSE ✓ Question E True or false: In Graph II, the run from b to c is positive.     TRUE ☹︎ The run from \\(x=b\\) to \\(x=c\\) is \\(c - b\\). Since \\(b&gt;c\\) b to c is negative.        FALSE ✓ Question F True or false: In Graph II, the rise from b to c is positive.     TRUE ✓        FALSE ☹︎ The rise from \\(x=b\\) to \\(x=c\\) is \\(f(x = c) - f(x = b)\\). Since \\(f(x=c) &gt; f(x=b)\\), the rise is positive. Question G For an interval [2, 6] what is the value of the run? (The answer is independent of any particular graph/function.)     4 ✓ The run is always the second number in the interval minus the first number. That’s \\(6 - 2\\) here.        -4 ☹︎ You got it backwards! The second number in the interval, 6, is numerically to the right of 2, so the run is positive. Question H Which is the run of the interval [6, 2]? (Again, the answer is independent of any particular graph/function.)     4 ☹︎ Sorry. The run from \\(x=6\\) to \\(x=2\\) is \\(2 - 6\\) which is \\(-4\\).        -4 ✓ The run is \\(2 - 6\\), the second number in the interval minus the first number. Exercise 9.7: WRWIX From the graph in Figure 9.2, compute the average rate of change over the interval \\(10 \\leq t \\leq 200\\). How does it compare to the average rate of change over the interval \\(10 \\leq t \\leq 125\\)? Exercise 9.11: YQCLE Open an R sandbox. You can use these function definitions to help you in your calculations. f &lt;- makeFun(2*exp(x+1) ~ x) g &lt;- makeFun(3*exp(-x) ~ x) h &lt;- makeFun(x*exp(x) ~ x) Using R, compute the average rate of change of the function over the given interval. Choose the closest answer for each problem. Question A \\(f(x) \\equiv 2 e^{x+1}\\) over [-2, 2]     -2.99 ☹︎        1.54 ☹︎        2.72 ☹︎        4.68 ☹︎        9.85 ✓        11.32 ☹︎ Question B \\(g(x) \\equiv 3 e^{-x}\\) over [-1, 1.5]     -2.99 ✓        1.54 ☹︎        2.72 ☹︎        4.68 ☹︎        9.85 ☹︎        11.32 ☹︎ Question C \\(h(x) \\equiv x e^x\\) over [0, 1]     -3 ☹︎        1.54 ☹︎        2.72 ✓        4.68 ☹︎        9.85 ☹︎        11.32 ☹︎ It’s much less work if we use the R function c() to define the interval, and the R function diff() to calculate differences. The next sandbox contains an example asking you to compute the average rate of change of \\(f(x) \\equiv e^x\\) over the interval [0, 4]. You only need lines 1, 3, and 5. The other lines show intermediate results to help you understand what diff() is doing. interval &lt;- c(0, 4) # creates the interval diff(interval) # calculate the run f &lt;- makeFun(exp(x) ~ x) # create the function f(interval) # evaluate function at the endpoints of the interval diff(f(interval)) / diff(interval) # complete answer Question D MMAC 4.1.61: True or false: The average rate of change of \\(f(x) \\equiv e^{x^2}\\) over [0.0, 0.1] is 0.1005017     TRUE ✓        FALSE ☹︎ Question E MMAC 4.1.62: True or false: The average rate of change of \\(f(x) \\equiv \\log(x)\\) over [2, 3] is 0.5062353. (Hint: Change the code above so the interval variable goes from 2 to 3 and f becomes the function \\(f(x) \\equiv \\log(x)\\))     TRUE ☹︎        FALSE ✓ Question F MMAC 4.1.61: True or false: The average rate of change of \\(f(x) \\equiv \\sin(x)\\) over [0.0, 0.5] is 0.9588511     TRUE ✓        FALSE ☹︎ Exercise 9.15: KEWIX Consider the sinusoid function, graphed below. Question A What is the average rate of change over the interval \\(0 &lt; x &lt; \\frac{1}{2}\\)? (Choose the closest value.)     0 ☹︎ For this to be true, the function output would need to be the same at the two endpoints of the interval.        0.5 ☹︎ Did you forget to divide the rise by the run?        1 ✓ Right. From the interval you have that the run is 1/2. The rise over that interval is from 0 to 1/2, so a rise of 1/2. Question B What is the average rate of change over the interval \\(0 &lt; x &lt; 6.25\\)? (Choose the closest value.)     -0.5 ☹︎        0 ✓ Right. The function output is zero at both endpoints of the interval, so the rise is zero. Hence, the run is zero.        0.5 ☹︎ Question C What is the average rate of change over the interval \\(0 &lt; x &lt; 10\\)? (Choose the closest value.)     -0.05 ✓ Right. The rise is -0.5 and the run is 10.        -0.5 ☹︎ This is the “rise” over the interval, but it’s not the average rate of change. You’ll need to divide the rise by another quantity to get the average rate of change.        0 ☹︎        0.5 ☹︎ The rise will be \\(f(10) - f(0) pprox -0.5 - 0 = -0.5\\). You’ve got the sign wrong. Exercise 9.19: URIMX For each of the following, compute the average rate of change of the function over the given interval. Question A The average rate of change of \\(f(x) \\equiv x + 5\\) over [3, 5] is     -2 ☹︎ Remember, the difference from \\(x=3\\) to 5 is \\(f(5) - f(3)\\), not the other way around. And the average rate of change is the difference divided by the length of the interval.        -1 ☹︎ Remember, the difference from \\(x=3\\) to 5 is \\(f(5) - f(3)\\), not the other way around. Similarly, the length of the interval from \\(x=3\\) to 5 is \\(5-3\\), not \\(3-5\\).        1 ✓ \\(f(x=5) = 10\\) and \\(f(x=3) = 8\\), so the difference in values is 2. Since this difference occurs over an interval of length 2 (that is, from #x=3$ to 5), the average rate of change is 2/2.        2 ☹︎ Are you sure you took the rate of change rather than simply the change? Question B The average rate of change of \\(f(x) \\equiv 3 - 2 x\\) over [-4, -2] is     -4 ☹︎ This is the total difference over the interval, not the rate of change.        -2 ✓ The difference from \\(x=-4\\) to \\(-2\\) is \\(f(-2) - f(-4) = (7) - (11) = -4\\). The length of the interval is \\((-2) - (-4) = 2\\). So the rate is -4/2, just as you got.        0 ☹︎        1 ☹︎ When \\(x\\) changes by two units, \\(f(x)\\) changes by 4. The rate of change is 4/2 = -2.        2 ☹︎ Check your +/- signs.        4 ☹︎ This is the negative total difference over the interval, not the rate of change. Also check your +/- signs. Question C The average rate of change of \\(f(x) \\equiv -3 x^2\\) over [0, 4] is     -24 ☹︎ Perhaps you are looking at the derivative at \\(x=4\\) and not the average rate of change from \\(x=0\\) to 4.        -12 ✓ The difference in \\(f()\\) over the interval is \\(f(4) - f(2) = (-48) - 0 = -48\\). The length of the interval is \\(4-0\\), so the average rate of change over the interval is \\((-48)/4 = -12\\).        0 ☹︎ Perhaps you are looking at the derivative at \\(x=0\\) and not the average rate of change from \\(x=0\\) to 4.        1 ☹︎        2 ☹︎        12 ☹︎ Check the signs in your arithmetic.        24 ☹︎ Question D The average rate of change of \\(f(x) \\equiv x^3 - 2 x + 1\\) over [0, 2] is     -2 ☹︎ Either check your +/- signs or perhaps you are looking at the derivative at \\(x=0\\) and not the average rate of change from \\(x=0\\) to 2.        1.5 ☹︎        2 ✓ The difference in \\(f()\\) over the interval is \\(f(2) - f(0) = 5 - 1 = 4\\). The length of the interval is \\(2 - 0\\) so the average rate of change is \\(4/2 = 2\\).        7 ☹︎        10 ☹︎ I think you are looking at the derivative at \\(x=2\\) rather than the average rate of change from 0 to 2. In Block 2, we’ll see that a good way to define an instantaneous rate of change at \\(t_0\\) is as the average rate of change over the interval \\(t_0 \\leq t \\leq t_1\\) with the proviso that the interval length \\(t_1 - t_0\\) goes as closely as it can to zero. “Slope” is a natural metaphor when thinking of a function as a graph. But a more general way to describe the concept is the rate of change of the output with respect to the input. The change in the output from one end of the interval is \\(f(x_1) - f(x_0)\\), the change in the input is \\(x_1 - x_0\\). If the input is time (in hours), and the output is the position of a car (in miles), then the rate of change is miles-per-hour: the car’s velocity. For a straight-line function—think of a car driving at constant speed on a highway—it doesn’t matter what you choose for \\(x_1\\) and \\(x_0\\) (so long as they are not identical). But for other functions, the choice does matter. Imagine a graph of the position of a car along a road as in Figure @ref{fig:stop-and-go}. Over the course of an hour, the car travelled about 25 miles. In other words, the average speed is 25 miles/hour: the slope of the red line segment. Given the traffic, sometimes the car was stopped (time C), sometimes crawling (time D) and sometimes much faster than average (time B). During the interval from B to C, the car was travelling relatively fast. The slope of the brown segment connecting the position at times B and C is the average rate of change between times B and C. It’s easy to see that the average rate of change from B to C is larger than the overall average from \\(t=0\\) to \\(t=1\\). Calculating that slope is a matter of evaluating the position at the endpoints and dividing by the length of the interval. 1140 What is the average rate of change in the car’s position during the interval \\(t_B = 0.40\\) to \\(t_C=0.54\\)? The length of the interval is \\(t_C - t_B = 0.54-0.40=0.14\\). Evaluating the function gives \\(x(t_C) = 18\\) and \\(x(t_B) = 12.6\\). Rise is \\(x(t_C) - x(t_B) = 18 - 12.6 = 5.4\\). Run is \\(t_C - t_B = 0.54-0.40=0.14\\). The average rate of change during the interval is $5.4/0.14 = 38.6 $ miles/hour. Exercise 9.23: HRTIX For each exercise, you are given a series of intervals that get smaller and smaller. Your job is to calculate the average rate of change of the function \\(f(x) \\equiv x^2\\) for each of the intervals. As the width of the intervals approach zero, our average rates of change become better approximations of the instantaneous rates of change. You should use the results you calculate to make an informed estimate of the instantaneous rate of change. interval &lt;- c(__start__ , __end__ ) f &lt;- makeFun(x^2 ~ x) diff(f(interval)) / diff(interval) A. Use these three intervals to estimate the instantaneous rate of change \\(\\partial_x f(x=3)\\) - [3, 3.1] - [3, 3.01] - [3, 3.001] B. Use these three intervals to estimate the instantaneous rate of change \\(\\partial_x f(x=5)\\) - [4.9, 5] - [4.99, 5] - [4.999, 5] C. Use these three intervals to estimate the instantaneous rate of change \\(\\partial_x f(x=-2)\\) - [-2, -1.9] - [-2, -1.99] - [-2, -1.999] 9.6 Instantaneous rate of change The water is cooling continuously. Sometimes we’ll be interested in the rate of change at a given instant \\(t_0\\). It’s straightforward to make out what the instantaneous rate of change will be on a graph: the slope of the line tangent to the curve at \\(t_0\\), as in Figure 9.3. 1150 Figure 9.3: A line tangent to a the curve at a single point. The slope of this line is the instantaneous rate of change. It’s convenient to be able to find the slope of such a tangent line using just the definition \\(f(t)\\), rather than having to draw a graph and eyeball the tangent. For now, let’s approximate the slope of tangent line by the average rate of change over a small run from \\(t_0\\) to \\(t_0 + 0.1\\): \\[\\text{slope of}\\ f(t) \\ \\text{at}\\ t_0 \\approx\\frac{f(t_0 + 0.1) - f(t_0)}{0.1} = \\frac{\\text{amount of rise}}{\\text{length of run}}\\] The \\(\\approx\\) symbol means “is approximately.” For now, I want to put off the question of what “approximately” means. In modeling, whether the 0.1 gives a good enough approximation will depend on the function \\(f()\\) and the context in which the slope is needed. For instance, in drawing Figure 9.3 I needed to find the tangent line. Using 0.1 is entirely satisfactory in this setting but it might not be in other settings. The notation “slope of \\(f(t)\\) at \\(t_0\\)” is long-winded and awkward. If we were looking at the “value of \\(f(t)\\) at \\(t_0\\) we have at hand a much more concise notation: \\(f(t_0)\\). But it doesn’t work to write”slope of \\(f(t_0)\\)\" because \\(f(t_0)\\) is a quantity and not a function. Instead, let’s make a concise notation for “slope of \\(f(t)\\).” Following tradition, we’ll write \\({\\cal D}f(t)\\). The name of this “slope of \\(f(t)\\)” function is \\({\\cal D}f()\\): a two-letter name. When we want to say, “the (approximate) slope of the tangent line to \\(f(t)\\) at \\(t_0\\), we can write simply: \\[{\\cal D}f(t_0)\\] meaning, evaluate the”slope function of f()\" at \\(t_0\\). To formalize this, we’ll define the slope function of f() as \\[{\\cal D}f(t) \\equiv \\frac{f(t + 0.1) - f(t)}{0.1}\\] Let’s look at the slope functions that correspond to some of naked modeling functions: \\(e^x\\), \\(\\sin(x)\\), \\(x^{-1}\\) and \\(\\ln(x)\\). We can define them easily enough in R: Dexp &lt;- makeFun((exp(t+0.1) - exp(t))/0.1 ~ t) Dsin &lt;- makeFun((sin(t+0.1) - sin(t))/0.1 ~ t) Dxm1 &lt;- makeFun(((1/(t+0.1)) - (1/t))/0.1 ~ t) Dlog &lt;- makeFun((log(t+0.1) - log(t))/0.1 ~ t) Figure 9.4: Comparing the naked modeling function (blue) to it’s slope function (red) Exercise 9.27: CUXLR There is a web of connections between the naked modeling functions and their slopes. Question A 1. Which naked modeling function has a slope function that is simply a input-shifted version of itself? (For small enough \\(h\\).) exponential ☹︎ sinusoid ✓ logarithm ☹︎ power-law \\(x^{-1}\\) ☹︎ Question B 2. Which naked modeling function has a slope function that is identical to itself? (For small enough \\(h\\).) exponential ✓ sinusoid ☹︎ logarithm ☹︎ power-law \\(x^{-1}\\) ☹︎ Question C 3. Which naked modeling function has a slope function that is another naked modeling function? (Hint: The other function is also listed among the choices.) exponential ☹︎ sinusoid ☹︎ logarithm ✓ power-law \\(x^{-1}\\) ☹︎ Why did you plot both the function and the slope function in the same graphics frame? 1160 Excellent question! In general, it is illegitimate to plot a function and it’s slope function on the same vertical axis. The reason is the units of the two functions will be different. For instance, the output of a function position(t) might have units of “miles,” while the output of the slope function of position (that is, \\({\\cal D}\\)position(t) would have units such as miles-per-hour.) So, as a general rule, never plot a function and its corresponding slope function on the same scale. An exception is for the naked modeling functions. These always take a number as input and produce a number as output. The slope function of a naked modeling function also produces a number as output. This exception is not a good excuse for indulging a bad practice. Perhaps you’ll forgive me if I point out that I wanted to emphasize the point by demonstrating it. I’ve been writing the slope function of \\(f(t)\\) as \\({\\cal D}f(t)\\). That works for this chapter, which deals with functions of only one variable. But in general modeling functions have more than one variable, for instance \\(g(x, t)\\). To work with slope functions with more than one variable, we need to extend the notation a little. We will place a small subscript after \\({\\cal D}\\) to indicate which variable we are changing. Thus, there will be two slope functions for \\(g(x,t)\\): \\[\\require{color}{\\cal D}_{\\color{blue}x} g(x, t) \\equiv \\frac{g({\\color{blue}x + 0.1}, t) - g(x, t)}{0.1}\\\\ \\text{and}\\\\ {\\cal D}_{\\color{red}t} g(x, t) \\equiv \\frac{g(x, {\\color{red}t + 0.1}) - g(x, t)}{0.1}\\] The input referred to in the subscript following \\({\\cal D}\\) is called the with-respect-to input. tree-harvesting.Rmd For an in-the-world: Calculate the slope function of the naked sigmoidal function. What is its value at x=0. Do some other functions as well. Also, some where we change the 0.1 to something smaller. Maybe a “What is small?” "],["function-inverses-and-solving.html", "Chapter 10 Function inverses and “solving” 10.1 Function inverses 10.2 Exercises", " Chapter 10 Function inverses and “solving” [Fun-inverse] Understand the operation of “solving” a function and be able to translate this into “zero-finding.” Very much in the spirit of naming common tasks, the process of turning an output from a function into the corresponding input using a computer program is called zero finding. As is often the case, computer programming often involves reformatting things to fit in a standard format. Here, the standard format is to find the input that corresponds to an output of zero. In reality, as in our snowplow problem, you might not care about an output zero. (The facilities manager in charge of zero miles of road is likely to be out of a job pretty soon!) 1200 But output zero is just a format. You can easily re-write any function to create a new one where the output you want turns out to be zero. For instance, in our snowplow problem, instead of applying zero-finding to the function \\(g(x) = 168 x\\), we would construct another, related function \\(h(x) \\equiv g(x) - 400\\). Finding a zero of \\(h()\\) gives us directly an input for \\(g()\\) corresponding to an output of 400. 10.1 Function inverses [Fun-3a2] Determine whether a function has an inverse. Know that exponential and logarithmic functions are inverses and that the inverse of a power-law function is another power-law function. This may sound like a familiar word problem from your high-school algebra course: You are a facilities manager for a small town. The town contains approximately 400 miles of road that must be plowed following a significant snowfall. How many plows must be used in order to complete the job in one day if the plows can travel at approximately 7 miles per hour when engaged? — Source The task of answering such a question is often called solving a word problem. You don’t need calculus to solve this problem, but insofar as the format is familiar to you, it might help to depict how it would be addressed as a modeling task and how to use the model created to guide the mathematical work of getting a numerical answer to the problem. Modeling Phase: The objective is to create a function that represents snow plowing and that will let us answer the question about how much plowing activity is needed. Here’s a function that takes as input \\(x\\) a number of plows and provides as output the number of miles that can be serviced in a day. \\[\\mbox{miles_plowed}(x) \\equiv 7 \\times 24 \\times x\\] In reality, “miles plowed” depends on the amount of snow, the safe speed limit of the plows, the number of rest breaks needed by the drivers, how far the snowplow terminus is from the road system, how many cars are parked on the road and the available number of tow trucks, and the day of the week and the time of day. (Remember, there might be other traffic on the road. Plowing at rush hour is bound to be small! And slow down at night!) It seems that textbook “word problems” never mention such issues, having been written in a world where plowing snow is exactly the same as doing simple arithmetic. Likely, we’re going to have to use the modeling cycle to end up with a genuinely useful model. Still, we have to start somewhere, so let’s start with \\(7 \\times 24 \\times x\\). We can use this function to solve the problem: How many plows are needed to get the 400-miles of road serviced in 1 day? It’s a matter of choosing a suitable method for applying the function to guide us to the answer. 1210 One simple method, which sometimes is called guess and check is to propose some answers and see what happens. Being experts in snow plowing, we know that you can’t have negative or fractional plows, so our guesses for \\(x\\) will be integers. Let’s do this systematically: Number of plows \\(x\\) Miles plowed in a day 1 \\(7 \\times 24 \\times 1 = 168\\) 2 \\(7 \\times 24 \\times 2 = 336\\) 3 \\(7 \\times 24 \\times 3 = 504\\) 4 \\(7 \\times 24 \\times 4 = 672\\) \\(\\vdots\\) … and so on. We really don’t need all the scratch work crowding up the table, so let’s streamline it, keeping the essentials: input \\(x\\) output \\(\\mbox{miles_plowed}(x)\\) 1 168 2 336 3 504 4 672 The domain of the miles_plowed() function is \\(x = 0, 1, 2, 3, \\ldots\\), so our table covers only a bit of the domain. Miles_plowed() might be a genius function, but in using it we have to keep in mind that we don’t actually know the input. What we do know is something in the form of the output: 400 miles. The mathematical operation of solving consists of looking up what we do know in the output column of the table, then reading off the corresponding input as our answer. Since 400 doesn’t appear in the output column, we’ll look for an interval that includes 400. Of course, that’s the interval from 336 to 504. So the answer will be something bigger than \\(x=2\\) but doesn’t need to be any larger than \\(x=3\\). You’ve been in the facilities management business for many years, so you know to choose the answer \\(x=3\\). If you have a graph of a function, it can be easy to calculate what the input should be for a given output. Just reverse the finger action, looking up the output on the vertical axis, tracing horizontally to the function graph, then reading off the result from the input axis. Now let’s write the problem using math notation rather than a table. We’re looking for a value of \\(x\\) such that \\[\\mbox{miles_plowed}(x) = 400\\] This is an equation as opposed to a function definition which we write with \\(\\equiv\\) rather than \\(=\\). The point of writing equations is often to signal to us that the task is to “solve for \\(x\\).” An algebraic solution relies on replacing miles_plowed(\\(x\\)) with the function’s formula and then re-arranging numbers and possibly other symbols until we have an equation of the form \\(x = \\ldots\\). Here, that’s easy: \\[7 \\times 24 \\times x = 400\\ \\ \\implies\\ \\ x = 400/(7\\times 24)\\] Do some arithmetic and we find \\(x = 2.381\\). Apply some common sense and we translate this into “three plows.” An industrious facilities manager might go further. “Today there is 400 miles of road. But next year there will be more, although I don’t yet know the exact number. While I’m doing all this math work, I’ll write up a memo so that next year, when I know how much road there will be, I can just to some arithmetic.” This is a good idea, although a mathematician might prefer the word “function” to “memo [to guide] arithmetic.” 1220 You likely learned how to set up and solve this memo-writing function. The key is to replace 400 with a symbol standing for the number of miles of road. We’ll use \\(M\\). Then you do the re-arrangement with \\(M\\) in place of 400. \\[168 x = M\\ \\ \\implies\\ \\ x = M/168\\] All that remains is to give a more informative name in place of \\(x\\) and to write it as a proper function: \\(n_{plows}(M) \\equiv M/168\\). This process of starting with a function like \\(\\mbox{miles_plowed(x)}\\) and transforming it into a function in a more convenient format for the task at hand \\(n_{plows}(M)\\) is called inverting the function. High-school algebra emphasizes techniques for inverting functions by moving symbols around. This is great when it can be done, but it’s often impossible in real science and engineering problems. In such cases we use a very powerful, general-purpose method, that is, guess and check. Another common strategy for inverting functions that are beyond our reach algebraically is to rely on a specialist to develop the inverse function, give it a name, write it down a formula in mathematical notation or, sometimes more usefully, write a computer program that implements the inverse function’s algorithm. With this strategy, all that’s needed to invert a function is to know the name or formula of the function’s inverse. Here’s a table of such names and formulas, most of which is likely familiar to you. function inverse function Exponential: \\(e^x\\) Logarithm: \\(\\ln(x)\\) Exponential: \\(2^x\\) Log base 2: \\(\\log_2(x)\\) Exponential: \\(10^x\\) Log base 10: \\(\\log_{10}(x)\\). Power law: \\(x^2\\) Square root: \\(\\sqrt{x}\\) Power law: \\(x^{-1}\\) Power law: \\(x^{-1}\\) Trig: \\(\\sin(x)\\) Trig: \\(\\arcsin(x)\\) Trig: \\(\\tan(x)\\) Trig: \\(\\arctan(x)\\) You can of course read this table either from left to right or from right to left. For instance, the inverse of \\(\\ln(x)\\) is \\(e^x\\). As you know, for a function \\(g(x)\\), the set of valid values of \\(x\\) is called the domain of the function. The set of possible outputs from the function is called the range of the function. The inverse function to \\(g()\\) has a domain which is the range of \\(g()\\) and a range which is the domain of \\(g()\\). Sometimes the notation \\(g^{-1}(x)\\) is used for \"the inverse function of \\(g()\\). This is potentially confusing, since \\(g^{-1}(x)\\) might reasonable be interpretted as \\(1/g(x)\\) and, in general, those two things are not equal. Straight-line (with non-zero slope), exponential (\\(e^{kt}\\) where \\(k\\neq 0\\)), and logarithm functions aways have inverse functions. For power-law and sinusoid functions, there can be several (or many) different inverse functions. We’ll get to this when we need to. 1230 There’s an easy graphical test for whether there is a unique inverse function or not. Draw the graph, then see if any horizontal line touches the graph of the function in more than one place. If so, there is no unique inverse function. 10.2 Exercises Exercise 10.3: RDWKW Some years ago, you learned to calculate the slope of a straight-line function. If you had a graph, you would mark out a run and the corresponding rise, then compute rise/run. If you had a formula definition, e.g. \\(f(x) \\equiv 3 - 4 x\\), you would simply read the slope off as the coefficient on the function input. Here, the input is named \\(x\\) and its coefficient in the formula is \\(-4\\). In this question, we ask you to estimate the slope from a graph of the function. But the function is exponential, so not a straight line. A fundamental idea in calculus is that even a function with a curved graph, if you zoom in closely around a given point, will look like a straight line. And you know how to calculate the slope of a straight line. When the graph is curved, the slope will be different at different points along the graph. So there’s not a single slope for the function. Still, we can talk about the “slope at a point.” One way to specify a point on a function’s graph is to give the horizontal coordinate: the input to the function. But here we’re going to give you the output of the function. Estimate the slope of the exponential function \\(g(x) \\equiv e^x\\) at several inputs, which we’ll call \\(x_1\\), \\(x_2\\), \\(x_3\\) and \\(x_4\\). We won’t give you numerical values for the \\(x_i\\) points, but we will tell you the output of the function at each of those inputs. the values of \\(x\\) where: \\(g(x_1) = 1\\) \\(g(x_2) = 5\\) \\(g(x_3) = 10\\) \\(g(x_4) = 0.1\\) The code sandbox below already contains an R command to plot out the mathematical exponential function over the domain \\(-3 \\leq x \\leq 3\\). For each of (a)-(d), modify the command to zoom in on the domain around around the appropriate value of \\(x_i\\). Then calculate the slope of the curve at that \\(x_i\\). slice_plot(exp(x) ~ x, domain(x = c(-3, 3))) Question A Using your answers for the slope at the points given in (a)-(d), choose the best answer to this question: What is the pattern in the slope as \\(x\\) varies? The slope at each value \\(x_i\\) is the same as \\(e^{x_i}\\). ✓ This property of the exponential function becomes important when describing a wide range of phenomena, from nuclear isotope decay to population growth. The slope at each value \\(x_i\\) is the same as \\(x_i\\). ☹︎ That would being saying the slope at \\(x_3\\) is \\(\\approx 2.30\\). Is that what you got? The slope at each value of \\(x_i\\) is the same as \\(x_i^2\\). ☹︎ That would being saying the slope at the \\(x_3\\) is \\(\\approx 5.30\\). Is that what you got? The slope at each value of \\(x\\) is the same as \\(\\sqrt{x}.\\) ☹︎ That would being saying the slope at the \\(x_i\\) is \\(\\approx 1.52\\). Is that what you got? Now that you’ve found the answer and seen how to specify the domain on a slice plot, here’s a technique that can make your work a bit easier. Add this to the command that plots \\(e^x\\) on the domain \\(-3 \\leq x \\leq 3\\) %&gt;% plotly::ggplotly() Make sure the %&gt;% is on the same line as the slice_plot() expression itself. Run the amended command then hover the cursor over the graph. Reflection: One goal of this problem is to introduce you to a way of writing about functions that is somewhat different than you may have seen before. Instead of using the letter \\(y\\)—as in \\(y = mx + b\\), we give each function a name and, in the parentheses after the name, list the inputs to the function. For instance, we use \\(f(x)\\) and \\(g(x)\\) in this problem. We are not using the equal sign (\\(=\\)) to give a name to the function; we use \\(\\equiv\\). As you know, \\(=\\) means “equality.” But \\(h(x) \\equiv x^2\\) describes a definition: “we define \\(h\\) to be the name of a function of \\(x\\) with the formula \\(x^2\\).” Definitions are different from equations. Equations have an important role in mathematics, so it’s worth not confusing them with definitions. We will often use letters from the end of the alphabet—\\(x\\), \\(y\\), \\(z\\), \\(t\\), \\(u\\), \\(v\\), \\(w\\)—as the names of inputs to functions. It will be important for us to give names to inputs because we will often deal with functions with more than one input and we’ll need to keep straight which one stands for what. A function is a kind of machine that takes inputs and produces outputs. Similarly, a printer is a machine that takes several inputs—paper, ink, electricity, PDF file—and produces the familiar kind of output. Printers are designed to have different places for the different inputs, so you can’t mistake one for the other. With mathematical functions, all we have for this purpose is the different names for the inputs. The input slot on a printer is often called the “paper tray.” You would never confuse the paper tray with paper itself. Inputs to function are like the paper tray. When we put a particular value into the input slot \\(x\\) of a function, we will often call the particular value something like \\(x_0\\) or \\(x^\\star\\), or \\(x_3\\). When you see something like \\(x_0\\), remember that it is a particular piece of paper, not the input tray for paper. We’ll even sometimes give you the output from the function—as we did here with the exponential function—and ask you to figure out the particular input that corresponds to that output. This is like asking, “Find a piece of paper that, once it’s printed on, the ink won’t show through to the other side.” There are good reasons why to start to make simple distinctions that might have been ignored or glossed over in high-school math. "],["fun-assembling.html", "Chapter 11 Assembling functions 11.1 Linear combination 11.2 Function composition 11.3 The modeling polynomial 11.4 Tukey’s ladder (optional) 11.5 Function multiplication 11.6 All together now! 11.7 Exercises", " Chapter 11 Assembling functions When we need a new function for some purpose, we practically always build it out of existing functions. For instance, a parameterized function like \\[A \\sin\\left(\\frac{2 \\pi}{P}x\\right) + C\\] is built by assempling together a straight-line input scaling, a naked \\(\\sin()\\) function, and another straight-line function for scaling the output from \\(\\sin()\\). 1300 In this chapter, we’ll introduce three general frameworks for combining functions: linear combination, composition, and multiplication. 11.1 Linear combination One of the most widely used sorts of combination is called a linear combination. The mathematics of linear combination is, it happens, at the core of the use of math in applications, whether that be constructing a Google-like search engine or analyzing medical data to see if a treatment has a positive effect. You’ve worked for many years with one kind of linear combination: polynomials. No doubt you’ve seen functions12 like \\[f(x) \\equiv 3 x^2 + 5 x - 2\\] There are three modeling functions in this polynomial. In this case, as in polynomials generally, they are all power-law functions: \\(g_0(x) \\equiv 1\\), \\(g_1(x) \\equiv x\\), and \\(g_2(x) \\equiv x^2\\). With these functions defined, we can write the polynomial \\(f(x)\\) as \\[f(x) \\equiv 3 g_2(x) + 5 g_1(x) - 2 g_0(x)\\] Each of the functions is being scaled by a quantity—3, 5, and -2 in this example—and the scaled functions are added up. That’s a linear combination; scale and add. (Later, we’ll see that the scalars generally come with units. So we might well have a metric polynomial and an equivalent traditional-unit polynomial. Just wait.) Notice that we said \\(g_0(x) \\equiv 1\\) is a power-law function. Why? Since \\(x^0=1\\) for all \\(x\\), we might equally well have written \\(g_0(x) \\equiv x^0\\) which is visibly a power-law function. We’re just trying to emphasize that a polynomial is a linear combination of power-law functions, in particular those power-law functions with whole-number, positive exponents. The individual functions, say, \\(x^2\\) or \\(x^5\\) are called monomials. A polynomial is a combination of monomials, just like a chemical polymer is a combination of monomers. There are other places where you have seen linear combinations: The parameterized sinusoid \\[A \\sin\\left(\\frac{2 \\pi}{P}t\\right) + C\\] is a linear combination of the functions \\(h_1(t) \\equiv \\sin\\left(\\frac{2 \\pi}{P} t\\right)\\) and \\(g_0(t) \\equiv 1\\). The scalars are \\(A\\) and \\(C\\). The parameterized exponential \\[A e^{kt} + C\\] The functions being combined are \\(e^{kt}\\) and \\(g_0(t) \\equiv 1\\). The scalars are, again, \\(A\\) and \\(C\\). The straight line function \\(a x + b\\). The functions being combined are \\(x\\) and \\(1\\), the scalars are \\(a\\) and \\(b\\). 1310 Note that neither the parameterized exponential or the parameterized sinusoid is a polynomial. There are a few reasons for us to be introducing linear combinations here. You will see linear combinations everywhere once you know to look for them. There is a highly refined mathematical theory of linear combinations that gives us powerful ways to think about them as well as computer software that can quickly find the best scalars to use to match input-output data. The concept of linear combination generalizes the simple idea that we have been calling “scaling the output.” From now on, we’ll use the linear-combination terminology and avoid the narrower idea of “scaling the output.” Many physical systems are described by linear combinations. For instance, the motion of a vibrating molecule or a helicopter in flight or a building shaken by an earthquake are described in terms of simple “modes” which are linearly combined to make up the entire motion. More down to Earth, the timbre of a musical instrument is set by the scalars in a linear combination of pure tones. Many modeling tasks can be put into the framework of choosing an appropriate set of simple functions to combine and then (letting the computer) figure out the best scalars to use in the combination. Even better, there is an automatic, reliable, and fast algorithm for finding the scalars for a set of functions that are to be combined to match data as closely as possible. So the modeler just has to select the functions to be used, the computer can find the coefficients. (We’ll explore the mathematics and methods of linear combinations, usually called linear algebra, in Block 5.) Exercise 11.3: JWUVA The graph shows two hump functions, hump1(t) and hump2(t) A linear combination of the hump functions is shown in Graph (A). Question A What is the linear combination of hump1(t) and hump2(t) shown in Graph (A)? 0.5*hump1(t) + hump2(t) ✓ hump1(t) + 0.25*hump2(t) ☹︎ If this were the case, the right bump would be only one-quarter as big as the left bump. hump1(t) + 2hump2(t) ☹︎ Since hump2(t) has a maximum value of 20, 2hump2(t) would reach a value of 40. That isn’t what’s shown in the graph. Another linear combination of the hump functions is shown in Graph (B). Question B Which linear combination of hump1(t) and hump2(t) is shown in Graph (B)? hump1(t) - 2*hump2(t) ✓ hump1(t) - hump2(t) ☹︎ The second (downward) hump is bigger than the first (upward) hump. 0.5*hump1(t) - 0.5*hump2(t) ☹︎ If this were so, the first hump would reach a value of 10 rather than the 20 seen in Graph (B). -hump1(t) - hump2(t) ☹︎ The first hump is positive. 11.2 Function composition To compose two functions, \\(f(x)\\) and \\(g(x)\\), means to apply one of the functions to the output of the other. “\\(f()\\) composed with \\(g()\\)” means \\(f(g(x))\\). This is generally very different from “\\(g()\\) composed with \\(f()\\)” which means \\(g(f(x))\\). For instance, suppose you have recorded the outdoor temperature over the course of a day and packaged this into a function \\(\\mbox{AirTemp}(t)\\): temperature as a function of time \\(t\\). Your digital thermometer uses degrees Celsius, but you want the output units to be degrees Kelvin. The conversion function is \\[\\mbox{CtoK}(C) \\equiv C + 273.15\\] Notice that CtoK() takes temperature as input. With this, we can write the “Kelvin as a function of time” as \\[\\mbox{CtoK}\\left(\\mbox{AirTemp}(t)\\right)\\] It’s important to distinguish the above time \\(\\rightarrow\\) Kelvin function from something that looks very much the same but is utterly different: \\(\\mbox{AirTemp}\\left(\\mbox{CtoK}(t)\\right)\\). As a matter of arithmetic, you can put time as an input to CtoK(). But it has a completely different meaning in terms of the real world. If time were measured in hours, then CtoK\\((t)\\) would be looking at the temperature eleven and a half days ago, instead of the temperature at time \\(t\\). We used \\(C\\) as the name of the input to CtoK(). Shouldn’t it be something like \\(x\\) or \\(y\\)? Keep in mind that the names of the inputs to a function can be anything whatsoever, so long as they are used consistently in the function algorithm. If we wanted, we could call the first input to any function \\(x\\), or for that matter \\(y\\) or giraffe. The point of the notation \\(\\mbox{CtoK}(C) \\equiv C + 273.15\\) is to make it utterly clear that \\(C\\) is the name we’re using for the input by listing it in the parentheses that follow the function name CtoK(). This, unlike high-school notation, allows us great freedom in the choice of names. 1320 We can use that freedom to make it easier to communicate with other people. (And remember, one of those other people is “future you.”) We used the name \\(C\\) to reinforce the message that CtoK() converts celsius to kelvin, and not vice versa. Here is a simple, approximate formula for the length of day (in hours) as a function of latitude \\(L\\) and the declination angle \\(\\delta\\) of the sun. \\[\\text{day_length}(L, \\delta) \\equiv \\frac{2}{15} \\arccos\\left(-\\tan(L)*\\tan(δ)\\right)\\] The declination angle is the latitude of the point on the earth’s surface pierced by an imagined line connecting the centers of the earth and the sun. On the summer solstice, it is \\(23.44^\\circ\\), the longest day of the year. A computer implement must look different, since \\(L\\) and \\(\\delta\\) are typically provided in degrees while the tan() and other trigonometric functions in most computer languages expect units of radians. The conversion is easy: \\(\\text{deg2rad}(d) \\equiv \\frac{\\pi}{180} d\\). The conversion the other way is \\(\\text{rad2deg}(r) \\equiv \\frac{180}{\\pi} r\\). In order to get the day-length formula to work in a computer, we have to compose the \\(\\tan()\\) function with deg2rad(). The output of acos() is in radians, so we have to convert it back to degrees. Like this: day_length &lt;- makeFun( (2/15)*rad2deg( acos( -tan(deg2rad(L))*tan(deg2rad(d)) ) ) ~ L+d) Exercise 11.7: JWUVA Question tmp-7: Using an R sandbox, calculate the length of the day at latitude \\(39^\\circ\\) on the longest day of the year, which is when the declination of the sun is \\(23.44^\\circ\\). How long is it? 13.9 hours [] 14.7 hours (+) [] 14.9 hours [] 15.1 hours [] Now to make a plot of day length as a function of day of the year. Of course, day_length(L, d) does not take day of the year into account. What’s missing is to know the declination of the sun as a function of calendar day. We’ll represent calendar day as a number \\(n\\) that runs from 0 at the start of January 1st to 365 at the end of December 31. Given this convention, the declination of the sun is delta_sun &lt;- makeFun(-23.44*cos((2*pi/365)*(n+10) ) ~ n) Composing day_length() with delta_sun() (on the d argument only) we get a function of day of year n: slice_plot( day_length(39, delta_sun(n)) ~ n, domain(n=c(0,365)) ) Exercise 11.11: VAXRB Question tmp-8: How long is the day on April Fools (\\(n=90\\)) at Latitude 39N? (Use a sandbox for the calculation.) 12.38 hours (+) [] 12.59 hours [] 12.64 hours [] 12.74 hours [] Income inequality is a matter of perennial political debate. In the US, most people support Social Security, which is an income re-distribution programming dating back almost a century. But other re-distribution policies are controversial. Some believe they are essential to a healthy society, others that the “cure” is worse than the “disease.” 1330 Whatever one’s views, it’s helpful to have a way to quantify inequality. There are many ways that this might be done. A mathematically sophisticated one is called the Gini coefficient. Imagine that society was divided statistically into income groups, from poorest to richest. Each of these income groups consists of a fraction of the population and has, in aggregate, a fraction of the national income. Poor people tend to be many in number but to have a very small fraction of income. Wealthy people are few in number, but have a large fraction of income. The table shows data for US households in 2009:13 group label population aggregate income cumulative income poorest 20% 3.4% 3.4% low-middle 20% 8.6% 12.0% middle 20% 14.6% 26.6% high-middle 20% 23.2% 47.8% richest 20% 50.2% 100.0% The cumulative income shows the fraction of income of all the people in that group or poorer. Similarly for the cumulative population. A function that relates the cumulative population to the cumulative income is called a “Lorenz” function. The data are graphed in Figure ?? and a function has been fitted to the data. Figure 11.1: Data on household incomes in the US in 2009. Lorenz curves are necessarily concave up, which amounts to saying that the curve gets steeper and steeper as the population percentile increases. (Why? Because at any point, poorer people are to the left and richer to the right.) And it must connect (0,0) to (1, 1). Calling the income percentile \\(L\\) a function of the population percentile \\(p\\), a Lorenz function is \\(L(p)\\) that satisfies the requirements in the previous paragraph. Here are some functions that meet the requirements: \\(L_b(p) \\equiv p^b\\) where \\(1 \\leq b\\). \\(L_q(p) \\equiv 1 - (1-p)^q\\) where \\(0 &lt; q \\leq 1\\) Notice that each of these functions has just one parameter. It seems implausible that the workings of a complex society can be summarized with just one number. We can use the curve-polishing techniques introduced in Section 8.6 to find the “best” parameter value to match the data. Then we can see if “best” is good enough. 1340 Lb &lt;- fitModel(income ~ pop^b, data = Income, start=list(b=1.5)) Lq &lt;- fitModel(income ~ 1 - (1-pop)^q, data = Income, start=list(q=0.5)) Figure 11.2 compares the polished functions to the data. Figure 11.2: Lorenz curves \\(L_b(p)\\) (blue) and \\(L_q(p)\\) (red) fitted to the household income data. Neither form \\(L_b(p)\\) or \\(L_q(p)\\) gives a compelling description of the data. What to do. We can provide more parameters by constructing more complicated Lorenz functions. Here are two ways to build a new Lorenz function out of an existing one: The product of any two Lorenz functions, \\(L_1(p) L_2(p)\\) is itself a Lorenz function. A linear combination of any two Lorenz functions, \\(a L_1(p) + (1-a) L_2(p)\\), so long as the scalars add up to 1, is itself a Lorenz function. For instance, the white curve in Figure 11.2 is the linear combination of 0.45 times the red curve plus 0.55 times the blue curve. Question: Is the composition of two Lorenz functions a Lorenz function? To get started, figure out whether or not \\(L_1(L_2(0)) = 0\\) and \\(L_1(L_2(1)) = 1\\). If the answer is yes, then we need to find a way to compute the concavity of a Lorenz function to determine if the composition will always be concave up. We’ll need additional tools for this. 11.3 The modeling polynomial Sometimes, in order to model some simple relationship you need to build a function whose graph has a simple, curving shape. 1350 A simple but surprisingly powerful approach is to use a low-order polynomial. The order of a polynomial is the highest exponent on the input. For example, a straight-line function, \\(g_1(x) \\equiv a_0 + a_1 x\\), is a first-order polynomial. A quadratic, \\(g_2(x) \\equiv b_0 + b_1 x + b_2 x^2\\) is a second-order polynomial. Many modelers are tempted to extend the technique to third-, fourth-, fifth-order and even higher. This is only rarely worthwhile since all second-, fourth-, sixth- and higher-even-order monomials have basically the same U-shape, like a referee signalling a touch-down. Similarly, first-, third-, fifth- and higher odd-order monomial have similar shapes. An ofttimes better approach is to compose the polynomial with a curved but monotonic function, such as a logarithm. Explain why we are now using subscripts for the names of scalars. 11.4 Tukey’s ladder (optional) [[Tukey’s ladder]] Using a simple straight line with input composition and/or output composition. You can get a variety of curve shapes using only a linear function. Exercise 11.15: UVGMA The “Rule of 72” For the quantitatively literate, systems showing exponential growth and decay are encountered almost every day and are usually presented as “percent per year” rates. Some examples: Money. Credit card interest rates, bank interest rates, student loans. Your credit card might charge you 18% per year, your bank might pay you 0.3% on a savings account, “subsidized” student loans are often around 7%. Population. Statistics are often given as “growth rates” in percent. For instance, in 2016-17, Colorado’s population grew by an estimated 1.39% and Idaho by 2.2%. Illinois’s population shrank by 0.26%, and Wyoming’s by 0.47%. Prices. Inflation rates are usually presented as percent. Home prices and medical costs. These are some of the largest expenses encountered by families and they typically grow. You might hear a statistic like, “Regional median home prices increased by 10% over the last year,” or “Health insurance rates are increasing by 7% this year.” In understanding the long-term consequences of such growth or decay, it can be helpful to frame the rate of growth not as a percentage, but as a doubling time (or halving time for decay). Happily, there is a formula to calculating doubling (or halving) time directly from the percentage growth (or decay) rate. It is \\[n = \\frac{\\ln(2)}{\\ln(1 + r/100)}\\] where \\(r\\) is the percent per year growth rate and \\(n\\) is the number of years for doubling (or halving). Could you do this calculation in your head? Perhaps you could carry around a card with a graph for looking up the answer: doubling_time &lt;- makeFun(log(2) / log(1 + r/100) ~ r) slice_plot(doubling_time(r) ~ r, domain(r = c(1,30))) It’s hard to be very precise in reading off values from such a graph. Instead, maybe we can simplify the formula. Clearly, a straight-line calculation is not going to match the doubling-time curve well. How about a quadratic approximation? Let’s make one centered on \\(r = 5\\). The formula, as for all quadratic approximations will be \\[n(r) \\approx a + b (r - r_0) + c (r-r_0)^2/2\\] When centering on \\(r_0=5\\) the value of \\(a\\) will be doubling_time(5), the value of \\(b\\) will be dr_doubling_time(5), and the value of \\(c\\) will be drr_doubling_time(5). Question A 1) What’s the numerical value of \\(a\\)?     10.2 ☹︎        11 ☹︎        11.9 ☹︎        12.9 ☹︎        14.2 ✓        15.7 ☹︎        17.7 ☹︎ Question B 2) Just by looking at the graph of doubling_time(r) figure out what will be the signs of \\(b\\) and \\(c\\). What are they? \\(b\\) positive and \\(c\\) positive ☹︎ \\(b\\) negative and \\(c\\) positive ✓ \\(b\\) negative and \\(c\\) negative ☹︎ \\(b\\) positive and \\(c\\) negative ☹︎ Question C 3) What’s the numerical value of \\(b\\)? (Hint: Use the D() operator to calculate the derivative of doubling_time() with respect to r. Then evaluate that function at \\(r=5\\).)     -3.4 ☹︎        -2.8 ✓        -2.3 ☹︎        2.3 ☹︎        2.8 ☹︎        3.4 ☹︎ Question D 4) What’s the numerical value of \\(c\\)? (Hint: Again, use D() to find the 2nd derivative with respect to r. Then evaluate that function at \\(r=5\\).     -1.11 ☹︎        -0.83 ☹︎        -0.64 ☹︎        0.64 ☹︎        0.83 ☹︎        1.11 ✓ Using the numerical values for \\(a\\), \\(b\\) and \\(c\\) that you just calculated, construct the quadratic approximation function and plot it in red on top of the \\(n(r)\\) function. (Hint: Connect the two slice_plot() commands with a pipe %&gt;%. You can give slice_plot() a color = \"red\" argument.) Question E 5) Comparing the actual \\(n(r)\\) and your quadratic approximation, over what domain of \\(r\\) do the functions match pretty well? Choose the best of these answers. \\(r \\in [3,7]\\) ✓ \\(r \\in [1,6]\\) ☹︎ \\(r \\in [2, 10]\\) ☹︎ \\(r \\in [4, 10]\\) ☹︎ What we’ve got with this quadratic approximation constructed from derivatives of \\(n(r)\\) is hardly very usable. You couldn’t do the calculations in your head and even if you could, the result would have a limited domain of relevance. Occasionally, there are other simple functions that give a good approximation. The one for interest rates is called the “Rule of 72.” The function is \\[n(r) \\approx 72 / r\\]. Plot the Rule of 72 function on top of the actual \\(n(r)\\). Question F 6) Comparing the actual \\(n(r)\\) and the Rule of 72 function, over what domain of \\(r\\) do the functions match pretty well? Choose the best of these answers. \\(r \\in [1,25]\\) ✓ \\(r \\in [3,9]\\) ☹︎ \\(r \\in [4, 15]\\) ☹︎ \\(r \\in [8, 30]\\) ☹︎ Question G 6) Compare numerically the actual \\(n(r)\\) and the Rule of 72 function for an interest rate of \\(r = 10\\) (per year). How many years different are the two answers.     0.007 years ☹︎        0.07 years ✓        0.7 years ☹︎        7 years ☹︎ As exercises? Log transformation of used car prices [[Perceived brightness or loudness]] is a log scale. 11.5 Function multiplication The third in our repertoire of methods for making new function out of old is plain old multiplication. With two functions \\(f(x)\\) and \\(g(x)\\), the product is simply \\(f(x)g(x)\\). It’s essential to distinguish between function multiplication and function composition: \\[\\underbrace{f(x) g(x)}_\\mbox{multiplication}\\ \\ \\ \\ \\underbrace{f(g(x)) \\ \\ \\mbox{or}\\ \\ \\ g(f(x))}_\\mbox{composition}\\] In function composition, only one of the functions—the interior function is applied to the overall input, \\(x\\) in the above example. The other function gets its input from the output of its partner. In multiplication, each of the functions is applied to the input individually. Then their outputs are multiplied to produce the overall output. In function composition, the order of the functions matters: \\(f(g(x))\\) and \\(g(f(x))\\) are in general completely different functions. In function multiplication, the order doesn’t matter because multiplication is commutative, that is, if \\(a\\) and \\(b\\) are each quantities, \\(a \\times b = b \\times a\\). 1360 Transient vibration A guitar string is plucked to produce a note. The note is, of course, vibrations of the air created by vibrations of the string. After plucking, the note fades away. An important model of this is a sinusoid (of the correct period to correspond to the frequency of the note) times an exponential. Function multiplication is used so often in modeling that you’ll see it in many modeling situations. Here’s one example that is important in physics and communication: the wave packet. Overall, the wave packet is a localized oscillation as in Figure @ref{fig:wave-packet}. Figure 11.3: A wave packet constructed by multiplying a sinusoid by a hump function. This is the product of two simple functions: a hump times a sinusoid. Figure 11.4: The two components of the wave packet in Figure 11.3 EXERCISES: Say which two kinds of functions are being multiplied here. Question tmp-9: What are the two basic modeling functions being multiplied? A sinusoid and another sinusoid with a faster period. (+) [] A hump and a sinusoid. [] A sigmoidal function and a sinusoid. [] [] Question tmp-10: What is the period of the envelope? 10 [It’s true that the broad peaks in the overall function occur every 10 time units. But a sine wave has two excursions from zero every cycle, one positive and one negative. So if the period of the envelope were 10, we would see an amplitude of the faster sinusoid near zero every 5 time units.] 20 (+) [] 30 [If this were so, the dips in amplitude of the faster sign would occur every 15 time units.] Other examples along the same lines. EXERCISE: Provide a sigmoid and a series of humps. Ask the student to sketch out the product. 11.6 All together now! Two or all three of the techniques for combining functions—linear combinations, function composition, and function multiplication—can be used in the same function. 1370 Consider the function for the length of the day \\[\\text{day_length}(L, \\delta) \\equiv \\frac{2}{15} \\arccos\\left(-\\tan(L)*\\tan(δ)\\right)\\] The 2/15 is scaling the output of \\(\\arccos()\\). The \\(\\arcos()\\) is being composed with an interior function that is itself a scaled product of two functions. 11.7 Exercises Exercise 11.19: MWDKVA It’s very common in communications systems to have a signal that is a sine-wave carrier that is modulated by another function. That is, the carrier is multiplied by the other function: waveform(t) = modulator(t) \\(\\times\\) carrier(t). Here are four examples in each of which a sine with a period of about 2 units is modulated by another function, one of the modeling functions we have studied. Question A (A) Of what sort is the function that is modulating the carrier?     exponential ✓        hump ☹︎        sigmoid ☹︎        sine ☹︎ Question B (B) Of what sort is the function that is modulating the carrier?     exponential ☹︎        hump ✓        sigmoid ☹︎        sine ☹︎ Question C (C) Of what sort is the function that is modulating the carrier?     exponential ☹︎        hump ☹︎        sigmoid ✓        sine ☹︎ Question D (D) Of what sort is the function that is modulating the carrier?     exponential ☹︎        hump ☹︎        sigmoid ☹︎        sine ✓ Exercise 11.23: TWLC One common measure of quality of life is “life expectancy at birth.” A measure of the availability of health care is the number of physicians per 1000 people. The question we are going to examine is whether life expectancy is a function of the availability of health care and, if so, what kind of function it is. The data frame LifeExpectancyPhysicians contains the official 2010 figures from many countries for life expectancy and the number of physicians per 1000 population. Graph LifeExpectancy versus Physicians. Use linear axes, semi-log axes, or log-log axes to determine a reasonable functional form. (Recall that giving scale_y_log10() as an argument to gf_refine() will set the y axis on a log scale, and similarly for the x axis.) gf_point(LifeExpectancy ~ Physicians, data = LifeExpectancyPhysicians) %&gt;% gf_refine() Using fitModel(), your instructor found the following model of life-expectancy (which we’ll call L, in years) as a function of physicians-per-1000 people. (We’ll call this “doctor-density” for short, so D.) The instructor’s model is: \\[L(D) \\equiv 70.9 \\times D^{0.0683}\\] Define this function in R and graph it over your data. Confirm that it is a reasonable match to the data. (If not, you’ve copied the parameters wrong.) Question A What kind of function is the instructor’s proposed model?     linear ☹︎ Is it a straight line on linear axes?        exponential ☹︎ Is it a straight line on semi-log axes?        power-law ✓ C is a consonant, Chub        sigmoidal ☹︎ Is it S-shaped Question B According to the instructor’s model, what’s the life expectancy when there are no physicians at all? 0 years ✓ Not very believable, since there were (living) people before there were physicians. The power-law functional form always forces zero input to be zero output. So maybe not to be taken so seriously. 35 years ☹︎ 50 years ☹︎ 70 years ☹︎ 100 years ☹︎ 115 years ☹︎ Question C According to the instructor’s model, would be the life expectancy if every person in the world were a physician? (Hint: Translate this into physicians/1000-people.) 0 years ☹︎ 35 years ☹︎ 50 years ☹︎ 70 years ☹︎ 100 years ☹︎ 110 years+ ✓ But probably we would all starve to death if everybody was a physician! This also is an unreasonable extrapolation. It could be argued that the doctor-density should be a function of life expectancy rather than the other way around. (All those seniors consume a lot of medical care.) Question D Which of these models agrees reasonably well with the data? (Hint: You can plot the model over the data.) \\(D(L) \\equiv 7.24\\times 10^{-19} \\times L^9.8\\) ✓ \\(D(L) \\equiv 3.19 \\times L^{3.1}\\) ☹︎ \\(D(L) \\equiv 8.64 \\times L^{6.3}\\) ☹︎ \\(D(L) \\equiv 5.50 \\times L^{2.4}\\) ☹︎ The question now is whether the function \\(D(L)\\) (from the previous question) which is a good match to the data, is equivalent to the function \\(L(D)\\) which the instructor first proposed. In order to compare them, we have to make both of them functions of the same input. Let’s say we take \\(D(L)\\) and algebraically find the inverse which we’ll call \\(D^{inv}(D)\\). That inverse function takes an input in the form D and produces an output in the form L. Using algebra, confirm that \\[D^{inv}(D) \\equiv 70.9 \\times D^{1/9.8}\\] In the sandbox, plot both the instructor’s proposed model \\(L(D)\\) and the model \\(D^{inv}(D)\\) on the same axes, along with the data. (You’ll have to decide which variable to put on the horizontal axis, but the notation \\(L(D)\\) and \\(D^{inv}(D)\\) should give you a good clue.) Question E Which model, \\(L(D)\\) or \\(D^{inv}(D)\\) is a better match to the data when \\(D &lt; 1\\)? \\(L(D)\\) ✓ \\(D^{inv}(D)\\) ☹︎ They are the same function. ☹︎ Complex social phenomena, like life expectancy, are … well, complex. Life expectancy depends on many factors other than health care: nutrition, war, automobile safety, etc. Notice from the data that the countries with the highest life expectancies are those where \\(D \\approx 3\\). And yet, there are many countries with \\(D \\approx 3\\) that have relatively low life expectancy. One reason for this is inequality. In many countries, urbanites live at a high standard and people in the countryside have very little access to health care or reliably good nutrition, civil order, and so on. EXERCISE: The algebra of composition of the hump function \\(e^{-\\frac{x^2}{2}}\\). Parabola is a nice starting point. But we want it to go to zero asymptotically, not to \\(-\\infty\\). That might seem a tall order, but the exponential function is up to it. It’s likely that you saw polynomials as things to be factored, rather than as functions taking an input and producing an output. So they were written as equations: \\(e x^2 + 5x - 2 = 0\\)↩︎ These data, as well as the general idea for the topic come from La Haye and Zizler (2021), “The Lorenz Curve in the Classroom,” The American Statistician, 75(2):217-225↩︎ "],["fun-multiple-inputs.html", "Chapter 12 Functions with multiple inputs 12.1 f(x) times g(t) 12.2 Two-variable modeling polynomial 12.3 Function composition (not!)", " Chapter 12 Functions with multiple inputs We can use linear combination and function multiplication to build up custom functions from the basic modeling functions. Similarly, linear combination and function multiplication provide ways to construct functions of multiple inputs. 1400 12.1 f(x) times g(t) For example, soon after a guitar string is plucked it conforms to a sinusoid pattern of displacement from the straight-line connecting the two fixed ends of the string: one set by finger pressure on the fret and the other at the bridge. For a string of length \\(L\\), the string displacement is a function of position \\(x\\) along the string and is a linear combination of functions \\[g_k(x) \\equiv \\sin(k \\pi x /L)\\] where \\(k\\) is an integer. A few of these functions are graphed in Figure 12.1. Figure 12.1: Vibrational modes of a guitar string. Shapes of the sort in Figure 12.1 are a stop-motion flash snapshot of the string. The string’s shape also changes in time, so the string’s displacement is a function of both \\(x\\) and \\(t\\). The displacement itself is a sinusoid whose time period depends on the length and tension of the string as well as the number of cycles of the spatial sine: \\[g_k(x, t) \\equiv \\sin(\\frac{k \\pi}{L} x) \\ \\sin(\\frac{k \\pi}{P}t)\\] Figure 12.2 shows a few snapshots of the 1.5 cycle string at different moments in time, and the motion of the linear combination.1410 Figure 12.2: String position changes over time. 12.2 Two-variable modeling polynomial In Section 11.3 we introduced the low-order polynomial, either \\(g_1(x) \\equiv a_0 + a_1 x\\) or \\(g_1(x) \\equiv b_0 + b_1 x + b_2 x^2\\) as a general-purpose way of generating a function with a smoothly curved shape. The same applies in constructing simple functions of two variables. Almost always, you should use at least a first-order polynomial, which is: \\[h_1(x, y) \\equiv a_0 + a_x x + a_y y\\] But there is an important extension of this, using what’s called a bilinear term or, more evocatively in statistics, an interaction term. This is \\[h_2(x, y) \\equiv \\underbrace{b_0}_\\mbox{intercept} + \\underbrace{b_x\\, x + b_y\\, y}_\\mbox{linear terms} + \\underbrace{b_{xy}\\,x\\, y}_\\mbox{bilinear term}\\] The bilinear term arises in models of phenemona such as the spread of epidemics, the population dynamics of predator and prey animals, and the rates of chemical reactions. In each of these situations one thing is interacting with another: a predator killing a prey animal, an infective individual meeting a person susceptible to the disease, one chemical compound reacting with another. 1420 Under certain circumstances, modelers include one or both quadratic terms, as in \\[h_3(x, y) \\equiv c_0 + c_x\\, x + c_y\\, y + c_{xy}\\,x\\, y + \\underbrace{c_{yy}\\, y^2}_\\mbox{quadratic in y}\\] The skilled modeler can often deduce which terms to include from basic facts about the system being modeled. We’ll need some additional calculus concepts before we can explain this in a straightforward way. Explain why we are not using letter subscripts on the scalars in the linear combination. 12.3 Function composition (not!) We left function composition out of the list of ways to build multivariable functions out of simpler functions with a single input. For instance, consider the two functions \\(f(x)\\) and \\(g(t)\\). The composition \\(f(g(t))\\) has only one input: \\(t\\). Similarly, \\(g(f(x))\\) has only one input: \\(x\\). EXERCISE: In Section 11.2 you saw a function giving the declination of the sun as a function of day of year, and length-of-day as a function of latitude and sun’s declination. Putting these together let’s us assemble day-length as a function of latitude and day of year. Give function. DRAW CONTOUR PLOT, take slices. Day length as seen by a migrating bird. [Plug in a simple sinusoid for latitude to reduce the function to day-length versus day-of-year.] Exercise 12.3: NOAA Many printed tables are meant to be used as functions; you plug in the input values and read off the output. Here’s a table published by the National Oceanic and Atmospheric Administration for the heat index, a way of summarizing the perceived comfort (or discomfort) of summer-like weather conditions. Question A A) What are the inputs to the heat-index function temperature and relative humidity ✓ temperature and wind speed ☹︎ Those are the inputs to the wind-chill function, not the heat index. temperature, latitude, and longitude ☹︎ The heat index doesn’t depend on location. The table actually shows three different functions: The heat index in \\(^\\circ\\) F. The heat index in \\(^\\circ\\) C. A caution warning level. Question B B) For inputs of 70% relative humidity and \\(88^{\\circ}\\) F, what are the outputs of the three functions? \\(100^{\\circ}\\) F, \\(38^\\circ\\) C, and “extreme caution.” ✓ \\(100^\\circ\\) F, \\(38^\\circ\\) C, and “danger.” ☹︎ Check again! \\(100^\\circ\\) F, \\(33^\\circ\\) C, and “extreme caution.” ☹︎ 33C does is not the same temperature as 100F. Question C C) Holding the relative humidity at 70%, how much would the ambient temperature have to increase (from \\(88^\\circ\\) F) to change the caution-level output to “dangerous?” Increase by \\(2^\\circ\\) F ✓ Increase by \\(6^\\circ\\) F ☹︎ It looks like you’re increasing the humidity to the point where the heat index is \\(106^circ\\) F. But we asked you how much the temperature input has to change, not the heat-index output. Increase relative humidity to 80%. ☹︎ It’s true that at \\(100^\\circ\\) F and 80% humidity, the caution-index is “dangerous.” But the problem specified holding humidity constant. Question D D) From a starting point of \\(88^\\circ\\) F and 70% humidity, what is the slope of the increase in heat index when moving to 80% humidity. \\(6^\\circ\\) F per 10 percentage points humidity ✓ \\(6^\\circ\\) F ☹︎ A slope is always “rise over run.” You’ve got the rise right, but what about the run? \\(6^\\circ\\) F per 80% humidity. ☹︎ The slope is the change in output divided by the change in input, i.e. “rise over run.” 80% is the humidity at the endpoint, but the run is the change in humidity from the starting point to the endpoint. Question E E) What is the heat-index output when the inputs are 52% relative humidity and \\(91^\\circ\\) F? Choose the best answer. \\(98.4^\\circ\\) F ✓ Of course, the 4 in the last digit is sketchy, but it’s reasonable to calculate the interpolated output by averaging over neighboring outputs. \\(101^\\circ\\) F ☹︎ That’s the output at 55% humidity and \\(92^\\circ\\) F. The table doesn’t say. ☹︎ While it’s true that there is no table entry specifically for 52% and \\(91^\\circ\\) F, you can make a very reasonable guess by interpolation, that is, reading between the rows and columns. Question F True or false: The caution-level output could have been presented as a function of just one variable, rather than needing both temperature and humidity both.     TRUE ✓ The caution-level output is not a function of ambient temperature alone or of humidity alone. But if you know the heat-index, you know that caution level exactly.        FALSE ☹︎ Notice that the caution-level output is the same for any given level of the heat index, regardless of the ambient temperature or humidity separately. The US National Weather Service also publishes a heat index graphic, the one below. Source link Exercise 12.7: EDKKW Recall the Pythagorean theorem: \\(C^2 = A^2 + B^2\\). Let’s write this as a function that takes as inputs the lengths of the two legs and produces as output the length of the hypotenuse. \\[\\mbox{hypotenuse}(a, b) \\equiv \\sqrt{\\strut a^2 + b^2}\\] This can be seen as a composition of a function \\(f()\\) onto a linear combination of power-law functions \\(g()\\) of different inputs. Question A What is the function \\(f()\\)? \\(f(x) \\equiv a^2\\) ☹︎ This wouldn’t make sense. The output of \\(f()\\) doesn’t depend on its input. \\(f(x) \\equiv \\sqrt{x}\\) ✓ \\(f(x) \\equiv x^2\\) ☹︎ This is part of the interior function, not the outer function. \\(f(x) \\equiv +\\) ☹︎ Sorry, but the output of the hypothenuse() function needs to be a quantity, and \\(+\\) is not a quantity. Question B What is the function \\(g()\\)? \\(g(x) \\equiv a^2\\) ☹︎ This wouldn’t make sense. The output of \\(f()\\) doesn’t depend on its input. \\(g(a) \\equiv x^2\\) ☹︎ This wouldn’t make sense. The output of \\(f()\\) doesn’t depend on its input. \\(g(x) \\equiv x^2\\) ✓ Right, a power-law function. It doesn’t matter what we call the input, so long as it’s used consistently in the definition. \\(g(x) \\equiv a^2 + b^2\\) ☹︎ Sorry, but the input name is \\(x\\) and the formula on the right side of the tilde expression has \\(a\\) and \\(b\\) in it. Question C There are two functions in the linear combination. What are they? \\(g(a)\\) and \\(g(b)\\) ✓ \\(f(x)\\) and \\(g(x)\\) ☹︎ \\(f(b)\\) and \\(g(b)\\) ☹︎ Question D What are the scalars in the linear combination? \\(1\\) and \\(1\\) ✓ \\(1\\) and \\(-1\\) ☹︎ There are no scalars. ☹︎ I think I know what you’re getting at. The tradition in mathematics is that when a scalar is \\(1\\), we don’t write it down. But still, the scalar is \\(1\\). You used \\(a\\) and \\(b\\) as the names of the inputs to hypotenuse(). Aren’t \\(a\\) and \\(b\\) meant to be parameters, not input names? You can use whatever you want as input names, so long as they are used consistently between the left and right sides of the \\(\\\\equiv\\). Names like \\(x\\), \\(t\\), and \\(y\\) scream out to be recognized as input names, so these are what we use most of the time. But the Pythagorean theorem is usually written using A, B, and C. I’m honoring that convention so that a human reader gets a cultural hint what the inputs stand for. I’m unapologetic about this, since you got fair warning by the left side of the \\(\\\\equiv\\) what the argument names are. Exercise 12.11: EDKYV The function bigger() is defined piecewise in terms of two extremely simple functions. bigger &lt;- makeFun(ifelse(y &gt; x, y, x) ~ x + y) contour_plot(bigger(x,y) ~ x+y, domain(x=c(-2,2), y=c(-2,2))) {bg2-1, echo=FALSE, results=\"markup\"} askMC( \"Which of the following best describes the two pieces of the domain?\", \"+One is above and to the left of the line of identity (that is, $y=x$) and the other is below and to the right of that line.+\", \"One is $x &gt; 0$ and the other $x \\\\leq 0$\", \"One is $x &gt; 0$ and the other $y \\\\leq 0$\" ) "],["fun-piecewise.html", "Chapter 13 Piecewise functions 13.1 Piecewise functions", " Chapter 13 Piecewise functions [Fun-4-b-4a] Identify graphs of a piecewise linear function. [Fun-1C-d] Construct a hock-stick function by piecewise combination of a constant function and a straight-line function with non-zero slope. [Fun-4-b-4b] Recognize traditional curly-brace notation for piecewise functions. [Fun-4-b-4c] Be able to create a piecewise function in R. [Fun-4-b-4d] Distinguish between continuous and discontinuous functions Each of our basic modeling functions, with two exceptions, has a domain that is the entire number line \\(-\\infty &lt; x &lt; \\infty\\). No matter how big or small is the value of the input, the function has an output. Such functions are particularly nice to work with, since we never have to worry about the input going out of bounds. 1500 The two exceptions are: the logarithm function, which is defined only for \\(0 &lt; x\\). some of the power-law functions: \\(x^p\\). When \\(p\\) is negative, the output of the function is undefined when \\(x=0\\). You can see why with a simple example: \\(g(x) \\equiv x^{-2}\\). Most students had it drilled into them that “division by zero is illegal,” and \\(g(0) = \\frac{1}{0} \\frac{1}{0}\\), a double law breaker. When \\(p\\) is not an integer, that is \\(p \\neq 1, 2, 3, \\cdots\\) the domain of the power-law function does not include negative inputs. To see why, consider the function \\(h(x) \\equiv x^{1/3}\\). It can be tedious to make sure that you are on the right side of the law when dealing with functions whose domain is not the whole number line. The designers of the hardware that does computer arithmetic, after several decades of work, found a clever system to make it easier. It’s a standard part of such hardware that whenever ta function is handed an input that is not part of that function’s domain, one of two special “numbers” is returned. To illustrate: sqrt(-3) ## [1] NaN (-2)^0.9999 ## [1] NaN 1/0 ## [1] Inf NaN stands for “not a number.” Just about any calculation involving NaN will generate NaN as a result, even those involving multiplication by zero or cancellation by subtraction or division.14 For instance: 0 * NaN ## [1] NaN NaN - NaN ## [1] NaN NaN / NaN ## [1] NaN Division by zero produces Inf, whose name is reminiscent of “infinity.” Inf infiltrates any calculation in which it takes part: 1510 3 * Inf ## [1] Inf sqrt(Inf) ## [1] Inf 0 * Inf ## [1] NaN Inf + Inf ## [1] Inf Inf - Inf ## [1] NaN 1/Inf ## [1] 0 To see the benefits of the NaN / Inf system let’s plot out the logarithm function over the graphics domain \\(-5 \\leq x \\leq 5\\). Of course, part of that graphics domain, \\(-5 \\leq x \\leq 0\\) is not in the domain of the logarithm function and the computer is entitled to give us a slap on the wrists. The NaN provides some room for politeness. Open a sandbox and see what happens when you make the plot. slice_plot(log(x) ~ x, domain(x=c(-5,5))) In a purely mathematical sense, the problem with functions being undefined over an extended part of a domain has been handled with cunning and imagination. But the solution—the invention of complex numbers—is not our concern here. Instead, we’re going to embrace functions that have a domain smaller than the whole number line and see what we can do with them. To illustrate, let’s use computer notation to create a function whose domain is \\(x &lt; 1\\). To do this, we need a way to write “if,” as in, “If \\(x\\) is 1 or greater, return NaN.” We’ll use a function in R that let’s ask a TRUE/FALSE question and, depending on the answer, do one or another calculation. The question-answering R function is ifelse() whose name is remarkably descriptive. The ifelse() function takes three arguments. The first is the question to be asked, the second is the value to return if the answer is “yes,” and the third is the value to return for a “no” answer. g &lt;- makeFun( ifelse(x &lt; 1, x, NaN) ~ x) slice_plot(g(x) ~ x, domain(x = c(-2, 2))) What takes getting used to here is the expression x &lt; 1 which is a question not a statement of fact. There’s no standard traditional mathematical notation for questions, although some people use a question mark as in \\(x \\stackrel{?}{&lt;} 1\\). The table shows computer notation for some common sorts of questions. 1520 R notation English x &gt; 2 “Is \\(x\\) greater than 2?” y &gt;= 3 “Is \\(y\\) greater than or equal to 3?” x == 4 “Is \\(x\\) exactly 4?” 2 &lt; x &amp; x &lt; 5 “Is \\(x\\) between 2 and 5?”15 x &lt; 2 | x &gt; 6 “Is \\(x\\) either less than 2 or greater than 6?” abs(x-5) &lt; 2 “Is \\(x\\) within two units of 5?” 13.1 Piecewise functions Having an ability to split up the domain of a function and provide different formula for each of the pieces allows us to construct piecewise functions. To illustrate, the function \\(h(x) \\equiv |x|\\). You’ll recognize this as the “absolute value” function. The intuitive algorithm is to “strip the negative sign, if any” from the input. But with the ability to divide the domain into pieces, we gain access to a less mysterious sort of arithmetic operation and can re-write \\[h(x) \\equiv \\left\\{ \\begin{array}{cl} x &amp; \\text{for}\\ 0 \\leq x\\\\-x &amp; \\mbox{otherwise}\\end{array} \\right.\\] Or, in computer notation h &lt;- makeFun(ifelse(x &gt;= 0, x, -x) ~ x) Note that the absolute value function is built-in to R in the form of the abs() function. Less familiar is the Heaviside function which has important uses in physics and engineering: \\[\\mbox{Heaviside}(x) \\equiv \\left\\{ \\begin{array}{cl} 0 &amp; \\text{for}\\ x &lt; 0\\\\1 &amp; \\mbox{otherwise}\\end{array} \\right.\\] In computer notation, this is Heaviside &lt;- makeFun(ifelse(x &lt; 0, 0, 1) ~ x) The vertical gap between the two pieces is called a discontinuity. Intuitively, you cannot draw a discontinuous function without lifting the pencil from the paper. The Heaviside function has a discontinuity at \\(x=0\\). Similarly, the ramp function is a kind of one-sided absolute value: \\[\\mbox{ramp}(x) \\equiv \\left\\{ \\begin{array}{cl} x &amp; \\text{for}\\ 0 \\leq x\\\\0 &amp; \\mbox{otherwise}\\end{array} \\right.\\] Or, in computer notation: ramp &lt;- makeFun(ifelse(0 &lt; x, x, 0) ~ x) slice_plot(ramp(x) ~ x, domain(x=c(-3, 3))) A linear combination of two input-shifted ramp functions gives a piecewise version of the sigmoid. sig &lt;- makeFun(ramp(x+0.5) - ramp(x-0.5) ~ x) slice_plot(sig(x) ~ x, domain(x=c(-3, 3))) Figure ?? is a graph of monthly natural gas use in the author’s household versus average temperature during the month. (Natural gas is measured in cubic feet, appreviated ccf.) 1530 The graph looks somewhat like a hockey stick. A sloping straight-line dependence of ccf on temperature for temperatures below \\(60^\\circ\\)F and constant for higher temperatures. The shape originates from the dual uses of natural gas. Gas is used for cooking and domestic hot water, the demand for which is more of less independent of outdoor temperature at about 15 ccf per month. Gas is also used for heating the house, but that’s needed only when the temperature is less than about \\(60^\\circ\\)F. We can accomplish the hockey-stick shape with a linear combination of the ramp() function and a constant. The ramp function represents gas used for heating, the constant is the other uses of gas (which are modeled as not depending on temperature. Overall, the model is \\[\\text{gas_ccf}(x) \\equiv 4.3\\, \\mbox{ramp}(62-x) + 15\\] Even simpler is the model for the other uses of natural gas: \\[\\text{other_ccf}(x) \\equiv 15\\]. Do heating degree days in integration. Similarly with power from wind turbines Our last example concerns a bit of familiar technology: music synthesis. Generating a pure tone electronically is easy done using a sinusoid. Generating a note with rich instrumental timbre can be accomplished by a linear combination of sinusoids. Of course, the note will be localized in time. This could be accomplished by multiplying the sinusoids by a hump function envelope. 1540 It turns out that our standard hump function, dnorm(), does not generate a realistic sound. Instead, a more complicated envelope is used, such as the ADSR function shown in Figure 13.1. The function has six (!) parameters: the time the key is pressed, the duration A of the “attack” phase when the sound amplitude is increasing in response to the impulse imposed on the key, a decay of duration D to an output level S that lasts until the key is released, then a decay to zero over duration R. It’s reasonable to think of the D and S phases as a piecewise linear approximation to exponential decay. Figure 13.1: The ADSR envelope function used in music synthesis consists of 6 pieces including zero output before the key is pressed and after the pulse ends. Source One that does produce a number is NaN^0.↩︎ Literally, “Is \\(x\\) both greater than 2 and less than 5?”↩︎ "],["magnitudes.html", "Chapter 14 Magnitudes 14.1 Counting digits 14.2 Using digit() to understand magnitude 14.3 Quantity and magnitude 14.4 Composing \\(\\ln()\\) 14.5 Magnitude graphics 14.6 Magnitude scales 14.7 Fractional digits (optional)", " Chapter 14 Magnitudes Undoubtedly you are comfortable with the standard way of writing numbers, for instance 33 or 512 or 1051. Elementary school students master the comparison of such numbers. Which is greater: 512 or 33? Which is less, 1051 or 512? You can answer such questions at a glance; the comparison can be accomplished simply by counting the number of digits. 1051 has four digits, so it is larger than the three-digit number 512. There are two digits in 33, so it smaller than 512. When two numerals have the same number of digits—say, 337 and 512—you can’t answer the “greater than” question by simple counting. Instead, you proceed from left to write and compare the number in each place. So, for 512 and 337, you compare 5 to 3 and … since 5 is greater than 3, 512 is greater than 337. If the two leading digits are the same, go on to the next digit and so on for all the digits in turn. 1600 Things were not always this simple. Our number system that uses place and Arabic numerals is a human invention. An example of an earlier number system is Roman numerals. Here, comparison is hard. For instance, which of these three numbers is bigger? \\[\\mbox{MLI or CXII or XXXIII}\\] The typographically shorter number is the largest, and vice versa. Even when two Roman numerals have the same length, it’s not trivial to compare them on a place-by-place basis. For instance, IC is about fifteen times bigger than VI, even though I is much smaller than V. 14.1 Counting digits Digit counting provides an easy, fast way to perform many calculations, at least approximately. What is \\(\\sqrt{10000}\\)? There are five digits, and the square root of a number will have “half the number of digits.” So, \\(\\sqrt{10000} = 100\\). What is \\(10 \\times 34\\)? Easy: 340. Just append the one zero from 10 to the end of 34. What is \\(1000 \\times 13\\)? Just as easy: 13,000. We even punctuate written numbers with commas and a period in order to facilitate counting digits. Imagine having a digit counting function called digit(). It takes a number as input and produces a number as output. We don’t have a formula for digit(), but for some inputs the output can be calculated just be counting. For example: digit(10) \\(\\equiv\\) 1 digit(100) \\(\\equiv\\) 2 digit(1000) \\(\\equiv\\) 3 … and so on … digit(1,000,000) \\(\\equiv\\) 6 … and on. The digit() function easily can be applied to the product of two numbers. For instance: digit(1000 \\(\\times\\) 100) = digit(1000) + digit(100) = 3 + 2 = 5. Similarly, applying digit() to a ratio gives the difference of the digits of the numerator and denominator, like this: digit(1,000,000 \\(\\div\\) 100) = digit(1,000,000) - digit(100) = 6 - 2 = 4 14.2 Using digit() to understand magnitude We haven’t shown you the digit() function for anything but the handful of discrete inputs listed above. It was a heroic task to produce the continuous version of digit(). The method is sketched out in 14.7. In practice, digit() is so useful that it could well have been one of our basic modeling functions: \\[\\text{digit(x)} = 2.302585 \\ln(x)\\] or, in R, log10(). We elected \\(\\ln()\\) rather than digit() for reasons that will be seen when we study differentiation. 14.3 Quantity and magnitude The familiar quantity 60 miles-per-hour is written as a number (60 here) followed by units. The quantity is neither the number nor the units: it is the combination of the two. For instance, 100 is obviously not the same as 60. And miles-per-hour is not the same as kilometers-per-hour. Yet, 60 miles-per-hour is almost exactly the same quantity as 100 kilometers-per hour.16 1610 6, 60, 600, and 6000 miles-per-hour are quantities that differ in size by orders of magnitude. Such differences often point to a substantial change in context. A jog is 6 mph, a car on a highway goes 60 mpg, a cruising commercial jet goes 600 mph, a rocket passes through 6000 mph on its way to orbital velocity. In everyday speech, the difference between 60 and 6 is 54; just subtract. Modelers and scientists routinely mean something else: the difference between 60 and 6 is “one order of magnitude.” Similarly, 60 and 6000 are different by “two orders of magnitude,” and 6 and 6000 by three orders of magnitude. In everyday English, we have phrases like “a completely different situation” or “different in kind” or “qualitatively different” (note the l) to indicate substantial differences. “Different orders of magnitude” expresses the same kind of idea but with specific reference to quantity. The use of factors of 10 in counting orders of magnitude is arbitrary. A person walking and a person jogging are on the edge of being qualitatively different, although their speeds differ by a factor of only 2. Aircraft that cruise at 600 mph and 1200 mph are qualitatively different in design, although the speeds are only a factor of 2 apart. A professional basketball player (height 2 meters or more) is qualitatively different from a third grader (height about 1 meter). Modelers develop an intuitive sense for when to think about difference in terms of a subtractive difference (e.g. 60 - 6 = 54) and when to look at orders of magnitude (e.g. 60-to-6 is one order of magnitude). This seems to be a skill based in experience and judgment, as opposed to a mechanical process. One clue that thinking in terms of orders of magnitude is appropriate is when you are working with a set of objects whose range of sizes spans one or many factors of 2. Comparing baseball and basketball players? Probably no need for orders of magnitudes. Comparing infants, children, and adults in terms of height or weight? Orders of magnitude may be useful. Comparing bicycles? Mostly they fit within a range of 2 in terms of size, weight, and speed (but not expense!). Comparing cars, SUVs, and trucks? Differences by a factor of 2 are routine, so thinking in terms of order of magnitude is likely to be appropriate. Another clue is whether “zero” means “nothing.” Daily temperatures in the winter are often near “zero” on the Fahrenheit or Celcius scales, but that in no way means there is a complete absence of heat. Those scales are arbitrary. Another way to think about this clue is whether negative values are meaningful. If so, thinking in terms of orders of magnitude is not likely to be useful. You may have guessed that digits() is handy for computing differences in terms of orders of magnitude. Here’s how: 1620 Make sure that the quantities are expressed in the same units. Calculate the difference between the digits() of the numerical part of the quantity. What is the order-of-magnitude difference in velocity between a snail and a walking human. A snail slides at about 1 mm/sec, a human walks at about 5 km per hour. Putting human speed in the same units as snail speed: \\[5 \\frac{km}{hr} = \\left[\\frac{1}{3600} \\frac{hr}{sec}\\right] 5 \\frac{km}{hr} = \\left[10^6 \\frac{mm}{km}\\right] \\left[\\frac{1}{3600} \\frac{hr}{sec}\\right] 5 \\frac{km}{hr} = 1390 \\frac{mm}{sec} \\] Calculating the difference in digits() between 1 and 1390: log10(1390) - log10(1) ## [1] 3.143015 So, about 3 orders of magnitude difference in speed. To a snail, we walking humans must seem like rockets on their way to orbit! Animals, including humans, go about the world in varying states of illumination, from the bright sunlight of high noon to the dim shadows of a half moon. To be able to see in such diverse conditions, the eye needs to respond to light intensity across many orders of magnitude. The lux is the unit of illuminance in the Système international. This table17 shows the illumination in a range of familiar outdoor settings: Illuminance Condition 110,000 lux Bright sunlight 20,000 lux Shade illuminated by entire clear blue sky, midday 1,000 lux Typical overcast day, midday 400 lux Sunrise or sunset on a clear day (ambient illumination) 0.25 lux A full Moon, clear night sky 0.01 lux A quarter Moon, clear night sky For a creature active both night and day, they eye needs to be sensitive over 7 orders of magnitude of illumination. To accomplish this, eyes use several mechanisms: contraction or dilation of the pupil accounts for about 1 order of magnitude, photopic (color, cones) versus scotopic (black-and-white, rods, nighttime) covers about 3 orders of magnitude, adaptation over minutes (1 order), squinting (1 order). 14.4 Composing \\(\\ln()\\) The logarithm is the inverse of the exponential function. In other words, \\[\\ln(e^x) = x\\ \\ \\text{and}\\ \\ e^{\\ln(x)} = x\\] Think about this in terms of the kinds of quantities that are the input and output to each function. 1630 Logarithm: The input is a quantity, the output is the magnitude of that quantity. Exponential: The input is a magnitude, the output is the quantity with that magnitude. Exercise 14.3: ILESX Question A A) True or false: \\(2^x\\) is a power-law function.     TRUE ☹︎ In a power-law function, the input is the base. In \\(2^x\\), the input is the exponent. So it’s an exponential function.        FALSE ✓ Question B B) True or false: \\(3/x^2\\) is a power-law function.     TRUE ✓        FALSE ☹︎ This is the same as \\(3 x^{-2}\\). You can see that \\(x\\) is the base, so this is a power-law function. Question C C) True or false: \\(5\\sqrt{x}\\) is a power-law function.     TRUE ✓        FALSE ☹︎ This is the same as \\(5 x^{1/2}\\). The input \\(x\\) is the base, so this is a power-law function. Question D D) The gravitational force, F, between two bodies is inversely proportional to the square of the distance \\(d\\) between them. Then … Inversely proportional to the square would be \\(d^{-2}\\) ☹︎ \\(F = kd^{-2}\\) ✓ This is a square-root relationship. ☹︎ This is inversely proportional to the square root. ☹︎ Exercise 14.7: RWESX Robert Boyle (1627-1691) iwas a founder of modern chemistry and of the scientific method in general. As any chemistry student already knows, Boyle sought to understand the properties of gasses. His results are summarized in Boyle’s Law. We going to examine some data from Boyle’s lab notebooks. (They are preserved at the Royal Society in London. The data have been copied from this source.) The data are available to you as the data frame Boyle. The units of pressure are mmHg and the units of volume are cubic inches. Open a sandbox to carry out some calculations with Boyle’s data. To see how the data frame is organized, use the head(Boyle) and names(Boyle) commands. The scaffolding here contains a command for plotting out Boyle’s data. It also includes a command, gf_lm() that will add a graph of the best straight-line model to the plotted points. Recall that the # symbol turns what follows on the line into a comment, which is ignored by R. By removing the # selectively you can turn on the display of log axes. gf_point(pressure ~ volume, data = Boyle) %&gt;% gf_refine( # scale_x_log10(), # scale_y_log10() ) %&gt;% gf_lm() Question A (A) In the sandbox, plot pressure versus volume using linear, semi-log, and log-log axes. Based on the plot, and the straight-line function drawn, which of these is a good model of the relationship between pressure and volume?     linear ☹︎ This would look like a straight line on linear axes.        exponential ☹︎ This would look like a straight line on semi-log axes.        power-law ✓ We want to find the slope and intercept of the straight-line model. This can be hard to read off a graph with log scales, so you will use a special purpose function to find the formula for the straight-line function that fits the data. Here’s an example of how to use it. fitModel(log(pressure) ~ a + b*volume, data = Boyle) %&gt;% coefficients() Notice that we use log(pressure) in the formula in the scaffolding. This would be appropriate if you think the data fall on a straight-line on semi-log axes. To use log-log axes, you would want to use log(volume) on the right side of the tilde expression. Or, if you’re using linear axes, leave out the logs altogether. Question B (B) What is the slope produced by fitModel() when fitting the correct model type from part (1)? Roughly -1 ☹︎ You must be a very precise person! Almost exactly -1 ✓ About -1.5 ☹︎ I’m not sure how you arrived at this answer. Slope \\(&gt; 0\\) ☹︎ You should be able to see from the graph you made in part (1) that the slope is negative. According to the appropriate model that you found in (A) and (B), interpret the function you found relating pressure and volume. Question C (C) As the volume becomes very large, what happens to the pressure? Pressure becomes very small. ✓ Pressure stays constant ☹︎ You can see from the graph in part (A) that pressure does change with volume. Pressure also becomes large. ☹︎ You can see from the graph in part (A) that pressure goes down as volume goes up. None of the above ☹︎ Return to your use of fitModel() to find the slope of the straight-line fit to the appropriately log-transformed model. When you carried out the log transformation, you could have used the so-called “natural logarithm” with expressions like log(pressure). Alternatively, you could have used the log base-10 or the log base-2, with expressions like log(pressure, base = 10) or log(volume, base = 2). Whichever you use, you should use the same base for all the logarithmic transformations when finding the straight-line parameters. Question D (D) Does the slope of the straight line found by fitModel() depend on which base is used?     No ✓        Yes ☹︎ Did you use the same base for both logarithms in your fitModel() expression?        There’s no way to tell. ☹︎ Yes, there is. Try using fitModel() with the different bases of log. Question E (E) Does the intercept of the straight line found by fitModel() depend on which base is used?     Yes ✓ Good. But this will come out in the wash when you calculate the parameter \\(C\\) in \\(C x^b\\), since \\(C\\) will be either \\(2^\\mbox{intercept}\\) or \\(10^\\mbox{intercept}\\) or \\(e^\\mbox{intercept}\\) depending on the base log you use.        No ☹︎ Are you sure you tried different bases? 14.5 Magnitude graphics Exercise 14.1: ILXEG gf_point(BHP ~ displacement, data = Engines) %&gt;% gf_refine(scale_x_log10(), scale_y_log10()) Based on the log-log plot of horsepower (BHP) versus engine displacement, answer these questions. Question A How many engines have a displacement of 1 liter or less?     none ☹︎ Perhaps you recognized that the left-most tick mark corresponds to a value of 1, and that no data points are 1 or smaller. But one liter corresponds to 1000 cc.        7 ☹︎ This is the number of engines with displacement of 10 cc or smaller. But one liter corresponds to 1000 cc.        14 ✓ Right. It’s the \\(10^3\\) tick that marks 1 liter, since 1 liter is 1000 cc.        25 ☹︎ That would be true if the cut-off were 10 liters. But it’s not.        randomAnswerOrder ☹︎ FALSE Question B Using the log-log plot, how many decades of BHP are spanned by the data?     4 ☹︎ Not a bad answer, but not the best one either. Notice that the smallest engine is about half a decade below 1 BPM, and the largest is about half a decade above 10,000 BPH        5 ✓        100 ☹︎ The number \\(10^{100}\\) is called a googol and is roughly how many particles (including photons, neutrinos, etc.) are in the universe. Imagine, quite contrary to fact, that 1 BHP could be generated by burning one molecule of fuel per second. Then as many fuel molecules as there are particles in the universe would have to be burned each second to power an engine at the high end of a span of 100 decades. Derive straight-line form of power-law function Suppose \\(f(x) = A x^p\\). The \\(\\ln(f(x)) = p \\ln(x) + \\ln(A)\\). f &lt;- makeFun(A * x^p ~ x, A=1, p=2.5) Pts &lt;- tibble::tibble( x = seq(1, 50, length=10), y = f(x), color = rainbow(length(x)) ) P &lt;- slice_plot(f(x) ~ x, domain(x=c(0,50))) %&gt;% gf_point(y ~ x, color=~color, data = Pts) %&gt;% gf_refine(scale_color_identity()) P P %&gt;% gf_refine(scale_y_log10(), scale_x_log10()) ## Warning: Transformation introduced infinite values in continuous y-axis ## Warning: Transformation introduced infinite values in continuous x-axis Exercise 14.15: EWLCI Here is a plot of the power output (BHP) versus displacement (in cc) of 39 internal combustion engines. gf_point(BHP ~ displacement, data = Engines) %&gt;% gf_lims(y = c(0, 30000)) Question A Your study partner claims that the smallest engine in the data has a displacement of 2000 cc (that is, 2.0 liters) and 100 horsepower. Based only on the graph, is this claim plausible? Yes, because 2000 cc and 100 hp would look like (0, 0) on the scale of this graph. ✓ Yes, because that size engine is typical for a small car. ☹︎ That may be, but certainly you’ve encountered lawn mower engines that are much smaller. No, the smallest engine is close to 0 cc. ☹︎ Would you be able to distinguish visually an engine of 1 cc from an engine of 1000cc on this graph? Both these values would lie on the same horizontal pixel in the graph. No, my study partner is always wrong. ☹︎ Be that as it may, we’re looking for a principled answer, not an ad hominem one. Semi-log scales The next command will make a graph of the same engine data as before, but with a log scale on the horizontal axis. The vertical axis is still linear. gf_point(BHP ~ displacement, data = Engines) %&gt;% gf_refine(scale_x_log10()) Question B Using just the graph, answer this question: The engines range over how many decades of displacement? (Remember, a decade is a factor of 10.) 7 decades ✓ Can’t tell ☹︎ Yes, you can. Figure out what one decade corresponds to in terms of distance on the log axes. \\(10^7\\) decades ☹︎ The estimated volume of the entire universe is about \\(4 \\times 10^{86}\\) cc. The volume of a neutron is about \\(6 \\times 10^{-81}\\) cc. The range between a neutron and the universe is therefore about \\(86 - -81 = 167\\) decades. Do you think it likely that there is an internal combustion engine smaller than a neutron or larger than the universe? About 3.5 decades ☹︎ Perhaps you’re treating the distance between axis labels as one decade. Look carefully and you see that it’s actually a factor of 100, that is, two decades. Log-log scales In order to make a graph with log-log scales, we refine the graph with both scale_y_log10() and scale_x_log10(), as in the following … gf_point(BHP ~ displacement, data = Engines) %&gt;% gf_refine(scale_x_log10(), scale_y_log10()) Based on the log-log plot, answer these questions. Question C How many engines have a displacement of 1 liter or less?     none ☹︎ Perhaps you recognized that the left-most tick mark corresponds to a value of 1, and that no data points are 1 or smaller. But one liter corresponds to 1000 cc.        7 ☹︎ This is the number of engines with displacement of 10 cc or smaller. But one liter corresponds to 1000 cc.        14 ✓ Right. It’s the \\(10^3\\) tick that marks 1 liter, since 1 liter is 1000 cc.        25 ☹︎ That would be true if the cut-off were 10 liters. But it’s not.        randomAnswerOrder ☹︎ FALSE Question D Using the log-log plot, how many decades of BHP are spanned by the data?     4 ☹︎ Not a bad answer, but not the best one either. Notice that the smallest engine is about half a decade below 1 BPM, and the largest is about half a decade above 10,000 BPH        5 ✓        100 ☹︎ The number \\(10^{100}\\) is called a googol and is roughly how many particles (including photons, neutrinos, etc.) are in the universe. Imagine, quite contrary to fact, that 1 BHP could be generated by burning one molecule of fuel per second. Then as many fuel molecules as there are particles in the universe would have to be burned each second to power an engine at the high end of a span of 100 decades. 14.6 Magnitude scales Plotting the logarithm of a quantity gives a visual display of the magnitude of the quantity and labels the axis as that magnitude. A useful graphical technique is to label the axis with the original quantity, letting the position on the axis show the magnitude. 1640 To illustrate, Figure ??(left) is a log-log graph of horsepower versus displacement for the internal combustion engines reported in the Engines data frame. The points are admirably evenly spaced, but it is hard to translate the scales to the physical quantity. The right panel in Figure ?? shows exactly the same data points, but now the scales are labeled using the original quantity. gf_point(log(BHP) ~ log(displacement), data = Engines) gf_point(BHP ~ displacement, data = Engines) %&gt;% gf_refine(scale_y_log10(), scale_x_log10()) The tick marks on the vertical axis in the left pane are labeled for 0, 2.5, 5.0, 7.5, and 10. That doesn’t refer to the horsepower itself, but to the logarithm of the horsepower. The right pane has tick labels that are in horsepower at positions marked 1, 10, 100, 1000, 10000. Such even splits of a 0-100 scale are not appropriate for logarithmic scales. One reason is that 0 cannot be on a logarithmic scale in the first place since \\(\\log(0) = -\\infty\\). Another reason is that 1, 3, and 10 are pretty close to an even split of a logarithmic scale running from 1 to 10. It’s something like this: 1 2 3 5 10 x |----------------------------------------------------| 0 1/3 1/2 7/10 1 log(x) It’s nice to have the labels show round numbers. It’s also nice for them to be evenly spaced along the axis. The 1-2-3-5-10 convention is a good compromise; almost evenly separated in space yet showing simple round numbers. Exercise 14.19: TLEXE Question A Consider the axis scales shown above. Which kind of scale is the horizontal axis? linear ✓ You can see this because a given length along the axis corresponds to the same arithmetic difference regardless of where you are on the axis. the distance between 0 and 50 is exactly the same as the difference between 50 and 100, or the distance between 150 and 200. logarithmic ☹︎ A clue that an axis is not logarithmic is that there is a zero marked. The log of zero is \\(-\\infty\\), which can’t appear on any actual graph. Another key is whether the scale shows doubling behavior. The distance between 50 and 100 represents one doubling: 100 is twice 50. If the scale were logarithmic, moving forward that same distance from 100 would bring you to 200. But that’s not what happens here. semi-logarithmic ☹︎ “Semi-logarithmic” is not about a single axis but about two axes: horizontal and vertical. It means that one axis is linear while the other is logarithmic. log-log ☹︎ “Log-log” is not about a single axis but about two axes. It means that both the horizontal and vertical axes are logarithmic. Question B Which kind of scale is the vertical axis? linear ☹︎ Measure the distance from 30 to 50. If the scale were linear, then moving that same distance from 50 would bring you to 70, and moving that distance again would bring you to 90. But you can see that instead of reaching 90, you’d reach something greater than 100 on the scale. So the scale is not linear. logarithmic ✓ semi-logarithmic ☹︎ “Semi-logarithmic” is not about a single axis but about two axes: horizontal and vertical. It means that one axis is linear while the other is logarithmic. log-log ☹︎ “Log-log” is not about a single axis but about two axes. It means that both the horizontal and vertical axes are logarithmic. Question C Given your answers to the previous two questions, what kind of plot would be made in the frame being displayed at the top of this question?     semi-log ✓        log-log ☹︎ A log-log plot has log scales for both axes. The horizontal axis here is linear.        linear-linear ☹︎ No, the vertical axis is logarithmic. Exercise 14.23: SELIX The data frame SSA_2007 comes from the [US Social Security Administration(https://www.ssa.gov/oact/STATS/table4c6.html) and contains mortality in the US as a function of age and sex. (“Mortality” refers to the probability of dying in the next year.) Open a sandbox and copy in the following scaffolding to see the organization of the data. data(SSA_2007) SSA_2007 Once you understand the data organization, delete the old scaffolding and insert this: ::: {scaffolding} data(SSA_2007) gf_point(mortality ~ age, color = ~ sex, data = SSA_2007) There is a slight mistake in the way the command is written, so and error message will be generated. To figure out what’s wrong, read the error message, check the variable names, and so on until you successfully make the plot. ::: Question A A) What was the mistake in the plotting command in the above code box? Variable names didn’t match the ones in the data. ✓ The tilde in the argument color = ~ sex ☹︎ The color = argument is right. The value being used, ~ sex, is a one-sided formula and is used for things like color, shape, transparency, …. The data frame name is spelled wrong. ☹︎ No.  There is no function gf_point(). ☹︎ No. gf_point() is one of the more commonly used plotting functions Essay question tmp-11: B) What’s the obvious (simple) message of the above plot? Now you are going to use semi-log and log-log scales to look at the mortality data again. To do this, you will use the gf_refine() function. gf_point( __and_so_on__) %&gt;% gf_refine( scale_y_log10(), scale_x_log10() ) Fill in the __and_so_on__ details correctly and run the command in your sandbox. As written, both vertical and horizontal axes will be on log scales. This may not be what you want in the end. Arrange the plotting command to make a semi-log plot of mortality versus age. Interpret the plot to answer the following questions. Note that labels such as those along the vertical axis are often called “decade labels.” Question B The level of mortality in year 0 of life is how much greater than in year 1 and after? About twice as large. ☹︎ C) Hint: How much is the change between successive labels on the y axis? About five times as large ☹︎ C) Hint: How much is the change between successive labels on the y axis? About 10 times as large ✓ About 100 times as large ☹︎ C) Hint: How much is the change between successive labels on the y axis? Question C D) Near age 20, the mortality of males is how much compared to females? Less than twice as large. ☹︎ Hint: Due to the nature of logs, a difference of half a decade corresponds to a change of \\(\\sqrt{10}\\). A bit more than three times as large ✓ About 8 times as large ☹︎ Hint: Due to the nature of logs, a difference of half a decade corresponds to a change of \\(\\sqrt{10}\\). About 12 times as large ☹︎ Hint: Due to the nature of logs, a difference of half a decade corresponds to a change of \\(\\sqrt{10}\\). Question D E) Between the ages of about 40 and 80, how does mortality change with age? It stays about the same. ☹︎ But the curve is sloping up, isn’t it? It increases as a straight line. ☹︎ It would be fair to say this about the logarithm of mortality. But a straight line in log mortality means that mortality itself is increasing exponentially. It increases exponentially. ✓ It increases, then decreases, then increases again. ☹︎ Interesting that you would say this when the function in clearly monotonically increasing above age 30. Remake the plot of mortality vs age once again, but this time put it on log-log axes. The sign of a power-law relationship is that it shows up as a straight line on log-log axes. Question E F) Between the ages of about 40 and 80 is the increase in mortality better modeled by an exponential or a power-law process? Power-law ☹︎ But it’s hard to find any straight line on the log-log plot. Exponential ✓ Right. The graph is much closer to a straight line on semi-log scales than on log-log scales. No reason to prefer one or the other. ☹︎ One is much closer to a straight line than the other. 14.7 Fractional digits (optional) So far, we have the digit() function in a tabular form: 1650 input output \\(\\vdots\\) \\(\\vdots\\) 0.01 -2 0.1 -1 1 0 10 1 100 2 1000 3 10,000 4 100,000 5 1,000,000 6 \\(\\vdots\\) \\(\\vdots\\) Here’s the point-plot presentation of the table: Figure 14.1: Connecting the data points for the digit function to make a continuous function. We’ve imagined digits() to be a continuous function so we’ve connected the gaps with a straight line. Now we have a function that has an output for any input between 0.01 and 1,000,000, for instance, 500,000. The angles between consecutive line segments give the function plotted in Figure 14.1 an unnatural look. Still, it is a continuous function with an output for any input even if that input is not listed in the table. Starting around 1600, two (now famous) mathematicians, John Napier (1550-1617) and Henry Briggs (1561-1630) had an idea for filling in gaps in the table. They saw the pattern that for any of the numbers \\(a\\) and \\(b\\) in the input column of the table \\[ \\text{digit}(a \\times b) = \\text{digit}(a) + \\text{digit}(b)\\] This is true even when \\(a=b\\). For instance, digit(10)=1 and digit(10\\(\\times\\) 10) = 2. Consider the question what is digit(316.2278)? That seems a odd question unless you realize that \\(316.2278 \\times 316.2278 = 100,000\\). Since digit(100000) = 5, it must be that digit(316.2278) = 5/2. Another question: what is digit(17.7828)? This seems crazy, until you notice that \\(17.7828^2 = 316.2278\\). So digit(17.78279) = 5/4. It happens that for a couple of thousand years mathematicians have known how to compute the square root of any number to a high precision. By taking square roots and dividing by two, it’s easy to fill in more rows in the digit()-function table. You get even more rows by noticing other simple patterns like \\[\\text{digit}(a/10) = \\text{digit}(a) -1 \\ \\ \\and \\ \\ \\ \\text{digit}(10 a) = \\text{digit}(a) + 1\\] Here are some additional rows in the table input output Why? 316.2278 2.5 From \\(\\sqrt{\\strut100,000}\\) 17.17828 1.25 From \\(\\sqrt{\\strut 316.2278}\\) 4.21696 0.625 From \\(\\sqrt{\\strut 17.17828}\\) 31.62278 1.5 From 316.2278/10 3.162279 0.5 From 31.62278/10 You can play this game for weeks. We asked the computer to play the game for about half a second and expanded the original digit() table to 7975 rows. Figure ?? plots the expanded digits() function table. Now we have a smooth function that plays by the digit rules of multiplication. Henry Briggs and his assistants did a similar calculation by hand. Their work was published in 1617 as a table. Figure 14.2: Part of the first page of Henry Briggs table of logarithms The table was called the Chilias prima, Latin for “First group of one thousand.” True to its name, the table gives the output of digits() for the inputs 1, 2, 3, …, 998, 999, 1000. For instance, as you can see from the top row of the right-most column, digits(67) = 1.82607480270082. In everyday speech, 67 has two digits. The authors of Chilias prima sensibly didn’t use the name “digit()” for the function. They chose something more abstract: “logarithm().” Nowadays, this function is named \\(\\log_{10}()\\). In R, the function is called log10(). 1660 log10(67) ## [1] 1.826075 Our main use for \\(\\log_{10}()\\)/log10() will be to count digits in order to quickly compare the magnitude of numbers. The difference digits(\\(x\\)) - digits(\\(y\\)) tells how many factors of 10 separate the magnitude of the \\(x\\) and \\(y\\). Another important logarithmic/digit-counting function is \\(\\log_2()\\), written log2() in R. This counts how many *binary digits are in a number. For us, \\(\\log_2(x)\\) tells how many times we need to double, starting at 1, in order to reach \\(x\\). For instance, \\(\\log_2(67) = 6.06609\\), which indicates that \\(67 = 2\\times 2 \\times 2 \\times 2 \\times 2 \\times 2 \\times 2^{0.06609}\\) \\(\\log_2(x)\\) and \\(\\log_{10}(x)\\) are proportional to one another. One way to think of this is that they both count “digits” but report the results in different units, much as you might report a temperature in either Celsius or Fahrenheit. For \\(\\log_2(x)\\) the units of output are in bits. For \\(\\log_{10}(x)\\) the output is in decades. A third version of the logarithm function is called the natural logarithm and is denoted \\(\\ln()\\) in math notation and simply log() in R. We’ll need additional calculus concepts before we can understand what justifies calling \\(\\ln()\\) “natural.” Exercise 14.27: TLCIX EXERCISE: Compute \\(10^y\\) to convert a “number of digits” into the number whose digits are being counted. For instance, \\(10^2.5\\) is 316.228. EXERCISE: How many binary digits in 64? in 127? EXERCISE: \\(\\log_{10}(x)\\) and \\(\\log_2(x)\\) are proportional to one another. What’s the constant of proportionality? 95.69 km/hr is exactly 60 mph.↩︎ Source: https://en.wikipedia.org/wiki/Daylight↩︎ "],["dimensions.html", "Chapter 15 Dimensions 15.1 Mathematics of quantity 15.2 Compound dimensions 15.3 Arithmetic with dimensions 15.4 Example: Dimensional analysis 15.5 Conversion: Flavors of 1 15.6 Dimensions and linear combinations", " Chapter 15 Dimensions Next time you’re at a family gathering with your 10-year old cousin, give her the following math quiz. 1700 What’s 3 + 2? What’s 7 - 3? What’s 3 miles + 2 miles? What’s 3 miles + 2 kilometers? What’s 3 miles + 2 kilograms? I don’t know your cousin, but I suspect she will have an easy time answering (1) and (2) correctly. As for (3), she might give the correct answer, “5 miles,” or just say “5.” If so, you’ll follow up with “5 what?” at which point she’ll definitely say “miles.” is a bit harder. You might need to prompt her with the information that 1 kilometer is about 0.6 miles. Then, if she’s pretty smart, she’ll answer “4.2 miles.” 10-year olds are pretty creative, so I’m not sure how she’ll answer (5). But if you ask your Ph.D. aunt, she’ll answer along the lines of “silly question,” or “there’s no such thing.” That’s true. Consider these everyday quantities: 60 miles per hour: a typical speed for driving on a highway 2106 square feet: the in-bounds area for a court used for singles tennis. 375 cubic centimeters: the volume in a canned beverage (in the US). 2.5 gallons per minute: the US mandated maximum flow rate for water through a shower head. 35 miles per gallon: a typical fuel economy for a small car in the US. Your body mass index: measure your mass then divide by the square of your height. Consider how you would measure such things: We ordinarily use a speedometer to measure instantaneous car speed and police use a radar gun. But fundamentally, you measure the distance traveled and the time used and divide distance by time. Most people would rely on the internet for this information, but you would check your local court by measuring the width (27 feet is the standard) and the length of the course (78). Multiply the two. Pour the beverage into a measuring cup and read off the volume. But more fundamentally, you could measure the circumference of the can (\\(2 \\pi r\\)), square it (\\(4 \\pi^2 r^2\\)) and divide by \\(4 \\pi\\) to get the cross section area of the can. Then multiply that by the height of the can. We don’t usually monitor water use by a shower. But if you need to, get a 5-gallon pail (the standard volume of the plastic pails used for so many purposes in construction), put it under the shower head, and measure the time it takes to fill the pail. Divide volume by the time. Record the mileage on the car’s odometer when you fill up the car with gas. Drive. When you next get gas, measure the new odometer reading and the volume of gas you purchased. Divide the change in odometer reading by the gas volume. (In Europe, you would divide the gas volume by the change in odometer reading.) Weigh yourself. The scale is usually graduated in both pounds and kilograms: take your choice. Measure your height; the ruler-in-the-doorway method works well. Then divide your weight by the square of your height. Evidently, it makes sense to multiply and divide different types of quantities: feet, gallons, kilometers, kilograms, pounds, hours, …. But you won’t ever see a quantity constructed by adding or subtracting miles and hours or gallons and and square feet. You can square feet and cube centimeters, but can you take the square root of a gallon? Does it make sense to raise 2 to the power of 3 yards? 1710 This section is about the mathematical structure of combining quantities; which kinds of mathematical operations are legitimate and which are not. 15.1 Mathematics of quantity [Fun-10a] Know the definition of a fundamental dimension and the notation for the most common ones (definition page 241-242) [Fun-10b] Understand how derived dimensions are formed from fundamental dimensions (definition page 241-242) [Fun-10c] Know that units are ways of measuring dimensions and derived dimensions. The first step in understanding the mathematics of quantity is to make an absolute distinction between two concepts that, in everyday life, are used interchangeably: dimension and unit. Length is a dimension. Meters is a unit of length. We also measure length in microns, mm, cm, inches, feet, yards, kilometers, and miles, to say nothing of furlongs, fathoms, astronomical units (AU), and parsecs. Time is a dimension. Seconds is a unit of time. We also measure time in micro-seconds, milli-seconds, minutes, hours, days, weeks, months, years, decades, centuries, millenia. Mass is a dimension. Kilograms is a unit of mass. Length, time, and mass are called fundamental dimensions. This is not because length is more important than area or volume. It’s because you can construct area and volume by multiplying lengths together. This is evident when you consider units of area like square-inches or cubic centimeters, but obscured in the names of units like acre, liter, gallon. We’ll use the notation L, T, and M to refer to the fundamental dimensions. (Electrical charge Q is also a fundamental dimension, but we won’t have much use for it in our examples.) 15.2 Compound dimensions There are other dimensions: volume, force, pressure, energy, torque, velocity, acceleration, and such. These are called compound dimensions because we represent them as combinations of the fundamental dimensions, L, T, and M. The notation for these combinations involves multiplication and division. For instance: Volume is L \\(\\times\\) L \\(\\times\\) L \\(=\\) L\\(^3\\), as in “cubic centimeters” Velocity is L/T, as in “miles per hour” Force is M L/T\\(^2\\), which is obscure unless you remember Newton’s Second Law that \\(\\text{F} = \\text{m}\\,\\text{a}\\): “force equals mass times acceleration.” In terms of dimension, mass is M, acceleration is L/T\\(^2\\). Multiply the two together and you get the dimension “force.” Multiplication and division are used to construct a compound dimension from the fundamental dimensions L, T, and M. Addition and subtraction are never used to form a compound dimension. Much of the work in understanding dimensions involves overcoming the looseness of everyday speech. Remember the weight scale graduated in pounds and kilograms. The unit kilograms is a way of measuring M, but the unit of pounds is a way of measuring force: M L/T\\(^2\\). Weight is not the same as mass. This makes no sense to most people and doesn’t really matter in everyday life. It’s only when you venture off the surface of the Earth that the difference shows up. A person in orbit is “weightless” but that person continues to have mass. The weight of a woman on Mars is different from her weight on Earth but her martian mass is exactly the same as her earthly mass. 1720 Another source of confusion carried over from everyday life is that sometimes we measure the same quantity using different dimensions. You can measure a volume by weighing water; a gallon of water weighs 8 pounds, a liter of water has a mass of 1 kg. Serious bakers measure flour by weight; a casual baker uses a measuring cup. We can measure water volume with length because water has a (more-or-less) constant mass density. But 8 pounds of gasoline is considerably more than a gallon. It turns out that the density of flour varies substantially depending on how it’s packed, on humidity, etc. This is why it matters whether you weigh flour for baking or measure it by volume. You can measure time by the swing of a pendulum. To measure the same time successfully with different pendula they need to have the same length, not the same mass. A unit is a conventional amount of a quantity of a given dimension. All lengths are the same dimensionally, but they can be measured with different conventions: inches, hards, meters, … Units for the same dimension can all be converted unambiguously one into the other. A meter is exactly the same quantity of length as 39.3701 inches, a mile is the same length as 1609.34 meters. Liters and gallons are both units of volume (L\\(^3\\)): a gallon is the same as 3.78541 liters. You will hear it said that a kilogram is 2.2 pounds. That’s not strictly true. A kilogram has dimension M and a pound has dimension ML/T\\(^2\\). Quantities with different dimensions cannot be “equal” or even legitimately compared to one another. Unless you bring something else into the game that physically changes the situation, for instance gravity (dimension of acceleration due to gravity (dimension \\(\\text{L}/\\text{T}^2\\)). The weight of a kilogram on the surface of the Earth is is 2.2 pounds because gravitational acceleration is (almost) the same everywhere on the surface of the Earth. It’s also potentially confusing that sometimes different dimensions are used to get at the same idea. For instance, the same car that gets 35 miles / gallon in the US (dimension \\(\\text{L}/\\text{L}^3 = 1/\\text{L}^2\\)) will use 6.7 liters per 100 kilometers (\\(\\text{L}^3 / L = \\text{L}^2\\)) in Europe. Same car. Same fuel. Different conventions using different dimensions. 1730 [Fun-10d] Understand the bracket notation and how it works with dimensional arithmetic. Keeping track of the various compound dimensions can be tricky. For many people, it’s easier to keep track of the physical relationships involved and use that knowledge to put together the dimensions appropriately. Often, the relationship can be described using specific calculus operations, so knowing dimensions and units helps you use calculus successfully. We’ll use a specific bracket notation to translate between words for the concept and the dimension. For instance, [length] = L, [mass] = M, [time] = T, [inches] = L, … Easy compound dimensions that you likely already know: [Area] \\(= \\text{L}^2\\). Some corresponding units to remind you: “square feet,” “square miles,” “square centimeters.” [Volume] \\(= \\text{L}^3\\). Units to remind you: “cubic centimeters,” “cubic feet,” “cubic yards.” (What landscapers informally call a “yard,” for instance “10 yards of topsoil” should properly be called “10 cubic-yards of topsoil.”) [Velocity] \\(= \\text{L}/\\text{T}\\). Units: “miles per hour,” “inches per second.” [Momentum] \\(= \\text{M}\\text{L}/\\text{T}\\). Units: “kilogram meters per second.” Anticipating that you will return to this section for reference, we’ve also added some dimensions that can be understood through the relevant calculus operations. acceleration: [Calculus: derivative of velocity with respect to time, 2nd derivative of position with respect to time] force: [Calculus: Derivative of momentum with respect to time] energy: [Calculus: Integral of force with respect to length] power: [Calculus: Derivative of energy with respect to time] Density sounds like a specific concept, but there are many different kinds of densities. These have in common that they are a ratio of a physical amount to a geometric extent: 1740 a physical amount: which might be mass, charge, people, etc. a geometric extent: which might be length, area, or volume. Some examples: “paper weight” is the mass per area, typically grams-per-square-meter “charge density” is the amount of electrical charge, usually per area or volume “lineal density of red blood cells” is the number of cells in a capillary divided by the length of the capillary. (Capillaries are narrow. Red blood cells go through one after the other.) “population density” is people per area of ground. The theory of dimensions and units was developed for the physical sciences. Consequently the fundamental dimensions are those of physics: length, mass, time, electrical current, luminous intensity. Since proper use of units is important even outside the physical sciences, it’s helpful to recognize several other kinds of quantity as dimensions. “people”/“passengers”/“customers”/“patients”/“children”/“students”/“professors” — these are different dimensions and not really units: no fixed translation between them as you would have with units. “money”: Units are dollars (in many varieties: US, Canadian, Australian, New Zealand), euros, yuan (synonym: renminbi), yen, pounds (many varieties: UK, Egypt, Syria, Lebanon, Sudan and South Sudan), pesos (many varieties), dinar, franc (Swiss, CFA), rand, riyal, rupee, won, and many others. Conversion rates depend on situation and national policy. Examples: Passenger-miles is a standard unit of transport. Passenger-miles-per-dollar is an appropriate unit of the economic efficiency of transport. Passenger-deaths per million passenger-mile is one way to describe the risk of transport. 15.3 Arithmetic with dimensions Recall the rules for arithmetic dimensioned quantities. We restate them briefly with the square-bracket notation for “the dimension of.” For instance, “the dimension of \\(b\\)” is written \\([b]\\). We also write \\([1]\\) to stand for the dimension of a pure number, that is, a quantity without dimension. Operation Result Only if satisfies Metaphor Multiplication \\([a \\times b] = [a] \\times [b]\\) anything goes promiscuous Division \\([a \\div b] = [a] \\div [b]\\) anything goes promiscuous Addition \\([a + b] = [a]\\) \\([a] = [b]\\) monogomous Subtraction \\([a - b] = [a]\\) \\([a] = [b]\\) monogomous Trigonometric \\([\\sin(a)] = [1]\\) \\([a] = [1]\\) celibate Exponential \\([e^a] = [1]\\) \\([a] = [1]\\) (of course, \\([e] = [1]\\)) celibate Power-law \\([b ^ a] = \\underbrace{[b]\\times[b]\\times ...\\times [b]}_{a\\ \\ \\mbox{times}}\\) \\([a] = [1]\\) with \\(a\\) an integer exponent celibate Square root \\([\\sqrt{b}] = [c]\\) \\([b] = [c\\times c]\\) idiosyncratic Cube root \\([\\sqrt[3]{b}] = [c]\\) \\([b] = [c \\times c \\times c]\\) idiosyncratic Hump \\([\\mbox{hump}(a)] = [1]\\) \\([a] = [1]\\) celibate Sigmoidal \\([\\mbox{sigmoid}(a)] = [1]\\) \\([a] = [1]\\) celibate 15.4 Example: Dimensional analysis We want to relate the period (in T) of a pendulum to it’s length and mass. Gravity also plays a role. For simplicity, we’ll assume that the pendulum cable or rod is massless. 1750 The analysis strategy is to combine the four quantities we think play a role into one total quantity that is dimensionless. Since it is dimensionless, it can be constant regardless of the mass, length, period, gravity of each individual situation. \\[\\mbox{[Period]}^a \\cdot \\mbox{[Mass]}^b \\cdot \\mbox{[Length]}^c \\cdot \\mbox{[Gravity]}^d = T^a \\cdot M^b \\cdot L^c \\cdot L^d \\cdot T^{-2d}\\] To be dimensionless … \\(c = -d\\), cancel out the L \\(a = -2d\\), cancel out the T \\(b=0\\), there’s no other mass term, and we need to cancel out the M Let \\(d=1\\) and see what happens. \\[ \\frac{\\mbox{Gravity}}{\\mbox{Length}\\cdot \\mbox{Period}^2} \\equiv c\\] Consequently \\[\\text{Period} = \\sqrt{\\frac{\\mbox{Gravity}}{\\mbox{Length}} }\\] ::: {.forinstructors} Test via experiment String knotted into 4 equal segments (about 1 foot each) with a bolt at the end o-------o-------o-------o-------Bolt Hang the string from the first knot: length L=4 Time 10 oscillations and record result Hang the string from the second knot: length L=3 Time 10 oscillations and record result … and so on Calculate the dimensionless quantity \\(c\\) in each case. They should all be approximately the same. ::: Exercise 15.3: RDWKW This activity will apply some of the concepts and techniques you’re learning to answer the following question: How fast does a satellite move along its orbit? As you can imagine, the answer is already known and you could look it up. The point of our reconstructing what is already known is to see the totality of a modeling project, even if it is a very simple one. In textbooks and in-class demonstrations, students are often shown complete, flawless models. In reality, model construction is a matter of trial and error. Whoops! We’re supposed to say “modeling cycle.” That phrase doesn’t suggest anything about “error.” But in reality, modelers make mistakes, operate under misconceptions, collect erroneous data, misunderstand the purpose of building a model, and make all sorts of mistakes. To cope with this unhappy situation, good modelers are constantly checking and testing their models for inconsistencies. To start, you should have A good idea of what the eventual answer will be. Often, that idea comes from somewhat vague and imprecise knowledge. For example, you may have heard that it takes a satellite in low orbit about 90 minutes to complete one circuit of the Earth. You may also know that the length of the equator is roughly 40,000 kilometers. (This is actually the original definition of the meter.) A velocity is distance traveled over time, so a satellite in low orbit has a velocity of roughly \\(40000 / 90\\) km/minute, which comes out to 7400 meters/second. A theory that relates what you want to know to what you already know. For our purposes, that theory comes directly from Isaac Newton in the 1680s: his laws of motion and his theory of universal gravitation. The theory We won’t assume that you have anything more than a vague understanding of Newton’s laws and theory of gravitation. The diagram shows the situation schematically. The satellite is traveling clockwise along a curved trajectory encircling the Earth. The position of the satellite is shown at several times by the numbered blue dots. Let’s focus on the satellite at time 1. The satellite is an object in motion. Newton’s First Law (“Lex I”) is stated in his 1687 book, Philosophiae Naturis Principia Mathematica (Mathematical principles of natural philosophy) on p.12 Translating into English, this is Law I: Every body persists in its state of rest or uniform motion in a straight line, unless compelled to change that motion by forces impressed upon it. The dashed line connecting the points labeled 1 and 2’ shows the path that the satellite would follow if there were no forces impressed upon it. Yet there is a force impressed on the satellite: the gravitational attraction between the Earth and the satellite. This force accelerates the satellite perpendicular to its orbit (toward the center of the Earth) causing the satellite to follow a curved path rather than a straight path off into deep space. The acceleration of the satellite traveling at constant speed in orbit depends on both the velocity \\(v\\) of the satellite and the radius \\(r\\) of its orbit. Task #1: Let \\(A_1\\) be the acceleration needed to keep the satellite in a circular orbit. Find a plausible relationship between \\(A_1\\), \\(r\\), and \\(v\\). One possibility is that the relationship is a general product of the form \\[A_1 = v^n\\ r^m .\\] Use dimensional analysis to find \\(n\\) and \\(m\\). Recall that acceleration has dimension L/T\\(^{2}\\), velocity has dimension \\(L/T\\) and radius has dimension L. Once you determine \\(n\\) and \\(m\\), write down the relationship \\(A_1\\) as a function of \\(r\\) and \\(v\\). As we all know, gravity pulls all objects toward the center of the Earth. The acceleration \\(A_2\\) due to gravity on an object a distance \\(r\\) from the enter of the Earth is proportional to the mass of the Earth and is known to be \\[A_2 = G\\ M_e/r^2\\] where \\(G\\) is a constant of proportionality and \\(M_e\\) is the mass of Earth. In order for the satellite to stay in orbit, the two accelerations \\(A_1\\) (what’s needed to stay in orbit) and \\(A_2\\) (what the Earth’s gravity provides) must be equal. Task #2: Set your expression for \\(A_1\\) equal to the expression for \\(A_2\\) and solve for the velocity \\(v\\) of the satellite (our original objective for this exercise). Your answer will involve \\(G\\), \\(M_e\\), and \\(r\\). Use the known numerical values for \\(G\\) and \\(M_e\\) given in the next section to check that your answer makes sense. The data The data here come from scientific observations made over centuries that give us numerical values (with units) of \\(M_e\\) and \\(G\\) in the theory. \\(G\\) is a universal constant (according to Newton’s theory of gravitation). The quantity is given by several sources as \\[G = 6.67 \\times 10^{−11} m^3 /(s^2 kg).\\] Similarly, the mass of the Earth is given as \\[M_e = 5.972 × 10^{24} kg\\] These reported facts seem plausible, but it’s a good practice to check. Toward that end, check The dimension and units of \\(A_2(v, r)\\) are consistent. The value of \\(A_2\\) at the Earth’s surface is consistent with the famous value 9.8 m/s\\(^2\\). Task #3: Finishing up. Use the formula you derived for \\(v\\) as a function of \\(r\\), \\(G\\), and \\(M_e\\) to find \\(v\\) for a satellite in low orbit around the Earth. (You’ll have to decide what “low” means.) As always, you want to do the calculation in a way that helps you to spot possible errors. Here are two good practices: You have already confirmed (or should have) that your formula for \\(v\\) as a function of \\(r\\), \\(G\\), and \\(M_e\\) is dimensionally consistent. As you plug in numerical values for \\(r\\), \\(G\\), and \\(M_e\\), make sure to keep track of the units explicitly and that the result you get has proper units for velocity. Compare your result to the rough estimate of \\(v\\) for satellites in low orbit that you made at the beginning of this activity. If there is a discrepancy, review both your initial rough estimate as well as your gravity-based derivation of \\(v\\) to figure out where the inconsistency comes from. Then fix it. 15.5 Conversion: Flavors of 1 Numbers are dimensionless but not necessarily unitless. Failure to accept this distinction is one of the prime reasons people have trouble figuring out to to convert from one unit to another. 1760 1 is a favorite of elementary school students because its multiplication and division tables are completely simple. Anything times one, or anything divided by one, is simply that thing. Addition and subtraction are pretty simple, too, but that’s not my concern here. When it comes to quantities, there’s not just one one but many. And often they look nothing like the numeral 1. Some examples of 1 as a quantity: \\(\\frac{180}{\\pi} \\frac{\\text{degrees}}{\\text{radians}}\\) \\(0.621371 \\frac{\\text{mile}}{\\text{kilometer}}\\) \\(3.78541 \\frac{\\text{liter}}{\\text{gallon}}\\) \\(\\frac{9}{5} \\frac{^\\circ F}{^\\circ C}\\) \\(\\frac{1}{12} \\frac{\\text{dozen}}{\\text{item}}\\) I like to call these and others different flavors of one. In every example, the dimension of the numerator matches the dimension of the denominator. [feet / meter] is L/L = 1. [cups / pint] is L3/L3 = 1. [miles/hour / ft per sec] = L/T / L/T = 1. Each of these quantities has units but it has no dimension. It’s helpful to think about conversion between units as a matter of multiplying by the appropriate flavor of 1. Such conversion will not change the dimension of the quantity but will render it in new units. Example: Convert 100 feet-per-second into miles-per-hour. First, write the quantity to be converted as a fraction and along side it, write the desired units after the conversion. In this case that will be \\[100 \\frac{\\text{feet}}{\\text{second}} \\ \\ \\ \\text{into} \\ \\ \\ \\frac{\\text{miles}}{\\text{hour}}\\] First, we’ll change feet into miles. This can be accomplished by multiplying by the flavor of one that has units miles-per-foot. What number will give a flavor of one? One mile is 5280 feet, so \\[\\frac{1}{5280} \\frac{\\text{miles}}{\\text{foot}}\\] is a flavor of one. Next, we need a flavor of one that will turn \\(\\frac{1}{\\text{second}}\\) into \\(\\frac{\\text{1}}{\\text{hour}}\\). This will have the form \\(\\frac{\\text{second}}{\\text{hour}}\\). What number will give a flavor of one with these units. One hour is 3600 seconds, so \\[3600 \\frac{\\text{second}}{\\text{hour}}\\] is a flavor of one. Multiplying our carefully selected flavors of one by the initial quantity, we get \\[ \\frac{1}{5280} \\frac{\\text{miles}}{\\text{foot}} \\times 3600 \\frac{\\text{second}}{\\text{hour}}\\times 100 \\frac{\\text{feet}}{\\text{second}} = 100 \\frac{3600}{5280} \\frac{\\text{miles}}{\\text{hour}} = 68.18 \\frac{\\text{miles}}{\\text{hour}}\\] 15.6 Dimensions and linear combinations Low-order polynomials are a useful way of constructing model functions. And a polynomial is a linear combination of monomials. For instance, suppose we want a model of the yield of corn in a field per inch of rain over the growing season, will call it corn(rain). The output will have units of bushels (of corn). The input will have units of inches (of rain). A second-order polynomial will be appropriate for reasons to be discussed in Chapter ??. 1770 \\[\\text{corn(rain)} \\equiv a_0 + a_1\\, \\text{rain} + \\frac{1}{2} a_2\\, \\text{rain}^2\\] Of course, the addition in the linear combination will only make sense if all three terms \\(a_0\\), \\(a_1\\,\\text{rain}\\), and \\(a_2\\, \\text{rain}^2/2\\) have the same dimension. But clearly \\([\\text{rain}] \\neq [\\text{rain}^2]\\). In order for things to work out, the scalars must themselves have dimension. We know the output of the function will have dimension \\([\\text{volume}] = \\text{L}^3\\). Thus, \\([a_0] = \\text{L}^3\\). \\([a_1]\\) must be different, because it has to cancel out the \\([\\text{rain}] = \\text{L}\\) and produce \\(\\text{L}^3\\). Thus, \\([a_1] = \\text{L}^2\\). Finally, \\([a_2] = \\text{L}\\). Multiplying that by \\([\\text{rain}]^2\\) will give the required \\(\\text{L}^3\\) In everyday communication as well as in most domains such as construction, geography, navigation, and astronomy we measure angles in degrees. 90 degrees is a right angle. But in mathematics, the unit of angle is radians where a right angle is 1.5708 radians. (1.5708 is the decimal version of \\(\\pi/2\\).) The conversion function, which we’ll call raddeg(), is \\[\\mbox{raddeg}(r) \\equiv \\frac{180}{\\pi} r\\] The function that converts degrees to radians, which we’ll call degrad() is very similar: \\[\\mbox{degrad}(d) \\equiv \\frac{\\pi}{180} d\\] (Incidentally, \\(\\frac{180}{\\pi} = 57.296\\) while \\(\\frac{\\pi}{180} = 0.017453\\).) In traditional notation, the trigonometric functions such as \\(\\sin()\\) and \\(\\tan()\\) can be written with an argument either in degrees or radians. For instance, \\(\\sin(90^\\circ) = \\sin\\left(\\frac{\\pi}{2}\\right)\\). Similarly, for the inverse functions like \\(\\arccos()\\) the units of the output are not specified. This works because there is always a human to intervene between the written expression and the eventual computation. With the computer, there is no valid expression like sin(90 deg) (although it would be good if there were!). The angles are always given in radians. Such consistency is admirable, but people are not always so consistent. It is a common source of computer bugs that angles in degrees are handed off to functions like \\(\\sin()\\) and that the output of \\(\\acos()\\) is (wrongly) interpreted as degrees rather than radians. 1780 Function composition to the rescue! Consider this function given in the [Wikipedia article on the position of the sun] (as seen from Earth)18. \\[\\delta_\\odot(n) \\equiv - 23.44^\\circ \\cdot \\cos \\left [ \\frac{360^\\circ}{365} \\cdot \\left ( n + 10 \\right ) \\right ]\\] Where \\(n\\) is zero at the midnight marking New Years and increases by 1 per day. (The \\(n+10\\) translates New Years back 10 days, to the day of the winter solstice.) \\(\\delta_\\odot()\\) gives the declination of the sun: the latitude pieced by an imagined line connecting the centers of the earth and the sun. The Wikipedia formula is well written in that it uses some familiar numbers to help the reader see where the formula comes from. 365 is recognizably the length of the year in days. \\(360^\\circ\\) is the angle traversed when making a full cycle around a circle. \\(23.44^\\circ\\) is less familiar, but the student of geography might recognize it as the latitude of the Tropic of Cancer, the latitude farthest north where the sun is directly overhead at noon (on the day of the summer solstice). But there’s a world of trouble for programmer who implements the formula as dec_sun &lt;- makeFun(-23.44 * cos((360/365)*(n-10)) ~ n) ::: Exercise 15.3: UGDKY NEED TO INSERT THE FORMULAS from MMAC For each mathematical operation, identify the operation as valid or invalid according to the rules of dimensional arithmetic. Question tmp-12: For Formula 25 on MMAC p. 259, choose which rule (if any) is violated. Addition or Subtraction rule [Both the numerator and denominator are valid subtractions, with dimension L and T respectively.] Multiplication or Division rule [There are no restrictions for multiplication and division, so a formula can hardly violate them!] Exponential [There’s no exponent here.] It’s valid. No rules are violated. (+) [] Question tmp-13: For Formula 26 on MMAC p. 259, choose which rule (if any) is violated. Addition or Subtraction rule [No addition or subtraction here.] Multiplication or Division rule [There are no restrictions for multiplication and division, so a formula can hardly violate them!] Exponential [There’s no exponent here.] It’s valid. No rules are violated. (+) [] Question tmp-14: For Formula 27 on MMAC p. 259, choose which rule (if any) is violated. Addition or Subtraction rule [No addition in this formula.] Multiplication or Division rule [There are no restrictions for multiplication and division, so a formula can hardly violate them!] Exponential (+) [The exponent is 4 ft / 3 g, which has dimension L / M. Exponents must always have dimension [1].] It’s valid. No rules are violated. [] Question tmp-15: For Formula 28 on MMAC p. 259, choose which rule (if any) is violated. Addition or Subtraction rule [No addition or subtraction in this formula.] Multiplication or Division rule [There are no restrictions for multiplication and division, so a formula can hardly violate them!] Exponential [The exponent is 4hr/3min, which has dimension T/T = [1]. So the rule is satisfied.] It’s valid. No rules are violated. (+) [] Question tmp-16: For Formula 29 on MMAC p. 259, choose which rule (if any) is violated. Addition or Subtraction rule (+) [You can’t subtract M from M\\(^2\\). (Strictly speaking, lbs has dimension of force, \\(M L^2 / T^2\\), but you can’t subtract force from M\\(^2\\) either.] Multiplication or Division rule [There are no restrictions for multiplication and division, so a formula can hardly violate them!] Exponential [There’s no exponent here.] It’s valid. No rules are violated. [] Question tmp-17: For Formula 30 on MMAC p. 259, choose which rule (if any) is violated. Addition or Subtraction rule (+) [You can’t add L\\(^3\\) to L\\(^2\\).] Multiplication or Division rule [There are no restrictions for multiplication and division, so a formula can hardly violate them!] Exponential [Maybe you’re thinking that the cube-root rule is violated, but since the quantity in the cube root is invalid, the root doesn’t do anything additionally wrong.] It’s valid. No rules are violated. [] Exercise 15.7: DVGKY Question tmp-18: A) The dimension of \\(t\\) is T, that is, \\([t] = T\\). What must the dimension of \\(k\\) for the arithmetic operation to make sense? [1] [Then $[kt] = $T, which would violate the exponential rule.] T\\(^{ -1}\\) (+) [Right, [k] needs to cancel out [t] so that the exponention is valid.] T [Then $[kt] = \\(T\\)^2$, which would violate the exponential rule.] None of the above [] Question tmp-19: B) What must the dimension of \\(c\\) for the arithmetic operation \\(1 + c \\cdot 2^{kt}\\) to make sense? [1] (+) [Right. You’re going to have to add \\(c \\cdot 2^{kt}\\) to 1. Since \\([kt] = [1]\\), \\(c\\) also needs to be dimensionless.] T\\(^{-1}\\) [] T [Then $[kt] = \\(T^2\\), which would violate the exponential rule.] Depends on the dimension of \\(2^{kt}\\) [We already determined that \\([kt] = [1]\\), so \\([2^{kt}] = [1]\\).] Exercise 15.11: KGYKY The surface area \\(S\\) of a mammal is reasonably well approximated by the function \\[S(M) \\equiv k M ^{2/3}\\] where \\(M\\) is the body mass (in kg) and the constant \\(k\\) depends on the particular species under consideration. Note that \\(M^{2/3}\\) is not an allowed arithmetic operation. \\([M] = \\mbox{mass}\\), and mass cannot be raised to a non-integer power. More properly, the expression should be written \\[\\left(\\frac{M}{1\\ kg}\\right)^{2/3}\\] The division by “1 kg” renders dimensionless the quantity in the parentheses: \\[\\left[\\frac{M}{1\\ kg}\\right] = 1\\] In order to render the quantity both dimensionless and unitless, \\(M\\) should be specified in kg. The usual practice is to skip the “1 kg” business and simply say, “Where \\(M\\) is in kg.” You will see such notation frequently in your career and should take care to use the indicated units. You’ll need to open a computing sandbox to do the calculations. Question tmp-20: A) Consider a baby and an adult. The adult’s mass is \\(8\\) times greater than the baby’s. Then the adult’s surface area is …? The same as the baby’s [] 1.5 times of the baby’s [] 4 times the baby’s (+) [] 8 times the baby’s [] Question tmp-21: B) Consider a human of body mass 70 kg with a skin surface area of 18,600 cm2. Which of the following units for the constant of proportionality \\(k\\) is correct? cm\\(^2\\) kg\\(^{-2/3}\\) (+) [] cm\\(^2\\) [What about the units of mass? What takes care of them?] cm\\(^2\\) kg\\(^{2/3}\\) [When you multiply 70 kg by \\(k\\), you need to get a result in \\(cm^2\\).] kg\\(^{-1}\\) [Would this cancel out the units of mass and produce \\(cm^2\\) for the result?] Question tmp-22: C) In the units of part (B), which value is \\(k\\) closest to? 1 [] 10 [] 100 [] 1000 (+) [] The numerical value of the constant \\(k\\) changes depending on what units you want to express it in. The value you found in part (C) works for masses stated in kg and skin areas in cm\\(^2\\). Suppose you want to present \\(k\\) in units that will make sense to people who are used to talking about skin area in square inches and mass in pounds. 1 inch \\(\\approx\\) 2.6 cm. In the rough-and-ready way everyday people express themselves, 1 kg \\(\\approx\\) 2.2 lbs. (Of course, pounds is a measure of force, not mass. But people use it as if it were mass. A mass of 70 kg corresponds to about 4.8 slugs. In Earth’s gravity, 4.8 slugs produces a force of 154 pounds.) Question tmp-23: Optional challenge) What is the rough numerical value of the conversion factor which would produce a constant of proportionality that would be suitable for converting body mass in pounds to skin area in square-inches? 0.03 [] 0.3 (+) [\\(k\\) is about 1000 cm\\(^2\\) kg\\(^{-2/3}\\). To convert the cm to inches, we need to multiply by (1 in/2.6 cm)\\(^2\\). To convert the kg to pounds, we need to multiply by (2.2 pounds/ 1 kg)\\(^{-2/3}\\).] 3 [] 30 [] 300 [] More exercises to include … Exercises/Dimension/Boyd-1.html Article accessed on May 30, 2021↩︎ "],["outline-of-block-2.html", "Outline of Block 2", " Outline of Block 2 This section is for development purposes only. It is not to be included in the released text. This outline was that established during the May 17-19, 2021 working sessions at USAFA. It’s copied directly from the Teams document. I’ve made some modifications which are noted in [[square brackets]] for deletions and bold face for additions.. Revisiting Calculating slope NTI: Admin: Sizeable quiz on interlude Outcomes: Calculate a slope given two points Given a graph of a function, identify graph of its slope function \\(s(x)\\) Given a graph of the slope function, identify features of the original function Readings: Chapter @ref{difference-and-change} Derivatives NTI: Explain that limits are the solution to the problem of having an arbitrary \\(h\\) in the slope function Topics: Show that there are different definitions of the slope function \\(s(x)\\) that depend on the \\(h\\) selected Describe derivative as the limit where \\(h \\rightarrow 0\\) Derivatives of basic modeling functions Linear properties of derivatives [[Derivative is a number; differentiation is an operator]] **We need to introduce operators earlier. Functions as arguments in R Introduce notation: \\(f&#39;\\), \\(\\frac{df}{dx}\\), \\(\\partial_x f(x)\\), [[$D_x f]]$ Introduce NaN and Inf Outcomes: Find the derivatives of all basic modeling functions Know the basic properties of differentiation Continue working graphing a derivative Readings: Chapter ?? Relationships between functions and their derivatives Part I NTIs: Split students into A/B pairs. A has graph of derivative. B can’t see that graph, but can talk to A. B should sketch out the original function based on information from A, who can see B’s sketch. Then reveal answer. Topics: Argmax/Argmin Max/min Critical points Outcomes: Determine a function’s critical points graphically and algebraically Determine whether a critical point is a max or min Readings: 22. It doesn’t take much to introduce max and min from graphs, argmax and argmin, and critical points. So the reading can be quite small. Relationships between functions and their derivatives Part II NTI: Curvature. Up like a cup, down like a frown 2nd derivative indicates curvature Topics: Second derivatives are the slope of the slope Concavity is the slope of the slope Readings: Chapter 22 This is the same as the previous days reading. Maybe we should add a section of chains of derivatives, especially for polynomials, showing how they eventually go to zero. Relationships between functions and their derivatives Part III Topics: Knowing \\(f&#39;(x_0) = 0\\) tells you there is a min/max/saddle at \\(x_0\\) 2nd derivative to distinguish between the three Chain of derivatives Outcomes: Be able to find max/min, argmax/argmin of given functions graphically. **Construct derivative function and use findZeros() to locate the argmax and evaluate the function to get the corresponding max Readings Chapter 22 Still the same as the previous two days. Continuity, Differentiability, Smoothness, Splines Topics: Spline is a piecewise function Order of continuity Determine graphically whether a function is continuous or not Determine order of continuity of a function Outcomes Be able to determine if first derivative of function is continuous from graph of function Be able to determine if second derivative of function is continuous from graph of function (or by taking the 1st derivative and plotting that) Be able to demonstrate discontinuities in 3rd derivative of spline Readings: Chapter 19 Differentiation of Products and composition of Functions Topics Identifying a composite function Chain rule Identifying a product of functions product rule Outcomes Identify when it is necessary to differentiate with chain rule Find the derivative using chain rule Identify when it is necessary to differentiate with product rule Find the derivative using product rule Homework: Save quotient rule for HW Readings: Chapter 21 Partial derivatives Local Polynomial Approximation NTI: Killer application of Taylor polynomials when Brook Taylor figured out that tools of Newton developed Topics: List the benefits of approximation and specifically the benefits of quadratic approximation as opposed to linear approximation [Average rate of change] moved to Block 1 slope function Tangent Lines Quadratic equations Factorials Readings Approximation at a point NTI: R exercise in constructing a Taylor polynomial computationally Outcomes: Calculate a Taylor polynomial Use Taylor polynomials to simplify mathematical operations (derivatives, limits, etc.) Note: We don’t touch the gradient here. Provisionally, I’m moving gradients to the Block on linear algebra. "],["change-relationships.html", "Chapter 16 Change relationships 16.1 Slopes and motion 16.2 Differentiation 16.3 Notations for differentiation 16.4 Dimension of derivatives 16.5 Visualizing the slope function", " Chapter 16 Change relationships The questions that started it all had to do with motion. There were words to describe speed: fast and slow. There were words to describe force: strong and weak, heavy and light. And there were words to describe location and distance: far and near, long and short, here and there. But what were the relationships among these things? And how did time fit in, an intangible quantity that had aspects of location (long and short) and of speed (quick and slow)? Galileo (1564-1642) started the ball rolling. As the son of a musician and music theorist, he had a sense of musical time, a steady beat of intervals. When a student of medicine in Pisa, he noted that swinging pendulums kept reliable time, regardless of the amplitude of their swing. After accidentally attending a lecture on geometry, he turned to mathematics and natural philosophy. Inventing the telescope, his observations put him on a collision course with the accepted classical truth about the nature of the planets. Seeking to understand gravity, he built an apparatus that enabled him to measure accurately the position in time of a ball rolling down a straight ramp. The belled gates he set up to mark the ball’s passage were spaced arithmetically in musical time: 1, 2, 3, 4, …. But the distance between the gates was geometric: 1, 4, 9, 16, …. Thus he established a mathematical relationship between increments in time and increments in position. Time advanced as 1, 1, 1, 1, … and position as 1, 3, 5, 7, …. He observed that the second increments of position, the increments of the increments 1, 3, 5, 7, …, were themselves evenly spaced: 2, 2, 2, …. Putting these observations in tabular form, and adding columns for the first increment \\(y(t) \\equiv x(t+1) - x(t)\\) and the second increment \\(y(t+1) - y(t)\\) \\(t\\) \\(x(t)\\) first increment second increment 0 0 1 2 1 1 3 2 2 4 5 2 3 9 7 4 16 Galileo had neither the mathematics nor the equipment to measure motion continuously in time. So what might be obvious to us now, that position is a function of time \\(x(t)\\), would have had little practical significance to him. But we discover in his first increments of \\(x\\) something very much like the slope function in Chapter ??. \\[{\\cal D}_t\\, x(t) \\equiv \\frac{x(t + 1) - x(t)}{1}\\] From his data, he observed that \\({\\cal D}_t\\, x(t)\\) increases linearly in \\(t\\): \\[{\\cal D}_t x(t) = 2 t + 1\\] Calculating the second increments of \\(x\\) is done by the “slope function of the slope function,” which we can call \\({\\cal D}_{tt}\\): \\[{\\cal D}_{tt} x \\equiv {\\cal D}_t \\left[{\\cal D}_t x(t)\\right] = 2(t+1) + 1 - (2 t + 1) = 2\\] ## Continuous time Newton considered the problem for continuous time rather than Galileo’s discrete time. He reframed the slope function from the big increments of the slope operator \\({\\cal D}_t\\) to imagined vanishingly small increments of a operator that we shall denote \\(\\partial_t\\) and call differentiation. The kind of question for which Newton wanted to be able to calculate the answer was, “How to find the function \\(x(t)\\) whose second increment, \\(\\partial_{tt} x(t) = 2\\)?” His approach, which he called the “method of fluxions,” became so important that its name became, simply, “Calculus.” Over the next three centuries, calculus evolved from a set of techniques for describing motion into the general-purpose mathematics of change. Applying calculus in the real world involves understanding change relationships between quantities. To give some examples: Electrical power is the change with respect to time of electrical energy. Birth rate is one component of the change with respect to time of population. Interest, as in bank interest or credit card interest, is the change with repect to time of assets. Inflation is the change with respect to time of prices. Disease incidence is one component of the change with respect to time of disease prevalence. Force is the change with respect to position of energy. Exercise 16.1 (kid-mean-table) Each question involves a pair of quantities that are a function of time and that might or might not be a quantity/rate-of-change pair. If they are, say which quantity is which. Feel free to look up a dictionary definition of words you are uncertain about. Question A Deficit and debt Deficit is the rate of change of debt with respect to time. ✓ Debt is the rate of change of deficit with respect to time. ☹︎ They are not a rate of change pair. ☹︎ Question B water contained and flow Flow is the rate of change of water contained with respect to time. ✓ Water contained is the rate of change of flow with respect to time. ☹︎ They are not a rate of change pair. ☹︎ Question C Interest rate and debt owed on credit card Interest rate is the rate of change of credit card debut with respect to time. ✓ Credit card debut is the rate of change of interest rate with respect to time. ☹︎ They are not a rate of change pair. ☹︎ Question D Rain intensity and total rainfall Rain intensity is the rate of change of total rainfall with respect to time. ✓ Total rainfall is the rate of change of rain intensity with respect to time. ☹︎ They are not a rate of change pair. ☹︎ Question E Force and acceleration Force is the rate of change of acceleration with respect to time. ☹︎ Acceleration is the rate of change of force with respect to time. ☹︎ They are not a rate of change pair. ✓ The dimension of force is \\(ML/T^2\\). The dimension of acceleration is \\(L/T^2\\). A rate of change with respect to time should have an extra T in the denominator of the dimensions. Question F Position and acceleration Position is the rate of change of acceleration with repect to time. ☹︎ Acceleration is the rate of change of position with respect to time. ☹︎ They are not a rate of change pair. ✓ The dimension of position is \\(L\\). The dimension of acceleration is \\(L/T^2\\). The rate of change of position would have dimension \\(L/T\\). That’s called ‘velocity.’ Question G Velocity and air resistence Velocity is the rate of change of air resistence with repect to time. ☹︎ Air resistence is the rate of change of velocity with respect to time. ☹︎ They are not a rate of change pair. ✓ Air resistence is a force, with dimension \\(M L/T^2\\). Velocity has dimension \\(L/T\\). The rate of change of velocity with respect to time is acceleration, which has dimension \\(L/T^2\\). 16.1 Slopes and motion Chapter 9.6 introduced the idea of a slope function: a function \\(g(t)\\) whose value at each instant gives the instantaneous rate of change of a partner function \\(f(t)\\). To keep easier track of the relationship between the function and it’s slope function, we use the \\({\\cal D}\\) notation: \\[{\\cal}D_t f(t)\\] is the slope function of \\(f(t)\\) with respect to \\(t\\). To illustrate, imagine a graph of the position of a car along a road as in Figure 16.1. Over the course of an hour, the car traveled about 25 miles. In other words, the average speed is 25 miles/hour: the slope of the red line segment. Given the traffic, sometimes the car was stopped (time C), sometimes crawling (time D) and sometimes much faster than average (time B). Figure 16.1: The position of an imagined car over an hour of time. (black) The red line shows what the position would have been if the car had travelled steadily at the average speed for the hour. Of course, when you’re driving you are aware of the car’s speed at any instant. You need only look at the speedometer to read off the value (in miles per hour). Speedometers don’t show the average speed for the entire trip. The average speed is the slope of the red line in Figure @ref(fig:stop-and-go2}, 25 miles in one hour, usually stated 25 miles-per-hour. In terms of Figure @ref(fig:stop-and-go2}, the speedometer reading is the slope of \\(f(t)\\) at the given instant. You can see from the Figure that at instant A the speed is very close to the average speed for the entire trip. At instant B the car is going faster; the slope is much steeper. On the other hand, at instant C the car is at a standstill; its position doesn’t change at all. The car’s speedometer shows the speed at each moment—or instant—of the trip. As you can see in Figure @ref{fig:stop-and-go}, the speed varies and is sometimes less than the average speed, sometimes greater, and occasionally equal to the average speed over the trip. Although you can easily judge whether the instantaneous speed is faster or slower than the average speed, quantifying the speed requires some work: calculating the slope of the tangent line. Far easier to have this job done for us. The means to do so is to compute the slope function of \\(f()\\), that is, \\({\\cal D}_tf()\\). Figure 16.2 shows \\({\\cal D}_tf()\\) directly. You can read off the speed from the graph at any instant simply by reference to the vertical axis. Figure 16.2: The instantaneous velocity of the car whose position vs time is shown in Figure 16.1. The two graphs in Figures ?? and 16.2 show exactly the same car trip. The presentation of the data in the different graphs makes it easy to see some things and hard to see others. For instance, figuring out when the car is at a stand-still is harder in the position-vs-time graph than in the speed-vs-time graph. Having worked out a theory of slope functions, Newton was ready to express the laws of motion in continuous time. He did this by denoting position as \\(x(t)\\). The familiar concepts of velocity and force could then be defined in terms of slope functions of position and the “quantity of matter,” which we call “mass.” Velocity is the slope function of position: \\(v(t) \\equiv {\\cal D}_t x(t)\\). Net force is the slope function of velocity times mass: \\(F(t) \\equiv m {\\cal D}_t v(t)\\) To take mass out of the formulation, we give a name specifically to the slope function of velocity; we call it acceleration. Acceleration is the slope function of velocity: \\(a(t) \\equiv {\\cal D}_t v(t)\\). With acceleration as a concept, we can define net force as mass times acceleration. This is better known as Newton’s Second Law of Motion. We used net force as the quantity we related to mass and the slope function of velocity. There are different sources of forces which add up and can cancel out. Famously, Newton formulated the law of universal gravitation which ascribed the force between masses as proportional to the product of the two masses and inversely proportional to the square of the distance between them. But a mass on a table has no net force on it, since the table pushes back (push = force) on the mass to cancel out the force due to gravity. “Net force” takes such cancellation into account. 16.2 Differentiation Two central operations in calculus are: Given a function \\(f(t)\\), find the function \\(\\partial_t\\,f(t)\\) giving the instantaneous rate of change of \\(f()\\). This process of deriving \\(\\partial_t\\, (t)\\) from \\(f(t)\\) is called differentiation. Given a function \\(\\partial_t\\,(t)\\), find the \\(f(t)\\) of which \\(\\partial_t\\,f(t)\\) is the instantaneous rate of change. This process of finding \\(f()\\) given \\(\\partial_t\\,f()\\) is called anti-differentiation. Notice that in (1) and (2) above we didn’t use the \\({\\cal D}_t\\) notation. It’s time to switch away from that. What prompts the change is the nuisance of the constant 0.1 in the definition of the slope function: \\[{\\cal D}_t f(t) \\equiv \\frac{f(t+0.1) - f(t)}{0.1}\\] Whereas the slope function \\({\\cal D}_t f(t)\\) gives an approximation to the instantaneous rate of change, \\(\\partial_t f(t)\\) refers to the instantaneous rate of change exactly. We’ll come back to the relationship between \\({\\cal D}_t\\) and \\(\\partial_t\\) in Chapter 20. It’s a subject of particular interest to mathematicians, hence a central part of traditional calculus texts (which are mostly written by mathematicians). For modeling and other applications of calculus, it is something of a side issue. As an intermediate step on the path between \\({\\cal D}_t\\) and \\(\\partial_t\\), let’s redefine the slope function to eliminate the 0.1 and replace it with a parameter \\(h\\): \\[{\\cal D}_x f(x) \\equiv \\frac{f(x+h) - f(x)}{h}\\] This way of writing the slope function will enable us to consider how the slope function changes as \\(h\\) gets smaller and smaller. 16.3 Notations for differentiation There are several traditional notations for differentiation of a function named \\(f()\\). For instance: Leibnitz: \\(\\frac{df}{dx}\\) Partial: \\(\\frac{\\partial f}{\\partial x}\\) Euler: \\(D_x f\\) One-line: \\(\\partial_x f\\) (a hybrid of partial and Euler notation.) Newton (or “dot”): \\(\\dot{f}\\) Lagrange (or “prime”): \\(f&#39;\\) In this book, we will mainly use the one-line notation, \\(\\partial_x f\\), but it means exactly the same as the Leibnitz and Partial notations, which are much more widely used in textbooks. If you’ve studied calculus before, you have likely seen the \\(f&#39;\\) notation. This is admirably concise but is only viable in a narrow circumstance: functions that take a single input. What \\(f&#39;\\) leaves out is a means to specify a crucial aspect of differentiation, the with-respect-to variable. The general situation for differentiation involves functions of one or more variables, for example, \\(g(x, y, z)\\). For such functions, you need to specify which is the with-respect-to variable. For instance, we can differentiate \\(g()\\) three different ways, each way incrementing one or another of the three inputs: \\[\\partial_z g(x, y, z) \\equiv \\frac{g(x, y, z+h) - g(x, y, z)}{h}\\\\ \\ \\\\ \\partial_x g(x, y, z) \\equiv \\frac{g(x+h, y, z) - g(x, y, z)}{h}\\\\ \\ \\\\ \\partial_y g(x, y, z) \\equiv \\frac{g(x, y+h, z) - g(x, y, z)}{h}\\] At this point in your studies, you haven’t seen why you might choose to differentiate a function with respect to one variable or another. That will come in time. But we want to set you up with notation that won’t narrow your options. Both the Leibnitz and Partial notations are explicit in identifying the function and the with-respect-to-variable. For example, using the Partial differentiation notation, the three ways of differentiating our example function \\(g(x, y, z)\\) are labeled : \\[\\frac{\\partial f}{\\partial x},\\ \\ \\ \\frac{\\partial f}{\\partial y},\\ \\ \\text{and}\\ \\ \\frac{\\partial f}{\\partial z}\\] Our R/mosaic computer differentiation is longer but explicit: dx_g &lt;- D(g(x, y, z) ~ x) dy_g &lt;- D(g(x, y, z) ~ y) dz_g &lt;- D(g(x, y, z) ~ z) The names being used here are arbitrary; you can use any names you like. What’s nice about dx_g and the others is that it mimics the math notation \\(\\partial_x g()\\). Notice that the R/mosaic operator for differentiation is named D() and that it is a function. It follows the same pattern as makeFun() or slice_plot() or contour_plot(): the first argument is a tilde expression, for instance g(x, y, z) ~ x, which identifies the mathematical function to work with (g()) and the name of the with-respect-to input to that function. The R/mosaic notation makes it clear that differentiation is an operation on a function. The D() operator takes a function as input and produces as output another function. We’ve seen similar behavior with, say, slice_plot(), which takes a function as input and produces graphics as output. Both D() and slice_plot() need to know the identity of the with-respect-to variable as well as the function to work with. What’s why both pieces of input are packaged into a tilde expression. We’re calling D() an operator rather than a function. The reason is purely for communication with other people. There are so many “functions” in a calculus course that we thought it would be helpful to distinguish between the kinds of functions that take quantities as input and produce a quantity as output, and the functions that take a function as input and produce a function as output. Both sorts are called “functions” in R terminology. But a sentence like, “Differentiation is a function that takes a function as input and produces a function as output,” true though it be, is dizzying. It is a fact of mathematical and scientific life that a variety of notations are used for differentiation. To some extent, this reflects historical precedence and, to be honest, nationalistic European politics of the 18th century. To make sense of mathematical writing in the many areas in which calculus is used, you have to recognize all of them for what they are. Your skill will be enhanced if you also memorize the names of the different styles. It’s not all that different from the pattern in English of having multiple words for the same sort of object, for instance: car, automobile, junker, ride, wheels, crate, jalopy, limo, motor car, horseless carriage. In the days when carriages where pulled by horses, the phrase “horseless carriage” made a useful distinction. Today, when horses are rarely seen on the road, it make sense to trim down the notation to its essentials: horseless cariage. Think of \\(\\partial_x\\) as this sort of minificat ion of older notations.19 Exercise 16.2 (pine-lead-car) Recall that a function is monotonically increasing on a given domain when the function’s slope is positive everywhere in that domain. A monotonically decreasing function, similarly, as a negative slope everywhere in the domain. When the slope is zero, or positive in some places and negative in others, the function is neither monotonically increasing or decreasing. Each of the following graphs shows the derivative of some function \\(f(x)\\). (Note: the graph doesn’t show \\(f()\\) but rather the function \\(\\partial_x f()\\) which is the derivative of \\(f()\\).) For each graph, say whether the function \\(f()\\) is monotonically increasing, monotonically decreasing, or neither. (Note that the horizontal scale is the same in every graph, but the vertical scale can be different from one scale to another.) Question A Function A is … monotonically increasing ✓ A monotonically increasing function has a function that is everywhere \\(&gt; 0\\) monotonically decreasing ☹︎ A monotonically increasing function has a function that is everywhere \\(&gt; 0\\) constant ☹︎ A constant function has a derivative that is everywhere 0. non-monotonic ☹︎ A non-monotonic function goes up and down, hence the derivative is positive in some places and negative in others. Can’t tell from the info provided ☹︎ This is the case if you cannot tell if the derivative is positive or negative. Question B Function B is … monotonically increasing ☹︎ A monotonically increasing function has a function that is everywhere \\(&gt; 0\\) monotonically decreasing ✓ A monotonically increasing function has a function that is everywhere \\(&gt; 0\\) constant ☹︎ A constant function has a derivative that is everywhere 0. non-monotonic ☹︎ A non-monotonic function goes up and down, hence the derivative is positive in some places and negative in others. Can’t tell from the info provided ☹︎ This is the case if you cannot tell if the derivative is positive or negative. Question C Function C is … monotonically increasing ☹︎ A monotonically increasing function has a function that is everywhere \\(&gt; 0\\) monotonically decreasing ☹︎ A monotonically increasing function has a function that is everywhere \\(&gt; 0\\) constant ☹︎ A constant function has a derivative that is everywhere 0. non-monotonic ✓ A non-monotonic function goes up and down, hence the derivative is positive in some places and negative in others. Can’t tell from the info provided ☹︎ This is the case if you cannot tell if the derivative is positive or negative. Question D Function D is … monotonically increasing ✓ A monotonically increasing function has a function that is everywhere \\(&gt; 0\\) monotonically decreasing ☹︎ A monotonically increasing function has a function that is everywhere \\(&gt; 0\\) constant ☹︎ A constant function has a derivative that is everywhere 0. non-monotonic ☹︎ A non-monotonic function goes up and down, hence the derivative is positive in some places and negative in others. Can’t tell from the info provided ☹︎ This is the case if you cannot tell if the derivative is positive or negative. Question E Function E is … monotonically increasing ☹︎ A monotonically increasing function has a function that is everywhere \\(&gt; 0\\) monotonically decreasing ☹︎ A monotonically increasing function has a function that is everywhere \\(&gt; 0\\) constant ☹︎ A constant function has a derivative that is everywhere 0. non-monotonic ☹︎ A non-monotonic function goes up and down, hence the derivative is positive in some places and negative in others. Can’t tell from the info provided ✓ This is the case if you cannot tell if the derivative is positive or negative. Question F Function F is … monotonically increasing ✓ A monotonically increasing function has a function that is everywhere \\(&gt; 0\\) monotonically decreasing ☹︎ A monotonically increasing function has a function that is everywhere \\(&gt; 0\\) constant ☹︎ A constant function has a derivative that is everywhere 0. non-monotonic ☹︎ A non-monotonic function goes up and down, hence the derivative is positive in some places and negative in others. Can’t tell from the info provided ☹︎ This is the case if you cannot tell if the derivative is positive or negative. Exercise 16.3 (robin-row-boat) Here are graphs of various functions. The right column shows functions named \\(f_1()\\), \\(f_2()\\), and so on. The left column shows functions \\(A()\\), \\(B()\\), \\(C()\\), and so on. Most of the functions on the right are the derivative of some function on the left, and most of the functions on the left have their corresponding derivative on the right. Your task: Match the function on the left to it’s derivative on the right. Question A The derivative of Function A() is which of the following:     f1() ☹︎        f2() ✓        f3() ☹︎        f4() ☹︎        not shown ☹︎ Question B The derivative of Function B() is which of the following:     f1() ✓        f2() ☹︎        f3() ☹︎        f4() ☹︎        not shown ☹︎ Question C The derivative of Function C() is which of the following:     f1() ☹︎        f2() ☹︎        f3() ☹︎        f4() ✓        not shown ☹︎ Question D The derivative of Function D() is which of the following:     f1() ☹︎        f2() ☹︎        f3() ☹︎        f4() ☹︎        not shown ✓ Exercise 16.4 (deer-pitch-saw) The left column of graphs shows functions A(), B(), C(), and D(). The right column shows functions dd1(), dd2(), and so on. Find which function (if any) in the right column corresponds to the 2nd derivative of a function in the left column. Remember the concepts of “concave up” (a smile!) and “concave down” (a frown). At those values of \\(x\\) for which the 2nd derivative of a given function is positive, the given function will be concave up. When the 2nd derivative is negative, the given function will be concave down. Question A The second derivative of Function A() is which of the following:     dd1() ☹︎        dd2() ☹︎        dd3() ☹︎        dd4() ✓        not shown ☹︎ Question B The second derivative of Function B() is which of the following:     dd1() ☹︎        dd2() ✓        dd3() ☹︎        dd4() ☹︎        not shown ☹︎ Question C The second derivative of Function C() is which of the following:     dd1() ☹︎        dd2() ☹︎        dd3() ☹︎        dd4() ☹︎        not shown ✓ Question D The second derivative of Function D() is which of the following:     dd1() ✓        dd2() ☹︎        dd3() ☹︎        dd4() ☹︎        not shown ☹︎ 16.4 Dimension of derivatives Recall that the differencing operator takes as input a function and returns as output another function that takes the same kind of input, but produces a different kind of output. For instance, suppose the function pressure() takes an altitude as input (in km) and returns as output a pressure (in kPa, “kiloPascal”20). The derivative function, let’s call it d_pressure(), also takes an input in km, but produces an output in kPA per km: a rate. You can see this by examining the differencing operator itself: \\[{\\cal D}_x f(x) \\equiv \\frac{f(x+h) - f(x)}{h}\\] Remember the notation for dimensions. A quantity \\(x\\) has dimensions denoted as \\([x]\\). (This is nothing more than saying, “Pronounce ‘\\([x]\\)’ as ‘the dimensions of \\(x\\).’”) The input to \\(f()\\) has dimension \\([x]\\). The output from \\(f()\\) has dimension \\([f(x)]\\). What is the dimension of \\(h\\)? (We could write this question more simply, \"What is \\([h]\\)?) Since the operator adds \\(x + h\\), it must be that \\([h] = [x]\\). Otherwise, addition wouldn’t be a viable operation to combine the two quantities. What is the dimension of \\(f(x + h) - f(x)\\)? (Again, we could ask this more simply, “What is \\([f(x+h) - f(x)]\\)?”) Since we’re subtracting two quantities, the two quantities must have the same dimension and the result is also that dimension. So \\([f(x+h) - f(x)] = [f(x)]\\). The output of the function \\(df(x)\\) produced by \\(\\mbox{Diff}(f)\\) therefore has dimension \\([f(x)] / [x]\\). Exercise 16.5 (kitten-put-kayak) A. The given function is \\(N(y)\\), the population of the Netherlands in year \\(y\\). Dimension of input to \\(N(y)\\)? Dimension of output from \\(N(y)\\)? Dimension of input to \\(\\partial_y N(y)\\)? Dimension of output from \\(\\partial_y N(y)\\)? B. The given function is \\(p(u)\\), the net profit from a manufactured good as a function of the number of units manufactured. Dimension of input to \\(p(u)\\)? Dimension of output from \\(p(u)\\)? Dimension of input to \\(\\partial_u p(u)\\)? Dimension of output from \\(\\partial_u p(u)\\)? C. The given function is \\(w(t)\\), the amount of water in a leaky bucket at any time after the bucket was filled. Dimension of input to \\(w(t)\\)? Dimension of output from \\(w(t)\\)? Dimension of input to \\(\\partial_t w(t)\\)? Dimension of output from \\(\\partial_t w(t)\\)? Exercise 16.6 (rat-take-fork) Question A Tanks for bulk storage of natural gas are typically large cylinders with a cap that can more up and down. The volume of the tank is a function of the position of the cap. What is the dimension of the derivative of cylinder volume with respect to cap position?     \\(L^2\\) ✓        \\(L\\) ☹︎        \\(L^3\\) ☹︎        \\(L^3/T\\) ☹︎        \\(T/L^3\\) ☹︎ Exercise 16.7 (SIR-dimensions) Is this the right placement? The standard model of epidemics used in public health planning is called the SIR model. (SIR stands for “Susceptible (S), Infective (I), Recovered (R),” the sequence that a person starts in, moves to, and ends up in (hopefully!) in an epidemic.) One of the equations in the SIR model is \\[\\frac{dS}{dt} = -a S I\\] The notation \\(dS/dt\\) means “the rate of change of number of susceptibles, S, with respect to time.” This has dimension “people/T.” The dimensions \\([S]\\) and \\([I]\\) are each simply “people.” Question A What is \\([a]\\)? T ☹︎ T\\(^{-1}\\) ☹︎ people/T ☹︎ Then \\([a S I]\\) would be people\\(^3\\)/T, but that’s not the same as \\([dS/dt]\\). people\\(^{-1}\\) T\\(^{-1}\\) ✓ This correctly gives \\([a S I]\\) as people/T, which is the same as \\([dS/dt]\\). people \\(\\times\\) T ☹︎ None of the above. ☹︎ Exercise 57 refers to a second equation of the SIR model \\[\\frac{dI}{dt} = - a S I - b I\\] where \\([\\frac{dI}{dt}] =\\) people/T. Question B What is \\([b]\\)? T ☹︎ T\\(^{-1}\\) ✓ people/T ☹︎ Then \\([a S I]\\) would be people\\(^3\\)/T, but that’s not the same as \\([dS/dt]\\). people\\(^{-1}\\) T\\(^{-1}\\) ☹︎ If this were true, \\([bI]\\) would be T\\(^{-1}\\). But \\([bI]\\) has to be the same as \\([dI/dt]\\), which is people \\(T^{-1}\\). people \\(\\times\\) T ☹︎ None of the above. ☹︎ 16.5 Visualizing the slope function The function produced by the differencing operation \\[{\\cal D}_x f(x) \\equiv \\frac{f(x+h) - f(x)}{h}\\] is in every way an ordinary function that takes an input and produces an output. Ordinarily, we visualize functions of one variable by drawing a graph. This technique is every bit as applicable to functions produced by \\(\\diff{x}\\) as to any other function. The input to a slope function \\(\\diff{x} f(x)\\) is exactly the same as the input to the mother function \\(f(x)\\). So a graph of the slope function will have the same horizontal axis as a graph of the mother function. However, the output of \\(\\diff{x} f(x)\\) is a different kind of thing than the output of \\(f(x)\\). Suppose, for instance, that we have a mother function \\(T(x)\\) giving atmospheric temperature at a location on Earth as a function of altitude \\(x\\). The output of \\(T(x)\\) has, as you would expect, the dimension of temperature with units of, say, degrees C. But the output of \\(\\diff{x} T(x)\\) has a different dimension: temperature divided by altitude with units of, say, degrees C per km. The different dimensions of the output of a function and the output of its slope fun means that the vertical axis for graphing \\(\\diff{x} f(x)\\) must be different from the vertical axis used for graphing \\(f(x)\\). Thus, in general, \\(\\diff{x} f(x)\\) and \\(f(x)\\) cannot be graphed in the same frame. This requirement to use different graphics frames for \\(f(x)\\) and \\(\\diff{x}f(x)\\) makes it somewhat difficult to visualize the relationship between \\(f(x)\\) and \\(\\diff{x}f(x)\\). Let’s explore a non-standard way to visualize \\(\\diff{x}f(x)\\) that can be shown in the same graphics frame as the graph of \\(f(x)\\). Perhaps this non-standard visualization will give you a better way to understand slope functions. If so, good. The ultimate benefit of a way to show \\(\\diff{x} f(x)\\) and \\(f(x)\\) in the same frame will come when we introduce the operation of anti-differentiation. Recall that the basic model of change in Calculus is the straight-line function \\(\\line(x) \\equiv a x + b\\). The slope \\(a\\) of \\(\\line(x)\\) tells how the output changes for a unit change in input. In differentiation, we approximate the mother function \\(f(x)\\) as a series of local line segments. extract the slope of each line segment as the value of the slope function at each input \\(x\\). Figure 16.3 shows the segment by segment approximation around each of several input values (marked in green). The slope function visualization is constructed by throwing away the vertical offset of each of the line segments and plotting them horizontally adjacent to one another. Figure 16.3: A function \\(f(x)\\) shown along with the tangent line segment touching \\(f()\\) at each of the green points. For the slope function visualization, the tangent line segments are moved down to the horizontal axis. Figure 16.4 shows several examples of the slope function visualization. Figure 16.4: Slope-function visualizations of several naked modeling functions. Yes, “minification” is a word!↩︎ Air pressure at sea level is about 100 kiloPascal.↩︎ "],["computing-derivs.html", "Chapter 17 Computing derivatives 17.1 A function from a function 17.2 Finite differencing 17.3 The slope-function operator 17.4 Symbolic differentiation", " Chapter 17 Computing derivatives To differentiate a function \\(g(x)\\) means simply to produce the corresponding function \\(\\partial_t g(x)\\). This is often called “finding the derivative,” language that resonates with the high-school algebra task of “finding \\(x\\).” Rather than conjuring an image of search high and low for a missing function, it’s more realistic to say, “compute the derivative.” In this chapter we’ll introduce two ways of computing a derivative. For simplicity we will write \\(x\\) for the with-respect-to-variable, although in practice you might be using \\(t\\) or \\(z\\) or something else. Symbolic differentiation, which uses a set of re-writing rules Finite-differencing, which is based directly on the differencing operator \\({\\cal D_x}\\) In the days when functions were always presented using formulas, symbolic differentiation was usually the only method taught. Nowadays, when functions are just as likely to be described using data and an algorithm, finite-differencing provides the practical approach. 17.1 A function from a function Recall that the goal of differentiation is to make a function out of an already known function. We’ll call the already known function \\(g(x)\\). In Chapter (change-relationships) we’ve outlined the properties that the new function should have and gave a nice naming convention, \\(\\partial_x g(x)\\) that shows where the new function comes from. In this section we’ll put that aside and focus on the question of what it means to “make a function.” When mathematics is done with paper and pencil, “making a function” is a matter of writing a formula, such as \\(x^2 \\sin(x) + 3\\) and sometimes giving a name to the formula, e.g. \\(h(x) \\equiv x^2 \\sin(x) + 3\\). We are essentially writing something down that will make sense when viewed by another person trained in the conventions of mathematical notation. For a computer, on the other hand, a function is a definite kind of thing. We “make a function” by creating that kind of thing and, usually, giving it a name. We use (or “evaluate”) a function by using a definite syntax, which in R involves the use of parentheses, for instance name(input). The computer language itself provides specific means to define a new function. In R/mosaic, you first construct a tilde expression naming the function inputs (right side of the tilde) and specifying the algorithm of that function (left side of the tilde), as with this formula: f_description &lt;- x^2 * sin(x) + 3 ~ x On its own, f_description cannot be used like a function because it was constructed as something else: a tilde expression. Trying to use f_description in the way one uses a function produces an error. f_description(2) ## Error in f_description(2): could not find function &quot;f_description&quot; In between the tilde expression and the final result—a function—is software that translates from tilde-expressions into functions: f &lt;- makeFun(f_description) The new creation, f() can now be used like any other function, e.g. f(2) ## [1] 6.63719 Down deep inside, makeFun() uses a more basic function-creation syntax which looks like this function(x) {x^2 * sin(x) + 3} ## function(x) {x^2 * sin(x) + 3} You can see all the same information that was in the tilde description, just arranged differently. Almost every computer language provides something like function. There workings are advanced technology and essentially impossible to describe in much the same way as the workings of a transistor or a COVID vaccine are known only to specialists. In the same spirit as makeFun(), which translates a tilde-expression into the corresponding function, in R/mosaic you have D() which takes a tilde expression and translates it into the derivative of the function described. For example: D(f_description) ## function (x) ## 2 * x * sin(x) + x^2 * cos(x) Exercise 17.1 (tilde-function.Rmd) The most common programming pattern in the R/mosaic calculus commands is: Operator(tilde_expression, [optional details]) Some operators: slice_plot(), contour_plot, make_Fun(), D(), antiD(), findZeros() For each of the R/mosaic expressions, determine which kind of thing is being created. Feel free to run the expressions in a SANDBOX. Question A makeFun(a*x - b ~ x) a function of x ☹︎ Fair enough. But the function also has arguments a and b a function of x, a, and b ✓ a tilde expression ☹︎ The tilde expression is the input to the operator. The operator translates the tilde expression into something else. a plot ☹︎ a data frame ☹︎ an error ☹︎ Question B D(a*x - b ~ x) a function of a ☹︎ a function of x, a, and b ✓ a tilde expression ☹︎ a plot ☹︎ a data frame ☹︎ an error ☹︎ Question C antiD(a*x - b ~ x) a function of a ☹︎ a function of x, a, and b ✓ a tilde expression ☹︎ a plot ☹︎ a data frame ☹︎ an error ☹︎ Question D slice_plot(a*x - b ~ x, domain(x=c(0,5))) a function of x ☹︎ a function of x, a, and b ☹︎ a tilde expression ☹︎ a plot ☹︎ The expression is intended to make a plot, but it doesn’t work. Specific numerical values would need to be provided for a and b. a data frame ☹︎ an error ✓ Question E f &lt;- makeFun(a*x + b ~ x, a=2, b=-4) slice_plot(f(x) ~ x, domain(x=c(0,5))) a function of x ☹︎ a function of x, a, and b ☹︎ a tilde expression ☹︎ a plot ✓ This works because there are specific values provided for the a and b parameters. a data frame ☹︎ an error ☹︎ Question F findZeros(a*x - b ~ x, domain(x=c(0,5))) a function of x ☹︎ a function of x, a, and b ☹︎ a tilde expression ☹︎ a plot ☹︎ The expression is intended to make a data frame, but it doesn’t work. Specific numerical values would need to be provided for a and b. a data frame ☹︎ an error ✓ Question G a*x - b ~ x a function of x ☹︎ a function of x, a, and b ☹︎ a tilde expression ✓ a plot ☹︎ The expression is intended to make a plot, but it doesn’t work. Specific numerical values would need to be provided for a and b. a data frame ☹︎ an error ☹︎ Question H f &lt;- makeFun(a*x + b ~ x, a=2, b=-4) findZeros(f(x) ~ x) a function of x ☹︎ a function of x, a, and b ☹︎ a tilde expression ☹︎ a plot ☹︎ a data frame ✓ an error ☹︎ Question I Suppose you create a function in the usual way, e.g. f &lt;- makeFun(a*x + b ~ x, a=2, b=-4). Which of the following will plot a straight-line function with a slope of 5. slice_plot(f(x) ~ x, domain(x=c(-5, 5))) ☹︎ The default value of a is 2, so the line would have a slope of 2. slice_plot(f(x, b=2), domain(x=c(-5, 5)) ☹︎ It’s a that is the slope parameter. slice_plot(f(x, a=2), domain(x=c(-5, 5)) ✓ 17.2 Finite differencing You can use the definition of the slope function \\[{\\cal D}_x f(x) = \\frac{f(x+0.1) - f(x)}{0.1}\\] to create an approximation to the derivative of any function. Like this: g &lt;- makeFun(sin(2*x)*(pnorm(x/3)-0.5) ~ x) dg &lt;- makeFun((g(x+0.1) - g(x))/0.1 ~ x) Whenever you calculate a derivative function, you should check against mistakes or other sources of error. For instance, whenever the derivative is zero, the original function should have an instantaneous slope of zero. Figure 17.1 shows a suitable plot for supporting this sort of check. zeros_of_dg &lt;- findZeros(dg(x) ~ x, xlim=c(-5,5)) slice_plot(g(x) ~ x, domain(x=c(-5,5)), npts=500) %&gt;% slice_plot(dg(x) ~ x, color=&quot;red&quot;, npts=500) %&gt;% gf_hline(yintercept = ~ 0, color = &quot;orange&quot;, size=2, alpha=0.2) %&gt;% gf_vline(xintercept = ~ x, data=zeros_of_dg, color=&quot;blue&quot;) Figure 17.1: A check that zero-crossings (blue) of the derivative function (red) correspond to inputs where the original function is flat (black). Look very closely at Figure 17.1, particularly at the places where the blue vertical markers cross the function \\(g(x)\\) (black). They should cross exactly at the flat zone, but they are a little shifted to the left. That’s the sense in which the finite-difference approach gives an approximation. This left-shift stems from the use of 0.1 in the definition of the zero function. Use a smaller value, say 0.01 or 0.001, and you won’t be able to see the shift at all. In modeling work, there’s nothing wrong with an approximation so long as it is good enough for your purposes. We picked the value 0.1 for our definition of the slope function because it works very well with the naked modeling functions. Here, “very well” means you can’t easily see in the graph any deviation compared the the exact derivative. When a calculation can be done exactly (without outrageous effort) it certainly makes sense to use the exact method. However: It’s useful to have an easy, approximate method always at hand. This lets you check the results of other methods against the possibility of some blunder or mis-conception. The slope function approach to differentiation is certainly easy, and if you think the approximation isn’t good enough, then instead of 0.1 use something smaller. (Chapter 20 discusses how small is too small.) The computer makes it practical to employ the slope function as a useful approximation to the derivative. There are many other mathematical methods that the computer has made feasible, for instance the methods of machine learning. These methods create functions that sometimes cannot be handled by the traditional (“exact”) methods of differentiation. Exercise 17.2 (check-h) Put this in Chapter 20. An exercise given a function \\(g(x)\\) for which 0.1 isn’t good enough. Vary \\(h\\) by factors of 10 until a change by 10 doesn’t make any discernable difference. 17.3 The slope-function operator Take a look at the statement we used to construct the slope function of g(): dg &lt;- makeFun((g(x+0.1) - g(x))/0.1 ~ x) There’s almost nothing about this statement that has anything to do with the specifics of how we defined g(); we could have used any \\(g()\\). The “almost” in the previous sentence is about the choice of 0.1, which isn’t guaranteed to be small enough. It would be convenient to have an operator that automates the process of constructing a slope function. This is a programming task and in that sense beyond the scope of this course. Still, it’s a good idea to get in the habit of reading programming code. So here goes … creating a slopeFun() operator: Remember the function(){} syntax for creating an operator. (If I were speaking to experienced programmers, I would have said “function” instead of “operator.” ) We’re going to use a tilde expression as the input to slopeFun(). This is how the other R/mosaic operators work. That will be easier to the user and will also give us access to those other operators if we need them in writing slopeFun(). The object returned by the slopeFun() operator will be, of course, a function. We’ve been using makeFun() to make our mathematical functions, so expect to see that in the code for slopeFun(). There’s that nuisance about using 0.1 and whether that is small enough. So let’s use an h argument that we can change when needed. slopeFun &lt;- function(tilde, h=0.1) { #two arguments, one with a default value g &lt;- makeFun(tilde) # Turn the tilde expression into a function makeFun((g(x + h) - g(x))/h ~ x, h=h) # just like before, with h instead of 0.1 } Figure 17.2 shows the results of a quick check of whether the function works and whether h=0.1 is small enough. dx_sin &lt;- slopeFun(sin(x) ~ x) slice_plot(dx_sin(x, h = 0.00000000001) ~ x, domain(x=c(-5,5)), size=2) %&gt;% slice_plot(dx_sin(x, h=0.001) ~ x, color=&quot;red&quot;) Figure 17.2: Checking whether the homemade slopeFun() operator works. ::: {.scaffolding} You can decide for yourself whether the red and black curves in Figure 17.2 are similar enough for your purposes. Even better, do some exploring yourself in a SANDBOX. You’ll have to copy and paste into your sandbox both the code defining slopeFun() and the graphics statements. Start by replacing dx_sin(x, h=0.1) by dx_sin(x, h=0.0001) Exercise 17.3 (h-too-small) On the computer (and in using data), you can set \\(h\\) too small in the slope function. This will become obvious in the graph when \\(h\\) is too small. Start adding zeros in sin(x, h=0.0001) until you see the problem. Question A Which of these values for h is the smallest you can go before the problems of too-small h start showing up? h=0.00001 ☹︎ h=0.00000001 ☹︎ h=0.00000000001 ✓ h=0.00000000000001 ☹︎ Not a bad choice, but if you look closely you’ll see little wobbles in the curve. h=0.000000000000000001 ☹︎ In practice, you won’t need to use slopeFun(). You’ll use D() instead, which gives the “exact” results whenever it can. 17.4 Symbolic differentiation Symbolic differentiation is the process of taking a formula and translating it to a new formula according to certain patterns or rules. Each rule is ultimately derived from the definition of the slope function and the differencing operator. As you recall, the differencing operator \\(\\diff{x}\\) turns a function into its slope function \\[\\diff{x} f(x) \\equiv \\frac{f(x+h) - f(x)}{h}\\] Let’s look at one where we already know the result: The straight line function \\(\\line(x) \\equiv a x + b\\) has a slope function that is constant: \\(\\diff{x}\\line(x) = a\\) \\[\\diff{x}\\line(x) = \\frac{a (x+h) + b - (a x + b)}{h} = \\frac{ah}{h} = a\\] The derivative is the slope function with \\(h\\) made as small as possible. It’s tempting to think of this as \\(h = 0\\), but that would imply dividing by zero in the differencing operator. Being cautious about this, we write that differentiation is differencing with \\(h \\rightarrow 0\\), or \\[\\partial_x \\line(x) \\equiv \\lim_{h\\rightarrow 0} \\frac{\\line(x+h) - \\line(x)}{h} = \\lim_{h\\rightarrow 0$ \\frac{a h}{h} = a\\] This derivation is unarguably correct for any non-zero \\(h\\). This short derivation gives us a basic differentiation rule which we can divide into 3 special cases. Line rule: \\(\\partial_x ax + b = a\\) \\(\\partial_x ax = a\\) \\(\\partial_x b = 0\\) \\(\\partial_x x = 1\\) Remember that \\(\\partial_x f(x)\\) for any \\(f(x)\\) is always a function. The functions associated with the line rule are all constant functions, meaning the output doesn’t depend on the input. Only for the \\(\\line()\\) function and its three special cases is the derivative a constant function. And \\(\\line()\\) is the only function for which the \\(h\\) in the differencing operator disappears on its own. For instance, consider \\(g(x) \\equiv x^2\\): \\[\\partial_x [x^2] = \\lim_{h\\rightarrow 0}\\frac{(x+h)^2 - x^2}{h} = \\lim_{h\\rightarrow 0}\\frac{(x^2 + 2 x h + h^2) - x^2}{h} = \\lim_{h\\rightarrow 0}\\frac{2 x h + h^2}{h} = \\lim_{h\\rightarrow 0} [2x + h]\\] It’s accepted that the limit of a sum is the sum of the limits. Also, the limit of something not involving \\(h\\) is just that thing: for instance \\(\\lim_{h\\rightarrow 0}2x = 2x\\). \\[\\partial_x [x^2] = 2x + \\lim_{h\\rightarrow 0}h = 2x\\] We’ll write this as another differentiation rule. Quadratic rule: \\(\\partial_x [x^2] = 2x\\) [When introducing product rule …] point out that \\(\\partial_x x^2 \\neq (\\partial_x x)(\\partial_x x) = 1\\) Let’s take on \\(h(x) \\equiv e^x\\): \\[\\partial_x e^x = \\lim_{h\\rightarrow 0}\\frac{e^{x+h} - e^x}{h} = e^x \\lim_{h\\rightarrow 0}\\left[\\frac{e^h - 1}{h}\\right]\\] At a glance, it can be hard to know what to make of \\(\\lim_{h\\rightarrow 0} (e^h-1)/h\\). Setting \\(h=0\\) in the denominator is perfectly legitimate and gives \\(e^0 - 1 = 0\\). But that still leaves the \\(h\\) in the numerator. Still, for any non-zero \\(h\\), the division is legitimate, so let’s see what happens as \\(h \\longarrow 0\\): f &lt;- makeFun((exp(h) - 1)/h ~ h) f(0.1) ## [1] 1.051709 f(0.01) ## [1] 1.005017 f(0.001) ## [1] 1.0005 f(0.0001) ## [1] 1.00005 f(0.0000001) ## [1] 1 f(0.0000000001) ## [1] 1 Setting \\(h\\) exactly to zero, however, won’t work: it produces NaN. f(0) ## [1] NaN Since \\(\\lim_{h\\rightarrow 0} (e^h-1)/h = 1\\), we have Exponentiation rule: \\(\\partial_x e^x = e^x\\) [Under taylor series, show that \\(\\frac{e^h - 1}{h} \\rightarrow 0\\).] Still another example: the reciprocal function, written equivalently as \\(1/x\\) or \\(x^{-1}\\) \\[\\partial x^{-1} = \\lim_{h\\rightarrow 0}\\frac{1/(x+h) - 1/x}{h} = \\lim_{h\\rightarrow 0}\\frac{x - x+h}{x(x+h)h} = -\\lim_{h\\rightarrow 0}\\frac{h}{x(x+h)h} = -\\lim_{h\\rightarrow 0}\\frac{1}{x^2 + hx}\\] So long as \\(x \\neq 0\\), there is no divide-by-zero problem, but let’s see what the computer thinks: g &lt;- makeFun(-1/(x^2 + h*x) ~ h, x=10) g(0.1) ## [1] -0.00990099 g(0.01) ## [1] -0.00999001 g(0.001) ## [1] -0.009999 g(0.0001) ## [1] -0.0099999 g(0.0000001) ## [1] -0.01 g(0.0000000001) ## [1] -0.01 g(0) ## [1] -0.01 Setting \\(h\\) to zero in the last expression gives another differentiation rule: Reciprocal rule: \\(\\partial_x \\frac{1}{x} = -\\frac{1}{x^2}\\) We’ll save for later the derivation of the derivatives of the other naked modeling functions, but note that the hump function is defined to be the derivative of the sigmoidal function. Name \\(f(x)\\) \\(\\partial_x f(x)\\) exponential \\(e^x\\) \\(e^x\\) logarithm \\(\\ln(x)\\) \\(1/x\\) sinusoid \\(\\sin(x)\\) \\(\\cos(x)\\) square \\(x^2\\) \\(2x\\) proportional \\(x\\) \\(1\\) reciprocal \\(1/x\\) or \\(x^{-1}\\) \\(-1/x^2\\) hump \\(\\dnorm(x)\\) \\(-x \\dnorm(x)\\) sigmoid \\(\\pnorm(x)\\) \\(\\dnorm(x)\\) When doing the basic modeling functions, show that the derivative of the cosine is -sin. Use \\(\\partial_x sin(x) = sin(x + \\pi/2)\\) and apply the scaling rule to that. Also, derive \\(\\partial_x x^p = \\partial_x e^{p\\ln(x)} = e^{p\\ln(x)} \\times \\frac{p}{x} = \\frac{p}{x} x^p = p\\, x^{p-1}\\) Exercise 17.4 (finch-trim-kayak) Is this the right placement? The R command defines a new operator named Diff() which implements the differencing operator \\(\\cal D_x\\) for functions with one input. Diff &lt;- function(f, h=0.001) { function(x) { (f(x + h) - f(x)) / h } } Open an R sandbox and copy the definition of Diff() into it. As an example of the use of Diff(), here is R code that defines a function f() and finds \\({\\cal D}_x f()\\), calling it D_f(). Then a slice plot is of both f() and D_f(). f &lt;- makeFun(sqrt(exp(x)) - x^2 ~ x) D_f &lt;- Diff(f) slice_plot(f(x) ~ x, domain(x=c(0, 5))) %&gt;% slice_plot(D_f(x) ~ x, color = &quot;red&quot;) For each of the following functions, write a brief comparison of the function to it’s differenced version. You can combine phrases such as “same shape,” “different shape. larger in amplitude,” “smaller in amplitude,” “same period,” “shorter period,” “longer period,” or whatever seems appropriate. For instance, for the original example in the sandbox, a reasonable comparison might be, “f() is concave down but Diff(f) is concave up.” Essay question tmp-24: A. For the function \\(f(x) \\equiv 3 x\\), compare \\(f()\\) to \\(\\cal D_x f\\). Essay question tmp-25: B. For the function \\(f(x) \\equiv x^2\\), compare \\(f()\\) to \\(\\cal D_x f\\). Essay question tmp-26: C. For the function \\(f(x) \\equiv \\exp(x)\\), compare \\(f()\\) to \\(\\cal D_x f\\). Essay question tmp-27: D. For the function \\(f(x) \\equiv \\exp(-0.3 x)\\), compare \\(f()\\) to \\(\\cal D_x f\\). Essay question tmp-28: E. For the function \\(f(x) \\equiv \\sin(x)\\), compare \\(f()\\) to \\(\\cal D_x f\\). Essay question tmp-29: F. For the function \\(f(x) \\equiv \\sin(2 \\pi x)\\), compare \\(f()\\) to \\(\\cal D_x f\\)). Essay question tmp-30: G. For the function \\(f(x) \\equiv \\sin(\\frac{2 \\pi}{20} x)\\), compare \\(f()\\) to \\(\\cal D_x f\\)). "],["convexity-and-curvature.html", "Chapter 18 Convexity and curvature 18.1 Concavity 18.2 Curvature", " Chapter 18 Convexity and curvature Looking locally at the graph of a function our eyes immediately register the slope. A glance shows whether the slope is positive or negative. Comparing the slopes at two locales is also an automatic visual task: most people have little difficulty saying which slope is steeper. One consequence of this is our ability to perform a task visually: Tangent line: We can recognize whether a line that touches the graph at a point is tangent to the graph. Exercise 18.1 (Positive or negative) Question A Glance at the graph. In which boxes the slope is negative?     A, B, C ☹︎        B, C, D ☹︎        A, C, D ✓ Exercise 18.2 (relative-slope) Question B Consider the slope of the function in the domains marked by the boxes. What is the order of boxes from least steep to steepest?     A, B, C ☹︎        C, A, B ☹︎        A, C, B ✓        none of these ☹︎ Exercise 18.3 (tangents-to-curves) Question C Which of the line segments is tangent to the curve at the point marked with a dot?     A ☹︎        B ☹︎        C ☹︎        all of them ✓        none of them ☹︎ Question D Which of the line segments is tangent to the curve at the point marked with a dot?     A ✓        B ☹︎ too shallow        C ☹︎ too steep        all of them ☹︎        none of them ☹︎ Finding a numerical value for the slope is not an automatic process. We need to do some arithmetic, computing rise over run. Or, in the language of calculus, we can calculate the slope by evaluating the derivative function. Other aspects of functions are also readily discerned from a glance at the function graph. Concavity: We can tell within each locale whether the function is concave down, concave up, or not concave. Curvature: Generalizing the tangent line capability a bit, we can do a pretty good job of eyeballing the tangent circle recognizing whether a circle has much too large or much too small a radius.. Smoothness: We can distinguish smooth functions from non-smooth ones. Or, as you will see, there are some kinds of smoothness that we can discern and others that are not apparent to the eye. This chapter is about how to quantify these properties. It turns out that this is naturally done by calculating derivatives. (In the case of smoothness, continuity of the derivative function. So do continuity before smoothness.) The following exercises are simply meant to test your visual acuity in spotting concavity, tangency, and smoothness. Exercise 18.4 (concave-A) Question E In which of the boxes is the function concave up?     A and E ✓        B and D ☹︎        C and D ☹︎ Question F In which boxes is the function smooth? A and B ☹︎ B and C ☹︎ A and C ✓ none of them ☹︎ all of them ☹︎ Question G In which boxes is the function smooth? A and B ☹︎ B and C ☹︎ A and C ☹︎ none of them ☹︎ all of them ✓ Question H In which boxes is the function smooth?     A ✓        B ☹︎        neither of them ☹︎        both of them ☹︎ 18.1 Concavity Change in the slope 18.2 Curvature Orthogonal to tangent Tangent circle to function. Graphics frame. We’re also pretty good at eyeballing the radius of curvature. This can be calculated from the first and second derivatives. The radius of curvature operator is \\[{\\cal K} f(x) \\equiv \\frac{\\left|\\partial_{xx} f(x)\\right|}{\\left|1 + \\left(\\strut\\partial_x f(x)\\right)^2\\right|^{3/2}}\\] Exercise 18.5 (curvature-dimension) Show that the dimension of the curvature only makes sense if the \\([x]\\) and \\([f(x)]\\) are the same. "],["cont-and-smooth.html", "Chapter 19 Continuity and smoothness 19.1 Continuity 19.2 Smoothness 19.3 Doesn’t exist? 19.4 Piecewise functions 19.5 Continuity 19.6 Differentiability", " Chapter 19 Continuity and smoothness You’ve seen how various properties of a functions—whether it is monotonic, how it slopes, whether it is concave up or down (or not at all), curvature, etc.—can be related to the first and second derivatives of the function. It’s time to introduce two new ways of describing functions that can be useful for determining whether a given function is fit for the purpose intended for it. These are continuity and smoothness. 19.1 Continuity The intuition behind continuity is simple: If you can draw the graph of a function without lifting the pencil from the paper, the graph is continuous. Continuity can be an important attribute of a modeling function. Often, we are modeling phenomena where a small change in input is expected to produce a small change in output. For instance, if your income changes by one penny, you would expect your lifestyle not to change by much. If the temperature of an oven changes by 1 degree, you don’t expect the quality of the cake you are baking to change in any noticeable way. All of our basic modeling functions are continuous over their entire input domain (with one exception). To illustrate discontinuity we’ll consider piecewise functions, as introduced in Chapter 13. The Heaviside function, graphed in Figure ?? is discontinuous. Drawing the graph of the Heaviside function \\(H(x)\\) involves lifting the pencil at \\(x=0\\). In contrast, the piecewise ramp function (Figure ?? is continuous, you don’t need to lift the pencil from the paper in order to draw the ramp function. Imagine that you were using a Heaviside function, say \\(H(W-20)\\), as a model of plant growth as a function of the amount of water (in cc) provided each day. The model implies that if you provide 20.001 cc of water, the plant will thrive. But if you are stingy, and provide only 19.999 cc of water, the plant will die. In other words, a very small change in the input can lead to a large change in the output. Common sense suggests that a change of 0.002 cc in the amount of water—that’s a small fraction of a drop, 2 cubic millimeters of volume, is not going to lead to a qualitative change in output. So you might prefer to use a sigmoidal function as your model rather than a Heaviside function. On the other hand, sometimes a very small change in input does lead to a large change in output. For instance, a model of the hardness of water as a function of temperature sensibly would include a discontinuity at \\(32^\\circ\\)F, the temperature at which water turns to ice. One of author Charles Dicken’s famous characters, Mr. Macawber, described the relationship between income, expenditure, and happiness this way: \"Annual income 20 pounds, annual expenditure 19 [pounds] 19 [shillings] and six [pence], result happiness. Annual income 20 pounds, annual expenditure 20 pounds ought and six, result misery.\" Macawber was referring to the common situation in pre-20th century England of putting debtors in prison, regardless of the size of their debt. Macawber statement suggests he would model happiness as a Heaviside function \\(H(\\text{income}- \\text{expenditure})\\). Whenever the output of a function is a yes-or-no value, you can anticipate that a model will involve a discontinuous function. 19.2 Smoothness Smoothness is a different concept than continuity, although the two are related. Most simply, any discontinuous function is not smooth at any input where a discontinuity occurs. But even the continuous ramp function is not smooth at the start of the ramp. Intuitively, imagine you were sliding your hand along the ramp function. You would feel the crease at \\(x=0\\). A function is not smooth if the derivative of that function is discontinuous. For instance, the derivative of the ramp function is the Heaviside function, so the ramp is not smooth at \\(x=0\\). All of our basic modeling functions (with one exception!) are smooth everywhere in their domain. In particular, the derivatives of the basic modeling functions are continuous, as are the second derivative, third derivative, and so on down the line. Such functions are called C-infinity, written \\(C^\\infty\\). The superscript \\(\\infty\\) means that every order of derivative is continuous. For piecewise functions, it can be useful to consider other orders of smoothness. For example \\(C^0\\) means that the function is continuous but its derivative is not, as with the ramp function. Figure 19.1 shows a \\(C^1\\) function, which has a continuous first derivative but a discontinuous second derivative. Figure 19.1: A function whose derivative is the ramp function (hence continous) and whose second derivative is the Heaviside function (discontinous). Since the first derivative is continuous, this function has \\(C^1\\) smoothness. You cannot tell from the plot that the second derivative is discontinuous. But if you were in a plane flying along that trajectory, you would feel a jerk as you crossed \\(x=0\\). 19.3 Doesn’t exist? Recall the logical path that led us to the idea of the derivative of a function. We started with the differencing operator, which takes as input a function and a “small” value of \\(h\\): \\[{\\cal D}_x f(x) \\equiv \\frac{f(x+h) - f(x)}{h}\\] Then, through algebraic manipulation and numerical experiments we found that, once \\(h\\) is small enough, the graph of \\({\\cal D}_x f(x)\\) does not depend on \\(h\\). And so we defined a function \\(\\partial_x f(x)\\) where \\(h\\) doesn’t play a role, writing \\(\\lim_{h\\rightarrow 0}\\) to remember the ancestors, now departed from the scene: \\[\\partial_x f(x) \\equiv \\lim_{h\\rightarrow 0} \\frac{f(x+h) - f(x)}{h}\\] Conveniently, we found that the derivatives of the naked modeling functions can be written in terms of the naked modeling functions without making any reference to \\(h\\). With discontinuous functions, we have no such luck. Here’s what happens if we compute \\({\\cal D}_x H(x)\\), the derivative of the Heaviside function, for smaller and smaller \\(h\\). H &lt;- makeFun(ifelse(x &gt;=0, 1, 0) ~ x) DH01 &lt;- makeFun((H(x + 0.01) - H(x))/0.01 ~ x) DH001 &lt;- makeFun((H(x + 0.001) - H(x))/0.001 ~ x) DH0001 &lt;- makeFun((H(x + 0.0001) - H(x))/0.0001 ~ x) slice_plot(DH01(x) ~ x, domain(x=c(-0.02, 0.02)), npts=500, color=&quot;red&quot;) %&gt;% slice_plot(DH001(x) ~ x, color=&quot;green&quot;, npts=500, alpha=0.5) %&gt;% slice_plot(DH0001(x) ~ x, color=&quot;blue&quot;, npts=500, alpha=0.5) Differencing the Heaviside function produces very different functions depending on the value of \\(h\\). Since there is no convergence as \\(h\\) gets smaller, it’s fair to say that the Heaviside function does not have a derivative. Perhaps a more useful way to think of it is that the “derivative” of the Heaviside function at \\(x=0\\) is unaccountably large as \\(h\\rightarrow 0\\). We know that when a function has a large derivative, a small difference in the input will make a large difference in the output. This brings us back to the definition of discontinuous at the start of the chapter. So I like to think of the “derivative” of the Heaviside function as discontinuous. A strictly logical thinker would rebel at the conflict between the previous two paragraphs: The first saying that the Heaviside function does not have a derivative, the second saying that the derivative is discontinuous. The resolution is to point out that away from \\(x=0\\), the Heaviside function has a perfectly sensible derivative: \\(\\partial_x H(x) = 0\\) for \\(x\\neq 0\\). But there is no derivative at \\(x=0\\). [Deriv-3a] Understand the physical analogs of continuity and smoothness. [Deriv-3b] Determine if a function is continuous by thinking about the “pencil stays on paper” technique [Deriv-3c] Understand smooth of degree 1 as “Function is continuous, derivative is continuous [Deriv-3d] Understand smooth of degree as “Smooth of degree and the derivative is continuous” [Fun-4-b-4e] Identify “division by zero” as a source of interruption in the domain of a function. [[??? Redefine the function to avoid the disruption.]] Now that you have a concept of the derivative of a function, we can discuss some of the terms that are used to describe functions in general. 19.4 Piecewise functions Our foil for showing smoothness and continuity. See section in Fun-modeling.Rmd and connect to that. 19.5 Continuity Lift the pen. 19.6 Differentiability We want the derivative to exist no matter the details of how we define the derivative. \\(\\partial_x f(x) \\equiv \\lim_{h\\rightarrow 0} \\frac{f(x+h) - f(x)}{h}\\) \\(\\partial_x f(x) \\equiv \\lim_{h\\rightarrow 0} \\frac{f(x) - f(x-h)}{h}\\) \\(\\partial_x f(x) \\equiv \\lim_{h\\rightarrow 0} \\frac{f(x+h) - f(x-h)}{2 h}\\) Exercise 19.1 (spider-tug-gloves) Draw the graph of a function from your imagination over the domain \\(x \\in [-5, 5]\\). The function should be continuous everywhere *except at \\(x = -2, 1, 3\\). Draw the graph of a function from your imagination over the domain \\(x \\in [-5,5]\\). The function should be continuous everywhere in \\([-5,5]\\). It should also have a derivative everywhere except at \\(x = -2, 1, 3\\). Exercise 19.2 (moose-hears-door) For the sketched functions below, decide what level of smoothness best describes the function. (No tricks in the drawings. Where a function looks like it’s broken–that is, the function locally has a V-shape or a \\(\\Lambda\\)-shape–take that at face value. Question A What’s the smoothness level of function A(x)? (Hint: A quadratic function has a first derivative that changes with x but a second derivative that is constant for all x.)     discontinuous ☹︎        \\(C^0\\) ☹︎        \\(C^1\\) ✓        \\(C^2\\) or higher ☹︎ Question B What’s the smoothness level of function B(x)?     discontinuous ✓        \\(C^0\\) ☹︎        \\(C^1\\) ☹︎        \\(C^2\\) or higher ☹︎ Question C What’s the smoothness level of function C(x)?     discontinuous ☹︎        \\(C^0\\) ✓        \\(C^1\\) ☹︎        \\(C^2\\) or higher ☹︎ Question D What’s the smoothness level of function D(x)?     discontinuous ☹︎        \\(C^0\\) ☹︎        \\(C^1\\) ☹︎        \\(C^2\\) or higher ✓ "],["evanescent-h.html", "Chapter 20 Evanescent h 20.1 Role of h 20.2 Derivatives of linear combinations 20.3 Derivatives of the basic modeling functions", " Chapter 20 Evanescent h Our goal in this chapter is to motivate the differentiation rules presented in Chapter 17 for the naked modeling functions. Recall that the slope-function operator can be written as a ratio of rise-over-run: \\[{\\cal D}_t f(t) \\equiv \\frac{f(t+h) - f(t)}{h}\\] where \\(h\\) is the length of the “run.” The idea of the instantaneous slope function is to make \\(h\\) as small as possible. In the very early days of calculus, the vanishing \\(h\\) was described as “evanescent.” (Dictionary definition: “tending to vanish like vapor.”21) Another good image of \\(h\\) becoming as small as possible comes from the same University of Oxford mathematician whose poem The Jabberwocky we considered earlier. In Alice in Wonderland, Dodgson introduced the character of the Cheshire Cat. Figure 20.1: Vanishing \\(h\\) in the form of the Chesire Cat from Alice in Wonderland. “All right,” said the Cat; and this time it vanished quite slowly, beginning with the end of the tail, and ending with the grin, which remained some time after the rest of it had gone. “Well! I’ve often seen a cat without a grin,” thought Alice; “but a grin without a cat! It’s the most curious thing I ever saw in my life!” Start our story with two of the basic modeling functions that, like the characters from Alice in Wonderland, have considerable “personality”: the sinusoid (sin()) and the sigmoid (pnorm()). Figure 20.2: The naked sinusoid and sigmoidal functions. A vertical blue line has been added to mark the input \\(t=0\\) The computer can easily construct the slope functions for the sinusoid and sigmoid, which we’ll call Dsin() and Dsigma() respectively. Dsin &lt;- makeFun(( sin(t+h) - sin(t))/h ~ t, h=0.1) Dsigma &lt;- makeFun((pnorm(t+h) - pnorm(t))/h ~ t, h=0.1) In the tilde expression handed to makeFun(), we’ve identified t as the name of the input and given a “small” default value to the h parameter. But R recognizes that both Dsin() and Dsigma() are functions of two variables, t and h, as you can see in the parenthesized argument list for the functions. Dsin ## function (t, h = 0.1) ## (sin(t + h) - sin(t))/h Dsigma ## function (t, h = 0.1) ## (pnorm(t + h) - pnorm(t))/h This is a nuisance, since when using the slope functions we will need always to think about h, a number that we’d like to describe simply as “small,” but for which we always need to provide a numerical value. A surprisingly important question in the development of calculus is, “What can we do to avoid the nuisance?” To find out, let’s look at Dsin() and Dsigma() for a range of values of h, as in Figure 20.3. Figure 20.3: The slope functions of the sinusoid and sigmoid. Each curve shows the slope function for a particular numerical choice of h. Both panels show \\(h=2, 1, 0.5, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001\\). Some observations from this numerical experiment: As \\(h\\) gets very small, the slope function doesn’t depend on the exact value of \\(h\\). This will provide a way for us, eventually, to discard \\(h\\) so that the slope function will not need an \\(h\\) argument. For small \\(h\\), we have \\({\\cal D}_t \\sin(t) = \\sin(t + \\pi/2) = \\cos(t)\\). That is, taking the slope function of a sinusoid gives another sinusoid, shifted left by \\(\\pi/2\\) from the original. Or, in plain words, for small \\(h\\)H the cosine is the slope function of the sine. For small \\(h\\), we have \\({\\cal D}_t \\text{pnorm}(t) = \\text{dnorm(t)}\\). That is, for small \\(h\\) the hump function is the slope function of the sigmoid function. You can confirm these last two statements by comparison with the original functions, especially the alignment of the peaks of the slope functions with respect to the peak of the sinusoid and the half-way point of the sigmoid. Here you use \\(t\\) as the name of the input and \\(\\partial_t\\) as the notation for differentiation. Previously in this block you used \\(x\\) as the input name and \\(\\partial_x\\) for differentiation. Are they the same? Mathematically, the name of the input makes no difference whatsoever. We could call it \\(x\\) or \\(t\\) or \\(y\\) or Josephina. What’s important is that the name be used consistently on the left and right sides of \\(\\equiv\\), and that the derivative symbol \\(\\partial\\) has a subscript that identifies the with-respect-to input. All these are the same statement mathematically: \\[\\partial_x\\, x = 1\\ \\ \\ \\ \\partial_t\\, t = 1\\ \\ \\ \\ \\partial_y\\, y = 1\\ \\ \\ \\ \\partial_\\text{Josephina} \\text{Josephina} = 1\\] Admittedly, the last one is hard to read. When we look at derivatives of functions of multiple variables we will need to be thoughtful about our choice of the with-respect-to input. But we want you to get used to seeing different input names used for differentiation. Now consider the slope functions of the logarithm and exponential functions. Figure 20.4: The slope functions of the logarithm and exponential. These numerical experiments with the logarithm and exponential functions are more evidence that, as \\(h\\) gets small, the slope function doesn’t depend on \\(h\\). And, we find that: For small \\(h\\), the slope function of the logarithm is a power-law function: \\({\\cal D}_t \\ln(t) = \\frac{1}{t}\\). For small \\(h\\), the slope function of the exponential is the exponential itself: \\({\\cal D}_t e^x = e^x\\). You can confirm these by evaluating the slope function of the exponential at \\(t=0\\) and \\(t=1\\), and the slope function of the logarithm at \\(t= 2, 1, 1/2, 1/4, 1/8.\\) Such numerical experiments on the other naked modeling functions reveal the patterns presented in Chapter 17 20.1 Role of h In motivating differentiation of the naked modeling functions, we introduced a quantity \\(h\\) and then ignored it, saying that it doesn’t really matter so long as it is “small.” A reasonable person might wonder what “small” really means, and why we needed to introduce \\(h\\) in the first place if we were eventually going to ignore it. One reason is that “small” and “zero,” although related, are different. For example, refering to the slope functions Dsin() and Dsigma() that we created in an early example in this chapter, we see that setting \\(h\\) to zero does not get us where we need to be: Dsin(t=1, h=0) Dsigma(t=0, h=0) In NaN, you can hear the echo of your fourth-grade teacher reminding you that it is illegal to divide by zero. Think of evanescent \\(h\\) as the vapor in the definition of “evanescent”: “tending to vanish like vapor.” This vapor is the solvent in paint. You don’t want the solvent once the paint is on the wall; wet paint is a nuisance. But getting the paint from the can to the wall absolutely needs the solvent. We used the solvent \\(h\\) earlier in the chapter in the numerical experiments that led us to the derivatives of the naked modeling functions, for instance \\(\\partial_x e^x = e^x\\) or \\(\\partial_x \\sin(x) = \\cos(x)\\). Eventually, we’ll construct an \\(h\\)-free theory of differentiation, reducing the process to a set of algebraic rules in which \\(h\\) never appears. With this as our goal, let’s continue using \\(h\\) for a while to find some additional useful facts about derivatives. 20.2 Derivatives of linear combinations Linear combination is one of the ways in which we make new functions from existing functions. As you recall, linear combination involves scaling a function and adding the scaled functions. We can easily use \\(h\\) to show what is the result of differentiating a linear combination of functions. We’ll use \\(f(x)\\) and \\(g(x)\\) as the names that could stand for any function whatsoever. And we’ll let \\(b\\) be the name of a scalar. First, let’s figure out what is \\(\\partial_x\\, b f(x)\\), Going back to writing \\(\\partial_x\\) in terms of a slope function: \\[\\partial_x\\, b\\,f(x) = \\frac{b\\, f(x + h) - b\\,f(x)}{h}\\\\ \\ \\\\ = b \\frac{f(x+h) - f(x)}{h} = b\\, \\partial_x f(x)\\] In other words, if we know the derivative \\(\\partial_x\\, f(x)\\), we can easily find the derivative of any scaled version of \\(f()\\). Now consider the derivative of the sum of two functions, \\(f(x)\\) and \\(g(x)\\): \\[\\partial_x\\, \\left[f(x) + g(x)\\right] =\\\\ \\ \\\\ =\\frac{\\left[f(x + h) + g(x + h)\\right] - \\left[f(x) + g(x)\\right]}{h} = \\\\ \\ \\\\ = \\frac{\\left[f(x+h) -f(x)\\right] + \\left[g(x+h) - g(x)\\right]}{h}\\\\ \\ \\\\ = \\frac{\\left[f(x+h) -f(x)\\right]}{h} + \\frac{\\left[g(x+h) - g(x)\\right]}{h}\\\\ \\ \\\\ = \\partial_x\\, f(x) + \\partial_x\\, g(x)\\] Using these two rules together, we can differentiate any linear combination of functions in terms of the differentiated functions themselves: \\[\\partial_x\\ \\left[\\strut a_1 g_1(x) + a_2 g_2(x) + a_3 g_3(x) + \\cdots\\right] =\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\\\ \\ \\\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ a_1 \\partial_x\\, g_1(x) + a_2 \\partial_x\\, g_2(x) + a_3 \\partial_x\\, g_3(x) + \\cdots\\] Because of the way that \\(\\partial_x\\) can be “passed through” a linear combination, mathematicians say that differentiation is a linear operator. Consider this new fact about differentiation as a down payment on what will eventually become a complete theory telling us how to differentiate a product of two functions or the composition of two functions. In 1734, famous philosopher George Berkeley (1685-1753) published a long-titled book: The Analyst: A Discourse Addressed to an Infidel Mathematician: Wherein It Is Examined Whether the Object, Principles, and Inferences of the Modern Analysis Are More Distinctly Conceived, or More Evidently Deduced, Than Religious Mysteries and Points of Faith. In The Analyst, Berkeley took issue with the arguments of that time that it is legitimate to divide by \\(h\\) when, ultimately, \\(h\\) will be replaced by zero. Calling \\(h\\) an “evanescent increment,” he asked, “And what are these same evanescent Increments? They are neither finite Quantities nor Quantities infinitely small, nor yet nothing. May we not call them the ghosts of departed quantities?” Interesting, Berkeley believed that the ghost of \\(h\\) yielded correct results. His objection was that the framers of calculus had made two, canceling errors. “[B]y virtue of a two fold mistake you arrive, though not at science, yet truth.” Berkeley was saying that calculus had not yet been put on a solid logical foundation. It was to be more than a century after Berkeley’s death until this work was accomplished. Once accomplished, the results that had been claimed true all along were confirmed. Exercise 20.1 See tree harvesting in Diffs/tree-harvest.Rmd Exercise 20.2 Show that the derivative of dnorm(x) is - x *dnorm(x) by using the differencing operator with small \\(h\\). 20.3 Derivatives of the basic modeling functions The basic modeling functions are the same as the naked modeling functions, but with bare \\(x\\) replaced by \\(\\line(x)\\). By convention, there are different ways of writing \\(\\line(x)\\) for the different naked functions, for instance: $$       \\  \\ (x)      ( 2 (x-x_0)/P)\\ (x)      (k x)\\ x^2       (mx + b)^2\\ 1/x       1/(mx + b)\\ (x)       (a x + b)\\ $$ The general rule for the derivatives of the basic modeling functions is \\[\\partial f(\\line(x)) = \\partial_x \\line(x) \\times [\\partial_x f]\\left(\\strut\\line(x)\\right)\\] To illustrate: \\(\\partial_x e^{kx} = k\\, e^{kx}\\) \\(\\partial_x \\sin(2\\pi (x-x_0)/P) = \\frac{2\\pi}{P} \\sin(2\\pi (x-x_0)/P)\\) \\(\\partial_x (mx + b)^2 = m\\, 2 (m x + b) = 2 m^2 x + m^2 b\\) \\(\\partial_x \\frac{1}{mx + b} = - \\frac{m}{(mx + b)^2}\\) \\(\\partial_x \\ln(a x + b) = a/(ax+b)\\) \\(\\partial_x \\text(dnorm)(x, mn, sd) = - \\frac{x}{sd} \\text(dnorm)(x, mn, sd)\\) The notation for the basic hump and sigmoidal functions has two equivalent formulations: hump: \\(\\dnorm\\left(\\frac{x-mn}{sd}\\right)\\) or \\(\\dnorm(x, mn, sd)\\) sigmoid: \\(\\pnorm\\left(\\frac{x-mn}{sd}\\right)\\) or \\(\\pnorm(x, mn, sd)\\) The derivative of the sigmoid can be written in either of two equivalent ways: \\(\\partial_x \\pnorm\\left(\\frac{x-mn}{sd}\\right) = \\frac{1}{sd}\\, \\pnorm\\left(\\frac{x-mn}{sd}\\right)\\) \\(\\partial_x \\pnorm(x, mn, sd) = \\dnorm(x, mn, sd)\\) It’s very easy to get confused by this. Exercise 20.3 Check the “general rule” numerically. Divide the finite-difference derivative by the “theoretical” derivative and show that they are 1. Source↩︎ "],["prod-comp-rules.html", "Chapter 21 Differentiation of assembled functions 21.1 Step 1: Identify f() and g() 21.2 Step 2: Find f’() and g’() 21.3 Product rule 21.4 Composition (“chain”) rule 21.5 Step 3: Apply the relevant rule 21.6 Exponentials and logarithms (optional) 21.7 Checking your work", " Chapter 21 Differentiation of assembled functions In Chapter 11 we introduced three major methods for putting two or more basic modeling functions together in order to make a new function. Linear combinations: e.g. \\(a f(x) + b g(x)\\) Products: e.g. \\(f(x) g(x)\\) Composition:, e.g. \\(f(g(x))\\) (which is usually a different function than \\(g(f(x))\\).) We have already looked at differentiation of linear combinations. In this chapter, we’ll examine products of functions and compositions of functions. 21.1 Step 1: Identify f() and g() We will write the rules in terms of two function names, \\(f()\\) and \\(g()\\), which can stand for any functions whatsoever. It’s rare to see the product or the composition written explicitly as \\(f(x)g(x)\\) of \\(f(g(x))\\). Instead, you are given something like \\(e^x \\ln(x)\\). The first step in differentiating the product or composition is to identify what are \\(f()\\) and \\(g()\\) individually. In general, \\(f()\\) and \\(g()\\) might be complicated functions, themselves involving linear combinations, products, and composition. But to get started, we’ll practice with cases where they are simple, naked modeling functions. Exercise 21.1 (decompose-drill1) For each of the following, say whether the function is a composition \\(f(g(x))\\) or a product \\(f(x) g(x)\\), or neither. Then identify \\(f()\\). For a product, take \\(f()\\) as the function on the left. \\(h_1(x) \\equiv \\ln(x) e^x\\) Question A What is \\(h_1(x)\\)?     product ✓        composition ☹︎        neither ☹︎ Question B In \\(h_1()\\), which of these is \\(f(x)\\)? \\(\\sin()\\) ☹︎ \\(\\cos()\\) ☹︎ \\(\\exp()\\) ☹︎ \\(\\ln()\\) ✓ \\(\\recip()\\) ☹︎ \\(\\pnorm()\\) ☹︎ \\(\\dnorm()\\) ☹︎ \\(h_2(x) \\equiv \\sin(x) \\cos(x)\\) Question C What is \\(h_2(x)\\)?     product ✓        composition ☹︎        neither ☹︎ Question D In \\(h_2()\\), which of these is \\(f(x)\\)? \\(\\sin()\\) ✓ \\(\\cos()\\) ☹︎ \\(\\exp()\\) ☹︎ \\(\\ln()\\) ☹︎ \\(\\recip()\\) ☹︎ \\(\\pnorm()\\) ☹︎ \\(\\dnorm()\\) ☹︎ \\(h_3(x) \\equiv \\sin(\\cos(x))\\) Question E What is \\(h_3(x)\\)?     product ☹︎        composition ✓        neither ☹︎ Question F In \\(h_3()\\), which of these is \\(f(x)\\)? \\(\\sin()\\) ✓ \\(\\cos()\\) ☹︎ \\(\\exp()\\) ☹︎ \\(\\ln()\\) ☹︎ \\(\\recip()\\) ☹︎ \\(\\pnorm()\\) ☹︎ \\(\\dnorm()\\) ☹︎ \\(h_4(x) \\equiv e^{\\ln(x)}\\) Question G What is \\(h_4(x)\\)?     product ☹︎        composition ✓        neither ☹︎ Question H In \\(h_4()\\), which of these is \\(f(x)\\)? \\(\\sin()\\) ☹︎ \\(\\cos()\\) ☹︎ \\(\\exp()\\) ✓ \\(\\ln()\\) ☹︎ \\(\\recip()\\) ☹︎ \\(\\pnorm()\\) ☹︎ \\(\\dnorm()\\) ☹︎ \\(h_5(x) \\equiv \\sin(x) - \\cos(x)\\) Question I What is \\(h_5(x)\\)?     product ☹︎        composition ☹︎        neither ✓ Question J In \\(h_5()\\), which of these is \\(f(x)\\)? \\(\\sin()\\) ✓ \\(\\cos()\\) ☹︎ \\(\\exp()\\) ☹︎ \\(\\ln()\\) ☹︎ \\(\\recip()\\) ☹︎ \\(\\pnorm()\\) ☹︎ \\(\\dnorm()\\) ☹︎ \\(h_6(x) \\equiv e^{x^2}\\) Question K What is \\(h_2(x)\\)?     product ☹︎        composition ✓        neither ☹︎ Question L In \\(h_6()\\), which of these is \\(f(x)\\)? \\(\\sin()\\) ☹︎ \\(\\cos()\\) ☹︎ \\(\\exp()\\) ✓ \\(\\ln()\\) ☹︎ \\(\\recip()\\) ☹︎ \\(\\pnorm()\\) ☹︎ \\(\\dnorm()\\) ☹︎ \\(h_7(x) \\equiv \\pnorm(x^2)\\) Question M What is \\(h_7(x)\\)?     product ☹︎        composition ✓        neither ☹︎ Question N In \\(h_7()\\), which of these is \\(f(x)\\)? \\(\\sin()\\) ☹︎ \\(\\cos()\\) ☹︎ \\(\\exp()\\) ☹︎ \\(\\ln()\\) ☹︎ \\(\\recip()\\) ☹︎ \\(\\pnorm()\\) ✓ \\(\\dnorm()\\) ☹︎ \\(h_8(x) \\equiv \\pnorm(x) \\dnorm(x)\\) Question O What is \\(h_8(x)\\)?     product ✓        composition ☹︎        neither ☹︎ Question P In \\(h_8()\\), which of these is \\(f(x)\\)? \\(\\sin()\\) ☹︎ \\(\\cos()\\) ☹︎ \\(\\exp()\\) ☹︎ \\(\\ln()\\) ☹︎ \\(\\recip()\\) ☹︎ \\(\\pnorm()\\) ✓ \\(\\dnorm()\\) ☹︎ \\(h_9(x) \\equiv 1/\\sin(x)\\) Question Q What is \\(h_9(x)\\)?     product ☹︎        composition ✓        neither ☹︎ Question R In \\(h_9()\\), which of these is \\(f(x)\\)? \\(\\sin()\\) ☹︎ \\(\\cos()\\) ☹︎ \\(\\exp()\\) ☹︎ \\(\\ln()\\) ☹︎ \\(\\recip()\\) ✓ \\(\\pnorm()\\) ☹︎ \\(\\dnorm()\\) ☹︎ 21.2 Step 2: Find f’() and g’() For differentiating either products or compositions, you will need to identify both \\(f()\\) and \\(g()\\) (the first step) and then compute the derivatives \\(\\partial_x f()\\) and \\(\\partial_x g()\\). That is, you’ll write down four functions. Exercise 21.2 (product-table) For each of the \\(h_i()\\) in the previous section, fill in a row of the following table. (The row for \\(h_1()\\) is already entered.) Name \\(f()\\) \\(g()\\) \\(\\partial_x f()\\) \\(\\partial_x g()\\) \\(h_1()\\) \\(\\ln(x)\\) \\(e^x\\) \\(\\recip\\) (that is \\(1/x\\)) \\(e^x\\) \\(h_2()\\) \\(h_3()\\) \\(h_4()\\) \\(h_5()\\) \\(h_6()\\) \\(h_7()\\) \\(h_8()\\) \\(h_9()\\) 21.3 Product rule Written in terms of the pronoun functions \\(f()\\) and \\(g()\\), the product rule is Decide if colorizing the formulas, as in the following, is helpful and worthwhile. \\[\\partial_x \\left[\\strut \\color{blue}{f(x)}\\times \\color{green}{g(x)}\\right] = \\color{blue}{[\\partial_x f(x)]} \\times \\color{green}{g(x)}\\ \\ {\\mathbf +} \\ \\ \\color{green}{[\\partial_x g(x)]} \\times \\color{blue}{f(x)}\\] Some people find it easier to read the rule in Lagrange shorthand, where f and g stand for \\(f(x)\\) and \\(g(x)\\) respectivly, and f’ (“f-prime”) and g’ (“g-prime”) stand for \\(\\partial f()\\) and \\(\\partial g()\\). \\[\\text{Lagrange shorthand:}\\ \\ \\partial[f \\times g] = [f \\times g]&#39; = f&#39;g + g&#39;f\\] Let’s start with some very simple examples where we already know the answer: \\(\\partial [x \\times x^2] = [\\partial x] \\times x^2 \\ +\\ [\\partial x^2] \\times x =1\\times x^2 + 2x \\times x = 3 x^2\\) Since \\([x \\times x^2] = x^3\\), we could have figured out directly that the derivative is \\(3 x^2\\) \\(partial_x [e^x \\times e^x] = [\\partial_x e^x] \\times e^x \\ + \\ [\\partial_x e^x] \\times e^x = 2 e^x e^x = 2 e^{2x}\\) Since \\([e^x \\times e^x] = e^{2x}\\), one of our basic modeling functions, we could have figured out directly that the derivative is \\(2 e^{2x}\\). 21.4 Composition (“chain”) rule Written in terms of functions \\(f()\\) and \\(g()\\), the rule for the composition \\(f(g(x))\\) is \\[\\partial_x \\left[\\strut \\color{blue}{f\\left(\\right.}\\strut \\color{green}{g(x)}\\color{blue}{\\left.\\right)}\\right] = [\\color{blue}{\\partial_x f}](\\color{green}{g(x)}) \\times [\\color{green}{\\partial_xg(x)}]\\] Or, using the Lagrange prime notation \\[\\text{Lagrange shorthand:}\\ \\ \\partial[f(g)] = f&#39; (g) \\times g&#39;\\] This is almost universally called the chain rule, presumably because the result involves a chain of derivatives. Again, we’ll practice with some simple examples where we already know the result: \\(\\partial [\\exp\\left(\\ln(x)\\right)] = [\\partial \\exp](\\ln(x)) \\times \\partial_x \\ln(x) = \\exp\\left(\\ln(x)\\right) \\times 1/x\\) Since \\(\\exp\\left(\\ln(x)\\right) = x\\) we can simplify the above \\[\\partial [\\exp\\left(\\ln(x)\\right)] = \\exp\\left(\\ln(x)\\right) \\times 1/x = x/x = 1\\] which is consistent with what we know about \\(\\partial_x x\\). \\(\\partial[ \\recip(x^2)] = [\\partial \\recip](x^2) \\times \\partial_x x^2 = [\\partial\\, \\recip](x^2) \\times 2 x\\) Since \\(\\partial_x \\recip(x) = \\partial_x [1/x] = \\partial_x x^{-1} = -x^{-2} = - \\frac{1}{x^2}\\), we can simplify the above to \\(\\partial[ \\recip(x^2)] = [\\partial_x \\recip](x^2) \\times \\partial_x x^2 = - \\frac{1}{(x^2)^2} \\times 2 x = -2 \\frac{x}{x^4} = -2 x^{-3}\\) The derivatives of the basic modeling functions can be shown using the chain rule. Remember, that each of the basic modeling functions is the composition of a naked modeling function with \\(\\line(x) \\equiv ax + b\\). \\(\\partial_x [\\sin(a x + b)] = [\\partial \\sin](a x + b) \\times \\partial_x [ax + b = \\cos(ax + b) \\times a\\). 21.5 Step 3: Apply the relevant rule Exercise 21.3 (product-table-1) Go back to the table in the previous section. For those rows involving a product of functions, add a column giving the derivative of the product according to the product rule. See 141 DD 31 for drill problems 21.6 Exponentials and logarithms (optional) The natural logarithm function, \\(\\ln(x)\\), is one of our basic modeling functions. The digit() function, introduced in Chapter 14 is different, the logarithm-base-10, written \\(\\log_{10}(x)\\) or log10(x). Ten an integer, and a nice round number to boot. So in practice, it’s “natural” to use \\(\\log_10()\\). The “natural” in the “natural logarithm” means something different. The base of the natural logarithm is the number called Euler’s constant and written \\(e\\). As a celebrity number, \\(e\\) is right up there with \\(\\pi\\) and \\(-1\\). Just as \\(\\pi\\) has a decimal expansion that is infinitely long, the familiar \\(\\pi = 3.14159265358979...\\), Euler’s constant has an infinitely long decimal representation: \\(e = 2.71828182845905...\\) It’s not obvious at first glance why \\(e = 2.71828182845905...\\) should be called “natural” by mathematicians. The reason is not the number itself, but the derivative \\(\\partial_x \\ln(x)\\) which has a particularly simple form, namely, \\(1/x\\). \\(\\ln(x)\\) is the inverse of \\(e^x\\), which itself is the nicest of all derivatives \\(\\partial_x e^x = e^x\\). Let’s look at the log-base-10 and it’s computer-savvy cousin log-base-2. The very definition of logarithms means that both 10 and 2 can be written \\[10 = e^{\\ln(10)}\\ \\ \\ \\text{and}\\ \\ \\ 2 = e^{\\ln(2)}\\] This implies that the base-10 and base-2 exponential functions can be written \\[10^x = [e^{\\ln(10)}]^x = e^{\\ln(10)x} \\ \\ \\ \\text{and}\\ \\ \\ 2^x = [e^{\\ln(2)}]^x = e^{\\ln(2) x}\\] Calculating \\(\\partial_x 10^x\\) or \\(\\partial_x 2^x\\) is a matter of applying the chain rule: \\[\\partial_x [10^x] = \\partial_x [e^{\\ln(10)x}] = e^{\\ln(10)x} \\times \\ln(10) = 2.30258509299405... \\times 10^x\\\\ \\ \\text{and}\\\\ \\partial_x [2^x] = \\partial_x [e^{\\ln(2)x}] = e^{\\ln(2)x} \\times \\ln(2) = 0.693147180559945...\\times 2^x\\] Like \\(e^x\\), the derivatives of \\(10^x\\) and \\(2^x\\) are proportional to themselves. For \\(e^x\\) the constant of proportality is 1, a very natural number indeed. 21.7 Checking your work When you get the result for a derivative, plot it out along with the finite-difference approximation. If they are close, you’re good. Apply the antiD() operator to your derivative and graphically confirm that there is a constant difference between the output of antiD() and the original function. "],["optim-and-shape.html", "Chapter 22 Optimization 22.1 Structure of the problem 22.2 Interpreting the argmax 22.3 Derivatives and optimization 22.4 Tree harvesting", " Chapter 22 Optimization To “optimize” means to make something as good as possible with the available resources. Optimization problems are common in science, logistics, industry, and any other area where one seeks the best solution to a problem. Some everyday examples: How much salt to add to a stew. Stews can be too salty, or they can be not salty enough. Somewhere in the middle is the optimum. When to harvest trees being grown for lumber. Harvest too soon and you might be losing out on the prime growing years. Wait too long and trees will have settled in to slow growth, if any. Walking up too steep a slope is tiring and slows you down; that’s why hiking trails have switchbacks. When the switchbacks are too shallow, it takes a long time to cover the distance. What’s the most efficient angle to enable hikers to get up the hill in the shortest time. 22.1 Structure of the problem In an optimization problem, there is one or more input quantity whose value you have to choose. The amount of salt; the years to wait from planting to harvesting a tree; the angle of the trail with respect to the slope. We’ll call this the decision quantity. Similarly, there is one or more output quantity that you value and want to make as good as possible. The taste of the stew; the income produced by selling the lumber; the time it takes to walk up the hill. The output quantity is called the objective. The model that relates to inputs to the objective output is called the objective function. Solving an optimization problem—once the modeling phase is complete—amounts to finding a value for the decision quantity (the input to the objective function) that produces the best level of the objective (the output from the objective function). Sometimes the objective is something that you want to minimize, make as small as possible. In the hiking trail problem, we seek to minimize the amount of time it takes to walk up the trail. Sometimes you want to maximize the objective, as in the wood-harvest problem where the objective is to harvest the most wood per year. Mathematically, maximization and minimization are the same thing. Every minimization problem can be turned into a maximization problem by putting a negative sign in front of the objective function. To simplify the discussion, in talking about finding the solution to an optimization problem we’ll imagine that the goal is to maximize. But keep in mind that many circumstances in the real world, “best” can mean to minimization. The solution you seek in a maximization problem is called the argmax. This is a contraction of two words: the argument (that is, input) that produces the maximum output. (For minimization, the solution is the ***argmin.) Once you have found the argmax you can plug that value into the objective function to find the value of the output. That value is the maximum. People often talk about “finding the maximum.” This is misleading. The setup for an optimization problem is: Construct (that is, model) the objective function. Now that you know the objective function, find the input to that function—that is, the argmax—that produces the maximum output. To illustrate the setup of an optimization problem, imagine yourself in the situation of a contest to see who can shoot a tennis ball the farthest into a field with a slingshot. During the contest, you will adjust the vertical angle of launch, place the ball into the slingshot’s cradle, pull back as far as possible, and let go. To win the contest, you need to optimize how you launch the ball. The objective is the distance travelled by the ball. For simplicity, we’ll imagine that the velocity of the ball at release is fixed at \\(v_0\\). You’ll win or lose based on the angle of launch you choose. Before you head out into the field to experiment, let’s do a bit of preparation. We’ll model how far the ball will travel (horizontally) as a function of the angle of launch \\(\\theta\\) and the initial velocity \\(v_0\\). The mathematics of such problems involves an area called differential equations, an important part of calculus which we’ll come to later in the course. Since you don’t have the tools yet, we’ll just state a simple model of how long the ball stays in the air. \\[\\text{duration}(v_0, \\theta) = 2 v_0 \\sin(\\theta)/g\\] \\(g\\) is the acceleration due to gravity, which is about \\(9.8 \\text{m}\\text{s}^{-2}\\), assuming that the contest is being held on Earth. The horizontal distance travelled by the tennis ball will be \\[\\text{hdist}(v_0, \\theta) = \\cos(\\theta) v_0\\, \\text{duration}(v_0, \\theta) = 2 v_0^2 \\cos(\\theta)\\sin(\\theta) / g\\] Our objective function is hdist(), and we seek to find the argmax. The input \\(v_0\\) is (we have assumed) fixed, so the decision quantity is the angle \\(\\theta\\). The best choice of \\(\\theta\\) will make the quantity \\(\\cos(\\theta)\\sin(\\theta)\\) as large as possible. So in finding the argmax, we don’t need to be concerned with \\(v_0\\) or \\(g\\). Finding the argmax can be accomplished simply by plotting the function \\(\\cos(\\theta)\\sin(\\theta)\\). We’ll implement the function so that the input is in units of degrees. f &lt;- makeFun(cos(pi*theta/180)*sin(pi*theta/180) ~ theta) slice_plot(f(theta) ~ theta, domain(theta=c(0,90))) slice_plot(f(theta) ~ theta, domain(theta = c(40, 50))) Figure 22.1: The distance travelled by a ball launched at an angle of \\(\\theta\\)$, according to the simple model is duration of flight and distance travelled. From the graph, especially the zoomed-in version, you can read off the argmax as \\(\\theta = 45^\\circ\\). Finding the argmax solves the problem. You may also want to present your solution by saying what the value of the output of hdist() is when the argmax is given as input. You can read off the graph that the maximum of \\(\\cos(\\theta)\\sin(\\theta)\\) is 0.5 at \\(\\theta = 45^\\circ\\), so overall the distance will be \\(v_0^2 / g\\) Review Exercise: What is the dimension of \\(v_0^2 / g\\)? 22.2 Interpreting the argmax The graphical solution given to the slingshot problem is entirely satisfactory. Whether that solution will win the contest depends of course on whether the model we built for the objective function is correct. There are potentially important things we have left out, such as air resistence. Solving the optimization problem has prepared us to go out in the field and test the result. Perhaps we’ll find that the real-world optimum angle is somewhat steeper or shallower than \\(\\theta = 45^\\circ\\). Besides the argmax, another important quantity to read from the graph in Figure 22.1 is the precision of the argmax. In strict mathematical terms, the argmax is exactly 45 degrees. But in practical terms, it may not matter so much to the outcome if we are a little away from \\(45^\\circ\\). For example, according to the model, any angle in the range \\(40^\\circ &lt; \\theta &lt; 50^\\circ\\) would produce an output that is within 1% of the distance reached at the argmax. Contests are won or lost by margins of less than 1%, so you should not casually deviate from the argmax. On the other hand, \\(45^\\circ\\) is the argmax of the model. Reality may deviate from the model. For instance, suppose that air resistance or wind might might have an effect of about 1% on the distance. You can expect that such factors might change the optimal angle by as much or more than \\(\\pm 5^\\circ\\). 22.3 Derivatives and optimization We’re now going to reframe the search for the argmax and it’s interpretation in terms of derivatives of the objective function with respect to the decision quantity (\\(\\theta\\) in the slingshot problem). For a function of one variable, this will not be an improvement from the look-at-the-graph technique to find the argmax. A genuine reason to use derivatives is to set us up in the future to solve problems with more than one variable, where it is hard to draw or interpret a graph. Also, describing functions in the language of derivatives can help us think more clearly about aspects of the problem, such as the precision of the argmax. With a graph such as Figure 22.1, it’s easy to find the argmax; common sense carries the day. So it won’t be obvious at first why we are going to take the following approach: Let’s denote an argmax of the objective function \\(f(x)\\) by \\(x^\\star\\). Let’s look at the derivative \\(\\partial_x f(x)\\) in the neighborhood of \\(x^\\star\\). Referring to Figure 22.1, where \\(x^\\star = 45^\\circ\\), you may be able to see that \\(\\partial_x f(x^\\star)\\) is zero; the line tangent to the function’s graph at \\(x^\\star\\) is flat. Seen another way, the slope of \\(f(x)\\) to the left of \\(x^\\star\\) is positive; moving a tiny bit to the right (that is, increasing \\(x\\) by a very small amount, leads to an increase in the output \\(f(x)\\). Intuitively, as you approach the peak of a hill, you are walking uphill.) Just to the right of \\(x^\\star\\), the slope of \\(f(x)\\) is negative; as you reach the top of a hill and continue on, you will be going downhill. So the derivative function is positive on one side of \\(x^\\star\\) and negative on the other, suggesting that it crosses zero at the argmax. Inputs \\(x^\\star\\) such that \\(\\partial_x f(x^\\star) = 0\\) are called critical points. Why not call them simply argmaxes? Because a the slope will also be zero at an argmin. And it’s even possible to have the slope be zero at a point that’s neither an argmin or an argmax. Question tmp-31: Consider the function \\(f(x) \\equiv x^3\\). Confirm that the value of the derivative \\(\\partial_x f(x = 0)\\) and so \\(x^\\star = 0\\) is a critical point. Which sort of critical point is \\(x^\\star=0\\)? (Hint: Draw the graph of \\(f(x)\\) near \\(x=0\\) to see what’s going on.) An argmax [But \\(f(0) &lt; f(x &gt; 0)\\), so \\(x^\\star=0\\) can’t be an argmax.] An argmin [But \\(f(x &lt; 0) &lt; f(0)\\), so \\(x^\\star=0\\) can’t be an argmin.] Neither (+) [] At this point, we know that values \\(x^\\star\\) that give \\(\\partial_x f(x^\\star) = 0\\) are “critical points,” but we haven’t said how to figure out whether a given critical point is an argmax, an argmin, or neither. This is where the behavior of \\(\\partial_x f(x)\\) near x=x^$ is important. If \\(x^\\star\\) is an argmax, then \\(\\partial_x f(x)\\) will be positive to the left of \\(x^\\star\\) and negative to the right of \\(x^\\star\\); walk up the hill to get to \\(x^\\star\\), at the top the hill is flat, and just past the top the hill has a negative slope. For an argmin, changing \\(x\\) from less than \\(x^\\star\\) to greater than \\(x\\star\\); you will be walking down into the valley, then level at the very bottom \\(x=x^\\star\\), then back up the other side of the valley after you pass \\(x=x^\\star\\). Figure 22.2 shows the situation. ## Warning: geom_vline(): Ignoring `mapping` because `xintercept` was provided. ## Warning: geom_vline(): Ignoring `mapping` because `xintercept` was provided. ## Warning: geom_vline(): Ignoring `mapping` because `xintercept` was provided. ## Warning: geom_vline(): Ignoring `mapping` because `xintercept` was provided. Figure 22.2: Top row: An objective function near an argmax (left) and an argmin (right). Bottom row: The derivative of the objective function The bottom row of graphs in Figure 22.2 shows the derivative of the objective function \\(f(x)\\), that is, \\(\\partial_x f(x)\\). You can see that for the argmax of \\(f(x)\\), the derivative \\(\\partial_x f(x)\\) is positive to the left and negative to the right. Similarly, near the argmin of \\(f(x)\\), the derivative \\(\\partial_x f(x)\\) is negative to the left and positive to the right. Stated another way, the derivative \\(\\partial_x f(x)\\) has a positive slope near an argmin and a negative slope near an argmax. Just as we differentiate \\(f(x)\\) to find it’s slope, so to find the slope of the function \\(\\partial_x f(x)\\) we can differentiate it. The result is called the second derivative. We could write it \\(\\partial_x \\left[\\partial_x f(x)\\right]\\), but for brevity we write it \\(\\partial_{xx} f(x)\\). The second derivative of the objective function \\(f(x)\\) at a critical point \\(x^\\star\\) is what tells us whether the critical point is an argmax, an argmin, or neither. Critical point \\(x^\\star\\) | \\(\\partial_x f(x^\\star)\\) | \\(\\partial_{xx} f(x^\\star)\\) ———————–|———————|——————- argmax | 0 | negative argmin | 0 | positive neither| 0 | 0 Question tmp-32: Returning to the function \\(f(x) \\equiv x^3\\), find the value of the second-derivative \\(\\partial_{xx} f(x^\\star)\\) evaluated at the critical point \\(x = x^\\star = 0\\). Which of these is \\(\\partial_{xx} f( x=0\\)? Negative [But you established in the previous exercise that the critical point \\(x^\\star=0\\) is neither an argmin nor wan argmax.] Positive [But you established in the previous exercise that the critical point \\(x^\\star=0\\) is neither an argmin nor wan argmax.] Zero (+) [] When we differentiate a function \\(f(x)\\), we produce a new function that we can call anything we like. To help readers follow the thread of the story, it’s nice to name the new function \\(\\partial_x f(x)\\). That signals clearly to the reader the origins of the new function with respect to the original function \\(f(x)\\). In words, \\(\\partial_x f(x)\\) is often called the derivative of \\(f(x)\\) (with respect to x). To “derive” is a very general term and could mean just about any way of creating something new from something old. In calculus, “derivative” always means “created by differentiation.” Perhaps it would have been better if history had led us to call \\(\\partial_x f(x)\\) by the name “differentiated \\(f(x)\\)” or “the differential function of \\(f(x)\\).” Graphically, we can read the second derivative \\(\\partial_{xx} f(x)\\) as the slope of the first derivative \\(\\partial_x f(x)\\) or as the concavity of the function \\(f(x)\\) itself. When \\(\\partial_{xx} f(x) &lt; 0\\), then \\(f(x)\\) is concave down (a frown). Likewise, when \\(\\partial_{xx} f(x) &gt;0\\) the \\(f(x)\\) is concave up (a smile). When \\(\\partial_{xx} f(x) = 0\\), then \\(f(x)\\) has no curvature. To this point, we’ve translated features of functions that are evident on a graph into the language of derivatives: The slope of a function \\(f(x)\\) at any input \\(x\\) is the value of the derivative function \\(\\partial_x f(x)\\) at that same \\(x\\). The concavity of a function \\(f(x)\\) at any input is the slope of the derivative function, that is, \\(\\partial_x f(x)\\). Putting (i) and (ii) together, we get that the concavity of a function \\(f(x)\\) at any input \\(x\\) is the value of the second derivative function, that is, \\(\\partial_{xx} f(x)\\). At an argmax \\(x^\\star\\) of \\(f(x)\\), the value of the derivative function \\(\\partial_x f(x^\\star)\\) is zero and the value of the second derivative function \\(\\partial_{xx} f(x^\\star)\\) is negative. (The situation at an argmin is similar, the derivative of the objective function is zero and the second derivative is positive.) Exercise 22.1 (02/concavity) The graph shows three different functions labeled (A), (B), and (C). Question A Function (A) is     concave down ✓        non-concave ☹︎        concave up ☹︎ Question B Function (B) is     concave down ☹︎        non-concave ☹︎        concave up ✓ Question C Function (C) is     concave down ☹︎        non-concave ✓        concave up ☹︎ Question D The negative of function (A) is     concave down ☹︎        non-concave ☹︎        concave up ✓ The graph shows a function \\(\\mbox{wave}(t) \\equiv \\sin(2 \\pi t/4)\\) and labels four input values \\(t\\). Question E For what values of the input \\(t\\) is the function concave up? \\(t = A\\) and \\(t=D\\) ☹︎ \\(t = A\\) and \\(t=C\\) ☹︎ \\(t = C\\) and \\(t = D\\) ✓ none of the above ☹︎ Question F For what values of the input \\(t\\) is the function non-concave?     \\(t = A\\) ✓        \\(t=B\\) ☹︎        \\(t=C\\) ☹︎        none of the above ☹︎ Question G Where is the function steepest?     \\(t = A\\) ✓        \\(t=B\\) ☹︎        \\(t=C\\) ☹︎        \\(t=D\\) ☹︎ Exercise 22.2 (tree-loves-fish) Here is a smooth function marked at a few points. Your task is, at each point, to estimate the value of the derivative, the sign of the second derivative, and the radius of the circle that would nicely match the function in a small region around each point. (Remember, we’re asking for the radius of the circle, which is half the diameter.) To simplify things, here is a table giving seven different combinations of the quantities you are to estimate. Some of them correctly match one of the labeled points, some do not. All you need to do is choose which is the correct set of quantities for each labeled point. row value of 1st deriv sign of 2nd deriv radius                                        i -0.3 pos 0.25 ii 2.1 near 0 2000 iii -1.4 neg 12 iv 0.3 neg 0.3 v 2.1 pos 0.1 vi 1.3 neg 3 vii 0.5 pos 1 Question A Which row from the table best matches the function at point A?     i ☹︎        ii ☹︎        iii ☹︎        iv ☹︎        v ☹︎        vi ☹︎        vii ✓ Question B Which row from the table best matches the function at point B?     i ☹︎        ii ✓        iii ☹︎        iv ☹︎        v ☹︎        vi ☹︎        vii ☹︎ Question C Which row from the table best matches the function at point C?     i ☹︎        ii ☹︎        iii ☹︎        iv ✓        v ☹︎        vi ☹︎        vii ☹︎ Question D Which row from the table best matches the function at point D?     i ✓        ii ☹︎        iii ☹︎        iv ☹︎        v ☹︎        vi ☹︎        vii ☹︎ Question E Which row from the table best matches the function at point E?     i ☹︎        ii ☹︎        iii ☹︎        iv ☹︎        v ☹︎        vi ✓        vii ☹︎ Pick up on the Lorenz curve {.intheworld} in block 1. Compute the concavity of a lorenz function, showing that it’s everywhere positive. Then examine the concavity of a composition of lorenz functions to determine if that is necessarily everywhere positive. What’s the critical point? You’re familiar with the quadratic polynomial: \\[g(x) = a_0 + a_1 x + a_2 x^2\\] The graph of a quadratic polynomial is a parabola, which might be concave up or concave down. As you know, a parabola has only one critical point, which might be an argmin or an argmax. Let’s find the critical point. We know that the critical point is \\(x^\\star\\) such that \\(\\partial_x g(x_0) = 0\\). Since we know how to differentiate a power law, we can see that \\[\\partial_x g(x) = a_1 + 2 a_2 x\\] and, more specifically, at the critical point \\(x^\\star\\) the derivative will be \\[a_1 + 2 a_2 x^\\star = 0\\] The above is an equation, not a definition. It says that whatever \\(x^\\star\\) happens to be, the quantity \\(a_1 + 2 a_2 x^\\star\\) must be zero. Using plain old algebra, we can find the location of the critical point \\[x^\\star = -\\frac{a_1}{2 a_2}\\] Exercise 22.3 (optim-violet) You’re very proud of your pet dog, Swimmer. You often go to the beach and walk along the water’s edge. You throw a ball down the beach, but at an angle so it lands in the water. Swimmer goes to work. She runs down the beach (fast) and then plunges into the water, heading toward the ball. She can run fast on the beach: 400 m/minute. But she swims rather slower: 50 m/min. Suppose you threw the ball to a point 50 meters down the beach and 10 meters out in the water. The overall distance to the ball is therefore \\(\\sqrt{50^2 + 10^2} = 51\\) meters. If Swimmer entered the water immediately, she would take about minute to reach the ball (51 m / 50 m/min). Swimmer can get to the ball faster by running down the beach a big and then turning into the water. If Swimmer ran all 50 meters down the beach and then turned to swim the 10 meters, it would take her (50/400 + 10/50) minutes, about one-third of a minute. Can Swimmer do better? You can set up the calculation like this. Imagine \\(x\\) to be the distance down the beach that Swimmer runs. The time to run this distance will be \\(x/400\\). The distance remaining to the ball can be found by the pythagorean theorem. One leg of the triangle has length \\((50-x)\\), the other has length 10 m. So if \\(x\\) were 45, the distance to swim in the water would be \\(\\sqrt{(50-45)^2 + 10^2}\\). Divide this distance by 50 m/min to get the time spent in the water. distance_in_water &lt;- makeFun( your_pythagorus_calculation ~ x) time_to_ball &lt;- makeFun(x/400 + distance_in_water/50 ~ x) Time_to_ball() takes one argument, the distance \\(x\\) Swimmer runs down the beach before turning into the water. Use a SANDBOX to find the distance that calculus-savvy Swimmer runs down the beach before turning into the water, if Swimmer’s goal is to get to the ball as fast as possible. Question A What’s the optimal running distance for Swimmer?     47.25 ☹︎        47.5 ☹︎        48.25 ☹︎        48.75 ✓        49.25 ☹︎        49.75 ☹︎ Here’s a news story about a mathematician’s dog on the shore of Lake Michigan. It’s not plausible that Swimmer has been trained in calculus. Perhaps the way Swimmer solves the running distance problem is simply to graph time_to_ball(x) ~ x over a suitable domain and find the argmax by eye! Exercise 22.4 (optim-pink) If you’re skeptical that a dog might do a calculus problem before running to fetch a ball, consider the path taken by a photon. “Fermat’s Principle” is that light takes the path of least time. To illustrate, consider the problem of a photon travelling from a point A to a point B, as in the diagram. The shortest path between the two points is a straight line. Along this straight-line path, the time taken by the photon will be the distance divided by the speed of light. The diagram shows another path consisting of two segments, one of length \\(l_1\\) and the other \\(l_2\\). Obviously, the two-segment path is longer than the straight-line path. But Fermat’s principle would lead light to “prefer” the longer path if the time taken to traverse it is shorter. ## Warning in normalizePath(&quot;www/1200px-Fermat_Snellius.svg.png&quot;): path[1]=&quot;www/ ## 1200px-Fermat_Snellius.svg.png&quot;: No such file or directory The reason the indirect path might be shorter is that the speed of light differs in different physical media. Light traveling in a vacuum famously has a speed of about 300,000 km per second. In air, the speed is smaller by a factor of 1/1.003. In water, the speed is smaller still: the factor is 1/1.3. Imagine that the blue zone of the diagram is water and the clear zone air. The time for the photon to travel from point A to B is proportional to \\(1.003\\ l_1 + 1.3\\ l_2\\). To see the path actually taken by light, let’s imagine that point A is \\((x=0, y=10)\\) and point B is \\((x=20, y=-10)\\), and that the boundary between water and air is at \\(y=0\\). We’ll place the point P at \\((x, 0)\\). The total time taken for light to traverse this path is 1.003 dist(A to P) + 1.3 dist(P to B). Question A Which of these formulas gives the total time it takes for light to traverse the path from A to P at relative speed 1/1.003 and then the path from P to B at relative speed 1/1.3? A is located at \\((0, 10)\\), B is located at \\((20,-10)\\), and P is located at \\((x, 0)\\) \\(1.003 \\sqrt{(x-0)^2 +(0-10)^2}+ 1.3\\sqrt{(20-x)^2 + (-10 - 0)^2}\\) ✓ \\(\\sqrt{(x-0)^2 +(0-10)^2}/1.003+ \\sqrt{(20-x)^2 + (-10 - 0)^2}/1.3\\) ☹︎ It’s true that you divide distance by speed to get time, but here the relative speeds are \\(1/1.003\\) and \\(1/1.3\\). \\(1.003 \\sqrt{(x-10)^2 +(0-0)^2}+ 1.3\\sqrt{(-10 -x)^2 + (50 - 0)^2}\\) ☹︎ This mixes up the x and y coordinates. The distance from A to P is \\(\\sqrt{(x_P - x_A)^2 + (y_P - y_A)^2}\\). In this problem, point P is at \\((50-x, 0)\\). Implement the calculation of total_time() in R, then use a graph to find the argmin. total_time &lt;- makeFun( your_formula ~ x) slice_plot(total_time(x) ~ x, domain(x=c(0, 20))) # For the next problem dx_time &lt;- D(total_time(x) ~ x) dxx_time &lt;- D(total_time(x) ~ x + x) Question B i) What value of \\(x\\) (that is, the argmin) minimizes the travel time of light between points A and B? (Choose the best answer) 10.52 ☹︎ 11.02 ☹︎ 11.19 ☹︎ 11.61 ☹︎ 12.07 ☹︎ 12.22 ☹︎ 12.46 ☹︎ 12.50 ✓ 12.95 ☹︎ 13.19 ☹︎ 13.21 ☹︎ 13.34 ☹︎ 13.92 ☹︎ 14.03 ☹︎ 14.14 ☹︎ 14.16 ☹︎ 14.44 ☹︎ 14.5 ☹︎ 14.94 ☹︎ Question C ii) Suppose that instead of being water, the blue area was glass. The speed of light in glass is roughly 1/1.5 times as big as in vacuum. What value of \\(x\\) minimizes the travel time of light between points A and B? (Choose the best answer) 10.13 ☹︎ 11.07 ☹︎ 11.13 ☹︎ 11.5 ☹︎ 11.57 ☹︎ 12 ☹︎ 12.38 ☹︎ 12.62 ☹︎ 12.87 ☹︎ 12.88 ☹︎ 12.95 ☹︎ 13.16 ☹︎ 13.4 ☹︎ 13.60 ✓ 13.71 ☹︎ 13.85 ☹︎ 14.18 ☹︎ 14.25 ☹︎ 14.34 ☹︎ 14.7 ☹︎ Exercise 22.5 (optim-red) Turn this into a problem about algebra. Later in accumulation, figure out the mile-markers on the road. There is a tradition in mathematics education of using geometrical, distance-related problems to illustrate optimization. As it happens, some such problems can provide some valuable insight into physical situations. Suppose you have a function \\(f(x)\\) whose graph represents the path of a road through the jungle. There is a lion at coordinates \\((3, 2)\\) in the jungle. At what point as you travel along the road will you be closest to the lion. The trick here is to see that your position on the road at any value of \\(x\\) is \\((x, f(x))\\). The distance to the lion as a function of \\(x\\) is \\[ \\text{lion_dist}(x) \\equiv \\sqrt{(x - 3)^2 + (f(x)-2)^2} .\\] The road and the lion are graphed in the sandbox for the road \\(f(x) \\equiv x^2 e^{-x}\\). You can see that the road comes closest to the lion at roughly \\(x=3\\). When you implement the \\(\\text{lion_dist}(x)\\) function, you’ll be able to find the argmin, that is, the value of the input \\(x\\) for which the output \\(\\text{lion_dist}(x)\\) is minimal. The value of the function \\(\\text{lion_dist}(x)\\) at the argmin is the min of the function. slice_plot(x^2 * exp(-x) ~ x, domain(x=c(0,5))) %&gt;% gf_label(2 ~ 3, label=&quot;lion&quot;) %&gt;% gf_refine(coord_fixed()) To find the argmin of the distance to the lion more precisely, implement the \\(\\text{lion_dist}(x)\\) function in the sandbox. Plot this out and look for the minimum. Alternatively, find \\(\\partial_x \\text{lion_dist}(x)\\) and find the \\(x\\) of the zero crossing. Question A Using the sandbox above, find the argmin for which the graph of the function \\(g(x) \\equiv x^2 \\exp(-x)\\) comes closest to the point \\((3, 2)\\)? (Choose the best answer.) 2.03 ☹︎ 2.07 ☹︎ 2.21 ☹︎ 2.27 ☹︎ 2.28 ☹︎ 2.33 ☹︎ 2.37 ☹︎ 2.39 ☹︎ 2.43 ☹︎ 2.48 ☹︎ 2.58 ☹︎ 2.71 ☹︎ 2.80 ✓ 2.94 ☹︎ Exercise 22.6 (optim-blue) In the previous problem, you used graphics to find the argmin of a function. You can, of course, successively reset the domain of the graphing window to zoom in on the location of the argmin. To find the argmin numerically, you start with a (pretty good) guess for the argmin. Recall that a function (such as total_time()) can be modeled with a low-order polynomial. When the function has an extreme point the polynomial should include a quadratic term. Suppose you have guessed that \\(x=10\\) is a good starting guess for the argmin of the air-to-water problem. You can compute the first and second derivatives of total_time(x) with respect to x and evaluate those derivative functions at \\(x=10\\). (Use the D() function to construct the derivatives.) In the sandbox, use the value of those two derivatives at the \\(x=10\\) guess to find the approximation to the minimum of the function. To help remind you, the quadratic approximation to a function \\(t(x)\\) around a reference point \\(x_0\\) is: \\[q(x) \\equiv t(x_0) + \\partial_x t(x_0) [x - x_0] + \\frac{1}{2} \\partial_{xx} t(x_0) [x - x_0]^2\\] Find the derivative \\(\\partial_x q(x)\\) and set this equal to zero. Inserting appropriate values for \\(x_0\\), \\(\\partial_x t(x_0)\\), and \\(\\partial_{xx} t(x_0)\\) will enable you to calculate the value of \\(x\\) at the minimum of the approximating quadratic. Question A iii) Letting the blue area be water (1/1.3 speed factor) and starting with a guess \\(x_0=10\\), find the \\(x\\) that minimizes the approximating quadratic. 9.912 ☹︎ 10.748 ☹︎ 11.017 ☹︎ 11.151 ☹︎ 11.267 ☹︎ 11.327 ☹︎ 11.515 ☹︎ 11.713 ☹︎ 11.81 ☹︎ 12.074 ☹︎ 12.276 ☹︎ 12.321 ☹︎ 12.438 ☹︎ 12.461 ☹︎ 12.579 ✓ 12.618 ☹︎ 12.637 ☹︎ 12.993 ☹︎ 13.261 ☹︎ 13.36 ☹︎ 13.527 ☹︎ 13.888 ☹︎ Question B iv) Using the correct answer from (iii) for a new \\(x_0\\), find the value of \\(x\\) that minimizes the new approximating quadratic. 9.912 ☹︎ 10.748 ☹︎ 11.017 ☹︎ 11.151 ☹︎ 11.267 ☹︎ 11.327 ☹︎ 11.515 ☹︎ 11.713 ☹︎ 11.81 ☹︎ 12.074 ☹︎ 12.276 ☹︎ 12.321 ☹︎ 12.438 ☹︎ 12.461 ✓ 12.579 ☹︎ 12.618 ☹︎ 12.637 ☹︎ 12.993 ☹︎ 13.261 ☹︎ 13.36 ☹︎ 13.527 ☹︎ 13.888 ☹︎ 22.4 Tree harvesting Your uncle Bob is writing a business plan for a tree farm for lumber. Having heard that you are taking Math 141Z, he emails you giving some information asking for some numbers. In particular, Bob sends you a report saying that, for the species of tree he plans to plant, the amount of usable lumber is a function of growth time \\(t\\) looking like the function defined in the sandbox: lumber &lt;- makeFun(ifelse(t&lt;10, 0, 100*exp((t-25)/8)/(1 + exp((t-25)/8))) ~ t) dt_lumber &lt;- D(lumber(t) ~ t) ave_growth_rate &lt;- makeFun( your_expression_here ~ t) slice_plot(lumber(t) ~ t, domain(t=c(0,100))) Bob has heard that the time to harvest is when the tree is growing fastest. Question C A) What is the value of t (in years) at which \\(\\partial_t\\) lumber(t) is largest?     15 ☹︎        16 ☹︎        17 ☹︎        18 ☹︎        19 ☹︎        20 ☹︎        21 ☹︎        22 ☹︎        23 ☹︎        24 ☹︎        25 ✓        26 ☹︎        27 ☹︎        28 ☹︎        29 ☹︎        30 ☹︎ You patiently explain to your uncle that you certainly do not want to harvest trees when they are growing the fastest. You say, “You want to wait until the average growth rate up to that point is fastest. That will be a little while before the tree reaches its adult volume.” Question D B) What is the value of t (in years) for which the average growth rate, up to that time, is fastest.     15 ☹︎        17 ☹︎        19 ☹︎        21 ☹︎        23 ☹︎        25 ☹︎        27 ☹︎        29 ☹︎        31 ☹︎        33 ☹︎        35 ✓        37 ☹︎        39 ☹︎        41 ☹︎ Exercise 22.7 (optim-purple) This is probably misplaced. and the plot_lens() function would have to be provided. Figure 1 shows a lens together with a source and target point. Light passing through the lens is refracted. The path followed by the light will be the one with the shortest time of transit from source to target. The light enters the lens at some point \\(P_{in} = (x_{in}\\ , \\ -\\mbox{Lens}(x_{in}))\\) and leaves at \\(P_{out} = (x_{out}\\ ,\\ \\mbox{Lens}(x_{out}))\\). We don’t know either \\(x_{in}\\) or \\(x_{out}\\). but we can find them by optimization. To do this, we find the distance from the source to \\(P_{in}\\), and from \\(P_{out}\\) to the target. These two legs of the route are through air, so the time of transit on each leg is proportional to the refractive index 1.03 times the distance. Of course, light also has to travel through the lens. We’ll make the lens out of glass with a high refractive index, so the transit time will be the distance from \\(P_{in}\\) to \\(P_{out}\\) multiplied by the lens’s refractive index of 1.8. The objective function will be the sum of the three legs’ transit times. It’s already programmed for you in the sandbox. So is the command to make a contour plot of the output of the objective function over a domain of \\(x_{in}\\) and \\(x_{out}\\). Finally, the last line in the sandbox draws a picture of the lens and the light path, but you will have to insert the argmins \\(x_{in}\\) and \\(x_{out}\\) that you pick from the contour plot of the objective function. (The \\(x_{in}\\) and \\(x_{out}\\) shown in the initial code of the sandbox are not right!) # Describe the shape of the lens Lens_top &lt;- makeFun(-90 + sqrt(100^2 - x^2) ~ x) Lens_bottom &lt;- makeFun(-Lens_top(x) ~ x) # Define the objective function transit_time &lt;- makeFun( 1.03 * sqrt((x_in - -20)^2 + (Lens_bottom(x_in)- (-30))^2) + 1.80 * sqrt((x_out-x_in)^2 + (Lens_top(x_out) - Lens_bottom(x_in))^2) + 1.03 * sqrt((x_out - -10)^2 + (Lens_top(x_out)-50)^2) ~ x_in + x_out) # Graph the objective function contour_plot(transit_time(x_in, x_out) ~ x_in + x_out, domain(x_in = c(-40,40), x_out = c(-40,40)), npts=200) # Insert argmax from contour plot plot_lens(10, -5, Lens_top, Lens_bottom) Question A When the index of refraction of the lens is 1.80, what are the optimal values for \\(x_{in}\\) and \\(x_{out}\\)? (Choose the best answer.) \\(x_{in} = -22, \\ x_{out} = -21\\) ✓ \\(x_{in} = -26, \\ x_{out} = -20\\) ☹︎ \\(x_{in} = -24, \\ x_{out} = -21\\) ☹︎ \\(x_{in} = -18, \\ x_{out} = -17\\) ☹︎ \\(x_{in} = -25, \\ x_{out} = -20\\) ☹︎ It’s a good practice to test software against situations where you know the right answer. A simple situation is when there is no lens at all. One way to do this is to change the middle line of transit_time() so that the index of refraction is 1.03, just like the surrounding air. Question B When the index of refraction of the lens is 1.03, what are the optimal values for \\(x_{in}\\) and \\(x_{out}\\)? (Choose the best answer.) \\(x_{in} = -17, \\ x_{out} = -15\\) ✓ \\(x_{in} = -18, \\ x_{out} = -14\\) ☹︎ \\(x_{in} = -16, \\ x_{out} = -16\\) ☹︎ \\(x_{in} = -18, \\ x_{out} = -18\\) ☹︎ \\(x_{in} = -17, \\ x_{out} = -18\\) ☹︎ Let’s explore an extreme situation. Diamond is the transparent material that has the highest index of refraction, 2.417. Imagine a material with an index of refraction of 10. This means that light will travel very slowly within the lens. Essay question tmp-33: When you examine the contour plot of transit_time() for this high index of refraction, there will be two, widely separated local minima. Explain briefly which part of the lens these two minima correspond to. Hint: High index means slow speed of light. Sometimes it’s worthwhile to go out of your way to avoid slowdowns. Exercises involving computing derivatives In the previous discussion, we used phrases such as “every function has a derivative,” or that “any function can be approximated” by a second-order polynomial. For most practical purposes, this is true. In the next chapter, however, we’ll set mathematical conditions on “every” and “any” that will let us see when there can be an exception. [Deriv-10a] Understand and distinguish between max (min) and argmax (argmin) [Deriv-10b] Visually identify max (min) and argmax (argmin) in graphs of functions of one and two variables. [Deriv-10c] Find max and min of a quadratic function using calculus and algebra [Deriv-11a] Convert a word problem into an Objective function and constraint. [Deriv-11b] Convert a multivariate objective function to a univariate objective function using the constraint "],["partial-change.html", "Chapter 23 Partial change 23.1 Calculus on two inputs 23.2 All other things being equal … 23.3 Gradient vector 23.4 Gradient vector", " Chapter 23 Partial change This is a good time to point out something we have been doing all along, but which has likely been such a persistent component of your mathematics education that you may not have realized that it is a construction. We have two ways by which we represent functions: As a computational algorithm for generating the output from an input(s), typically involving arithmetic and the such. As a geometrical entity, specifically the graph of a function which can be a curve or, for functions of two inputs, a surface. These two modes are sometimes intertwained, as when we use the name “line” to refer to a computational object: \\(\\line(x) \\equiv a x + b\\). Unfortunately for functions of two inputs, a surface is hard to present in the formats that are most easily at hand: a piece of paper, a printed page, a computer screen. That’s because a curved surface is naturally a 3-dimensional object, while paper and screens provide two-dimensional images. Consequently, the graphics mode we prefer for presenting functions of two variables is the contour plot, which is not a single geometrical object but a set of many objects: contours, labels, colored tiles. We’ve been doing calculus on functions of one variable because it is so easy to exploit both the computational mode and the graphical mode. And it might fairly be taken as a basic organizing theme of calculus that a line segment can be as good an approximation to a curve as you choose to make it. When figuring out the derivative function \\(\\partial_x f(x)\\) from a graph of \\(f(x)\\), we find the tangent to the graph at each of many input values, record the slope of the line (and throw away the intercept) and then write down the series of slopes as a function of the input, typically by representing the slope by position along the vertical axis and the corresponding input by position along the horizontal axis. Figure 23.1 shows the process. Figure 23.1: The slope of the function \\(f(x)\\) at any given input becomes the value of the derivative at that input. Consider the top panel (A). At the input \\(x=0\\)—the point labeled “L”—the value of the function is \\(f(0) \\approx 25\\). This is practically the same as the value at “K.” The slope of the short line segment labeled “L” is \\(\\partial_x f(0) = -3.4\\) Now look at the same input in the bottom panel (B). This shows \\(\\partial_x f(x)\\) on the vertical axis. The slope of \\(f()\\) at \\(x=0\\) was negative, even though \\(f(0)\\approx 25\\).On the graph of \\(\\partial_x f()\\), the position of “L” is in negative territory. And it’s quite different from the position of its neighbor “K.” 23.1 Calculus on two inputs To think about derivatives of functions of two inputs, we need to have some way to approximate the surface at each point with a small linear form that is tangent to the surface at that point. An applet written by Alfredo Sánchez Alberca lets you visualize the tangent plane to a surface. (Instructions: Check “tangent plane” then rotate the view. Move the (x,y) coordinate of the point to see how the tangent plane differs from place to place.) The tangent plane is infinite in extent. Let’s use the word facet to refer to a little patch of the tangent plane centered at the point of contact. The facet is flat. (It’s part of a plane!) Figure 23.2 shows some facets tangent to a curved surface. No two of them are oriented the same way. Figure 23.2: A melon as a model of a curved surface such as the graph of a function of two inputs. Each tangent facet has its own orientation. (Disregard the slight curvature of the small pieces of paper. Summer humidity has interfered with my attempt to model a flat facet with a piece of Post-It paper! Better than a picture of a summer melon, pick up a hardcover book and place it on a curved surface that’s convex facing away from the cover. The cover will match the orientation of the surface at the point of tangency. Change the orientation of the cover and you will find that the point of tangency will change correspondingly. For the purposes of computation by eye, a contour graph of a surface can be easier to deal with. Figure 23.3 shows the contour graph of a smoothly varying function. Three points have been labeled A, B, and C. Figure 23.3: A function of 2 inputs with 3 specific inputs marked A, B, and C Zooming in on each of the marked points presents a simpler picture for each of them, although one that is different for each point. Each zoomed-in plot contains almost parallel, almost evenly spaced contours. If the surface had been exactly planar over the zoomed-in domain, the contours would be exactly parallel and exactly evenly spaced. Figure 23.4: Zooming in on the neighborhoods of A, B, and C in Figure 23.3 shows a simple, almost planar, local landscape. Just as the function \\(\\line(x) \\equiv a x + b\\) describes a straight line, the function \\(\\text{plane}(x, y) \\equiv a + b x + c y\\) describes a plane whose orientation is specified by the value of the parameters \\(b\\) and \\(c\\). In Figure 23.5, the facets tangent to the original surface at A, B, and C are displayed. Comparing Figures 23.4 and 23.5 you can see that each facet has the same orientation as the surface; the contours face in the same way. Figure 23.5: The facets around the points are linear functions, each aligned with the contours near that point in Figure 23.3 Remember that the point of constructing such facets is to generalize the idea of a derivative from a function of one input \\(f(x)\\) to functions of two and more inputs such as \\(g(x,y)\\). Just as the derivative \\(\\partial_x f(x_0)\\) reflects the slope of the line tangent to the graph of \\(f(x)\\) at \\(x=x_0\\), our plan for the “derivative” of \\(g(x_0,y_0)\\) is to represent the orientation of the facet tangent to the graph of \\(g(x,y)\\) at \\((x=x_0, y=y_0)\\). The question for us now is what information is needed to specify an orientation. One clue comes from the formula for a function whose graph is a plane oriented in a particular direction: \\[\\text{plane}(x,y) \\equiv a + b x + cy\\] To explore the roles of the parameters \\(b\\) and \\(c\\) in setting the orientation of the line, open a SANDBOX. The scaffolding code generates a particular instance of \\(\\text{plane}(x,y)\\) and plots it in two ways: a contour plot and a surface plot. Change the numerical values of \\(b\\) and \\(c\\) and observe how the orientation of the planar surface changes in the graphs. You can also see that the value of \\(a\\) is irrelevant to the orientation of the plane, just as the intercept of a straight-line graph is irrelevant to the slope of that line. plane &lt;- makeFun(a + b*x + c*y ~ x + y, a = 1, b = -2.5, c = 1.6) interactive_plot(plane(x, y) ~ x + y, domain(x=c(-2, 2), y=c(-2, 2))) contour_plot(plane(x, y) ~ x + y, domain(x=c(-2, 2), y=c(-2, 2))) %&gt;% gf_refine(coord_fixed()) As always it can be difficult to extract quantitative information from a surface plot. For the example here, you can see that the high-point on the surface is when \\(x\\) is most negative and \\(y\\) is most positive. Compare that to the contour plot to verify that that two modes are displaying the same surface. (Note: The gf_refine(coord_fixed()) part of the contour-plot command makes numerical intervals on the horizontal and vertical axes have the same length.) An instructive experience is to pick up a rigid, flat object, for instance a smartphone or hardcover book. Hold the object level with pinched fingers at the mid-point of each of the short ends, as shown in Figure 23.6 (left). Figure 23.6: Combining two simple movements can tip a plane to all sorts of different orientations. You can tip the object in one direction by raising or lowering one hand. (middle picture) And you can tip the object in the other coordinate direction by rotating the object around the line joining the points grasped by the left and right hands. (right picture) By combining these two motions, you can orient the surface of the object in a wide range of directions. The purpose of this lesson is to show that two-numbers are sufficient to dictate the orientation of a plane: the amount that one hand is raised relative to the other and the angle of rotation around the hand-to-hand axis. Similarly, in the formula for a plane, the orientation is set by two numbers, \\(b\\) and \\(c\\) in \\(\\text{plane}(x, y) \\equiv a + b x + c y\\). How to find the right \\(b\\) and \\(c\\) for the tangent facet to a function \\(g(x,y)\\) at a specific input \\((x_0, y_0)\\)? Taking slices of \\(g(x,y)\\) provides the answer. In particular, these two slices: \\(\\text{slice}_1(x) \\equiv g(x, y_0) = a + b\\, x + c\\, y_0 \\ \\ \\text{and}\\ \\ \\text{slice}_2(y) \\equiv g(x_0, y) = a + b x_0 + c y\\) Look carefully at the formulas for the slices. In \\(\\text{slice}_1(x)\\), the value of \\(y\\) is being held constant at \\(y=y_0\\). Similarly, in \\(\\text{slice}_2(y)\\) the value of \\(x\\) is held constant at \\(x=x_0\\). The parameters \\(b\\) and \\(c\\) can be read out from the derivatives of the respective slices: \\[b = \\partial_x \\text{slice}_1(x)\\left.\\strut\\right|_{x=x_0} \\ \\ \\text{and}\\ \\ c=\\partial_y \\text{slice}_2(y)\\left.\\strut\\right|_{y=y_0}\\] These derivatives of slice functions are called partial derivatives. The word “partial” refers to examining just one input at a time. Here, we’re evaluating the partial derivative functions at a specific inputs, \\(x=x_0\\) or \\(y=y_0\\). You don’t need to create the slices explicitly in order to calculate the partial derivatives. Simply differentiate \\(g(x, y)\\) with respect to \\(x\\) in order to get parameter \\(b\\) and differentiate \\(g(x, y)\\) with respect to \\(y\\) to get parameter \\(c\\). To demonstrate, we’ll make use of the sum rule: \\[\\partial_x g(x, y) = \\underbrace{\\partial_x a}_{=0} + \\underbrace{\\partial_x b x}_{=b} + \\underbrace{\\partial_x cy}_{=0} = b\\] Similarly, \\[\\partial_y g(x, y) = \\underbrace{\\partial_y a}_{=0} + \\underbrace{\\partial_y b x}_{=0} + \\underbrace{\\partial_y cy}_{=c} = c\\] Get in the habit of noticing the subscript on the differentiation symbol \\(\\partial\\). When taking, for instance, \\(\\partial_y f(x,y,z, \\ldots)\\), all variables other than \\(y\\) are to be held constant. Some examples: \\[\\partial_y 3 x^2 = 0\\ \\ \\text{but}\\ \\ \\ \\partial_x 3 x^2 = 6x\\\\ \\ \\\\ \\partial_y 2 x^2 y = 2x^2\\ \\ \\text{but}\\ \\ \\ \\partial_x 2 x^2 y = 4 x y \\] 23.2 All other things being equal … Recall that the derivative of a function of one variable, say, \\(\\partial_x f(x)\\) tells you, at each possible value of the input \\(x\\), how much the output will change proportional to a small change in the value of the input. This is exactly what the first-order polynomial approximation (that is, the linear approximation), is saying: for small \\(dx\\), \\[f(x+dx) = f(x) + \\partial_x f(x) \\times dx\\] The same logic applies for functions of two inputs: \\[g(x + \\color{blue}{dx}, y) = g(x,y) + \\color{blue}{\\partial_x} g(x,y) \\times \\color{blue}{dx}\\\\ \\text{and} \\\\ g(x, y+\\color{red}{dy}) = g(x,y) + \\color{red}{\\partial_y} g(x,y) \\times \\color{red}{dy}\\] Each of these statements is about changing one input while holding the other input(s) constant. Or, as the more familiar expression goes, \"The effect of changing one input all other things being equal. [Deriv-4a] Understand that there are many different slopes at any point of a non-constant function of 2 or more variables. [Deriv-4b] Calculate partial derivatives on a contour plot [Deriv-4c] Understand “partial derivative” as “changing one input while holding constant all the other inputs.” [Deriv-8b] Calculate partial derivatives by “changing one input while holding constant all the other inputs.” [Deriv-4d] Know the three properties of gradient vectors Everything we’ve said about differentiation rules applies not just to functions of one input, \\(f(x)\\), but to functions with two or more inputs, \\(g(x,y)\\), \\(h(x,y,z)\\) and so on. In this chapter, we’ll consider the interpretation and applications of derivatives of functions with multiple inputs. 23.3 Gradient vector For functions of two inputs, there are two partial derivatives. For functions of three inputs, there are three partial derivatives. We can, of course, collect the partial derivatives into coordinate form. This collection is called the gradient vector. Just as our notation for differences (\\(\\cal D\\)) and derivatives (\\(\\partial\\)) involves unusual typography on the letter “D,” the notation for the gradient involves such unusual typography although this time on \\(\\Delta\\), the Greek version of “D.” For the gradient symbol, turn \\(\\Delta\\) on its head: \\(\\nabla\\). That is, \\[\\nabla g(x,y) \\equiv \\left(\\stackrel\\strut\\strut\\delta_x g(x,y), \\ \\ \\delta_y g(x,y)\\right)\\] Note that \\(\\nabla g(x,y)\\) is a function of both \\(x\\) and \\(y\\), so in general the gradient vector differs from place to place in the function’s domain. The graphics convention for drawing a gradient vector for a particular input, that is, \\(\\nabla g(x_0, y_0)\\), puts an arrow with its root at \\((x_0, y_0)\\), pointing in direction \\(\\nabla g(x_0, y_0)\\), as in Figure 23.7. Figure 23.7: The gradient vector \\(\\nabla g(x=1,y=2)\\). The vector points in the steepest uphill direction. Consequently, it is perpendicular to the contour passing through it’s root. A gradient field (see Figure 23.8) is the value of the gradient vector at each point in the function’s domain. Graphically, in order to prevent over-crowding, the vectors are drawn at discrete points. The lengths of the drawn vectors are set proportional to the numerical length of \\(\\nabla g(x, y)\\), so a short vector means the surface is relatively level, a long vector means the surface is relatively steep. Figure 23.8: A plot of the gradient field \\(\\nabla g(x,y)\\). Since each gradient vector points uphill, start at a point and follow the vectors as you go, you will get to a local maximum! Exercise 23.1 (partial-purple) Open a sandbox and use the following commands to make a “surface plot” and a contour plot of a function \\(g(x)\\) centered on the reference point \\((x_0\\!=\\!0,\\, y_0\\!=\\!0)\\). g &lt;- rfun( ~ x + y, seed = 802, n = 15) x0 &lt;- 0 y0 &lt;- 0 size &lt;- 5 interactive_plot(g(x, y) ~ x + y, domain(x = x0 + size*c(-1, 1), y = y0 + size*c(-1, 1))) contour_plot(g(x, y) ~ x + y, domain(x = x0 + size*c(-1, 1), y = y0 + size*c(-1, 1))) Rotate the graphic around until you feel comfortable with the controls. By making size smaller, you can zoom in around the reference point. Zoom in gradually (say, size = 1.0, 0.5, 0.1, 0.05, 0.01) until you reach a point where the surface plot is (practically) a pretty simple inclined plane. From either the surface plot or from the contour plot, zoomed in so that the graph shows an inclined plane, figure out the sign of \\(\\partial_x g(0,0)\\) and \\(\\partial_y g(0,0)\\). Question A Which answer best describes the signs of the partial derivatives of \\(g(x,y)\\) at the reference point \\((x_0=0, y_0=0)\\)? \\(\\partial_x g(0,0)\\) is pos, \\(\\partial_y g(0,0)\\) is pos ☹︎ \\(\\partial_x g(0,0)\\) is pos, \\(\\partial_y g(0,0)\\) is neg ☹︎ \\(\\partial_x g(0,0)\\) is neg, \\(\\partial_y g(0,0)\\) is neg ☹︎ \\(\\partial_x g(0,0)\\) is neg, \\(\\partial_y g(0,0)\\) is pos. ✓ \\(\\partial_x g(0,0)\\) is 0, \\(\\partial_y g(0,0)\\) is pos ☹︎ Exercise 23.2 (partial-tan) Consider this close up of a function around a reference point at the center of the graph. By eye, estimate these derivatives of the function at the reference point \\((x_0=-2, y_0=-5)\\). Question A What is the numerical value of \\(\\partial_x g(x,y)\\) at the reference point?     -1 ☹︎        -0.50 ☹︎        -0.25 ☹︎        0 ☹︎        0.25 ☹︎        0.50 ✓        1 ☹︎ Question B What is the numerical value of \\(\\partial_y g(x,y)\\) at the reference point?     -1 ☹︎        -0.50 ☹︎        -0.25 ☹︎        0 ☹︎        0.25 ☹︎        0.50 ☹︎        1 ✓ The next questions ask about second-order partial derivatives. As you know, the second derivative is about how the first derivative changes with x or y. Insofar as the function is a simple inclined plane, where the contours would be straight, parallel, and evenly spaced, the second derivatives would all be zero. But you can see that it is not such a plane: the contours curve a bit. In determining the second derivatives by eye from the graph, you are encouraged to compare first derivatives at the opposing edges of the graph, as opposed to at very nearby points. Question C What is the sign of \\(\\partial_{xx} g(x,y)\\) at the reference point?     negative ✓        positive ☹︎ Question D What is the sign of \\(\\partial_{yy} g(x,y)\\) at the reference point?     negative ☹︎        positive ✓ Question E What is the sign of \\(\\partial_{xy} g(x,y)\\) at the reference point?     negative ☹︎        positive ✓ Question F What is the sign of \\(\\partial_{yx} g(x,y)\\) at the reference point?     negative ☹︎        positive ✓ Exercise 23.3 (partial-doctor) At numerous occasions in your professional life, you will be in one or both of these positions: You are a decision-maker being presented with the results of an analysis conducted by a team of unknown reliability, and you need to figure out whether what they are telling you is credible. You are a member of the analysis team needing to demonstrate to the decision-maker that your work should be believed. As an example, consider one of the functions presented in a comedy book, Geek Logic: 50 Foolproof Equations for Everyday Life (2006), by Garth Sundem. The particular function we’ll consider here is Dr(), intended to help answer the question, “Should you go to the doctor?” \\[\\mbox{Dr}(d, c, p, e, n, s) = \\frac{\\frac{s^2}{2} + e(n-e)}{100 - 3(d + \\frac{p^3}{70} - c)}\\] where \\(d\\) = How many days in the past month have you been incapacitated? \\(d_0 \\equiv 3\\) \\(c\\) = Does the issue seem to be getting better or worse. (-10 to 10 with -10 being “circling the drain” and 10 being “dramatic improvement”) \\(c_0 \\equiv -2\\) \\(p\\) = How much pain or discomfort are you currently experiencing? (1-10 with 10 being “currently holding detached toe in Ziploc bag”) \\(p_0 = 3\\) \\(e\\) = How embarrassing is this issue? (1-10 with 10 being “slipped on ice and fell on 1972 Mercedes-Benz hood ornament, which is now part of my body”) \\(e_0 = 4\\) \\(n\\) = How noticeable is the issue? (1-10 with 10 being “fell asleep on waffle iron”) \\(n_0 = 5\\) \\(s\\) = How serious does the issue seem? (1-10 with 10 being “may well have nail embedded in frontal lobe [of brain]”) \\(s_0 = 3\\) Although the function is offered tongue-in-cheek, let’s examine it to see if it even roughly matches common sense. The tool we will use relates to low-order polynomial approximation around a reference point and examining appropriate partial derivatives. To save time, we stipulate a reference point for you, noted in the description of variables above. The code creates an R implementation of the function that is set up so that the default values of the variables are those at the given reference point. You can use this in a sandbox to try different changes in each of the input quantities. According to the instructions in the book, if Dr()\\(&gt; 1\\), you should go to the doctor. Essay question tmp-34: 1) The value of Dr() at the reference point is 0.10, indicating that you shouldn’t go to the doctor. But we don’t yet know whether 0.10 is very close to the decision threshold of 1 or very far away. Describe a reasonable way to figure this out. Report your description and the results here. Essay question tmp-35: There are six inputs to the function. Go through the list of all six and (without thinking too hard about it) write down for all of them your intuitive sense of whether an increase of one point in that input should raise or lower the output of Dr() at the reference point. Also write down whether you think the input should be a large or small determinant of whether to go to the doctor. (You don’t need to refer to the Dr() function itself, just to your own intuitive sense of what should be the effect of each of the inputs.) The operator D() can calculate partial derivatives. You can calculate the value of a partial derivative very easily at the reference point, using an expression like this, which gives the value of the partial of Dr() with respect to input \\(s\\) at the reference point: D(Dr(s = s) ~ s)() We’re now going to use these partial derivatives to compare your intuition about going to the doctor to what the function has to say. Of course, we don’t know yet whether the function is reasonable, so don’t be disappointed if your intuition conflicts with the function. Essay question tmp-36: Calculate the numerical value of each of the partial derivatives at the reference point. List them here and say, for each one, whether it accords with your intuition. 23.4 Gradient vector Exercise 23.4 (gradient-field-red) Here are contour maps of several functions with input \\(x\\) and \\(y\\). Underneath them are plots of the gradient field of the functions, but they are not in order. Your job is to match the contour plot with the gradient field. Question A Which contour plot matches gradient field 1?     A ☹︎        B ☹︎        C ☹︎        D ☹︎        E ☹︎        F ✓ Question B Which contour plot matches gradient field 2?     A ✓        B ☹︎        C ☹︎        D ☹︎        E ☹︎        F ☹︎ Question C Which contour plot matches gradient field 3?     A ☹︎        B ☹︎        C ☹︎        D ✓        E ☹︎        F ☹︎ Question D Which contour plot matches gradient field 4?     A ☹︎        B ☹︎        C ✓        D ☹︎        E ☹︎        F ☹︎ Question E Which contour plot matches gradient field 5?     A ☹︎        B ☹︎        C ☹︎        D ☹︎        E ✓        F ☹︎ Question F Which contour plot matches gradient field 6?     A ☹︎        B ✓        C ☹︎        D ☹︎        E ☹︎        F ☹︎ Exercise 23.5 (gradient-field-blue) Question A What’s wrong with gradient field 1? arrows point down the hill instead of up it ☹︎ magnitude of arrows are wrong, but direction is right ✓ arrows don’t point in the right direction ☹︎ nothing is wrong ☹︎ Question B What’s wrong with gradient field 2? arrows point down the hill instead of up it ✓ magnitude of arrows are wrong, but direction is right ☹︎ arrows don’t point in the right direction ☹︎ nothing is wrong ☹︎ Question C What’s wrong with gradient field 3? arrows point down the hill instead of up it ☹︎ magnitude of arrows are wrong, but direction is right ☹︎ arrows don’t point in the right direction ☹︎ nothing is wrong ✓ Question D What’s wrong with gradient field 4? arrows point down the hill instead of up it ☹︎ magnitude of arrows are wrong, but direction is right ☹︎ arrows don’t point in the right direction ✓ nothing is wrong ☹︎ Exercise 23.6 (gradient-field-orange) It’s relatively easy to assess partial derivatives when you know the gradient. After all, the gradient is the vector of \\((\\partial_x\\,f(x,y), \\partial_y f(x,y))\\). To train your eye, here’s a contour plot and a corresponding gradient plot. Question A What is the rule for determining \\(\\partial_x f(x,y)\\) from the direction of the gradient vector? If the vector has a component pointing right, \\(\\partial_x f\\) is positive. ✓ If the vector has a component pointing left, \\(\\partial_x f\\) is positive ☹︎ If the gradient points left, then uphill is to the left. So the function is increasing from right to left. That’s a negative partial derivative. If the vector has a vertical component pointing up, \\(\\partial_x f\\) is positive. ☹︎ This would be true for the partial derivative with respect to \\(y\\), but that has to relevance to the partial with respect to \\(x\\). If the vector has a component pointing downward, the partial derivative \\(\\partial_x f\\) is positive. ☹︎ No, but the partial with respect to \\(y\\) would be negative. Using the gradient field depicted below, figure out the sign of the partial derivatives at the labeled points. We’ll use “neg” to refer to negative partial derivatives, “pos” to refer to positive partial derivatives, and “zero” to refer to partials that are so small that you can’t visually distinguish them from zero. Question B Which is \\(\\partial_y f\\) at point A?     neg ✓        zero ☹︎        pos ☹︎ Question C Which is \\(\\partial_x f\\) at point A?     neg ☹︎        zero ☹︎        pos ✓ Question D Which is \\(\\partial_x f\\) at point B?     neg ☹︎        zero ☹︎        pos ✓ Question E Which is \\(\\partial_x f\\) at point C?     neg ☹︎        zero ✓        pos ☹︎ Question F Which is \\(\\partial_y f\\) at point E?     neg ☹︎        zero ☹︎        pos ✓ Question G Which is \\(\\partial_x f\\) at point E?     neg ✓        zero ☹︎        pos ☹︎ Question H At which letter are both the partial with respect to \\(x\\) and the partial with respect to \\(y\\) negative.?     A ☹︎        B ☹︎        C ☹︎        D ☹︎        E ☹︎        F ☹︎        none of them ✓ Exercise 23.7 (gradient-field-pink) The contour plot below is marked with several colored lines which represent slices through the surface. Your job is to match these up with the slice plots presented below. In the slice plots, the input \\(t\\) reflects the position on the slice. At \\(t=0\\), position is at the leftmost point of the slice, while at \\(t=1\\) position is at the right terminus of the slice. Question A Which color line corresponds to slice 1?     black ☹︎        gray ☹︎        orange ☹︎        red ✓        yellow ☹︎ Question B Which color line corresponds to slice 2?     black ☹︎        gray ✓        orange ☹︎        red ☹︎        yellow ☹︎ Question C Which color line corresponds to slice 3?     black ✓        gray ☹︎        orange ☹︎        red ☹︎        yellow ☹︎ Question D Which color line corresponds to slice 4?     black ☹︎        gray ☹︎        orange ☹︎        red ☹︎        yellow ✓ Exercise 23.8 (gradient-field-violet) The contour plot below is marked with several colored lines which represent slices through the surface. Your job is to match these up with the slice plots presented below. In the slice plots, the input \\(t\\) reflects the position on the slice. At \\(t=0\\), position is at the leftmost point of the slice, while at \\(t=1\\) position is at the right terminus of the slice. Question A Which color line corresponds to slice 1?     black ☹︎        gray ✓        orange ☹︎        red ☹︎        yellow ☹︎ Question B Which color line corresponds to slice 2?     black ☹︎        gray ☹︎        orange ✓        red ☹︎        yellow ☹︎ Question C Which color line corresponds to slice 3?     black ☹︎        gray ☹︎        orange ☹︎        red ☹︎        yellow ✓ Question D Which color line corresponds to slice 4?     black ☹︎        gray ☹︎        orange ☹︎        red ✓        yellow ☹︎ Exercise 23.9 (partial-house) For almost everyone, a house is too expensive to buy with cash, so people need to borrow money. The usual form of the loan is called a “mortgage.” Mortgages extend over many years and involve paying a fixed amount each month. That amount is calculated so that, by paying it each month for the duration of the mortgage, the last payment will completely repay the amount borrowed plus the accumulated interest. The monthly mortgage payment in dollars, \\(P\\), for a house is a function of three variables, \\[P(A, r, N)\\] where \\(A\\) is the amount borrowed in dollars, \\(r\\) is the interest rate (per year), and \\(N\\) is the number of years before the mortgage is paid off. A studio apartment is selling for $220,000. You will need to borrow $184,000 to make the purchase. Question A Suppose \\(P(184000,4,10) = 2180.16\\). What does this tell you in financial terms? The monthly cost of borrowing $184,000 for 10 years at 4% interest per year. ✓ The monthly cost of borrowing $184,000 for 4 years at 10% interest per year. ☹︎ You’ve got the order of the argument wrong. The annual cost of the mortgage at 4% interest for 10 years. ☹︎ The output of the function \\(P()\\) is the monthly mortgage payment. The annual cost of the mortgage at 10% interest for 4 years ☹︎ The output of the function \\(P()\\) is the monthly mortgage payment. Question B What would you expect about the quantity \\(\\partial P / \\partial A\\)?     It’s positive ✓ If you borrow more money, holding mortgage duration and interest rate constant, you are going to have to pay more each month.        It’s zero ☹︎        It’s negative ☹︎ Question C What would you expect about the quantity \\(\\partial P / \\partial N\\)?     It’s positive ☹︎        It’s zero ☹︎        It’s negative ✓ If you borrow the same amount of money at the same interest rate, but have more years to pay it back, your monthly payment will be smaller. Question D Suppose \\(\\partial P / \\partial r (184000,4,30) =\\) $145.64. What is the financial significance of the number $145.65?? If the interest rate \\(r\\) went up from 4 to 5, the monthly payment would increase by $145.65. ☹︎ This is a perfectly reasonable answer, but … recall that the derivative gives the rate of increase in the output of the function when the input changes by a tiny amount. It turns out that a 1 percentage point increase in interest rate is a very large amount of change. If the interest rate \\(r\\) went up from 4 to 4.001, the monthly payment would increase by $145.65. ☹︎ This is indeed a small change in interest rate, but the value of the derivative is the rate of increase, not the increase itself. If the interest rate \\(r\\) went up from 4 to 4.001, the monthly payment would increase by $0.001 imes $145.65. ✓ You might think that nobody would be concerned about such a small increase in interest rate. But knowing the result for each very small increase allows us to calculate what would be the impact of a large increase by a process called integration. Exercise 23.10 (spider-blow-lamp) In economic theory, the quantity of the demand for any good is a decreasing function of the price of that good and an increasing function of the price of a competing good. The classical example is that apple juice competes with orange juice. The demand for orange juice is in units of thousands of liters of orange juice. The price is in units of dollars per liter. Here’s a graph with the input variables unlabeled. The concept of partial derivatives makes it much easier to think about the situation. There are two partial derivative functions relevant to the function in the graph. Well denote the input variables apple and orange, but remember that these are the prices of those commodities in dollars per liter. \\(\\partial_\\mbox{apple} \\mbox{demand}()\\) – how the demand changes when apple-juice price goes up, holding orange-juice price constant. (Another notation that is more verbose but perhaps easier to read \\(\\frac{\\partial\\, \\mbox{demand}}{\\partial\\,\\mbox{apple}}\\)) \\(\\partial_\\mbox{orange} \\mbox{demand}()\\) – how the demand changes when orange-juice price goes up, holding apple-juice price constant. (Another notation: \\(\\frac{\\partial\\, \\mbox{demand}}{\\partial\\,\\mbox{orange}}\\)) Notice that the notation names both the output and the single input which is to be changed–the other inputs will be held constant. The first paragraph of this problem gives the economic theory which amounts to saying that one of the partial derivatives is positive and the other negative. Question A What are the numbers labeling the contours? Quantity of orange juice. ✓ Price of apple juice. ☹︎ The prices of apple juice and of orange juice are the inputs to the function. Input values are displayed as position on an axis. The contour labels identify the output value for any input that corresponds to a point on the contour. Price of orange juice. ☹︎ The prices of apple juice and of orange juice are the inputs to the function. Input values are displayed as position on an axis. The contour labels identify the output value for any input that corresponds to a point on the contour. Quantity of apple juice. ☹︎ A reasonable answer, but the function output is the quantity of orange juice. Question B What is the proper translation of the notation \\(\\partial_\\mbox{apple}\\mbox{demand}()\\)? The partial derivative of orange-juice demand with repect to apple-juice price ✓ The partial derivative of apple-juice price with repect to demand for orange juice ☹︎ Derivatives are always with respect to an input variable. Demand for orange juice is the output variable. The partial derivative of apple-juice demand *with respect to price of apple juice ☹︎ This problem is about orange-juice demand, not apple-juice demand. The partial derivative of orange-juice price with respect to apple-juice price. ☹︎ Both of these are input variables to the demand function. A partial derivative is always about the change in output when one of the inputs changes, not the change in one input when another input changes. Question C According to the economic theory described above, one of the partial derivatives will be positive and the other negative. Which will be positive. \\(\\partial_\\mbox{apple} \\mbox{demand}()\\) ✓ \\(\\partial_\\mbox{orange} \\mbox{demand}()\\) ☹︎ If orange juice prices went up, would you drink more orange juice? Question D What does the vertical axis measure? Price of orange juice ✓ Quantity of apple juice ☹︎ Quantity of orange juice ☹︎ Price of apple juice ☹︎ Question E Consider the magnitude (absolute value) of the partial derivative of demand with respect to orange-juice price. Is this magnitude greater toward the top of the graph or the bottom?     top ✓        bottom ☹︎ The horizontal distance between contour lines is larger at the bottom of the graph than at the top. Far-apart contours mean that the function is flatter.        neither ☹︎ Remember, we’re talking about the partial derivative with respect to orange juice price. That corresponds to the slope when moving in a horizontal direction. Exercise 23.11 (grass-grows-red) The contour plot of function \\(g(y, z)\\) is overlaid with vectors. The black vector is a correct representation of the gradient (at the root of the vector). The other vectors are also supposed to represent the gradient, but might have something wrong with them (or might not). You’re job is to say what’s wrong with each of those vectors. Question A What’s wrong with the red vector? nothing ☹︎ too long ✓ The red vector is located in a place where the function is almost level. You can tell this because the contour lines are spaced far apart. The magnitude of the gradient will be small in such an area. But here, the red vector is even longer than the black vector, even though black is in a very steep area (with closely spaced contours). too short ☹︎ points downhill ☹︎ points uphill ☹︎ Pointing uphill is what gradient vectors do! No problem with this. wrong direction entirely ☹︎ Question B What’s wrong with the green vector? nothing ☹︎ too long ☹︎ Note that the vector reflects the steepness at the point where the root of the vector is drawn. The root of the green vector is in an area where the contour lines are spaced similarly to the area near the root of the black vector. So it’s correct that the length of the green vector is similar to the length of the black vector. too short ☹︎ points downhill ✓ The root of the green vector is near contour=4, the head at contour=2. So the vector is incorrectly pointing downhill. Gradients point in the steepest direction uphill. points uphill ☹︎ Pointing uphill is what gradient vectors do! No problem with this. wrong direction entirely ☹︎ Question C What’s wrong with the blue vector? nothing ✓ too long ☹︎ too short ☹︎ The blue vector is in a very flat area of the function. That’s why it’s so short. points downhill ☹︎ points uphill ☹︎ Pointing uphill is what gradient vectors do! No problem with this. wrong direction entirely ☹︎ Question D What’s wrong with the orange vector? nothing ☹︎ too long ☹︎ too short ☹︎ points downhill ☹︎ points uphill ☹︎ wrong direction entirely ✓ Gradient vectors should be perpendicular to nearby contours and should point uphill. The orange vector is neither Question E What’s wrong with the gray vector? nothing ☹︎ too long ☹︎ too short ✓ The function is practically as steep at the root of the gray vector as it is at the root of the black vector. (You can tell this from the spacing of the contour lines.) So the magnitude of the gray vector should be just about the same as the magnitude of the black vector. points downhill ☹︎ points uphill ☹︎ Exercise 23.12 (grass-grows-blue) "],["local-approximations.html", "Chapter 24 Local approximations 24.1 Eight simple shapes 24.2 Low-order polynomial 24.3 The low-order polynomial with two inputs 24.4 Derivatives of polynomials 24.5 Approximations around \\(x^\\star\\) 24.6 Solving computationally 24.7 From an earlier draft", " Chapter 24 Local approximations We have focused in this book on a small set of basic modeling functions and three operations for assembling new functions out of old ones: linear combination, multiplication, and composition. All of these have a domain that is the whole number line, or the positive half of the number line, or perhaps the whole number line leaving out zero or some other isolated point. Consider such domains to be global. We also discussed the components of piecewise functions. Each component is a function defined on a limited domain, and interval \\(a \\leq x \\leq b\\). In contrast to the global domains, we’ll call the limited domains local. In this chapter, we’ll explore a simple and surprisingly powerful method to approximate any function locally, that is, over a small domain. Why would you want to approximate a function? Why not just use the function itself? It’s often the case—in some fields, usually the case—that we don’t have a functional form for a relationship. Instead we know about the relationship only through data. It’s possible that by deep introspection you or a colleague could construct a theory of the relationship that points to one of the basic modeling functions or a combination of them. Suppose you could? Then anyone else having your theory in mind could approximate your function locally using the methods in this chapter. The utility of the methods is that you can skip the theoretical relationship and apply the methods directly to the data. Such a skip-the-theory approach is ubiquitous in all fields. The information that you have about the relationship often takes the form of a data table. Each row shows records one trial in which the values of the inputs have been measured and the corresponding output value recorded. We’ll discuss the methods of constructing functions to match such data in Block 4 of this course. Another common form for the information about the relationship is about derivatives. That is, you know something about the derivative of a relationship even though you don’t (yet) have a form for the function describing the relationship. As an example, think about building a model of the sustainable speed of a bicycle as a function of the gear selected and the grade of the road—up or down. Consider these three questions that any experienced bicyclist can likely answer: On a given grade of road, is there an optimal gear for the highest sustained speed? (Have in mind a particular rider, perhaps yourself.) Imagine that the grade of the road is described by a positive number for uphill and a negative number for downhill: that is, the slope of the road. For a positive (uphill) grade and at a fixed gear, will the bike’s sustained speed be higher or lower as a function of the grade? (It’s much the same for downhill biking, but you have to keep in mind that a shallow downhill has a higher numerical slope than a steep downhill. That is, the derivative of the hill is near zero for a very shallow grade and far from zero (that is, more negative) for a steep downhill grade. Assuming you answered “yes” to question (1): Does the optimal gear choice depend on the grade of the road? (In concrete terms, would you choose different gears for an uphill climb than for a level road or a downhill stretch?) Using the methods in this chapter, the answers to those three questions let you choose an appropriate form for the speed(gear, grade) function. Then, using methods in Block 3, you can make a few measurements for any given rider and construct a model customized to that rider. Note that the three questions all have to do with derivatives. An “optimal gear” is a gear at which \\(\\partial_\\text{gear} \\text{speed}(\\text{gear}, \\text{grade}) = 0\\). That you ride slower the higher the numerical value of the slope means that \\(\\partial_\\text{grade} \\text{speed}(\\text{gear}, \\text{grade}) &lt; 0\\). And we know that \\(\\partial_\\text{gear} \\text{speed}(\\text{gear}, \\text{grade})\\) depends on the grade; that’s why there’s a different optimal gear at each grade. 24.1 Eight simple shapes In many modeling situations with a single input, you can get very close to a good modeling function \\(f(x)\\) by selecting one of eight simple shapes. I’ve sketched these out and annotated them with their properties and examples of function forms that have that shape. Straight-line functions sloping upward sloping downward not concave, slopes up, monotonic not concave, slopes down, monotonic \\(a x + b\\) \\(b - ax\\) shallow then steep concave down concave up monotonic monotonic \\(a - b e^{kx}\\) \\(a + b e^{kx}\\) steep then shallow concave down concave up monotonic monotonic \\(\\ln(x)\\) \\(e^{-kx}\\) \\(-1/x\\) \\(1/x\\) local extremum maximum minimum not monotonic not monotonic \\(a x^2\\) \\(-a x^2\\) \\(\\hump(x)\\) \\(-\\hump(x)\\) To choose among these shapes, consider your modeling context: is the relationship positive (slopes up) or negative (slopes down) is the relationship monotonic or not is the relationship concave up, concave down, or neither For instance, in micro-economic theory there are production functions that describe how much of a good is produced at any given price, and demand functions that describe how much of the good will be purchased as a function of price. As a rule, production increases with price and demand decreases with price. In the short term, production functions tend to be concave down, since it’s hard to squeeze increased production out of existing facilities. In the long term, production functions can be concave up as new businesses are established to meet demand. For demand in the short term, functions will be concave up when there is some group of consumers who have no other choice than to buy the product. An example is the consumption of gasoline versus price: it’s hard in the short term to find another way to get to work. In the long term, consumption functions can be concave down as consumers find alternatives to the high-priced good. For example, high prices for gasoline may, in the long term, prompt a switch to more efficient cars, hybrids, or electric vehicles. This will push demand down steeply. Cooling water or radio-activity as functions of time concave up and steep-then-shallow. The incidence of an out-of-control epidemic versus time is concave up, but shallow-then-steep. As the epidemic is brought under control, the decline is steep-then-shallow and concave up. Over the whole course of an epidemic, there is a maximum incidence. And experience shows that epidemics can have a phase where incidence reaches a local minimum: a decline as people practice social distancing followed by an increase as people become complacent. How many minutes can you run as a function of speed? Concave down and shallow-then-steep; you wear out faster if you run at high speed. How far can you walk as a function of time? Steep-then-shallow and concave down; you’re pace slows as you get tired? How much fuel is consumed by an aircraft as a function of distance? For long flights the function is concave up and shallow-then-steep; fuel use increases with distance, but the amount of fuel you have to carry also increases with distance and heavy aircraft use more fuel per mile. How does the stew taste as a function of saltiness. The taste improves as the amount of salt increases … up to a point after which it’s downhill. All these are examples of scenarios where the modeler knows about the derivative and concavity of the relationship being modeled. It’s often the case that your knowledge of the system comes in this form. As you see, there are often multiple basic modeling functions that can be used to construct a model that follows the appropriate slope and curvature pattern. But we can simplify the choice as well as the algebra involved in building a model. 24.2 Low-order polynomial There is a function form that can take on each of the eight forms, a second-order polynomial \\(g(x)\\) where \\[g(x) \\equiv a + b x + c x^2\\] As you know, the graph of \\(g(x)\\) is a parabola. The parabola opens upward if \\(0 &lt; c\\). That’s the shape of a local minimum. The parabola opens downward if \\(c &lt; 0\\). That’s the shape of a local maximum Consider what happens if \\(c = 0\\). The function becomes simply \\(a + bx\\), the straight-line function. When \\(0 &lt; b\\) the line slopes upward. When \\(b &lt; 0\\) the line slopes downward. So the form \\(a + bx + cx^2\\) is easily capable of representing four of the eight simple shapes. What about the other four? You can see how this is done by looking at the graphs of the parabolas with \\(0 &lt; c\\) and with \\(c &lt; 0\\), as in Figure ??. Figure 24.1: Four of the eight simple shapes correspond to the sides of the parabola. Figure 24.2: Four of the eight simple shapes correspond to the sides of the parabola. 24.3 The low-order polynomial with two inputs For functions with two inputs, the low-order polynomial approximation looks like this: \\[g(x, y) \\equiv a_0 + a_x x + a_y y + a_{xy} x y + a_{yy} y^2 + a_{xx} x^2\\] In reading this form, note the system being used to name the polynomial’s coefficients. First, we’ve used \\(a\\) as the root name of all the coefficients. Sometimes we might want to compare two or more low-order polynomials, so it’s convenient to be able to use \\(a\\) for one, \\(b\\) for another, and so on. The subscripts on the coefficients describes exactly which term in the polynomial involves each coefficient. For instance, the \\(a_{yy}\\) coefficient applies to the \\(y^2\\) term, while \\(a_x\\) applies to the \\(x\\) term. Each of \\(a_0, a_x,\\) \\(a_y,\\) \\(a_{xy}, a_{yy}\\), and \\(a_{xx}\\) will, in the final model, be a constant quantity. Don’t be confused by the use of \\(x\\) or \\(y\\) in the name that the coefficient is a function of the inputs. It’s always a constant, but you may not know exactly the value of that constant until later in in the process of modeling the setting of interest. It helps to have different names for the various terms. It’s not too bad say something like, “the \\(a_{xy}\\) term.” (Pronounciation: “a sub x y”) But the proper names are: linear terms, quadratic terms, and interaction term. (And a shout out to \\(a_0\\), the constant term.) \\[g(x, y) \\equiv a_0 + \\underbrace{a_x x + a_y y}_\\text{linear terms} \\ \\ \\ + \\underbrace{a_{xy} x y}_\\text{interaction term} +\\ \\ \\ \\underbrace{a_{yy} y^2 + a_{xx} x^2}_\\text{quadratic terms}\\] Figure 24.3: A saddle Figure 24.3: A saddle show_poly2(111) show_poly2(112) show_poly2(113) show_poly2(115) show_poly2(116) show_poly2(120) show_poly2(121) 24.4 Derivatives of polynomials Consider the function \\(h(t) \\equiv A e^{kt} + B\\). This is a linear combination of two functions, which we can call \\(f(t) \\equiv e^{kt}\\) and \\(g(t) \\equiv 1\\). Of course, \\(f(t)\\) and \\(g(t)\\) are basic modeling functions so we have memorized their derivatives: \\(f&#39;(t) = k e^{kt}\\) and \\(g&#39;(t) = 0\\). Putting this together gives \\[\\partial_t h(t) = A\\, k\\, e^{kt} + B\\times 0= A\\, k\\, e^{kt}\\] The derivative of a polynomial follows the linear combination rule. That’s because polynomials are a linear combination of monomials, \\(x^0\\), \\(x^1\\), \\(x^2\\), and so on. The consequence is that the derivative of a polynomial is another polynomial, with each term being reduced by one order. \\(\\partial_x x^0 = 0\\) \\(\\partial_x x^1 = x^0 = 1\\) \\(\\partial_x x^2 = 2 x^1 = 2x\\) and so on. Example: \\(f(x) \\equiv a + b x + c x^2\\ \\ \\implies\\ \\ \\partial_x f(x) \\equiv b + 2 c x\\) 24.5 Approximations around \\(x^\\star\\) Starting with just the naked modeling functions (e.g. \\(e^t\\)), you have a small but rich set of mathematical operations that enables you to make a huge variety of functions to suit a big range of modeling needs: input scaling, which turns the naked modeling functions into the more directly useful basic modeling functions. linear combinations of functions, e.g. \\(A + B e^{-kt}\\) compositions of functions, e.g. \\(e^{-kt^2}\\) which you can recognize as the composition of an exponential with a power-law function. products of functions, e.g., \\(\\sin\\left(\\frac{2\\pi}{P}x\\right) e^{-kt}\\) Now we want to tame this profusion of possibilities and consider a way to construct stand-ins for any function, using a universal format that needs a minimum of information and can be used for many purposes in place of the original function. It’s helpful to have a name for the stand-ins that reminds us of whom they are stand-ins for. If the original function is \\(f(x)\\), we’ll write the names of the stand-ins with a tilde, as in \\(\\widetilde{\\,f\\ }(x)\\). The stand-in functions are intended to be much simpler than the original but useable as a substitute for the original. The catch is that the stand-in is warranteed to be a good substitute only within a small neighborhood of the domain of the origin. The information we need to construct the stand-ins is very limited. First, we need to specify where the warranteed neighborhood is. We’ll tend to use \\(x_0\\) as identifying the center of that neighborhood. We’ll also need \\(f(x_0)\\), the output of the original function when the input is \\(x_0\\), and \\(\\partial_x f(x_0)\\) and \\(\\partial_{xx} f(x_0)\\). This is a good time to remind you of the notation conventions that we are using to write about functions and evaluating functions. A function with all its individual characteristics and idiosyncracies is written \\(f(x)\\): the function name and the name of the input or inputs. The name of this function is \\(f()\\). The name of the input to \\(f()\\) is \\(x\\), or whatever is the input name that was given in the parentheses following the name. Every function has a derivative function. We could call that derivative function anything we like, but it’s sensible to give it a name that states explicitly where it comes from. We’re using \\(\\partial_x f(x)\\) for this purpose. Similarly, the name we use for the second derivative is \\(\\partial_{xx} f(x)\\). Evaluating a function means to specify a particular value for the input. We use several ways of making it clear when we are talking about a particular value of the input, e.g. \\[\\mbox{function output:}\\ \\ \\ f(x = 3)\\ \\ \\ \\text{or}\\ \\ f(3)\\ \\ \\ \\text{or}\\ \\ \\left.f(x)\\strut\\right|_{x=3}\\] The output of such an evaluated function is a quantity. Sometimes we want to refer to the output for some particular input, but we don’t have that specific quantity pinned down yet. Our preferred style for writing this is to use a name that is similar to an input name, but which has a subscript as in \\(x_0\\), \\(x_1\\), \\(x_i\\), \\(x_\\star\\) or, occasionally, a superscript as in \\(x^\\star\\). The output of the function is then written like this: \\[\\mbox{function output:}\\ \\ \\ f(x = x_0)\\ \\ \\ \\text{or}\\ \\ f(x_0)\\ \\ \\ \\text{or}\\ \\ \\left.f(x)\\strut\\right|_{x=x_0}\\] This same style applies when the function has a name like \\(\\partial_x f()\\) or \\(\\partial_{xx} f()\\), for instance \\[\\mbox{function output:}\\ \\ \\ \\partial_x f(x = x_0)\\ \\ \\ \\text{or}\\ \\ \\partial_x f(x_0)\\ \\ \\ \\text{or}\\ \\ \\left.\\partial_x f(x)\\strut\\right|_{x=x_0}\\] Here are two universal formats that can be used to construct a stand-in for any function near a particular input \\(x_0\\). Since it’s useful to have a name for the stand-in, we’ll use a tilde on top of the original function name: First-order approximation: \\(\\widetilde{f_1}(x) \\equiv f(x_0) + \\partial_x f(x_0) (x-x_0)\\) Second-order approximation: \\(\\widetilde{f_2}(x) \\equiv f(x_0) + \\partial_x f(x_0) [x-x_0] + \\frac{1}{2} \\partial_{xx} f(x_0) [x - x_0]^2\\) Notice that the first two terms of \\(\\widetilde{f_2}(x)\\) are identical to \\(\\widetilde{f_1}(x)\\), so we could write the second-order approximation as \\[\\widetilde{f_2}(x) \\equiv \\widetilde{f_1}(x) +\\frac{1}{2} \\partial_{xx} f(x_0) [x-x_0]^2\\] The first-order approximation \\(\\widetilde{f_1}(x)\\) is nothing more than the straight-line function whose graph is tangent to the graph of \\(f(x)\\) at the input \\(x=x_0\\). The second-order approximation is a quadratic polynomial. Being quadratic, its graph is the familiar parabola. The graph of \\(\\widetilde{f_2}(x)\\) is the parabola that is tangent to the graph of \\(f(x)\\). Consider the function \\(g(x)\\) whose graph is shown in Figure ??. ## Warning: geom_vline(): Ignoring `mapping` because `xintercept` was provided. ## Warning: geom_vline(): Ignoring `mapping` because `xintercept` was provided. We haven’t given you a formula for \\(g(x)\\), but you can see that it isn’t any of the basic modeling functions but something more complicated. We’re going to construct a first-order and second-order approximation to \\(g(x)\\) in a neighborhood \\(x_0 = -1\\) as marked by the blue shaded area. Note that \\(x_0\\) is not an argmin of \\(g(x)\\). You can see that the argmin is a little to the right of \\(x_0\\). The “facts” about \\(g(x)\\) that are needed to construct the approximations, beyond the specification of the location of the neighborhood \\(x_0\\), are the values \\(g(x_0)\\), \\(\\partial_x g(x_0)\\), and \\(\\partial_{xx} g(x_0)\\). These are: x0 &lt;- -1 g(x0) ## [1] -23.992 dx_g &lt;- D(g(x) ~ x) dxx_g &lt;- D(g(x) ~ x + x) dx_g(x0) ## [1] -2.3493 dxx_g(x0) ## [1] 7.8077 With these facts, we can construct the first- and second-order approximations: tilde1_g &lt;- makeFun(-23.992 - 2.3493*(x-x0) ~ x) tilde2_g &lt;- makeFun(tilde1_g(x) + (7.8077/2) * (x-x0)^2 ~ x) Figure 24.4 shows \\(\\widetilde{g_1}(x)\\) and \\(\\widetilde{g_2}(x)\\), zooming in around \\(x_0 = -1\\). ## Warning: geom_vline(): Ignoring `mapping` because `xintercept` was provided. ## Warning: geom_vline(): Ignoring `mapping` because `xintercept` was provided. Figure 24.4: The first-order (green) and second-order (red) approximations to \\(g(x)\\) near \\(x_0=-1\\). You can see that \\(\\widetilde{g_2}(x)\\) is a good approximation to \\(g(x)\\). In particular, the argmin of \\(\\widetilde{g_2}(x)\\) is close to the that of \\(g(x)\\). In a previous example, we showed that the argmin of the parabolic function \\(a_0 + a_1 x + a_2 x^2\\) is \\(x^\\star = -\\frac{a_1}{2 a_2}\\). Using that formula, the argmin of \\(\\widetilde{g_2}(x)\\) is -2.3493/(7.8077/2) = -0.602. 24.6 Solving computationally How to find the zeros of the derivative of a function and how to evaluate the second derivative at those zeros to find out what kind of critical point it is. The cubic bifurcation. Start with a cubic with an argmax followed by an argmin. Then move the parameter to see the two critical points coalesce into a single point then disappear. Or, maybe, “the problem with polynomials.” Linear function always has 1 root and no critical points. Quadratic function always has one critical point (and subject to a constant may have two roots generically). But a cubic might have 1 or 3 solutions and the behavior depends on the constant. It might have one or three critical points. 24.7 From an earlier draft When facing a modeling problem, it’s nice to have a framework that provides a checklist approach: What is the output quantity and what input quantities are thought to have an important connection to the output? For each input in (1), what is a An important framework for simple models involves A function form often employed in models is the low-order polynomial. In the usual situation, there is region of the domain which is of particular interest, with \\(x_0\\) being a point in that region. The approximating polynomial starts out as \\[p(x) \\equiv \\frac{1}{2} a [x-x_0]^2 + b [x - x_0] + c\\] \\(f(x) = c\\), the constant function, which is appropriate when the output of \\(f()\\) doesn’t depend on the input. \\(f(x) = b x + c\\), the straight-line function, which is the simplest form where the output depends on the input. \\(f(x) = \\frac{1}{2}a x^2 + b x + c\\), the quadratic function, which is an appropriate form when there is some input \\(x\\) at which the output is a local maximum or minimum. In many modeling situations, the construction of a model function can be reduced to a short series of questions: What is the approximate output when the input is fixed neighborhood of interest? Does the output increase monotonically or is there a maximum or minimum? slice_plot((x+1)^0.5 ~ x, domain(x=c(0,1))) %&gt;% slice_plot(2*log(x+1) ~ x, color=&quot;red&quot;) %&gt;% slice_plot(.2*exp(x+1) ~ x, color=&quot;green&quot;) %&gt;% slice_plot(2*exp(-(x+1)) ~ x, color=&quot;orange&quot;) %&gt;% slice_plot(1/(x+2) ~ x, color=&quot;blue&quot;) 2 1.5, 1, .5, log(), -.5, [Deriv-5a] Understand strategy of looking at the behavior of function \\(f(x)\\) around a point \\(x_0\\) by considering a new, possibly simpler function in terms of \\(x\\). [Deriv-5b] Be able to construct a straight-line function (Linear Approximation) that approximates \\(f(x)\\) around \\(x_0\\) [Deriv-5c] Be able to construct a 2nd-order polynomial (Quadratic Approximation) whose value and derivatives at match those of a function Example about modeling walking There’s an exercise in DailyDigitals/ 141 DD-35 with some narrative and the project is in DD-37 Harvest the shiny app materials in DailyDigital/daily-digital-38.Rmd. Exercise 24.1 (rooster-pink) Consider the model presented in class of energy expenditure walking distance \\(d\\) on a grade \\(g\\): \\[E(d,g) = (a_0 + a_1 g)d\\] where \\(d\\) is the (horizontal equivalent) of the distance walked and \\(g\\) is the grade of the slope (that is, rise over run). We want \\(E\\) to be measured in Joules. Question A What is the dimension of Joules? dimensionless ☹︎ \\(L/T^2\\) ☹︎ \\(T/L^2\\) ☹︎ \\(M/T^2\\) ☹︎ \\(M L/T^2\\) ☹︎ \\(M/L^2\\) ☹︎ \\(M/(L^2 T^2)\\) ☹︎ \\(M L^2 / T^2\\) ✓ Question B What is the dimension of the parameter \\(a_0\\)? dimensionless ☹︎ \\(L/T^2\\) ☹︎ \\(T/L^2\\) ☹︎ \\(M/T^2\\) ☹︎ \\(M L/T^2\\) ✓ \\(M/L^2\\) ☹︎ \\(M/(L^2 T^2)\\) ☹︎ \\(M L^2 / T^2\\) ☹︎ Question C What is the dimension of \\(g\\)? dimensionless ✓ \\(L/T^2\\) ☹︎ \\(T/L^2\\) ☹︎ \\(M/T^2\\) ☹︎ \\(M L/T^2\\) ☹︎ \\(M/L^2\\) ☹︎ \\(M/(L^2 T^2)\\) ☹︎ \\(M L^2 / T^2\\) ☹︎ Question D What is the dimension of the parameter \\(a_1\\)? dimensionless ☹︎ \\(L/T^2\\) ☹︎ \\(T/L^2\\) ☹︎ \\(M/T^2\\) ☹︎ \\(M L/T^2\\) ✓ \\(M/L^2\\) ☹︎ \\(M/(L^2 T^2)\\) ☹︎ \\(M L^2 / T^2\\) ☹︎ Exercise 24.2 (rooster-violet) Suppose we describe the spread of an infection in terms of three variables: \\(N\\) infection rate with respect to time: the number of new infections per day \\(I\\) the current number of people who are infectious, that is, currently capable of spreading the infection \\(S\\) the number of people who are susceptible, that is, currently capable of becoming infectious if exposed to the infection. All three of these variables are functions of time. News reports in 2020 routinely such as the one below gave the graph of \\(N\\) versus time for Covid-19. On November 15, 2020, \\(N\\) was 135,187 people per day. (This is the number positive tests. The true value of \\(N\\) is 5-10 times greater.) The news reports don’t usually report \\(S\\) on a day-by-day basis. But a basic strategy in modeling with calculus is to take a snapshot: Given \\(I\\) and \\(S\\) today, what is a model of \\(N\\) for today. (Next semester, we’ll study “differential equations,” which provide a way of assembling from the snapshot model what the time course of the pandemic will look like.) The low-order polynomial for \\(N(S, I)\\) is \\[N(S,I) = a_0 + a_1 S + a_2 I + a_{12} I S.\\] We don’t include quadratic terms because there is no local maximum in \\(N(S, I)\\)—common sense suggests that \\(\\partial_S N() \\geq 0\\) and \\(\\partial_I N() \\geq 0\\), whereas a local maximum requires at least one of these derivatives to be negative near the max. Your job is to figure out which, if any, terms can be safely deleted from the low-order polynomial. A good way to approach this is to figure out, using common sense, what \\(N\\) would be for either \\(S=0\\) or \\(I=0\\). (Note that the previous is not restricted to \\(S = I = 0\\). Only one of them needs to be zero to produce the relevant result.) Question A Which of these is a sufficiently complete low-order polynomial given the behavior of \\(N\\) at \\(S=0\\) or \\(I=0\\)? \\(N(S,I) = a_0 + a_1 S + a_2 I + a_{12} I S\\) ☹︎ We don’t need all four terms. Think about it! \\(N(S,I) = a_0 + a_1 S + a_2 I\\) ☹︎ When both \\(S\\) and \\(I\\) are zero, \\(N\\) would be non-zero. \\(N(S,I) = a_1 S + a_2 I + a_{12} I S\\) ☹︎ \\(N(S,I) = a_2 I + a_{12} I S\\) ☹︎ \\(N(S,I) = a_1 S + a_{12} I S\\) ☹︎ \\(N(S,I) = a_{12} I S\\) ✓ \\(N(S,I) = a_1 S + a_2 I\\) ☹︎ Exercise 24.3 (rooster-red) It often happens in decision making that there are multiple criteria. For instance, in selecting cadets for pilot training, two obvious criteria are the cadet’s demonstrated flying aptitude and the leadership potential of the cadet. Let’s assume that the merit \\(M\\) of a candidate is a function of flying aptitude \\(F\\) and leadership potential \\(L\\). A simple model of decision making is that the candidates are ordered from highest \\(M\\) to lowest. Then, depending on how many pilot trainees are required, a threshold is set for \\(M\\) and candidates with \\(M\\) greater than the threshold are accepted. You’ve been tasked to develop a formula for use in the pilot-training selection process. A low-order polynomial model is \\[M(F, L) = d_0 + d_1 F + d_2 L + d_{12} F L ,\\] where both \\(d_1\\) and \\(d_2\\) are positive. (Think for a minute about why the coefficients must be positive to make sense as a way of combining \\(F\\) and \\(L\\) into a measure of merit.) You are trying to decide whether \\(d_{12}\\) should be positive, negative, or zero. To guide your decision, you have only this statement from the general in charge of the program: “I would rather have an good pilot who is a good leader than have a great pilot who is a poor leader or a poor pilot who is a great leader.” (You might reasonably agree or disagree with this point of view, but remember who is commanding whom.) Take a few minutes now to think about how you would decide whether \\(d_{12}\\) should be positive or negative or zero to implement the general’s view. The rest of the problem will guide you to a solution, but you’ll understand better if you try on your own, first. Using the low-order polynomial model, find algebraically these two partial derivatives \\(\\partial_F M(F, L)\\) and \\(\\partial_L M(F, L)\\) Question A Which of these possibilities is true about \\(\\partial_F M\\) as a function of \\(F\\)? Increases with F ☹︎ Decreases with F ☹︎ Is not a function of F. ✓ Question B Which of these possibilities is true about \\(\\partial_L M\\) as a function of \\(L\\)? Increasing ☹︎ Decreasing ☹︎ Is not a function of L. ✓ Question C Which one of these describes the relationship between \\(\\partial_F M()\\) as a function of \\(L\\) and \\(\\partial_L M()\\) as a function of \\(F\\)? (Hint: Remember that \\(d_1\\) and \\(d_2\\) are specified as being positive.) If \\(\\partial_F M()\\) is an increasing function of \\(L\\), then \\(\\partial_L M()\\) must be a decreasing function of \\(F\\). ☹︎ Notice that both partials involve the same \\(d_{12}\\) coefficient. If \\(\\partial_F M()\\) is an increasing function of \\(L\\), then \\(\\partial_L M()\\) must be an increasing function of \\(F\\). ✓ Neither of the above needs to be true. ☹︎ Notice that both partials involve the same \\(d_{12}\\) coefficient. Think now about the general’s statement and how to translate it into mathematical terms. Here’s a hint: Imagine Drew has very high \\(F\\) score and low \\(L\\) score. Consider another cadet, Blake, with scores \\(F-\\epsilon\\) and \\(L + \\epsilon\\). Blake’s flying and leadership scores are closer together than Drew’s. Both Drew and Blake have exactly the same average of \\(F\\) and \\(L\\). But would the general find Blake superior or inferior to Drew? If superior, then you would want \\(\\partial_L M &gt; \\partial_F M\\). If inferior, then your model should have \\(\\partial_L M &lt; \\partial_F M\\). If the general would be indifferent between Drew and Blake, then the two partial derivatives should be equal. Question D Based on the general’s statement, do you want \\(d_{12}\\) to be positive, negative, or zero? Positive ✓ Zero ☹︎ Negative ☹︎ It has nothing to do with the general’s statement. ☹︎ Exercise 24.4 (approx-tan) In this exercise, you’re going to be looking at the shape of contour lines very close to a reference point. The graph shows which function we’ll be examining. The contours are unlabeled, to avoid distracting you with numbers; we’re interested in shapes. Four different reference points are marked, with these coordinates label x0 y0 A -2.100 3.000 B -0.400 2.500 C -1.605 1.932 D 1.265 -2.725 For each of the reference points A to D, your job is to zoom in on the region around that point. The graphing expression in the sandbox has been written in a way that allows you to specify exactly the coordinates of the reference point, and the size of the region around that reference point being plotted. The initial example in the sandbox is for reference point A and a region size of 0.5. The reference point will always be exactly in the center of the plot. You are to consider the sequence of region sizes \\[\\mbox{size}: 0.5,\\ 0.1,\\ 0.05,\\ 0.01,\\ 0.005,\\ 0.001,\\ 0.0005,\\ 0.0001\\] Start at the largest size and try successively smaller sizes until you find a size where the shape of the contour lines is simple and very similar to the shape from the previous size. (Ignore the contour labels: just look at the shape.) x0 &lt;- -2.100 y0 &lt;- 3.000 size &lt;- 1.0 contour_plot(g(x, y) ~ x + y, domain(x = x0 + size*c(-1, 1), y = y0 + size*c(-1, 1))) Question A 1a) For reference point A how small should size be so that the shape of the contours does not differ substantially from the shape at the previous size.     0.1 ☹︎        0.01 ✓        0.001 ☹︎        1e-04 ☹︎ Question B 1b) For reference point A which phrase best describes the shape of the contours at the size you found in question (1a). contours are straight and almost exactly parallel and evenly spaced ✓ contours are straight, almost exactly parallel, but unevenly spaced. ☹︎ contours are straight, but fan out a bit ☹︎ contours are curved but concentric and evenly spaced ☹︎ contours are curved and concentric, but unevenly spaced. ☹︎ Question C 2a) For reference point B how small should size be so that the shape of the contours does not differ substantially from the shape at the previous size.     0.1 ☹︎        0.01 ✓        0.001 ☹︎        1e-04 ☹︎ Question D 2b) For reference point B which phrase best describes the shape of the contours at the size you found in question (2a). contours are straight and almost exactly parallel and evenly spaced ✓ contours are straight, almost exactly parallel, but unevenly spaced. ☹︎ contours are straight, but fan out a bit ☹︎ contours are curved but concentric and evenly spaced ☹︎ contours are curved and concentric, but unevenly spaced. ☹︎ Question E 3a) For reference point C how small should size be so that the shape of the contours does not differ substantially from the shape at the previous size.     0.1 ☹︎        0.01 ☹︎        0.001 ✓        1e-04 ☹︎ Question F 3b) For reference point C which phrase best describes the shape of the contours at the size you found in question (3a). contours are straight and almost exactly parallel and evenly spaced ✓ contours are straight, almost exactly parallel, but unevenly spaced. ☹︎ contours are straight, but fan out a bit ☹︎ contours are curved but concentric and evenly spaced ☹︎ contours are curved and concentric, but unevenly spaced. ☹︎ Question G 4a) For reference point D how small should size be so that the shape of the contours does not differ substantially from the shape at the previous size.     0.1 ☹︎        0.01 ☹︎        0.001 ☹︎        0.0001 ✓ Question H 4b) For reference point D which phrase best describes the shape of the contours at the size you found in question (4a). contours are straight and almost exactly parallel and evenly spaced ✓ Almost always, if you zoom in enough, the contours will be straight, almost parallel, and evenly spaced. The exceptions are if the reference point is exactly at a local maximum or minimum (point C is very close, but not exactly on the maximum) or exactly at a saddle point (point D is very close, but not exactly on the saddle point). contours are straight, almost exactly parallel, but unevenly spaced. ☹︎ contours are straight, but fan out a bit ☹︎ contours are curved but concentric and evenly spaced ☹︎ contours are curved and concentric, but unevenly spaced. ☹︎ Exercise 24.5 (rooster-blue) Consider the road descent summarized by this sign … The “grade” of road is defined to be rise-over-run. Since both rise and run have dimension \\(L\\), the ratio is dimensionless. The grade in percent is 100 times rise-over-run. A 100% grade corresponds to a \\(45^\\circ\\) angle. Question A Taking the “run” to be the 5 miles indicated on the sign, what’s the “rise?” (You can find unit conversion data on the internet.) 0.91 miles ☹︎ Close, but 18% times 5 miles is 0.9 miles. 4752 feet ✓ 1.5 km ☹︎ This is 0.932 miles. 292 rods ☹︎ This is 0.9125 miles. 7.36 furlongs ☹︎ This is 0.92 miles. 22.64 \\(\\sqrt{\\mbox{acre}}\\) ☹︎ A square-root of an acre is an unconventional unit for length. One acre is 43560 ft\\(^2\\), so the square root of an acre is 208.71 feet or 0.03953 miles. So 22.64 \\(\\sqrt{\\mbox{acre}}\\) is 0.895 miles. Since a vehicle’s odometer measures distance along the road surface rather than along the horizontal “run,” it’s likely that the sign-makers had in mind 5 miles being the length of the hypotenuse of the triangle rather than the horizontal leg. Question B Which of these expressions gives the horizontal run for a rise of \\(y\\) miles? \\(\\sqrt{5 - y^2}\\) ☹︎ \\(\\sqrt{25 - y^2}\\) ✓ \\(\\sqrt{y^2 + 25}\\) ☹︎ \\(\\sqrt{y^2+5}\\) ☹︎ Question C Given that the grade is 18% and that the length of the road surface is 5 miles, what is the “rise?” 0.85 miles ☹︎ 1.40 km ☹︎ 283.5 rods ✓ 6.8 furlongs ☹︎ 22.01 \\(\\sqrt{\\mbox{acre}}\\) ☹︎ [Deriv-9a] Eliminate terms in a possible model by considering simple inputs for which the result is known. [Deriv-9b] Understand the concept of grade as it relates to elevation change. [Deriv-9c] Use dimensional analysis to determine the units of terms within a model. "],["approximation-near-a-reference-input.html", "Chapter 25 Approximation near a reference input 25.1 The reference point 25.2 Taylor polynomials 25.3 Polynomials and data", " Chapter 25 Approximation near a reference input Back in Chapter 24 we considered eight simple shapes for functions of one input: Figure 25.1: The eight simple shapes, locally, of functions with one input. (See Chapter 24.) All these simple shapes can be generated with the same function formula and appropriate values for parameters \\(a\\), \\(b\\), and \\(c\\). \\[g(x) \\equiv a_0 + a_1 x + a_2 x^2\\] This chapter examines the possibilities for extending the formula a bit, to include higher-order terms, e.g. \\[h(x) \\equiv a_0 + a_1 x + a_2 x^2 + a_3 x^3 + a_4 x^4 + \\cdots\\] We’ll consider two possible applications: Creating an arithmetically simple approximation to a function whose formula is already known. Such approximations are known as Taylor polynomials. Creating a function to capture the patterns in data, as in Chapter 24. It turns out that this is a dubious practice. We discuss the reasons why so that you can know to avoid using high-order polynomials to fit data. 25.1 The reference point Since this is all about approximations, we need to have a way to specify the neighborhood of the function domain in which the approximation is intended to be good enough for use. We can use the same approach that turned the naked modeling functions (e.g., \\(x\\), \\(x^2\\), …) into the basic modeling functions: replacing \\(x\\) in the polynomial with \\(\\line(x)\\). But unlike the basic modeling functions, where the useful form of \\(\\line()\\) was usually \\(ax + b\\), here, we’ll use just a shift form of line, where the slope is 1: \\[\\text{shift}(x) \\equiv \\left[\\strut x - x_0\\right]\\] The parameter \\(x_0\\) is called the reference point. For a power-law function, \\[\\left[\\strut\\text{shift}(x)\\right]^n = \\left[\\strut x - x_0\\right]^n\\] the output is always zero when \\(x=x_0\\), which will be a matter of considerable importance as we go on. Also, note that we’re using square braces \\(\\left[\\ \\ \\right]\\) simply to make it completely unambiguous what is being exponentiated. Exercise 25.1 (locate-shift) Several exercises of this sort: Here are graphs of three power-law functions (that is, \\(\\left[x-x_0\\right]^n\\)) with different values of \\(x_0\\): Question A For the blue function, what is \\(x_0\\)?     -2 ☹︎        -1 ☹︎        0 ☹︎        1 ☹︎        2 ☹︎        3 ☹︎        4 ✓        5 ☹︎ Question B For the blue function, what is the order of the polynomial?     0 ☹︎        1 ✓        2 ☹︎        3 ☹︎        4 ☹︎        5 ☹︎ Question C For the red function, what is \\(x_0\\)?     -2 ☹︎        -1 ☹︎        0 ☹︎        1 ☹︎        2 ✓        3 ☹︎        4 ☹︎        5 ☹︎ Question D For the red function, what is the order of the polynomial?     0 ☹︎        1 ✓        2 ☹︎        3 ☹︎        4 ☹︎        5 ☹︎ Question E For the green function, what is \\(x_0\\)?     -2 ☹︎        -1 ☹︎        0 ☹︎        1 ☹︎        2 ☹︎        3 ☹︎        4 ✓        5 ☹︎ Question F For the green function, what is the order of the polynomial?     0 ☹︎        1 ☹︎        2 ☹︎        3 ✓        4 ☹︎        5 ☹︎ With the reference point \\(x_0\\) we will re-write the approximating polynomial as \\[h(x) \\equiv a_0 + a_1 [x-x_0] + a_2 [x - x_0]^2 + a_3 [x - x_0]^3 + \\cdots\\] This format is convenient because in finding the \\(a_0\\), \\(a_1\\), \\(\\ldots\\) for approximating a function \\(f(x)\\) in the neighborhood of \\(x_0\\), we have a way to calculate quickly the value of \\(a_0\\). Note that at \\(x=x_0\\), all the terms in the polynomial go to zero except the first, so we know \\(a_0 = f(x_0)\\). Now consider the derivative of the approximating polynomial. This is \\[\\partial_x h(x) = a_1 + 2 \\times a_2 [x-x_0] + 3 \\times a_3 [x-x_0] + \\cdots\\] Again, at \\(x=x_0\\) all the terms except the first go to zero. So if \\(h(x)\\) is an approximation to \\(f(x)\\) we’ll have \\(a_1 = \\partial_x f(x_0)\\). We can do this as many times as we want. Here’s the second derivative \\(\\partial_{xx} h(x)\\): \\[\\partial_{xx} h(x) = 2 a_2 + 2 \\times 3 \\times a_3 [x-x_0] + \\cdots\\] and the third \\[\\partial_{xxx} h(x) = 2 \\times 3 \\times a_3 + \\cdots\\] As before, all the terms in \\(\\partial_{xx} h()\\) and \\(\\partial_{xxx} h()\\) except the first go to zero when \\(x=x_0\\). This implies \\[a_2 = \\frac{1}{2} \\partial_{xx} f(x_0) \\ \\ \\ \\text{and}\\ \\ \\ a_3 = \\frac{1}{2\\times 3} \\partial_{xxx}f(x_0)\\] Just following the pattern, we can guess that \\(a_4 = \\frac{1}{2 \\times 3 \\times 4} \\partial_{xxxx} f(x_0)\\) and, in general for the nth term \\[a_n = \\frac{1}{1\\times 2 \\times 3 \\times \\cdots \\times n} \\partial^n f(x_0)\\] We’re writing \\[{\\huge \\partial^n} \\ \\text{to stand for}\\ \\ \\stackrel{\\Huge \\partial}{\\ } \\underbrace{xx...x}_\\text{n times}\\] The quantity \\(1\\times 2 \\times 3 \\times \\cdots \\times n\\) is called a factorial and written \\[\\huge n! = 1\\times 2 \\times 3 \\times \\cdots \\times n\\] In case you’re not already familiar with factorials, note the following: \\[1! = 1\\\\ 2! = 2\\\\ 3! = 6\\\\ 4! = 24\\\\ 5! = 120\\\\ \\text{... and so on} \\] In R, use the factorial() function to calculate \\(n!\\) for instance: factorial(5) ## [1] 120 factorial(6) ## [1] 720 factorial(7) ## [1] 5040 factorial(10) ## [1] 3628800 factorial(15) ## [1] 1.3077e+12 25.2 Taylor polynomials Putting together everything in the previous sections, we arrive at a remarkable formula for a polynomial to approximate any smooth, continuous function \\(f(x)\\) in the neighborhood of a selected input \\(x_0\\). The overall formula is daunting at first glance, but each of the terms has the same pattern: \\[f(x) \\approx f(x_0) + \\frac{\\partial_x f(x_0)}{1!} [x - x_0]^1 + \\frac{\\partial_{xx} f(x_0)}{2!} [x - x_0]^2 + \\frac{\\partial_{xxx} f(x_0)}{3!} [x - x_0]^3 + \\ldots \\] This is the Taylor polynomial. A Taylor polynomial that terminates with the \\([x-x_0]^2\\) term is a second-order Taylor polynomial, one that terminates with the \\([x-x_0]^3\\) term is a third-order Taylor polynomial. Mathematicians are particularly interested in the \\(n\\)th-order Taylor polynomial where \\(n \\rightarrow \\infty\\). Construction of a Taylor polynomial involves finding the various orders of derivatives. There are some cases where this is simple, especially if a felicitous choice of \\(x_0\\) can be made. Example: The successive derivatives of \\(\\sin(x)\\) are \\(cos(x)\\), then \\(-\\sin(x)\\), then \\(-\\cos(x)\\), then back to \\(\\sin(x)\\) and onward to any order derivative you like. If we select \\(x_0=0\\), then each of the derivatives evaluated at \\(x_0\\) will be zero, \\(-1\\), or \\(1\\). The Taylor polynomial (to 5th order) of \\(\\sin(x)\\) is: \\[\\sin(x) \\approx 0 + \\frac{1}{1!}[x] + \\frac{0}{2!} [x]^2 - \\frac{1}{3!} [x]^3 + \\frac{0}{4!} [x]^4 + \\frac{1}{5!} [x]^5 = x - \\frac{x^3}{3!} + \\frac{x^5}{5!}\\] Why say “smooth, continuous function” instead of just function when talking about the kinds of functions Taylor polynomials can approximate? Keep in mind that each of the terms in the polynomial has the form \\(a_n [x-x_0]^n\\) for \\(n=1,2,3, \\ldots\\). Each of these is a power-law function and therefore smooth and continuous. So the polynomial—the sum of the individual terms—will always be smooth and continous. If \\(f()\\) is not, no promises can be given about the quality of the approximation. 25.3 Polynomials and data In which we’ll show that high-order polynomials are trouble. Do data that’s close to a straight line, and look at the stability of the polynomials. Then show how sensitive a high-order polynomial is to slight changes in the data. Exercise 25.2 (approx-orange) The following graph shows a function \\(f(x)\\). Five values of \\(x\\) are labelled A, B, …. These are the possible values of \\(x_0\\) in the questions. Each of the graphs that follow show an approximation to \\(f(x)\\) at one of the points A, B, …. in the above graph. The approximations are either constant (“order 0” approximation), linear (“order 1” approximation), quadratic (“order 2” approximation), or something else. For each graph, say what order approximation is being used. Question A What order approximation in graph (I)?     constant ✓        linear ☹︎ A linear approximation would have exactly the same slope as \\(f()\\) at the reference point \\(x_0\\).        quadratic ☹︎        none of these ☹︎ Question B What is the reference position \\(x_0\\) for approximation in graph (I)?     A ☹︎ Not a bad choice, but notice that the constant approximation has a value a little lower than f(A).        B ✓ You’re right. This has the correct value for f(B).        C ☹︎        D ☹︎        E ☹︎        None of them ☹︎ Question C What order approximation in graph (II)?     constant ☹︎        linear ☹︎        quadratic ✓        none of these ☹︎ Question D What is the reference position \\(x_0\\) for approximation in graph (II)?     A ☹︎        B ☹︎        C ✓        D ☹︎ At the reference position, the value of the approximation should always be \\(f(x_0)\\). That’s not the case here.        E ☹︎        None of them ☹︎ Question E What order approximation in graph (III)?     constant ☹︎        linear ☹︎        quadratic ☹︎        none of these ✓ You can’t have two bends in a linear or quadratic function. Question F What is the reference position \\(x_0\\) for approximation in graph (III)?     A ☹︎        B ☹︎        C ☹︎        D ☹︎ At the reference position, the value of the approximation should always be \\(f(x_0)\\). That’s not the case here.        E ☹︎        None of them ✓ It’s not a polynomial approximation at any of those points. Question G What order approximation in graph (IV)?     constant ☹︎        linear ✓        quadratic ☹︎        none of these ☹︎ Question H What is the reference position \\(x_0\\) for approximation in graph (IV)?     A ✓        B ☹︎        C ☹︎        D ☹︎        E ☹︎        None of them ☹︎ Question I What order approximation in graph (V)?     constant ☹︎        linear ☹︎        quadratic ✓        none of these ☹︎ Question J What is the reference position \\(x_0\\) for approximation in graph (V)?     A ☹︎        B ☹︎        C ☹︎        D ☹︎        E ☹︎        None of them ✓ Exercise 25.3 (approx-blue) Here is a somewhat complex function in two variables. The labels A, B, C, D mark some possible reference points \\((x_0, y_0)\\) around which polynomial approximations are being made. For each of the following graphs, say what kind of two-variable polynomial approximation is being made and which reference point the approximation is centered on. Question A What order approximation in graph (I)?     constant ☹︎        linear ☹︎ The contours would be straight if the approximation were linear        bilinear ✓ Right. But it turns out that the quadratic approximation is similar, presumably because \\(d_{xx}f(x_0, y_0)\\) and \\(d_{yy} f(x_0, y_0)\\) are too small to make a difference.        quadratic ☹︎ Not a bad answer. In this case, the bilinear approximation looks a lot like the quadratic. Question B What is the reference position \\((x_0, y_0)\\) for approximation in graph (I)?     A ✓        B ☹︎        C ☹︎        D ☹︎ Question C What order approximation in graph (II)?     constant ☹︎        linear ☹︎ The contours would be straight if the approximation were linear        bilinear ✓ Right. But it turns out that the quadratic approximation is similar, presumably because \\(d_{xx}f(x_0, y_0)\\) and \\(d_{yy} f(x_0, y_0)\\) are too small to make a difference.        quadratic ☹︎ The circular (or elliptical) contours are the hallmark of a quadratic approximation near a maximum or minimum. Question D What is the reference position \\((x_0, y_0)\\) for approximation in graph (II)?     A ☹︎        B ✓ Practically a bullseye on B!        C ☹︎        D ☹︎ Question E What order approximation in graph (III)?     constant ☹︎        linear ✓ A linear approximation always produces straight, parallel, evenly spaced contours.        bilinear ☹︎        quadratic ☹︎ Question F What is the reference position \\((x_0, y_0)\\) for approximation in graph (III)?     A ☹︎        B ☹︎        C ☹︎        D ✓ Question G What order approximation in graph (IV)?     constant ☹︎        linear ☹︎ The contours would be straight if the approximation were linear        bilinear ☹︎ Not a bad answer. But curvature in bilinear approximations is always in one direction.        quadratic ✓ Sometimes quadratic approximations produce elliptical contours, as in a previous problem. But sometimes they produce the X-shaped contours seen here. In both cases, the contours curve in opposing ways in different parts of the domain. By the way, the contour pattern seen in the upper right of this graph corresponds to the shape of a saddle: curving up along one line and down along the perpendicular line. The place right in the middle of the saddle is called a ‘saddle point.’ Question H What is the reference position \\((x_0, y_0)\\) for approximation in graph (IV)?     A ☹︎        B ☹︎        C ✓        D ☹︎ "],["outline-of-block-3.html", "Outline of Block 3", " Outline of Block 3 This section is for development purposes only. It is not to be included in the released text. This outline was that established during the May 17-19, 2021 working sessions at USAFi. It’s copied directly from the Teams document. I’ve made some modifications which are noted in [[square brackets]] for deletions and bold face for additions.. Adding preliminary intro chapter, motivating a situation where you know the derivative but don’t know the function Change relationships Iteration and Euler’s Method NTI We’re only going to go by-hand up to 3 iterations of Euler’s method We’ll show the students a loop, but not make them create the loop Topics Tie in loops as (iteration) Reversing the difference quotient (the slope function \\(\\diff{x}f(x)\\)) Initial values By hand Implement on a computer Readings: Chapter 26. EXERCISES to ADD Exercises/Accum/chain-of-differentiation.Rmd Iteration and accumulation Topics Euler’s method Computing examples of iteration and loops Exercises Accum/accumulate-numeric-draft.Rmd Accum/computing-and-antiD.Rmd Readings: Chapter 27 Accumulation as net change NTI: Introduce definition of definite integral as the mathematical notation for accumulation [[(Euler’s method) moved to new Iteration and accumulation]] Topics Notation for definite integrals (connected to Euler’s method) Exercises/Accum/three-perspectives.Rmd Eyeballing accumulation This is where area under the curve goes a. motivating graph in www/covid-history.png from Economist June 26, 2021 p. 8 b. [Exercises/Accum/accumulation-limits.Rmd] c. [Exercises/Accum/ups-and-downs.Rmd] d. [App and exercises: Exercises/Accum/Graph-anti.Rmd] Concrete examples of anti-differentiation i. Power to energy [Exercises/Accum/solar-example.Rmd] ii. Velocity to position [Exercises/Accum/sailing-over-time.Rmd] i. Acceleration-velocity-displacement [Exercises/Accum/falling-from-pisa.Rmd] i. Probability: dnorm and pnorm, Road-cone-metaphor.Rmd in Exercises/Accum i. AreaA Accumulating the accumulation [Exercises/Accum/Glorias-family.Rmd] Fundamentals of integration (that is, the fundamental theorem) [Exercises/Accum/first-fundamental-theorem.Rmd] [what-is.Rmd] [u-on-the-bottom.Rmd] [MMAC-1.Rmd] Readings: Chapter 28 [[Basic antiderivative rules]] Anti-derivatives of basic modeling functions Topics Composition of naked function with a linear interior function and the pattern seen from the table of derivatives. [See Exercises/Accum/basic-modeling-functions.Rmd &amp; interior-funs-1.Rmd] Sometimes you need to multiply or divide by a constant to get the form that you can look up in the table of derivatives. Give a new table. The constant of integration [Exercises/Accum/lessons-from-euler.Rmd] [App: Exercises/Accum/find-C.Rmd] [[Exponential functions]] Moved to introductory block [[Sine and Cosine]] [[Logarithms]] [[Power functions]] [[Simple combinations of all of the above]] Moved to next block Properties of Accumulation Topics Linear properties Sum and difference Multiplication by a constant Reversing limits of integration Additive property for an inserted limit of integration Definite integrals of constant and linear functions geometrically Units and dimension of definite integral [Exercises/Accum/areas.Rmd] [wind-power.Rmd] [Exercises/Accum/Units_of_antiD.Rmd falcon-tell-mug.Rmd] [heat-engine.Rmd] Exercies Exercises/Accum/properties-of-anti-derivatives.Rmd Advanced algebraic methods Topics Antiderivatives by method of substitution Reversing the chain rule Antiderivatives by method of integration by parts Reversing the product rule Readings: Chapter 29 Review of all antiderivative methods Topics Tables of integrals [Exercises/Accum/function-order.Rmd] Readings: Chapter 30 Differential modeling Readings: Chapter ?? Orphaned Average value (?) DD-142Z-02/discrete-inputs.Rmd IODs and drill Latex (e.g. DD-142Z-02/three-perspecitives-2.Rmd) "],["change-accumulation.html", "Chapter 26 Change and accumulation 26.1 Differentiation and anti-differentiation 26.2 Visualizing anti-differentiation 26.3 Symbolic anti-derivatives", " Chapter 26 Change and accumulation Consider this table of population versus year, which records the overall results of the every-10-year US Census since 1790 Figure 26.1: US Population as counted by the US Census Bureau: 1790-2020 population These are discrete-time data, but nobody would dispute that the population is a continuous function of time and that we are entitled to graph it as in Figure 26.2. Figure 26.2: US population since 1790. Source Many of the student readers of this book will have children who will be about 70 years old in the year 2100. Use Figure 26.4 to make a prediction of the population in 2100. From the graph itself, you might just sketch out what you think is the trend. Or, more formally, and based on the ideas introduced in Block 1, you might seek an exponential or power-law function, fit it to the data, and extrapolate out to year 2100. The next figure does exactly that, but you’ll have to click on “Show model prediction” to see the results. Show model prediction Figure 26.3: Predicted US population using an exponential function (red) and a power-law function (green) The power-law function with power 2.56 is an excellent match to the historical data up through the present. But … There are occasions where the modeler has no alternative to curve fitting. However, it’s best when the modeler knows as much as possible about the mechanisms of the process being modeled and can somehow incorporate those processes into the model. With population, you know an awful lot about the mechanisms involved: birth, death, and immigration. As for births …. this is a personal matter. What I mean is that it’s appropriate to look at the mechanism in terms of births per person. And if we’re interested in the yearly growth of the population, what’s relevant is the rate of births per person per year. That’s a complicated rate, but when you multiply it by the population it turns into births per year, which is exactly right for studying population. The trend in births per person per year has been downward since 1900. Immigration has fluctuated over the decades. That’s going to be hard to predict. And death … Old age is still the primary risk factor for death. The population is getting older, so deaths per year may be going up. Births, deaths, and immigration are the components of the population rate of growth per year. The statements in the previous paragraph suggest that the population rate of growth per year is going down. The census data don’t break down population change into its components. Still, we can check for patterns over the decades, as in Figure 26.4. Figure 26.4: Annual growth rate of the US population (%) There’s a lot of fluctuation, but an overall trend stands out: the population growth rate has been declining since the mid-to late 1800s. The deviations from the trend are telling. There’s a relatively low growth rate seen in the 1870 census: that’s the effect of the US Civil War. The Great depression is seen in the very low growth from 1930 to 1940. Baby Boom: look at the growth from 1950-1960. The bump from 1990 to 2000? Not coincidentally, the 1990 Immigration Act substantially increased the yearly rate of immigration. The extrapolation of the historical pattern in annual growth rate has a zero crossing at about 2075. As you know from Block 2, a zero crossing of the rate of change corresponds to a local maximum. A reasonable prediction is therefore that the US population will max out in the second half of the 21st century and decline thereafter. What will that maximum population be? The derivative tells us only about the argmax, not the max. What we need to do to make a prediction of the future population is to accumulate the yearly change in the population on top of the known, current population. In other words, rather than going from the population vs time to the rate of change in population versus time, we need to go the other way. This process of knowing a derivative \\(\\partial_x f()\\) and finding the unknown function \\(f()\\) from which it was derived is called anti-differentiation. Just as the name suggests, anti-differentiation is the opposite of differentiation. But how to do it? The predictions from the accumulate-population-growth model are shown as a thin gray line in Figure 26.3 along with the exponential and power law models fit directly to the population vs year data. According to the accumulation model, the population peaks in 2075 at 390 million. Professional demographers make much more sophisticated models using data from many sources. The demographers at the US Census Bureau predict that the population will reach a maximum of 404 million in 2060, shown by the little blue dot in Figure 26.3. 26.1 Differentiation and anti-differentiation Block 2 introduced the derivative of a continuous function by looking at discrete differences. Given a function \\(g(t)\\), we quantified the rate of change using the differencing operator. We called this the \\[\\diff{t} g(t) \\equiv \\frac{g(t+h) - g(t)}{h}\\] As written above, \\(\\diff{t}\\) is properly called the finite-difference operator, since no suggestion is made that \\(h\\) is anything but a small number. We moved from \\(\\diff{t}\\) to \\(\\partial_t\\) by considering the limit as \\(h\\rightarrow 0\\) This move was fraught because of the concern about dividing by zero, but in the end we found simple algebraic expressions for the derivatives of the naked modeling functions as well as a few rules for handling the basic ways of combining functions using linear combinations, products, and function combinations. These rules were the sum rule, product rule, and chain rule respectively. In studying accumulation, we’ll follow much the same path. The major difference is that our starting point is knowing a function like \\(\\partial_t f(t)\\): a derivative. From there will will construct a \\(f(t)\\) from which \\(\\partial_t f(t)\\) could have been derived, had we known it in the first place. The idea is that sometimes information comes to us in the form of a rate of change and we need to figure out a function that could have generated that rate of change. It will help to keep in mind a fundamental principle of calculus, even if the mental image of this principle remains blurry: Accumulation is the reverse operation to differentiation, and vice versa. To make this principle even easier to remember, let’s restate it using the mathematical word used to say precisely what we mean by “accumulation”: Anti-differentiation is the reverse operation to differentation, and vice versa. The mathematical notation for differentiation is simple: \\(\\partial_t f(t)\\). For anti-differentiation the notation is typographically very different. The anti-derivative of a function \\(f(t)\\) is written: \\[\\huge \\color{blue}{\\int} f(\\color{blue}{t}) \\color{blue}{dt}\\] The math notation consists of several components, each of which has something to say. The components colored blue are part of the general notation. You can change the name of the input variable from \\(\\color{blue}{t}\\) to whatever you like, but you’ll have to change the \\(\\color{blue}{dt}\\) accordingly. The R/mosaic notation for the anti-derivative has exactly the same format as the derivative: antiD(f(t) ~ t) 26.2 Visualizing anti-differentiation Section 16.5 introduced a non-standard visualization of the slope function. We can build on that to show how the function \\(f(x)\\) can be reconstructed from \\(\\partial_x f(x)\\). Figure 26.5 shows a slope function visualization of some function \\(f(x)\\) Figure 26.5: A slope function \\(\\partial_x f(x)\\) from which we are going to reconstruct the mother function \\(f(x)\\). Each of the sloped segments has been given a label for later reference. We’ll reconstruct \\(f(x)\\) one segment at a time. Recall that each of the segments shows a linear approximation to \\(f(x)\\) at the input marked by the green dot. But in constructing the slope function, we threw away the information about the vertical placement of the segment. Now we have to recover that discarded information, as well as we can. The big clue for the reconstruction is that the function \\(f(x)\\) was continuous. But the piecewise function graphed in Figure 26.5 is discontinuous; the endpoints of adjacent segments don’t meet each other. That’s easy to fix: we’ll just move segment (b) vertically so that it becomes continuous with segment (a). Figure 26.6: Moving segment (b) to become continuous with segment (a). Now that (a) and (b) are joined, we can join (c) to that: Figure 26.7: Moving segment (c) to become continuous with segments (a) and (b). Continue this process one segment at a time to reconstruct \\(f(x)\\). Figure 26.8: After joining all the segments together, the picture of \\(f()\\) is complete. This process reconstructs the shape of \\(f(x)\\) from \\(\\partial_x f(x)\\). But there is still something missing. We never touched segment (a). Its vertical location was arbitrary. So we have to qualify our claim to have reconstructed \\(f(x)\\). What we’ve reconstructed is some function \\(\\widehat{f}(x)\\) whose derivative is \\(\\partial_x f(x)\\). There are other such functions; any function \\(\\widehat{f}(x) + C\\) can make a legitimate claim to being the anti-derivative of \\(\\partial_t f(x)\\). We’ll return to \\(C\\) in later chapters, but for now we’ll just name it: the constant of integration. In the population example that started this chapter, we constructed a model for \\(\\partial_t f(t)\\), where \\(f(t) = \\ln(P(t))\\). We can plot \\(\\partial_t f(t)\\) using an ordinary graph as we did in Figure 26.4, but let’s use the slope-function representation instead. Figure 26.9: The slope-function visualization corresponding to the plot of \\(\\partial_t f(t)\\) in Figure 26.4. To construct the original function \\(f(t)\\), just connect the segments in Figure 26.9. Figure 26.10: Accumulating the annual growth in Figure 26.9. The accumulated annual growth graph shows that by around 2075, the accumulated growth will be about 17% above the population of 2020. You may wonder why I’m introducing anti-differentiation with the “slope-function visualization” rather than the “area under a curve.” One reason is that the slope-function visualization is closer to the logic of Euler’s method, so in addition to showing how differentiation can be undone, we get a free introduction to Euler. The other reasons are more fundamental to pedagogy and the challenges students have relating differentiation and anti-differentiation when presented as slope-and-area. I’ll start with some history … Pyrrhus was a Greek king who invaded Italy in 280 B.C. and fought the Romans. His first battle, at Heraclea, was a famous victory, as was his second battle a year later at Asculum. History records Pyrrhus saying, after his second victory, “If we are victorious in one more battle with the Romans, we shall be utterly ruined.” The victories were so costly that the army could not be sustained. Such pyrrhic victories occur throughout history: the British at Bunker Hill (1775), Napolean at Borodino (1812), and Lee at Chancellorsville (1863). A pyrrhic victory in mathematics pedagogy: the visualization of integration as the “area under a curve.” This account of integration is utterly dominant among graduates of calculus courses. It is a brilliant and successful way to give the abstract operation of anti-differentiation an easily remembered visage. But it creates costs that are simply not worth bearing. There are not so many genuine applications for finding areas under curves. Students, seeing them as emblematic of calculus, are often dis-motivated by the lack of connection between the rhetoric of the importance of calculus and the seeming unimportance of the primary application. It’s extremely difficult to make a connection between the many genuine applications of anti-differentiation and the mental image of area. Because area is most easily shown as a fixed, delimited region, students are introduced to integration before they see anti-differentiation. It can be hard for students to make the transition between “slope at a point” or “tangent line” and a slope function. This cost has to be paid all over again when moving from integration to anti-differentiation. The Yin and Yang of calculus are differentiation and anti-differentation. Students are successfully taught that if \\(f(x)\\) is a function, the derivative is the slope of that function and the integral is the area under the function. This creates an unhelpful illusion that derivatives and anti-derivatives are related through the function, that there is an intermediary between them. Translating this image to the metaphor of family generations, the picture looks like \\(f(x)\\) is the parent of \\(\\partial_x f(x)\\) and \\(\\int f(x)dx\\) is the parent of \\(f(x)\\). In other words, the incorrect image is encouraged that an anti-derivative is the grandparent of the derivative. In fact the anti-derivative and the derivative have a parent-child relationship. At best, for many people, the relationship between the slope function and the area function is hard to see and sometimes mysterious. (Of course it’s hard to see: the slope function is the second derivative of the area function.) This For these reasons, I encourage instructors to avoid defining the calculus operation as “area under the curve.” Make use of areas when they are part of a genuine application of calculus. Save the Riemann Sum for courses in analysis. For demonstrating anti-differentiation, the starting point should be a function which we know to be the derivative of the sought-after function. Teach Euler as connecting together short segments of slopes. Emphasis the connections between differentiation and anti-differentiation from the start: both are relationships between one function and another function, just as every person is both a mother and a child. The anti-derivative is the mother of the child, the derivative is the child of the mother. 26.3 Symbolic anti-derivatives The Euler method involves a finite \\(h\\), which is just to say that \\(h\\) must be non-zero. Otherwise, \\(f(t_0 + h)\\) would be exactly the same as \\(f(t_0)\\). For some functions, however, it’s possible to construct the anti-derivative without needing to deal with \\(h\\) at all. Recall that anti-differentiation undoes differentiation, and vice versa. In the previous Block, we found the symbolic derivatives of the basic modeling functions and general methods for differentiating functions constructed by linear combination, products, and function composition. Using the techniques from Block 2, tables can be constructed of functions and their derivatives, looking like this: \\(f(x)\\) \\(\\partial_x f(x)\\) \\(e^{x}\\) \\(e^x\\) \\(\\ln{x}\\) \\(1/x\\) \\(\\sin{x}\\) \\(\\cos{x}\\) \\(\\pnorm(x)\\) \\(\\dnorm(x)\\) \\(x^2\\) \\(2x\\) \\(\\vdots\\) \\(\\vdots\\) Transforming this into a table of anti-derivatives is merely a matter of re-labeling the columns: \\(\\int g(x)dx\\) \\(g(x)\\) \\(e^{x}\\) \\(e^x\\) \\(\\ln{x}\\) \\(1/x\\) \\(\\sin{x}\\) \\(\\cos{x}\\) \\(\\pnorm(x)\\) \\(\\dnorm(x)\\) \\(x^2\\) \\(2x\\) \\(x^p\\) \\(p x^{p-1}\\) \\(\\vdots\\) \\(\\vdots\\) But unlike differentiation, anti-differentiation has no easy equivalents of the product rule or the chain rule (for compositions of functions). Recall that every smooth, continuous function has a derivative defined everywhere in the function’s domain. Similarly, every function has an anti-derivative, and even discontinuous, un-smooth functions have nicely behaved anti-derivatives. In this sense anti-differentiation is easy. It’s only the algebra of anti-differentiation that can be hard or often literally impossible. [Int-2b] Utilize your knowledge of derivatives rules to backwards solve for anti-derivatives. [Int-2f] Understand that the output of anti-differentiation is a function known as a general solution and more information is necessary to find the particular solution [DTK: This is language I associate with differential equations. How about: Find the constant of integration.] [Int-2c] Understand the notation of an indefinite integral to include a. the integral symbol; b. variable of integration (“with respect to” variable); c. the constant of integration [Int-2d] Understand the relationship between a (child) function and its (parent) integral. [Int-5c] Know common scientific application relationships between base functions and anti-derivatives: a. Acceleration, Velocity, Position; b. Force, Work; c. Area, Volume; d. Cash flow, assets Calculation of luminance using light intensity at different wavelengths integrated over the luminance function. https://en.wikipedia.org/wiki/Luminous_efficiency_function Pick up on the Lorenz curve {.intheworld} in Blocks 1 and 2. Integrate to find the Gini coefficient. Show that the Gini coefficient is the same for very different types of inequality and that therefore it’s not such a good measure. How about the integral over the poorest 25% or 50% of society.\" "],["iteration-and-accumulation.html", "Chapter 27 Iteration and accumulation 27.1 Automating Euler 27.2 Iteration 27.3 Accumulating population change", " Chapter 27 Iteration and accumulation Let’s review the concept of an Euler step. Problem statement: You seek to find a function, e.g. \\(f(t)\\) which you do not yet know. You already know \\(\\partial_t f(t)\\). (In the following chapters we’ll show you some of the many instances of this unlikely-sounding situation, where you don’t know \\(f(t)\\) but you do know \\(\\partial_t f(t)\\).) This relationship, \\(\\partial_t f(t) \\longrightarrow f(t)\\) is, of course, revealed by anti-differentiation. Setup: You know or make up a value for \\(f(t)\\) at a particular time of interest \\(t=t_0\\). “Making up” is a perfectly legitimate practice here to get started in creating an an anti-derivative. The reason is hard to explain until you see the whole process of anti-differentiation by the Euler method, so hang on. In the population modeling problem in Chapter 26, we were interested in forecasting the population into the future, so we chose \\(t_0\\) to be the most recent year for which we have information: \\(t_0 = 2020\\). (In polite mathematical conversation, “making up” is pronounced “assuming.”) Consider a quantity \\(h\\) which is to be regarded as a little bit of \\(t\\): they have the same dimension. \\(h\\) should be “small,” but “small” compared to what? Often, the modeling problem at hand involves a domain of interest. For instance, the population modeling problem in Chapter 26 involved a forecast over the time interval from year 2020 to 2100. Provisionally, take small to mean 1% or 0.1% of the extent of the domain of interest. (In the population modeling problem, we chose \\(h=1\\) year.) The Step Compute the value of the (still unknown) function \\(f(t)\\) at input \\(t_0 + h\\) as \\[f(t_0+h) = f(t_0) + h \\times \\partial_t f(t)\\] Now you know a little bit more about \\(f(t)\\), namely, its value at \\(t_0 + h\\). Since the original problem was to figure out \\(f(t)\\) over some domain of interest (starting at \\(t=t_0\\)), we are not finished. We have taken but one step of our journey and have many more to go. To continue on the journey, we take what we just found out, namely \\(f(t_0 + h)\\). We use this as the starting point in a new step. We don’t have to make anything up because we already know \\(f(t_0 + h)\\). The second step brings us to \\(f(t_0 + 2h)\\) \\[f(t_0+2h) = f(t_0+h) + h \\times \\partial_t f(t+h)\\] And the third: \\[f(t_0+3h) = f(t_0+2h) + h \\times \\partial_t f(t+2h)\\] How long to continue this step-by-step process? The original problem involved some domain of interest, and we selected \\(h\\) as 1% or 0.1% of the extent of this domain. For \\(h\\) as 1%, taking 100 steps will get us to the far end of the domain. For \\(h\\) as 0.1%, we would need to take 1000 steps. Exercise 27.1 (euler-step) Exercises like this: Using the Euler method find \\(\\int f(t) dt\\) over the interval \\(t_0=0\\) to \\(t_{end}=1\\). The \\(t\\) quantity is in steps of \\(h=0.01\\). \\(t\\) \\(\\partial_t f(t)\\) \\(\\int f(t) dt\\) 0 0.399 0.5 0.01 0.242 0.02 0.054 0.03 0.399 27.1 Automating Euler Although the Euler method was invented in the 18th century, it only became a practicable way of accumulating in the 1930s with the advent of analog computing and then in the 1940s when electronic computing was first becoming available. In those days, a primary mission for computers was accumulating the trajectories of artillery shells, a problem that was inaccessible to symbolic anti-differentiation because of the complexities of air resistence and the varying density of air at different altitudes, with different humidity, and so on. Nowadays computing is roughly one-billionth the cost that it was the World War II era, and we use computers for just about every task imaginable. But in those early days, the huge costs involved in developing early computers was justified only by the prospect of improved gunnery in war. And those problems were all about accumulation and, more specifically, Euler methods. What today seems an esoteric use for computers was in fact the prime motivation for their development. This section introduces various ways of programming the Euler method on a computer. The Euler method has been supplanted by other, more modern methods whose inner workings are based on a deeper knowledge of calculus than we have covered to date and programming methods that automatically check and adapt the size of \\(h\\). However sophisticated these methods may be, they are always easy to use. For example, the R/mosaic antiD() operator draws on one of these methods. 27.1.1 Euler as a spreadsheet Spreadsheets are popular for certain simple kinds of computer programming. The Euler method is a case in point. Figure 27.1 shows the formula layer of a Google Sheet implementing the Euler method for \\(\\int \\dnorm(t) dt\\). In the spreadsheet, NORMDIST() is the equivalent of \\(\\dnorm()\\). Figure 27.1: The formula layer of a spreadsheet implementing the Euler method for \\(\\int \\dnorm(x) dx\\). The whole spreadsheet is viewable here The first argument to NORMDIST() is a reference to a cell in column B which stores the sequence \\(t_0\\), \\(t_0 + h\\), \\(t_0 + 2h, \\ldots\\). (The value of \\(h\\) is stored in cell H2 (not shown).) Column D contains the results of the Euler calculation. It starts at time \\(t_0=0\\) by referencing cell H4 (not shown) which contains the starting value \\(f(t_0)\\). Each successive cell in that column refers to the one immediately above that, adding in the appropriate value from the NORMDIST() column and multiplying it by \\(h\\) (that is, H2). Only about 10 Euler steps are shown, out of 100 altogether. Typically in viewing a spreadsheet you don’t see the formula layer. Instead, the results of the calculation in each cell are presented. (Figure 27.2). Figure 27.2: Results from the formula layer shown in Figure 27.1. Plotting column D against column B gives a graph of \\(\\int \\dnorm(t) dt\\) versus \\(t\\). Notice that the output of the Euler method is a function stored as a table rather than as a function formula. And even though \\(\\int \\dnorm(t) dt\\) has a pretty simple form, namely, \\(\\pnorm(t)\\), the spreadsheet makes it look like something more elaborate. Spreadsheets are rightly criticized for being verbose. This can make it extremely challenging for the human programmer to create a spreadsheet that does what is claimed for it, let alone to demonstrate that the result is correct. Worse, it’s hard to generalize a spreadsheet to handle any given function rather than the one (here, NORMDIST()) hard-coded into the sheet. A usual practice is to copy a spreadsheet and then customize it to use the function whose anti-derivative is sought. This introduces the potential for human error in a way that can be hard to detect down the line. 27.1.2 Using antiD() The R/mosaic antiD() operator uses symbolic differentiation if it can. Otherwise it uses numerical methods in the spirit of Euler. Here is the same anti-differentiation as in the spreadsheet but done with antiD(): f &lt;- antiD(dnorm(t) ~ t) It happens that \\(\\dnorm(t)\\) is one of those many functions where the anti-derivative cannot be calculated symbolically. (We already know that \\(\\int \\dnorm(t) dt = \\pnorm(t)\\), but this in fact the definition of \\(\\pnorm()\\), which is only known from numerical calculations like Euler.) An advantage of using programming systems like R/mosaic is that they provide a way to do something with the result of the calculation. You could of course plot f() with slice_plot(), but let’s show something much more fundamental … How do we know that antiD() is giving the result it should give? Whenever you do a calculation, you should ask a similar question: “How do I know that [my calculation] is giving the result it should?” In general, it takes considerable experience to provide an answer to such a question, but in the case of antiD(), the approach is simple: If f() is really the anti-derivative of dnorm(), then differentiating f() should give us something that’s the same as dnorm(). Here’s the actual calculation: fprime &lt;- D(f(t) ~ t) deviation &lt;- makeFun(dnorm(t) - fprime(t) ~ t) slice_plot(deviation(t) ~ t, domain(t=c(-5,5))) With numerical methods, there will almost always be some error introduced by round-off in the calculations, so we should never expect the deviation to be zero. You can see from the plot of the deviation (Look carefully at the vertical axis!) that it is smaller than 0.0000000001, which is a tiny, tiny part of the size of the output from \\(\\dnorm()\\). It might seem odd to use 3 lines of R/mosaic commands to confirm an answer that was calculated in one line. That’s a pretty good representation of how much effort a professional will put into testing the result compared to getting the result. Exercise 27.2 Try another strategy for confirming that antiD() is giving a good answer. Compare f() from the antiD() calculation to pnorm(). 27.1.3 Using cumsum() antiD() produces a function that can be evaluated at any input. In contrast, the Euler method as described here produces a data table of values as, for example, seen in the spreadsheet implementation of Euler. In R, a data table can be created with the data.table() function. Here’ we’ll illustrate how to implement Euler with this format as a topic. The raw ingredients are: \\(t_0\\) and \\(t_\\text{end}\\), the start and end of the input interval over which you want to do the accumulation. Your choice of \\(h\\). We’ll set this to 1/100 of the length of the input interval. The function that you want to accumulate. We’ll represent that with a tilde expression in exactly the same manner as makeFun(), D(), and other operators in the R/mosaic suite of software. We’ll implement the method as a series of steps that make a data table whose t and accum columns describe the accumulated function. # Setup the incredients tilde_expr &lt;- dnorm(t) ~ t t_0 &lt;- -2 t_end &lt;- 2 h &lt;- (t_end - t_0) / 100 # Create the function to be accumulated from the tilde expression f &lt;- makeFun(tilde_expr) # Create a set of evenly spaced input values separated by h # tibble() arranges this as a data table Results &lt;- tibble( t = seq(t_0, t_end, by=h), # seq() makes a sequence steps = f(t) * h, accum = cumsum(steps) ) The cumsum() function is easy to understand. First, know that sum() adds together a set of numbers. For instance, here’s a data frame with the numbers 0, 1, 2, 3, …, 10. The sum of these is 55. The cumulative sum is also known as the “running sum.” n &lt;- seq(0, 10, by=1) n ## [1] 0 1 2 3 4 5 6 7 8 9 10 sum(n) ## [1] 55 cumsum(n) ## [1] 0 1 3 6 10 15 21 28 36 45 55 Exercise 27.3 (cumsum) Consider this sequence: 4, 5, 3, 1, 2 What is the sum? What is the cumulative sum? Which entry in the cumulative sum matches the sum? A good practice with numerical methods is to package them as a function, so that you can easily apply the same method in many different contexts. This is the best way to arrange a calculation so it can be debugged and verified. This is what such a function would look like in R: accumulate &lt;- function(tilde_expr, t_0=0, t_end=1, h=(t_end-t_0)/100) { f &lt;- makeFun(tilde_expr) tibble( t = seq(t_0, t_end, by=h), steps = f(t) * h, euler = cumsum(steps) ) } Let’s test accumulate(). Since dnorm() is the derivative of pnorm(), accumulating dnorm() should give a function that has the same shape as pnorm(). Pts &lt;- accumulate(dnorm(t) ~ t, t_0=-1, t_end=3, h=0.01) gf_point(euler ~ t, data = Pts) %&gt;% slice_plot(pnorm(t) ~ t, color=&quot;red&quot;) From the plot, you can see that accumulated version of dnorm() has the same shape as pnorm(). But the two functions are shifted vertically. By how much? For_plot &lt;- Pts %&gt;% mutate(actual = pnorm(t), diff = abs(actual - euler)) gf_point(diff ~ t, data = For_plot) %&gt;% gf_lims(y = c(0, NA)) The Euler method gives results that are roughly 0.16 units less than the true answer, pnorm(). Notice that the error is practically the same for all \\(t\\). This shows that the Euler accumulated dnorm() is practically pnorm(t) - 0.16: a pure vertical shift. (If you look very closely, you’ll see that diff is not exactly a constant. That’s the result of using finite \\(h\\) in the Euler accumulation.) Exercise 27.4 Implement accumulate() in a sandbox. Show that the vertical difference between the accumulated points and pnorm() gets smaller as you move \\(t_0\\) to the left. 27.2 Iteration There is an important computational strategy behind the Euler method, whether it be implemented on a spreadsheet or in R: iteration “Iteration” means to do something over and over again, or, as defined nicely by the New Oxford American Dictionary: repetition of a mathematical or computational procedure applied to the result of a previous application You saw iteration at work in Section 26.2 when we turned the discrete sloping segments of the slope-function visualization into continuous, joined line segments. We started with the right endpoint of segment (a). Then we applied a procedure: change the vertical position of segment (b) so that the left end of (b) joins with the right end of (a). Now repeat that, but starting not with the original segment (a) but the joined (a)-(b) segments: move segment (c) vertically until its left end is joined with the rightmost point of the (a)-(b) segments. This produces a continuous (a)-(b)-(c) structure. Repeat again, using (a)-(b)-(c) and joining (d) to that. And so on. Iteration. Iteration is behind many of the algorithms used throughout mathematics and computation generally. The fundamental structure of iteration involves three things: A set of items over which the iteration is to be performed. Call this the iteration set. Examples of iteration sets: the line segments in the slope-function visualization; the cells in a spreadsheet; the individual numbers in a sequence like 0, 1, 2, 3, An object, called the accumulator to hold the result of the accumulation. This might be in the shape of a single number, or it might be a sequence of things, more or less like the set in (1). A procedure that takes the accumulator as well as an item from (1) and calculates something, with which to augment the accumulator. To carry out the iteration, you initialize the accumulator in a way that’s appropriate, then apply the procedure to the first item of the set (1), thereby updating the accumulator. Next, move to the second item in the set (1) and update the accumulator. Repeat this for each of the items in the set (1). When you’ve processed each of those items the accumulator holds the result. Example 1: Summing a set of numbers. The iteration set is those numbers, for instance, 3, 5, -2, 1, 4. The accumulator is a single number, which we initialize to 0. The procedure takes the item from the iteration set and updates the accumulator by adding that item to the accumulator. The accumulator starts out as 0. Then 3 is added to it and the accumulator becomes 3. Then 5 is added to it and the accumulator becomes 8. Next, -2 is added to it and the accumulator becomes 6. The 1 in the iteration set updates the accumulator to 7 and, finally, the last item in the iteration set—4—updates the accumulator to 11. The final result: 11. Let’s look at how this might be written in base R, even though the R/mosaic software allows you to avoid such constructions. iteration_set &lt;- c(3, 5, -2, 1, 4) accumulator &lt;- 0 # initialize accumulator for (item in iteration_set) { # for every item in the set, do ... accumulator &lt;- accumulator + item # the procedure on that item } # Done! accumulator holds the final result accumulator ## [1] 11 Almost all computer languages have a structure like the for loop in R for carrying out the repetition. Learning how to use such things is a fundamental part of computer programming. Example 2: The cumulative sum We’ll use the same iteration set as in the previous example. But the accumulator will have two parts, a running_sum and a set of numbers. As in the summation iteration, we’ll initialize running_sum to zero. The set of numbers will be initialized to the empty set. In addition to updating running_sum, the update procedure will append the running sum to the end of the set of numbers. The process of appending is called concatenation. One of the many ways in R to concatenate the most recent result looks like set_of_numbers &lt;- c(set_of_numbers, running_sum) In R, the c() function performs the appending. “c” stands for “concatenate.” Here’s one way to write the cumulative sum operation in R: iteration_set &lt;- c(3, 5, -2, 1, 4) running_sum &lt;- 0 # initialize accumulator set_of_numbers &lt;- c() for (item in iteration_set) { # procedure on one item running_sum &lt;- running_sum + item # update running_sum set_of_numbers &lt;- c(set_of_numbers, running_sum) # append } # set_of_numbers holds the result set_of_numbers ## [1] 3 8 6 7 11 To experienced programmers, the cumulative-sum iteration code listed above will seem odd. That’s because in learning to program they mastered additional features of the programming language like indexing, which enables you to refer to a specific item in a set. Many, many bugs in programs originate in faulty indexing; it’s not always so easy to do right. Here’s the cumulative-sum iteration in a way that will seem more familiar to experienced programmers: iteration_set &lt;- c(3, 5, -2, 1, 4) accumulator &lt;- rep(iteration_set[1], length(iteration_set)) for (index in seq(2, length(iteration_set))) { accumulator[index] &lt;- accumulator[index-1] + iteration_set[index] } accumulator ## [1] 3 8 6 7 11 In programming languages such as Python or C, such a looping style is commonplace. It also works in R, but experienced R programmers know a set of functions such as cumsum() or cumprod() or lapply() that enable the programmer to write iteration operations without explicitly showing the loop. Hiding the loop makes the program much smaller and simpler, for instance, the following does the same accumulation as the loop. iteration_set &lt;- c(3, 5, -2, 1, 4) cumsum(iteration_set) ## [1] 3 8 6 7 11 Since functions like cumsum() have been carefully debugged and validated by their authors, they are much more reliable than home-brew loops. In addition, they are programmed to run close to the hardware and are therefore very fast. That’s not an issue with an iteration set containing five numbers, but such sets might well be 100,000 times longer, or more. 27.3 Accumulating population change Let’s return to the prediction of future population to show how it was done. Recall that we started with the total population of the US as estimated by the Census Bureau every ten years from 1790 on.22 Those numbers are monotonically increasing, so a projection into the future based just on those numbers is bound to give an ever-increasing value. Augmenting the data with our understanding of the mechanisms of population growth, and bringing in additional information from other sources—families are getting smaller on average, people are living longer—we decided to process the census numbers to give us a better representation of growth: the annual per-capita population growth. Writing “annual per-capita population growth” in explicit units gives “change in population per year per person.” We observed from the historical record that this quantity is decreasing over time in a way that’s reasonably extrapolated into the future by a straight-line function. That part of the quantity which is “change in population per year” has the units of the derivative with respect to time of population: \\(\\partial_t P(t)\\). In other words, the information that we’re taking as informative for predicting future population growth, the extrapolation of the growth rate, has the form of a derivative. We’re going to transform that derivative into the the population function itself \\(P(t)\\). This is an absolutely typical use of anti-differentiation. The annual growth rate in population \\(\\partial_t P(t)\\) can be approximated from the once-per-decade data by finite differencing: \\[\\diff{t} P(\\text{year}) = \\frac{P(\\text{year} + 10) - P(\\text{year})}{10}\\] The quantity graphed in Figure 26.4 is a little different, it is the population growth rate per capital, that is, population growth rate divided by the population. In terms of derivatives, the quantity we are using for the prediction is the function drawn as a blue line in Figure 26.4 we can directly estimate from the data \\(P(t)\\) is \\[\\frac{\\partial_t P(t)}{P(t)} = 0.0071 - 0.000120 (t - 2020)\\] Someone who has absolutely mastered the rules of differentiation in Block 2 might recognize that \\[\\partial_t \\ln(P(t)) = \\frac{\\partial_t P(t)}{P(t)}\\] In other words, our modeling of the data has told us the derivative not of \\(P(t)\\) but of \\(\\ln(P(t))\\). Let’s accumulate that. The growth rate model is \\[\\text{Growth rate model:}\\ \\ \\ \\partial_t \\ln(P(t)) = 0.0071 - 0.000120(t-2020)\\] We’ll start in 2020, when we know \\(P(t) = 331\\) million, so \\(\\ln(P(2020)) = 19.618\\). According to the growth rate model, for the year to 2021, the growth rate will be \\(0.0071 - 0.000120(2021-2020)n= 0.00698\\)$ per year. This means that \\(\\ln(P(2021)) = 19.619 + 0.00698 = 19.6247\\). Year \\(t\\) \\(P(t)\\) \\(\\ln(P(t))\\) \\(\\partial_t \\ln(P(t))\\) (from model) 2020 331M 19.618 0.00698 2021 19.625 0.00686 2022 19.632 0.00674 2023 19.639 0.00662 2024 19.645 0.00650 2025 19.652 0.00638 2026 19.658 0.00626 2027 19.664 0.00614 2028 19.670 0.00602 2029 351M 19.677 0.00590 Performing the accumulation is simply accounting. Our model has told us the 4th column of the table for each year. We the first row of the table: \\(P(2020) = 331\\)M and therefore \\(\\ln(P(2020)) = 19.618\\). To get the \\(\\ln(P(2021)\\) row, add the number in the fourth column of previous row. Continue on from each row to the next. Once we have accumulated \\(\\ln(P(t))\\), we can convert it through exponentiation to \\(P(t)\\). [Int-2e] Determine the units of an anti-derivative given the base function and the variable of integration. [Int-5a] Determine dimensions and units utilizing a graph. [Int-5b] Graph the anti-derivative of a function given the graph of the base function and a single point on the anti-derivative. [Int-2a] Utilize Euler’s Method to approximate anti-derivatives when the value of is small. The Census estimate was a particular and somewhat peculiar way of counting people. For instance, Native Americans were excluded from the count. So the census numbers give a false impression of a small population growing on an empty continent.↩︎ "],["net-change.html", "Chapter 28 Accumulation as net change 28.1 Quantifying uncertainty with probability 28.2 Calculus and probability 28.3 The probability density function 28.4 The cumulative distribution 28.5 The expectation value", " Chapter 28 Accumulation as net change The derivative function \\(\\partial_t F(t)\\) tells us, for any input \\(t\\), what was the instantaneous rate of change of some mother function \\(F(t)\\). Suppose \\(F(t)\\) is the position of a car along a city street, perhaps measured in miles from a marked starting point. The car, slowing down, stopping, and speeding up in traffic, has a velocity (instantaneous rate of change of position) that changes in time, so \\(\\partial_t F(t)\\) will have different outputs for different values of the input \\(t\\). By accumulating \\(\\partial_t F(t)\\), that is, by anti-differentiation, we recover \\(F(t)\\). The value of \\(F(t)\\) at any \\(t\\) tells us the amount of distance covered by the car since … well, since when? Since the beginning of the month? Since the morning? Since the car was first manufactured? Any of these questions might be legitimate for some purpose or another, but we need to be careful about using \\(F(t)\\) to make sure that the result we get answers the question that’s relevant. So after we’ve built \\(F(t)\\), we need to be specific about the answer to “Starting from where?” An important way in which the anti-derivative is used involves specifying the “Starting from where?” input. Let’s call this \\(t_a\\). Perhaps our interest in accumulating the velocity is to know how far we’ve traveled since starting on the present trip. So set \\(t_a\\) to be the start time. The word “net” has several meanings, including a means of fishing or trapping butterflies. Here, our use of “net” reflects the usage in accounting. The net of a quantity is that quantity minus some deduction. Without taking into account the deduction, the quantity is called a “gross” quantity. For instance, you can find the gross weight of a bottle of pickles by putting the sealed bottle on a scale. The resulting gross quantity might be important to a trucker who has to carry a load of 10,000 such bottles. But to the consumer, the weight of the pickles themselves is what matters. So from the gross weight subtract the weight of the brine and of the glass in the bottle. This gives the net weight. Figure 28.1: 32 ounces of pickles (net) come in a package with a larger gross weight that includes the brine and bottle. The position at \\(t_a\\) can be written as the accumulation up to \\(F(t_a)\\). The net distance traveled up to time \\(t\\) is then the difference \\[F(t) - F(t_a)\\] our position now at time \\(t\\) minus our starting position. As it happens, every car has a feature to display the anti-derivative of the velocity evaluated at the current time. The speedometer reads off the instantaneous velocity; the anti-derivative is shown on the odometer. You’re about to set out on a trip and want to keep track of how far you’ve gone. So you look at the odometer at the start and write that down. Later in your trip, to know how far you’ve gone, read the odometer again and subtract the value you wrote down at the start. \\(F(t) - F(t_a)\\). 28.1 Quantifying uncertainty with probability Note: This section introduces some new technical words, such as “probability,” “variance,” “state space,” and “cumulative” that are broadly important in quantitative work but not traditionally considered part of calculus. Try to understand what these words mean. That will help you in your later studies in downstream courses. But you will not be examined on the details in this course. Uncertainty is the state of being unreliable or undetermined. Probability is—in modern usage—a way of quantifying uncertainty, of putting uncertainty on a scale. Before the modern era, probability was a kind of opposite to uncertainty, a state of being reliable or determined. This almost complete reversal of the definition of probability reflects the difficulty untrained people have in doing probability calculations correctly. In the mathematical formulation of probability, central components are the “event” and the “state space.” An event is something that happens, think of one flip of a coin as an event, or one frame in bowling, or the wind speed at a particular instant. The state space is the set of all possible outcomes of an event. The state space of a coin flip is famously heads or tails. The state space of a frame in bowling is the numbers 0 through 10 reflecting the number of pins bowled over. (We’re ignoring “strikes” here.) The state space of wind speed is a non-negative number as might be read off of an anemometer. A probability is a number assigned to an element of a state space. For instance, in a coin flip, the number 1/2 is conventionally assigned to each of the possible outcomes: heads or tails. There are two essential properties that these assigned numbers must have to be valid probabilities: the number must be between zero and one (inclusive). You can’t have a probability of -0.2 or 13. added up across all the elements of a state space, the probability numbers must sum to 1. The probability number 0 is assigned to elements of the state space that need not have been listed in the first place, because they cannot happen. The probability number 1 is assigned to a single element of the state space that is inevitable. Other than the possibly unfamiliar formal vocabulary used in the preceding, the statements (1) and (2) are intuitive to many people. What might calculus have to contribute? This course being calculus, we are concerned particularly with quantities that are continuous, e.g. the location of a point on the number line, the weight of a bucket after it’s been rained on, etc. For a continuous quantity, the state space will be the number line \\(-\\infty &lt; x &lt; \\infty\\) or some finite segments of the number line, e.g. \\(0 \\leq x \\leq 1\\). Either way, the state space consists of an infinite number of possible values. For example, one member of the \\(0 \\leq x \\leq 1\\) state space is 0.963012894848362656100076390430914821056649089340673461090773. Another is 0.4204042488709096655207811854786639390334021305202371464110919373058862984183853728834073997986972243. Still others are \\(1/\\sqrt{2}\\) and \\(1/\\pi\\) and \\(1/e\\) and on and on without end. To illustrate, the sandbox allows you to specify any target number you like between 0 and 1, which we’ll call \\(\\tau\\) (tau). Using a professional quality “random number generator” called rnorm(), we’ll generate 100 or 1000 or 1,000,000 events, each of which is a random number between 0 and 1. Then calculate how many of those events hit your specific target. You can look at each of the events by uncommenting the middle line. The last line counts how many of the events “hit the target.” (0 means, “none of them hit the target.”) Play the game as many times as you like, with whatever number \\(0 \\leq \\tau \\leq 1\\) you think will be most lucky. The integer argument to rnorm() specifies how many trials to run. For the sake of not burdening the computers serving the Daily Digital, don’t make the argument much bigger than 1,000,000. You only need to change the numbers in blue font to play the game and hit the check your answer button. TURN THIS INTO AN APP tau &lt;- 1/3 # or whatever number you like between 0 and 1 # rnorm(100) == beta # look at each of the events sum(rnorm(10000) == tau) # 10,000 events 28.2 Calculus and probability Given the result from the “randomly hit the target” experiment, it would be reasonable to conclude that runif(0) picks numbers each of which has a probability of 0. It would be better to say that the probability is infinitesimal, just like the \\(h\\) in the definition of the derivative or the \\(dx\\) in the way we write integrals. Calculus provides the means to assign such infinitesimal probabilities to the elements of a continuous state space. The strategy is this: Assign a function whose output, over the state space, never negative. Ensure that, over the state space, e.g. for \\(x\\) in the interval \\(a \\leq x \\leq b\\) that \\[\\int_a^b\\! f(x) dx = 1\\] Such functions are called “probability density functions.” Here’s one probability density function: \\[\\mbox{uniform} (x) \\equiv \\left\\{\\begin{array}{cl}\\frac{1}{b-a} &amp; \\mbox{when} \\ a \\leq x \\leq b\\\\0&amp;\\mbox{otherwise} \\end{array}\\right.\\] Consider a question like, “What’s the probability that the outcome of an event governed by the uniform probability density will be \\(c\\)?” The answer is not \\(f(c)\\). Neither is it \\(f(c) dx\\). Instead, the answer is \\(\\int_c^c f(x) dx = 0\\). Many non-mathematicians might answer the question by saying that the probability is \\(f(c) dx\\). There’s something to that answer, but remember that \\(dx\\) is a notation meaning “take the limit as it goes to zero,” \\(f(c)dx\\) is a limit rather than a number. (Save yourself from trying to sort this out with a shortcut: \\(f(c) dx\\) isn’t a number. But \\(\\int_c^c f(x) dx\\) is a number, namely 0.) \\(f(c)\\) is much like the concept of “density.” We can meaningfully say that a material has a density at each point. But it’s not useful to say that a material has a mass at each point. The mass of a material is the integral of the density over the space occupied by the material. Question A What is \\[\\int_a^b dx\\ \\ \\mbox{?}\\] You haven’t said what the function to be integrated is. ☹︎ Let’s rewrite the integral in the question as \\[\\int_a^b 1 dx\\]. The function being integrated is the one where the output is 1, regardless of the input. \\(b-a\\) ✓ \\(b - a + C\\) ☹︎ This is a definite integral. There will be no constant of integration. Or, said another way, the answer is \\((b+C) - (a+C)\\), with the constant of integration attaching to both the evaluations of the anti-derivative at the limits of integration. The two \\(C\\) terms cancel out. 1.4 ☹︎ Reasonable answer insofar as a definite integral, with numerical limits of integration, evaluates to a number. But here the limits of integration (\\(a\\) and \\(b\\)) are parameters, so the definite integral is a function of those parameters. Question B According to the definition of uniform\\((x)\\), what is \\[\\int_{-\\infty}^a \\mbox{uniform}(x) dx\\ \\ \\mbox{?}\\]     0 ✓ Right. The value of uniform\\((x)\\) is zero everywhere on the interval \\(- \\infty \\leq x \\leq a\\).        1 ☹︎ This would be if the bounds of integration were a to b. Remember a is the lower bound of the uniform function.        \\(b - a\\) ☹︎ Remember a is the lower bound of the uniform function.        \\(a - b\\) ☹︎ Remember a is the lower bound of the uniform function. Question C According to the definition of uniform\\((x)\\), what is \\[\\int_a^b\\mbox{uniform}(x) dx\\ \\ \\mbox{?}\\] 0 ☹︎ uniform(x) by definition is a probability density function. 1 ✓ You can see this using the fact that \\[\\int_a^b dx = b - a\\], so \\(\\int_a^b \\mbox{uniform}(x) dx = 1\\). \\(b - a\\) ☹︎ uniform(x) by definition is a probability density function. \\(a - b\\) ☹︎ uniform(x) by definition is a probability density function. Not enough information to know. ☹︎ uniform(x) by definition is a probability density function. Question D Using the results from the previous questions, what is \\[\\int_{-\\infty}^{\\infty} \\mbox{uniform}(x) dx\\ \\ \\mbox{?}\\]     0 ☹︎        1 ✓ That’s part of the definition of a probability density function, that the integral over all possible values of \\(x\\) must be 1.        \\(b-a\\) ☹︎        \\(a-b\\) ☹︎ 28.3 The probability density function The probability density function is a helpful way of visualizing the possible outcomes of an event. By looking at a graph of the density function, you can see which outcomes are relatively likely and which are not. For instance, here is a probability density function called an “exponential density.” \\[p(t) \\equiv k\\, e^{-t/k}\\] Exponential densities are often used to model things like the time between earthquakes or the time between engine failures. As an example, if \\(t\\) is measured in years and \\(k=1/100\\), the exponential density is the standard model of the time between consecutive 100-year storms at a location. Notice that the probability density is zero for negative time. That’s just common sense at work; the time between consecutive storms can’t be negative. Perhaps more surprisingly, there’s a substantially non-zero probability density for the time between storms being just 10 years, or even less! And notice the very small numbers on the y-axis; the density is much less than 1. But that’s OK, because a probability density is not the same as a probability. Question E How much probability corresponds to one small gray square of area in the graph?     1 ☹︎ pick a gray box, what are its dimensions?        .0625 ✓ that is 6.25%        .125 ☹︎ pick a gray box, what are its dimensions?        .25 ☹︎ This is four gray boxes, not one and 25% Question F Using your answer from the previous question, estimate the probability (by counting gray boxes) of the time between 100 year storms being 50 years or less?     1 ☹︎ your bounds for t are between 0 and 50 years        .0039 ☹︎ This answer is not a percent        39% ✓ Correct. If you think this answer is counter-intuitive, that there is an almost 40% chance of the interval between 100 year storms being less than 50 years, you can appreciate why it’s important to hand probabilities quantitatively rather than intuitively.        .25 ☹︎ your bounds for t are between 0 and 50 years 28.4 The cumulative distribution The cumulative distribution translates the probability density into an actual probability (a number between zero and one). Formally, the cumulative distribution is \\[P(t) \\equiv \\int_{-\\infty}^t p(t) dt\\] Evaluating \\(P(t)\\) at given value of \\(t\\) gives a probability. For instance, \\(P(10) \\approx 0.095\\), roughly 10%. In terms of storms, this means that according to the standard model of these things, the time between consequtive 100-year storms has a 10% chance of being 10 years or less! A graph of the cumulative distribution shows what you might have anticipated: the hump function \\(p(t)\\) has an integral that is a sigmoid function. Question G Imagine that a 100-year storm has just happened at your location. What is the probability that the next 100-year storm will happen within 50 years?     11% ☹︎ What’s the value of \\(P(t=50)\\)        27% ☹︎ What’s the value of \\(P(t=50)\\)        39% ✓        51% ☹︎ What’s the value of \\(P(t=50)\\) Question H The median time between 100-year storms is the value where there is a 50% probability that consecutive storms will happen closer in time than this value and 50% that consecutive storms will happen further apart than this value. What is the median time between 100-year storms, according to the standard model? (Hint: You can read this off the graph.) about 30 years ☹︎ 50 years ☹︎ about 70 years ✓ 100 years ☹︎ about 130 years ☹︎ 28.5 The expectation value The expectation value is an important way to summarize a probability density function. It can be a valuable way to inform decisions, a topic we’ll save for another day. Here, we’ll focus on the calculation of the expectation value itself. Expectation values are useful, for example, in deciding whether to make an investment. Suppose you have been offered a “ground floor” opportunity in a start-up company. The statistics of start-ups show that 50% fail in their first year and another 50% of the survivors fail each year after that. You’ll have to forego salary, but you will be given stock options. You think, after 5 years, if the company gets that far, the options will be worth $5M. Should you take the job, instead of, say, a job paying $50K/year with a long-established company? Your simple model is that there is a 1/32 chance that the options will come through for $5M, otherwise they will be worthless. The expectation value is $5,000,000 \\(\\times 1/32 =\\) $156,250. This is less than what you would make working for the long-established company during the 5 years. A simple form of decision-making compares the expectation value of the start-up ($156,250) with the expectation value of then $50K/year job over five years. Calculus provides tools for working with more subtle models. You are working with a process where each event generates a numerical outcome according to a probability density function \\(f(x)\\). We collect the outcomes from many events: a series of numbers. As you know, the average of the numbers is often used to represent a “typical” outcome, a shorthand way of summarizing the sequence itself. The expectation value is the value we would get for the average if we could construct an infinitely long series of events. “Infinitely long series” is an imaginary, theoretical construct. But calculus provides a way to simulate an infinitely long series. The expectation value corresponding to a probability density function \\(f(x)\\) is an integral: \\[\\int_{-\\infty}^\\infty x \\cdot f(x) dx\\] Question I Recall that a uniform probability density is one that generates outcomes equally likely to be any number between specified lower and upper bounds. For the uniform density between \\(a\\) and \\(b\\), the probability density function \\[\\mbox{uniform} (x) \\equiv \\left\\{\\begin{array}{cl}\\frac{1}{b-a} &amp; \\mbox{when} \\ \\ a \\leq x \\leq b\\\\0&amp;\\mbox{otherwise} \\end{array}\\right.\\] What is the expectation value of uniform(x), that is, what is \\[\\int_{-\\infty}^{\\infty} x\\ \\mbox{uniform}(x) dx \\mbox{?}\\] Hint: you really only need to consider \\[\\int_a^b x\\ \\mbox{uniform}(x) dx\\], since \\[\\int_{-\\infty}^a \\mbox{uniform}(x) dx=\\int_b^{-\\infty} \\mbox{uniform}(x) dx=0\\] \\((b-a)/3\\) ☹︎ The anti-derivative of \\(x \\cdot\\) uniform\\((x)\\) is \\[\\frac{1}{2}\\frac{1}{b-a} x^2\\]. \\((a + b)/2\\) ✓ \\(\\sqrt{a^2 + b^2}\\) ☹︎ The anti-derivative of \\(x \\cdot\\) uniform\\((x)\\) is \\[\\frac{1}{2}\\frac{1}{b-a} x^2\\]. \\((a-b)/2\\) ☹︎ Remember that \\(b^2 - a^2 = (b+a)(b-a)\\) It involves \\(\\infty\\). ☹︎ I think you’re plugging \\(\\pm \\infty\\) as the bounds of the definite integral. But remember that \\(\\mbox{uniform}(x &lt; a) = \\mbox{uniform}(b &lt; x) = 0.\\) The sandbox below gives the probability density function for the exponential process used in the example of the time interval between successive 100 year storms. Your task is to compute the expectation value for the time between storms. In symbols, this is \\[\\int_{-\\infty}^\\infty t\\times p(t)\\, dt\\] You can use antiD() to find the antiderivative and Inf to stand for infinity. # probability density p &lt;- makeFun(ifelse(t &lt; 0, 0, exp(-t/100)/100) ~ t) # For the expectation value, we want to integrate t*p(t) F &lt;- antiD(...integrand... ~ t) # Evaluate F(...upper...) - F(...lower...) [Int-3a] Understand the notation of limits of integration within a definite integral. [Int-3b] Determine the units of a definite integral (MMAC pg. 614). [Int-3c] Use the algebraic properties of definite integrals (MMAC pg. 615-616) to calculate definite integrals. [Int-3d] Calculate definite integrals graphically [Int-4a] Understand the Fundamental Theorem of Calculus Part 2 as how to evaluate definite integrals [Int-4b] Comprehend how the Fundamental Theorem of Calculus Part 2 graphically can calculate the area between curves (MMAC pgs. 644-645) [Int-4c] Understand the Fundamental Theorem of Calculus Part 1 as the net accumulation function [Int-4d] Understand how a definite integral with a variable limit of integration outputs a function By introducing the parent/child metaphor for the kind of relationship captured by differentiation, we’ve anticipated the “Fundamental Theorem.” It therefore won’t seem so fundamental. So don’t overdo the “Fundamental” part. [Int-6a] Understand the relationship between the hump function and the sigmoidal function. [Int-6b] Discuss the scientific application of probability density and cumulative probability. [Int-6c] Understand the concept of expected value. "],["accum-advanced-algebra.html", "Chapter 29 Advanced algebraic methods 29.1 Differentials 29.2 U-substitution 29.3 Integration by parts", " Chapter 29 Advanced algebraic methods [Int-7a] Find the integral algebraically using the technique u-substitution. [Int-7b] Find the integral algebraically of select functions using Integration by Parts. 29.1 Differentials The notation we have been using in this course for “the derivative of \\(f()\\) with respect to \\(x\\) is \\[\\partial_x f\\] The subscript on the \\(\\partial\\) indicates the”with respect to\" variable, the curly-d \\(\\partial\\) itself signals “the derivative.” The identification of the “with respect to” variable is particularly important when the function \\(f()\\) has more than one input, for example with \\(f(x, t) \\equiv e^{-k x} \\sin(\\omega t)\\). With anti-differentiation (also called “integration”), we write things differently, for example \\[\\int f(x, t) dx\\] where the \\(dx\\) signals the “with respect to” variable. And just as \\(\\partial_x f(x, t)\\) and \\(\\partial_t f(x,t)\\) are different functions, so are \\(\\int f(x, t) dx\\) and \\(\\int f(x, t) dt\\). Writing anti-differentiation/integration this way follows a convention of long standing. In interpreting a sequence of symbols like \\(\\int f(x,t) dx\\), it’s natural to think of the sequence as three parts: \\[\\underbrace{\\int}_{\\mbox{integral sign}} \\overbrace{f(x, t)}^{\\mbox{function to be anti-differentiated}} \\underbrace{dx}_{\\mbox{&#39;with respect to&#39;}}\\] By analogy, the sentence \\[\\mbox{We loaded up on snacks.}\\] consists of five parts: the five words in the sentence. But you can also see “We loaded up on snacks” as having three parts: \\[\\underbrace{\\mbox{We}}_{\\mbox{subject}}\\ \\overbrace{\\mbox{loaded up on}}^{\\mbox{verb}}\\ \\ \\ \\underbrace{\\mbox{snacks}}_{\\mbox{object}}\\] Likewise, the integrate sentence can be seen as consisting of just two parts: \\[\\underbrace{\\int}_{\\mbox{integral sign}} \\overbrace{f(x, t) dx}^{\\mbox{differential}}\\] A differential corresponds to the little sloped segments that we add up when calculating a definite integral numerically using the slope function visualization. That is \\[\\underbrace{\\int}_{\\mbox{Sum}} \\underbrace{\\overbrace{f(x,t)}^\\mbox{slope of segment}\\ \\ \\overbrace{dx}^\\mbox{run}}_\\mbox{rise}\\] A differential is a genuine mathematical object and is used, for example, in analyzing the geometry of curved spaces, as in the Theory of General Relativity. But this is well beyond the scope of this introductory calculus course. There is one place in introductory calculus where you need to manipulate differentials: carrying out anti-differentiation of some functions that are not basic modeling functions with a linear interior function but which nonetheless have an anti-derivative that can be expressed in algebra. You should be thinking in terms of differentials when you see a sentence like the following: “In \\(\\int \\sin(x) \\cos(x) dx\\), make the substitution \\(u = \\sin(x)\\), implying that \\(du = \\cos(x) dx\\) and getting \\(\\int u du\\), which is simple to integrate.” The table gives some examples of functions and their differentials. “w.r.t” means “with respect to.” Function derivative w.r.t. differential \\(v(x) \\equiv x\\) 1 x \\(dv = dx\\) \\(u(x) \\equiv x^2\\) \\(2x\\) x \\(du = 2x dx\\) \\(f(x) \\equiv \\sin(x)\\) \\(\\cos(x)\\) x \\(df = \\cos(x)dx\\) \\(u(x) \\equiv e^{3 x}\\) \\(3 e^{3 x}\\) x \\(du = 3 e^{3 x} dx\\) \\(g(x) \\equiv t^3\\) \\(3 t^2\\) t \\(dg = 3 t^2 dt\\) As you can see, the differential of a function is simply the derivative of that function followed by the little \\(dx\\) or \\(dt\\) or whatever is appropriate for the “with respect to” variable. Exercise 29.1 Note: Tradition is to write something like \\(u \\equiv e^{3 x}\\) rather than \\(u(x) \\equiv e^{3 x}\\). The traditional notation is what we’ll use in the following exercises. Question A What is the differential of \\(u = x + 5\\)? \\(du = dx\\) ✓ Since \\(\\partial_x (x+5) = 1\\). \\(du = (x+5)dx\\) ☹︎ You should have used \\(\\partial_x (x+5)\\) instead of \\((x+5)\\) on the right side. \\(du = 5 dx\\) ☹︎ Is \\(\\partial_x (x+5) = 5\\)? No! \\(du = x dx\\) ☹︎ You should have used \\(\\partial_x (x+5) = 1\\) instead of \\(x\\) on the right side. Question B What is the differential of \\(u = \\sin(2x + 5)\\)? \\(du = 2 \\cos(2x + 5) dx\\) ✓ Since \\(\\partial_x \\sin(2x + 5) = 2 \\cos(2x + 5)\\). \\(du = (2x+5)dx\\) ☹︎ You should have used \\(\\partial_x \\sin(2x+5)\\) instead of \\((2x+5)\\) on the right side. \\(du = 5 dx\\) ☹︎ Is \\(\\partial_x \\sin(2x+5) = 5\\)? No! \\(du = 2x dx\\) ☹︎ You should have used \\(\\partial_x \\sin(2x+5) = 2 \\cos(2x + 5)\\) instead of \\(2x\\) on the right side. Question C What is the differential of \\(v = e^x\\)? \\(du = e^x dx\\) ☹︎ The name of the function here is \\(v()\\), not \\(u\\). So the differential should be written \\(dv\\). \\(dv = e^x dx\\) ✓ Since \\(\\partial_x e^x = 1\\). \\(du = x dx\\) ☹︎ The name of the function here is \\(v()\\), not \\(u\\). So the differential should be written \\(dv\\). \\(dv = x dx\\) ☹︎ But \\(\\partial e^x = e^x\\), not \\(x\\). Question D What is the differential of \\(f = \\cos(\\ln(t))\\)? \\(df = -\\sin(\\ln(t))/t dt\\) ✓ Since the chain rule tells us \\(\\partial_t\\cos(\\ln(t)) = -\\sin(\\ln(t))/x\\). \\(du = -\\sin(\\ln(t))/t dt\\) ☹︎ There’s no \\(u\\) in sight in this problem. It’s \\(f\\). \\(dv = -\\sin(\\ln(t))/t dt\\) ☹︎ There’s no \\(v\\) being used in this problem. It’s \\(f\\) that we’re asking about. \\(df = -\\sin(\\ln(x))/x dx\\) ☹︎ \\(f\\) is a function of \\(t\\), not \\(x\\). 29.2 U-substitution Differentiation and anti-differentiation are operations that undo one another. For instance, \\[F(t) = \\int \\left[\\partial_t F(t)\\right] dt + C\\] and \\[f(t) = \\partial_t \\int f(t) dt\\] We use differentiation and integration when we have information in one form (for instance a measurement of current in a circuit) and we find it more usefult to translate into another form (for instance the voltage across an element of the circuit). There is little reason to use \\(\\partial_t\\) and \\(\\int \\left[\\right]dt\\) to cancel each other out, but it is the basis of a successful strategy for finding some anti-derivatives algebraically. Here’s the differentiate/integrate algorithm behind u-substitution. Pick a function \\(f()\\) and another function \\(g()\\). Typically \\(f()\\) and \\(g()\\) belong to the family of basic modeling functions, e.g. \\(e^x\\), \\(\\sin(t)\\), \\(x^n\\), \\(\\ln(x)\\), and so on. For the purpose of illustration, we’ll use \\(f(x) = \\ln(x)\\) and \\(g(t) = \\cos(t)\\). Compose \\(f()\\) with \\(g()\\) to produce a new function \\(f(g())\\) which, in our case, will be \\(\\ln(\\cos(t))\\). Use the chain rule to find \\(\\partial_t f(g(t))\\). In the example, the derivative of \\(\\ln(x)\\) is \\(1/x\\), the derivative of \\(g(t)\\) is \\(-\\sin(t)\\). By the chain rule, \\[\\partial_t f(g(t)) = - \\frac{1}{g(t)} \\sin(t)= - \\frac{\\sin(t)}{\\cos(t)} = - \\tan(t)\\] In a sense, we have just watched a function give birth to another through the straightforward process of differentiation. Having witnessed the birth, we know who is the integration mother of \\(\\tan(t)\\), namely \\(\\int \\tan(t) dt = \\ln(\\cos(t)\\). For future reference, we might write this down in our diary of integrals: \\[\\int \\tan(t) dt = - \\ln(\\cos(t)) + C\\] Saving this fact in your diary is helpful. The next time you need to find \\(\\int \\tan(x) dx\\), you can look up the answer (\\(-\\ln(\\cos(x)) + C\\)) from your diary. If you use \\(\\int \\tan(x) dx\\) a lot, you will probably come to memorize the answer, just as you have already memorized that \\(\\int \\cos(t) dt = \\sin(t)\\) (a fact that you actually will use a lot in the rest of this course). Now for the u-substitution game. The trick is to take a problem of the form \\(\\int h(t) dt\\) and extract from \\(h(t)\\) two functions, an \\(f()\\) and a \\(g()\\). You’re going to do this so that \\(h(t) = \\partial_t F(g(t))\\), where \\(\\partial_x F(x) = f(x)\\) Once you’ve done this, you have an answer to the original integration question: \\(\\int h(t) dt = F(g(t)) + C\\). Here’s Example 7 from the MMAC book: Evaluate the definite integral \\(\\int \\frac{\\sin(\\ln(x))}{x} dx\\). You don’t know ahead of time that this is an integral amenable to solution by u-substitution. For all you know, it’s not. So you look at the instruction manual for calculating integrals that you don’t yet know: Is the integrand (that is \\(h(x)\\) in \\(\\int h(x) dx\\)) one of the basic modeling functions (with, perhaps, a linear interior function)? If so, you’ve already memorized the answer and you are done. If not … Assume for a moment—without any guarantee that this will work, mind you—that the answer can be built using u-substitution. You will therefore look hard at \\(h()\\) and try to see in it a plausible form that looks like the derivative of some \\(f(g(x))\\). In the problem at hand, we can readily see something of the form \\(f(g(x))\\) in the \\(\\sin(\\ln(x))\\). This immediately gives you a candidate for \\(g(x)\\), namely \\(g(x)\\equiv \\ln(x)\\) We don’t know \\(f()\\) yet, but if \\(g()\\) is the right guess, and if u-substitution is going to work, we know that \\(f()\\) has to be something that produces \\(\\sin()\\) when you differentiate it. That’s \\(-\\cos()\\). So now we have a guess \\[h_\\mbox{guess}(x) = -\\cos(\\ln(x)) \\partial_x \\ln(x) = - \\cos(\\ln(x)) / x\\] If this guess matches the actual \\(h()\\) then you win. The answer to \\(\\int h(x) dx\\) will be \\(f(g(x)) = -\\cos(\\ln(x))\\). If not, see if there is any other plausible guess for \\(g(x)\\) to try. If you can’t find one that works, go on to Integration by parts. We’ll talk about this later. If integration by parts doesn’t work … there is a variety of possibilities such as asking a math professor (who has a much larger set of functions at hand than you), looking through a table of integrals (which is to say, the collective calculus diary of generations of math professors), using a computer algebra system, or using numerical integration. One of these will work. Exercise 29.2 Question E In \\(h(x) = 2x/(x^2 + 2)\\) which of the following is a plausible candidate for an interior function \\(g(x)\\)?     \\(\\sin(x)\\) ☹︎        \\(\\ln(x)\\) ☹︎        \\(2x\\) ☹︎ In order for this to be an interior function \\(g(x)\\) there has to be some other function embracing it. \\(2x\\) is standing proudly on its own, so it’s not a good choice for \\(g(x)\\)        \\(x^2 + 2\\) ✓ Question F Continuing with the integral of \\(h(x) = 2x/(x^2 + 2)\\) and the working guess that \\(g(x) = x^2 + 2\\), do you see any part of \\(h()\\) which is a match to \\(\\partial_x g()\\)?     \\(1/x\\) ☹︎ But that’s not anything like \\(\\partial_x g(x)\\).        \\(\\ln(x)\\) ☹︎        \\(2x\\) ✓ Question G Taking seriously the progress we made in the previous two questions, we now need to write \\(h(x)\\) as \\(f(x^2 + 2) 2x\\)? What should \\(f()\\) be to make this match \\(h(x)\\)? \\(f(x) = \\sin(x)\\) ☹︎ \\(f(x) = \\ln(x)\\) ☹︎ \\(f(x) = 1/x\\) ✓ \\(x^2 + 2\\) ☹︎ Now that you have found both \\(g()\\) and \\(f()\\), you simply need to find a function \\(F(x)\\) such that \\(\\partial_x F(x) = f(x)\\). Since \\(\\partial_x \\ln(x) = 1/x\\), we know that \\(F(x) = \\ln(x)\\). Thus, \\(\\int h(x) dx = F(g(x)) = F(x^2 + 2) = \\ln(x^2 + 2)\\). Exercise 29.3 Question H \\[\\mbox{Find a plausible interior g(x) in} \\ x \\exp(x^2 + 3)\\]     \\(\\exp(x)\\) ☹︎        \\(x\\) ☹︎        \\(x^2 + 3\\) ✓        \\(x^2\\) ☹︎ The interior function has to be everything embraced by the parentheses of the exterior function \\(f()\\). Question I Using your candidate for \\(g()\\) from the previous question, which of these is a exterior f(x) in \\(x \\exp(x^2 + 3)\\) \\(f(x) = \\exp(x)\\) ✓ \\(f(x) = x\\) ☹︎ \\(f(x) = x \\exp(x)\\) ☹︎ If this were so, the resulting \\(h()\\) would have something like \\((x^2 + 3) \\exp(x^2 + 3)\\) in it. \\(f(x) = \\ln(x)\\) ☹︎ Confirm that \\(h(x) = f(g(x)) \\partial_x g(x)\\) and you win. The answer will be \\(F(g(x)) + C\\) Exercise 29.4 Question J Which of these candidates for \\(f()\\) and \\(g()\\) will produce \\[f(g(x))\\, \\partial_x g(x) = x^3 \\cos(x^4)\\ ?\\] \\(f(x) = \\cos(x)/4\\) and \\(g(x) = x^4\\) ✓ The 1/4 cancels out the 4 produced by \\(\\partial_x g(x)\\). \\(f(x) = \\cos(x)\\) and \\(g(x) = x^4\\) ☹︎ \\(f(x) = x^4\\) and \\(g(x) = \\cos(x)\\) ☹︎ But \\(h(x)\\) involves \\(\\cos(x^4)\\) not \\(cos^4(x)\\). Once again, \\(\\int h(x) dx = F(g(x))\\), where \\(\\partial_x F(x) = f(x)\\). Exercise 29.5 Question K What is \\[\\int \\frac{\\sin(x)}{\\cos^5(x)}dx\\ ?\\] \\(\\ln(cos(x))\\) ☹︎ \\(- \\frac{1}{4} \\cos^{-4}(x)\\) ✓ \\(\\frac{1}{6} \\cos^{-6}(x)\\) ☹︎ Exercise 29.6 Question L Use u-substitution to find \\[\\int \\frac{4 e^{4x} + 4}{e^{4x}}dx\\] \\(\\ln(e^{4x} + 4)\\) ✓ \\(1/(e^{4x} + 4)\\) ☹︎ \\(\\frac{1}{4} e^{4x} + 4\\) ☹︎ \\(\\frac{1}{2} 1/(e^{4x} + 4)^2\\) ☹︎ 29.3 Integration by parts So far in CalcZ we have developed methods for algebraically finding anti-derivatives for a small set of functions. These include basic modeling functions such as \\[\\int\\cos(3x)dx = \\frac{1}{3}\\sin(3x) + C\\] and more complicated functions where we reverse the chain rule, such as \\[\\int x^2 \\exp(x^3) dx = \\frac{1}{3} \\exp(x^3) + C .\\] With a bit more work, we can extend to a broader class of functions that do not fit into the two classes of examples above. For example, consider finding the anti-derivatives of the following functions: \\[f(x) \\equiv x e^x, \\ \\ \\ g(x)\\equiv x \\cos(x),\\ \\ \\mbox{and}\\ \\ h(x) = x \\ln(x)\\] None of these are basic modeling functions and none of these fit the “came from the chain rule” pattern. Now, we’re going to explore a “guess and correct” method for these types of anti-derivatives. It doesn’t always work, but when it does it’s impressive. Note that each of the function above are products of \\(x\\) with a basic modeling functions. Finding the anti-derivatives of these functions will, in some sense, involve reversing the product rule. Consider \\(f(x) = x e^x\\). This will seem to come out of the blue, but notice that \\(f(x) = x \\partial_x(e^x)\\). Our strategy has three steps. First, we will find a helper function by substituting \\(\\partial_x(e^x)\\) with the value produced by differentiation. In this case \\(\\partial_x (e^x) = e^x\\), so our helper function will be \\(x e^x\\). Second, differentiate the helper function, which we can do using the product rule: \\[\\partial_x (x e^x) = x e^x + e^x\\] Third, take the anti-derivative of each term in the above equation. Some of them are easy, but one of them is not. \\[\\int \\partial_x (x e^x) = \\int x e^x dx + \\int e^x dx\\\\ \\mbox{integrating what we can ...}\\\\ x e^x\\ \\ \\ \\ = \\int x e^x dx +\\ \\ \\ \\ e^x\\] The one we don’t know how to do is the same as the original problem. So now we know how to do it, by re-arranging the previous equation: \\[\\int x e^x dx = x e^x - e^x + C\\] We added in a constant \\(C\\) at the end to get the entire family of anti-derivatives. Aren’t sure this answer is right? You can check it by computing the derivative of the answer to see that it gives \\(x e^x\\). Exercise 29.7 Problem 1: Go through the steps above to find the anti-derivative of \\(g(x) \\equiv x \\cos(x)\\). Step 1 hint: We know the anti-derivative of \\(\\cos(x)\\) is \\(\\sin(x)\\), so an appropriate helper function is the function \\(x\\, \\sin(x)\\). Now do steps (2) and (3): (2) take the derivative of the helper function and then (3) integrate each term in the result. Question M What is the derivative of the helper function with respect to \\(x\\)? \\(\\partial_x \\mbox{helper}(x) = \\sin(x) + x \\cos(x)\\) ✓ \\(\\partial_x \\mbox{helper}(x) = \\sin(x) + x \\sin(x)\\) ☹︎ \\(\\partial_x \\mbox{helper}(x) = \\sin(x) + \\cos(x)\\) ☹︎ \\(\\partial_x \\mbox{helper}(x) = \\sin(x)\\cos(x)\\) ☹︎ Question N What is \\[\\int \\partial_x \\mbox{helper}(x)\\ ?\\] \\(\\mbox{helper}(x) + C\\) ✓ We included the constant of integration \\(C\\) just as a reminder. \\(\\frac{1}{2} \\mbox{helper}^2(x)\\) ☹︎ \\(1 / \\mbox{helper}(x)\\) ☹︎ Whatever it is, it’s just as complicated as the original integral. No obvious way to do it. ☹︎ Actually, the answer is simple, even if it doesn’t seem to get us anywhere. Wait for the next problem! Question O What is the integral with respect to \\(x\\) of the first part of the expanded form of the helper function, that is, \\(\\int \\sin(x) dx\\)? \\(-\\cos(x)\\) ✓ This is one of our basic modeling functions. \\(\\cos(x)\\) ☹︎ Close. \\(\\cos(x) = \\partial_x \\sin(x)\\), but we want \\(\\int \\sin(x) dx.\\) \\(e^x \\sin(x)\\) ☹︎ \\(e^x \\cos(x)\\) ☹︎ Question P What is the integral with respect to \\(x\\) of the second part of the expanded form of the helper function, that is, \\(\\int x\\, \\cos(x)\\)? It’s the same as the original problem! I thought you were showing us how to do the problem. If we didn’t know the answer when we started, why should we be able to do it now? ☹︎ An understandable frustration. But think! Now you have the original problem written out as part of an equation with two integrals that you do know. It’s the same as the original problem. I’ve got an equation involving the original problem and two bits of algebra/calculus that I know how to do. Thanks! ✓ \\(\\sin(x)\\) ☹︎ If this were true, then \\(\\partial_x \\sin(x)\\) would give us \\(x\\, \\cos(x)\\). But, as you know, \\(\\partial_x \\sin(x) = \\cos(x)\\), so this answer must be wrong. Solve for the answer to the original function and write the function in R notation here: makeFun( ...your stuff here... ~ x) Exercise 29.8 Problem 2: Use the same procedure to find the anti-derivative of \\(x\\, \\cos(2x)\\). Since \\[\\cos(2x) = \\frac{1}{2}\\partial_x \\sin(2 x)\\] a reasonable guess for a helper function will be \\(x \\sin(2x)\\). (We have intentionally dropped the \\(1/2\\) to simplify the rest of the procedure. You’ll see that such multiplicative constants don’t matter, since they will be on both sides of the equation showing the derivative of the helper function. You can see this by keeping the \\(1/2\\) in the helper function and watching what happens to it.) As you work through the steps be very careful about the constants and make sure you check your final answer by differentiating. Question Q What is \\(\\partial_x x\\, \\sin(x)\\)? \\(\\sin(x) + x\\, \\cos(x)\\) ✓ \\(\\sin(x) + x\\, \\sin(x)\\) ☹︎ \\(\\cos(x) + x\\, \\sin(x)\\) ☹︎ \\(\\cos(x) + x\\, \\cos(x)\\) ☹︎ Question R What is \\(\\int \\partial_x [ x\\, \\sin(x)] dx\\)? \\(x\\, \\sin(x)+C\\) ✓ Integration undoes differentiation! \\(\\sin(x)+C\\) ☹︎ \\(\\cos(x)+C\\) ☹︎ \\(x\\, \\cos(x)+C\\) ☹︎ Question S What is \\(\\int x\\, \\cos(x) dx\\)? \\(x\\, \\sin(x) + \\cos(x)\\) ✓ \\(x\\, \\cos(x) + \\cos(x)\\) ☹︎ \\(x\\, \\cos(x) + \\sin(x)\\) ☹︎ \\(x\\, \\sin(x) + \\sin(x)\\) ☹︎ Exercise 29.9 A giant tortoise (with very good eyesight and standing on an unobstructed plane!) spies a head of lettuce on the ground 65 meters away. Being hungry (and knowing the shortest path between two points on the plane!), the tortoise takes off in a straight line for the lettuce. She pretty quickly reaches her top speed, but then starts to tire. If her velocity as a function of time (in meters per minute) is modeled by \\(v(t) = 7 t e^{−0.3t}\\), how long does it take the tortoise to reach her lunch? Answer this question by finding an calculus/algebra formula for the tortoise’s displacement and then use it to approximate how long it takes to get to the lettuce. We’re going to be looking at \\(\\int v(t) dt = 7 \\int t e^{-0.3 t} dt\\). We’ll call the left side of the equation “displacement(t).” Use integration by parts to find displacement(t) as a simple formula in \\(t\\). The tortoise to reach the cabbage at time \\(t^\\star\\) such that \\(\\mbox{displacement}(t^\\star) = 65\\) meters. Graph your displacement function to find \\(t^\\star\\). You can use the sandbox. (Note that the graphics domain isn’t necessarily the best choice for answering the question.) displacement &lt;- makeFun(77.77 * WHAT ~ t) slice_plot(displacement(t) ~ t, domain(t=c(0,5))) Question T At what time \\(t^\\star\\) does the tortoise reach the cabbage? 5.95 sec ☹︎ 10.85 sec ✓ 15.75 sec ☹︎ Never! (That is, \\(t^\\star\\) is infinite. ☹︎ Commentary: The procedure we have been using to find these anti-derivatives can be formalized into a method called integration by parts (IBP). However, rather than simply giving a formula and an algorithm, we wanted you to understand what is actually going on behind the scenes. In a more formal IBP approach, you try to re-arrange the function you are integrating into the product of two simple functions: \\[\\int f(x)\\, \\partial_x g(x)\\, dx\\] That is, you assume part of the original function is the derivative of some function \\(g(x)\\). Once you’ve decided how to make the re-arrangement into \\(f(x)\\) and \\(\\partial_x g(x)\\), and calculated \\(g(x)\\) from \\(\\partial_x g(x)\\), you can write the original integral into a new, and possibly simpler, way: \\[\\int f(x)\\, \\partial_x g(x)\\, dx = f(x)\\, g(x) - \\int [\\partial_x f(x)]\\, g(x) dx\\] Notice that the formula replaces the integral we want to compute with another integral. The idea is that the new integral will be easier to compute than the one you started with. This procedure works in much more generality than for the examples we did, but it is not so easy to use. You need to correctly assign \\(f(x)\\) and \\(\\partial_x g(x)\\) to the parts of the original function, and you need to be able to integrate \\(\\partial_x g(x)\\) to get \\(g(x)\\). Finally, you need to be able to integrate \\([\\partial_x f(x)]\\, g(x)\\). Perhaps you can go back and look at the previous problems with this more general description of the procedure. 29.3.1 Application to probability In DD-08 we used the exponential probability density and talked about expectation values. Translate the following into a step-by-step process, asking questions along the way. Find \\(\\int \\frac{1}{k} t e^{-t/k} dt\\), the expectation value for the exponential probability distribution. \\[\\int_a^b u \\cdot dv = \\left.u\\cdot v \\right|_a^b - \\int_a^b v\\cdot du\\] Let’s look at the function \\(\\frac{1}{k}\\ t \\ e^{-t/k}\\) Suppose we let \\(dv = \\frac{1}{k} e^{-t/k} dt\\). This gives \\(v= -e^{-t/k}\\). Let \\(u = t\\). Then \\(du = dt\\). Plugging in to the integration-by-parts formula we have \\[\\int_{0}^\\infty \\frac{1}{k} t e^{-t/k} dt = \\left[ t e^{-t/k}\\right]_{0}^\\infty + \\int_{0}^{\\infty}e^{-t/k}dt= 0 - \\left[k e^{-t/k}\\right]_0^\\infty = k\\] "],["antidiff-review.html", "Chapter 30 Review of anti-differentiation methods", " Chapter 30 Review of anti-differentiation methods Whenever you undertake to study a field, it’s helpful to be able to figure out when you have already learned enough and can apply what you know with confidence to solve the analysis and design tasks you encounter. In academia, we sidestep the heart of this important question and define “enough” in procedural terms: “enough” is when the semester has ended and you have passed the final exam. For academic institutions, especially ones based on the liberal arts, there’s little point in trying to be more definitive. After all, the “analysis and design tasks you [will] encounter” are as yet unknown, even though we can make reasonable guesses what many of them will be. You will never know all there is to know about integration. Thousands of talented and highly trained mathematicians and applied scientists have contributed to the body of knowledge over 300+ years you simply don’t have enough time in your life to master all of it. Even if you devoted your life to this task, the field evolves. For instance, in 1953 (that may seem like antiquity) a hugely important integration innovation was presented in this paper. This method, which involves using random numbers, was refined, extended, and improved. A breakthrough in 1988 led to an algorithm for solving genuinely important applied problems in statistics that had previously been thought impossible. Since you’ll never know everything about integration, you need to prioritize. But you are not yet in a position to set priorities. You’re at the start of a university-level sequence of courses and don’t yet know what you will encounter. Of course, your instructors know what’s in that sequence of courses and can make sensible choices for you, except … what’s in those courses depends on the traditions and conventions of those fields as interpreted by by the textbook writers in those fields. That’s rooted in the textbooks that those instructors used as students. In turn, those textbooks were shaped by the education of earlier textbook authors 50 and 100 years ago. Another aspect of the prioritization we make for you has to do with the imperatives of our jobs as teachers. Instructors focus on topics that can be assessed successfully with the resources at hand. In practice this means topics where answers are either right or wrong and where its possible to generate new assessment questions easily. Sometimes, in some places, the cart gets put before the horse and ease of assessment becomes the highest priority. CalcZ is motivated by a desire to start over from scratch and reframe priorities according to what skills you are likely to need in the next few years. Yet it would be a disservice to you to sweep the floor completely clean. An important part of your work in the next few years will be engaging with instructors who communicate using their own conceptions of calculus, largely formed when they were educated. Which brings us to … today’s Daily Digital. We have already introduced you to methods of anti-differentiation based on algebraic notation, specifically anti-derivatives of basic modeling functions with a linear interior function. These are important and relatively easy to teach and learn. Today we’re going to introduce you to two more algebraic methods of anti-differentiation: “u-substitution” and “integration by parts.” You may encounter these in some of your future courses. That “may” is likely enough that instructors of those courses rank them as high-priority topics for your introduction to calculus. They want us to teach these topics and the topics are without argument traditional components of introductory statistics courses. Regrettably, an emphasis on three algebraic methods of integration will give you a picture that integration is about algebra. It is not. Integration is about functions. And there are many important and widely used function types for which there is no algebraic solution to the problem of integration. Yet every function can be anti-differentiated. And, a good technique for anti-differentiating any function is readily at hand via numerical techniques similar to the Euler method. These methods are implemented in a pretty simple R function: antiD(). Consider antiD() and learning to use it a fourth method of integration, and one that is much easier than either u-substitution or integration by parts. Since antiD() can handle all comers, while the algebraic methods can handle only a small (and hard to predict) set of functions, in terms of using anti-derivatives, antiD() would be the highest priority and would, on its own, be adequate for doing integration. The algebraic methods of integrating the basic modeling functions give you the vocabulary you need to communicate with the huge majority of people who learned calculus in the traditional, algebraic way. U-substitution and integration by parts bring you marginally further along, but not nearly so far along as computer algebra systems or even the traditional printed handbook called a “table of integrals.” Finally, as you will learn in statistics, they way you take a sample is of fundamental importance in whether you will get a faithful representation of a process. In calculus textbooks (even our own MMAC text), the sample of integration problems is highly influenced by the relatively ease for instructors to generate new and never-before-seen functions that can be anti-differentiated using u-substitution or integration by parts. It’s safe to say that you would never encounter such functions in professional uses of calculus. (Uses other than teaching calculus, that is!) If you have difficulty using u-substitution or integration by parts, you will be in the same league as the vast majority of calculus students. Think of your fellow students who master the topic in the way you think of ice dancers. It’s beautiful to watch, but hardly solves every problem. People who would fall on their face if strapped to a pair of skates have nonetheless made huge contributions in technical fields, even those that involve ice. (Prof. Kaplan once had a heart-to-heart with a 2009 Nobel-prize winner who confessed to always feeling bad and inadequate as a scientist because he had not done well in introductory calculus. It was only when he was nominated for the Nobel that he felt comfortable admitting to his “failure.”) Even if you don’t master u-substitution or integration by parts, remember that you can integrate any function using easily accessible resources. We’ve devoted about a third of this block on accumulation to algebraic techniques for calculating anti-derivatives. You will see these techniques in use in some of your future classes and work in science and engineering. It’s the nature of things that some people master the algebraic techniques and many do not. But it’s easy to make mistakes. Even more fundamentally, there are many accumulation problems where the functions to be integrated do not have an algebraic form for the anti-derivative. In such cases, professionals use numerical techniques such as the Euler method. In order to give you a simple way to construct the anti-derivative of (just about) any function, while minimizing the amount of computer programming, we have packaged up anti-differentiation techniques into one, easy to use R function. This is antiD(). The antiD() function has the same interface as D() or makeFun(): the argument is a tilde expression of the sort sqrt(x*sin(3*x)) ~ x. The result returned from antiD() is a new R function that takes as its argument the “with respect to” variable. The sandbox provides a space to play with antiD() so that you feel comfortable using it. antiD(x^-2 ~ x) f &lt;- makeFun(sqrt(x*sin(3*x)) ~ x) antiD(f(x) ~ x) As you can see from the output of the sandbox, antiD() returns an R function(). The variable on the right of the tilde expression in the argument becomes the first of the arguments to that function. There is also a C argument: the constant of integration. antiD() knows a few of the algebraic integration techniques, roughly at the level of the basic modeling functions part of the course. When antiD() identifies the tilde expression as something it can handle, it returns a function whose body is the algebraic formula for the anti-derivative (although sometimes written in a cumbersome way). When antiD() does not recognize its argument as a basic modeling function, the result is still an R function with the “with respect to” variable and C as arguments. But the body of the function is unintelligible to a human reader (except perhaps for the numerical_integration()). The method of numerical integration is more sophisticated than Euler, and is highly precise and reliable. We’re going to use antiD() in this daily digital simply because we want to focus on the process of differential modeling. The integrals you encounter will sometimes be ones you know how to handle algebraically. It’s a good idea to do such integrals by hand and then compare to the results of antiD() to check your work. Example: Find the numerical value of this definite integral. \\[\\int^{7}_{3} e^{x^{2}} dx\\] Example Solution in R F &lt;- antiD(exp(x^2)~x) F(7) - F(3) ## [1] 1.3767e+20 Exercise 15.3: ACD4Z Using whatever computational tool you like, find the numerical value of this definite integral. \\[\\int^{5}_{2} x^{1.5} dx\\] Recall that for a definite integral of function \\(f()\\), you find the anti-derivative \\(F(x) \\equiv \\int f(x) dx\\) and evaluate it at the limits of integration. Here that will be \\(F(5) - F(2)\\). Solution f &lt;- antiD( x^1.5 ~ x ) f(5) - f(2) ## [1] 20.098 Exercise 15.4: H2eu2 Question A What’s the numerical value of \\[\\int_2^5 x^{1.5} dx ?\\]     0.58 ☹︎        6.32 ☹︎        20.10 ✓        27.29 ☹︎        53.6 ☹︎        107.9 ☹︎        1486.8 ☹︎ Exercise 15.5: H2l32 Question B What’s the numerical value of \\[\\int^{10}_{0} \\sin( x^2 ) dx ?\\]     0.58 ✓        6.32 ☹︎        20.1 ☹︎        27.29 ☹︎        53.6 ☹︎        107.9 ☹︎        1486.8 ☹︎ Exercise 30.1 Exercise 15.6: H2l33 Question C What’s the numerical value of \\[\\int^{4}_{1} e^{2x} dx ?\\]     0.58 ☹︎        6.32 ☹︎        20.1 ☹︎        27.29 ☹︎        53.6 ☹︎        107.9 ☹︎        1486.8 ✓ Include the mortgage problem "]]
