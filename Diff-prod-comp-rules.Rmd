# Differentiation by algebra {#prod-comp-rules}

## Memorizing derivatives

Generations of calculus students have had to memorize the algebraic form  of some simple derivatives and *rules* for constructing the derivative of complicated algebraic expressions based on the simple forms.

Often, courses in many fields that have calculus as a pre-requisite make use of these simple forms and rules. So it's helpful to commit the most common ones to memory. 

**Naked modeling functions**

* The derivative of a **constant function** is the zero function.
    - $f(x) \equiv 7 \ \ \implies \ \ \partial_x f(x) \equiv 0$
    - $g(x) \equiv a \ \ \implies \ \ \partial_x g(x) \equiv 0$
    - $h(x,y) \equiv y \ \ \implies \ \ \partial_x h(x) \equiv 0$
* The derivative of the **identity function** is the 1  function.
    - $f(x) \equiv x \ \ \implies \ \ \partial_x f(x) \equiv 1$
    - $g(t) \equiv t \ \ \implies \ \ \partial_t g(t) \equiv 1$
    - BUT ... $h(x, t) \equiv t \ \ \implies \ \ \partial_x h(x, t) \equiv 0$. Make sure to pay attention to the "with respect to" argument,  that is, the subscript on the $\partial$.
* The derivative of an **exponential function** is an exponential function. 
    - $f(t) \equiv e^t \ \ \implies\ \ \partial_t f(t) = e^t$.
    - BUT ... watch out that the with-respect-to argument matches the argument in the exponent, for instance, $f(x, t) \equiv e^t  \ \ \implies\ \ \partial_x f(x, t) = 0$.
* Sinusoids have derivatives that are sinusoids.
    - $f(x) \equiv \sin(x)\ \ \implies\  \ \partial_x  f(x) = \cos(x)$
    - $f(x) \equiv \cos(x)\ \ \implies\  \ \partial_x  f(x) = -\sin(x)$. Note the minus sign!    
    
* The derivative of a **power-law function**  is a power-law  function.
    - $f(x) \equiv x^2 \ \ \implies \ \ \partial_x f(x) \equiv 2  x$
    - $f(x) \equiv x^3 \ \ \implies \ \ \partial_x f(x) \equiv 3  x^2$
    - $f(x) \equiv x^{1/2}\ \ \implies \ \ \partial_x f(x) \equiv -\frac{1}{2} x^{-1/2}$
    - $f(x) \equiv x^{1.43}\  \ \implies \ \ \ \partial_x f(x) \equiv 1.43 x^{0.43}$
    - In general, the rule is $f(x) \equiv x^n  \ \ \implies \partial_x f(x) \equiv n x^{n-1}$ but  only when $n \neq 0$. When $n = 0$ the function would be $x^0 = 1$ which is simply a constant so the derivative is zero.
* The derivative of the **natural logarithm function** $\ln(x)$  is  the reciprocal $1/x$.
    - $f(x) \equiv \ln(x)\ \ \implies \  \ \partial_x f(x) \equiv x^{-1}$
    
**Basic modeling functions**

Each of the basic modeling functions $f(x)$ is a naked function with a scaled input with the general form $f\left(A (x-x_0)\right)$. We'll call $A$ the ***scaling factor*** and $x_0$ the ***shift***. You differentiate the basic modeling functions in two steps:

1. Identify the derivative of the naked modeling function $\partial_x f(x)$. Let's call this derivative $f'(x)$. For instance, when $f(x) \equiv e^x$, then $f'(x) = e^x$. Or, when $f(x) \equiv \ln(x)$, then $f'(x) = 1/x$.
2. Replace the simple $x$ argument in (1) with the scaled input $A(x-x_0)$, then multiply by the scaling factor. The result will look like $A f'\!\left(A(x-x_0)\right)$
The derivative $\partial f\left(A (x-x_0)\right) = 

Naked function | Basic function | $\partial_x$ Basic function
---------------|----------------|-------------------
$e^x$          | $e^{k(x-x_0)}$ | $k e^{k(x-x_0)}$
$x^p$          | $\left(A(x-x_0)\right)^p$ | $A\, p\, \left(\strut A(x-x_0)\right)^{p-1}$
$\ln(x)$       | $\ln\left(k (x-x_0)\right)$ | $\frac{k}{x-x_0}$
$\sin(x)$      | $\sin\left(\frac{2\pi}{P}(x-x_0)\right)$ | $\frac{2\pi}{P}\cos\left(\frac{2\pi}{P}(x-x_0)\right)$

At first glance, the pattern for $\sin()$ may seem different, but it's really not. When we write $\sin\left(\frac{2\pi}{P}(t-t_0)\right)$ the scaling factor is $\frac{2\pi}{P}$.


## Exponentials and logarithms (optional)
    
    
 with the same base. The relationship is particularly simple when the base is $e$.
    - $f(x) \equiv e^x\ \ \implies \partial_x f(x) \equiv e^x$
    - $g(x) \equiv 2^x\ \ \implies \partial_x g(x) \equiv \ln(2)\cdot 2^x$
    - $h(x) \equiv 10^x\ \ \implies \partial_x h(x) \equiv \ln(10)\cdot 10^x$
    - Note that  $\ln()$ is the so-called "natural logarithm," which is the logarithm to the base $e \approx 2.71828182845905...$
    

    - $g(x) \equiv \log_{10}(x)\ \ \implies \  \ \partial_x g(x) \equiv [\ln(10) x]^{-1}  \approx  [2.30259  x]^{-1}$
    - $h(x) \equiv \log_2(x)\ \ \implies \  \ \partial_x h(x) \equiv [\ln(2) x]^{-1}  \approx  [0.69315  x]^{-1}$
    
## Combining functions

In Chapter \@ref(fun-assembling) we introduced three major methods for putting two or more basic modeling functions together in order to make a new function.

i. Linear combinations: e.g. $a f(x) + b g(x)$
i. Products: e.g. $f(x) g(x)$
i. Composition:, e.g. $f(g(x))$ (which is usually a different function than $g(f(x))$.)

The rule for linear combinations is particularly simple: the derivative of a linear combination of functions is the same linear combination of the derivatives of the functions, that is, if $$h(x) \equiv a f(x) + b g(x)\ \ \implies \ \ \partial_x h(x) = a \,\partial_x f(x) + b\, \partial_x g(x)$$

::: {.workedexample}
Consider the function $h(t) \equiv A e^{kt} + B$. This is a linear combination of two functions, which we can call $f(t) \equiv e^{kt}$ and $g(t) \equiv 1$.

Of course, $f(t)$ and $g(t)$ are basic modeling functions so we have memorized their derivatives: $\partial_t f(t) = k e^{kt}$ and $\partial_t g(t) = 0$. 

Putting this together gives $$\partial_t h(t) = A\, k\, e^{kt} + B\times 0= A\, k\, e^{kt}$$
:::

The derivative of a ***polynomial*** follows the linear combination rule. That's because polynomials are a linear combination of monomials, $x^0$, $x^1$, $x^2$, and so on.

The consequence is that the derivative of a polynomial is another polynomial, with each term being reduced by one order.

- $\partial_x x^0 = 0$
- $\partial_x x^1 = x^0 = 1$
- $\partial_x x^2 = 2 x^1 = 2x$
- and so on.

Example:  $f(x) \equiv a + b x +  c  x^2\  \  \implies\ \ \partial_x f(x) \equiv b  + 2 c x$

## Composition of functions








::: {.workedexample}
Derivation of the chain rule. Break down the following, step by step.

$$\partial_ f(g(x)) = \frac{f(g(x+h)) - f(g(x))}{h} \\
= \frac{1}{h} \left[f(g(x)) + \partial_x f(g(x)) \partial_x g(x) h - f(g(x) \right] \\
=\partial_x f(g(x)) \partial_x g(x)
$$
:::

## Product of functions


::: {.todo}
See 141 DD 31 for drill problems
:::
