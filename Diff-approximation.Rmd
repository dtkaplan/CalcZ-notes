# Local approximations {#local-approximations}

We have focused in this book on a small set of basic modeling functions and three operations for assembling new functions out of old ones: ***linear combination***, ***multiplication***, and ***composition***. All of these have a domain that is the whole number line, or the positive half of the number line, or perhaps the whole number line leaving out zero or some other isolated point. Consider such domains to be ***global***. `r mark(2750)`

We also discussed the components of ***piecewise functions***. Each component is a function defined on a limited domain, an interval $a \leq x \leq b$. In contrast to the global domains, we'll call the limited domains ***local***.  `r mark(2755)`

In this chapter, we'll explore a simple and surprisingly powerful method to approximate any function ***locally***, that is, over a small domain.  

::: {.why}
Why would you want to approximate a function? Why not just use the function itself? 

It's often the case that we know about or hypothesize about relationships only from data. We believe there is a definite functional form for the relationship, but it's unknown and unknowable to us. Still, we can approximate even an unknown function, matching the approximation to the data that is the visible manifestation of the unknown function. Local approximations provide a general-purpose method for creating functions that can represent a wide range of relationship patterns, even ones that are not otherwise known to us.

In fields such as physics or engineering, there are often theories that dictate a particular form of function. For example, Newton's universal law of gravitation posits an inverse square law for the force of gravity as a function of distance. Mechanical engineers use power laws to describe the shape of a beam under load, and communications engineers (and others) make extensive use of sinusoids. Textbooks in those fields rightfully emphasize those particular function forms. 

The utility of the local approximation methods is that you can move forward even in the absence of a detailed theory. Instead, you need only apply your insight to posit which quantities are related to each other and then apply the approximation methods to produce a functional form. This approach is ubiquitous in all fields. 

Sometimes, the local approximation *becomes* the theory. This is seen, for instance, in [Newton's law of cooling](https://en.wikipedia.org/wiki/Newton%27s_law_of_cooling), in [Hooke's law](https://en.wikipedia.org/wiki/Hooke%27s_law) relating force and extension, or the chemist's [law of mass action](https://en.wikipedia.org/wiki/Law_of_mass_action). `r mark(2760)`

:::

The information that you have about the relationship often takes the form of a data table. Each row shows records one trial in which the values of the inputs have been measured and the corresponding output value recorded. We'll discuss the methods of constructing functions to match such data in Block 5 of this course. `r mark(2765)`

Another common form for the information about the relationship is about derivatives. That is, you know something about the derivative of a relationship even though you don't (yet) have a form for the function describing the relationship. As an example, think about building a model of the sustainable speed of a bicycle as a function of the gear selected and the grade of the road---up or down. `r mark(2770)`

Consider these three questions that any experienced bicyclist can likely answer:

1. On a given grade of road, is there an optimal gear for the highest sustained speed? (Have in mind a particular rider, perhaps yourself.)
2. Imagine that the grade of the road is described by a positive number for uphill and a negative number for downhill: that is, the slope of the road. For a positive (uphill) grade and at a fixed gear, will the bike's sustained speed be higher or lower as a function of the grade?^[It's much the same for downhill biking, but you have to keep in mind that a shallow downhill has a higher numerical slope than a steep downhill. That is, the derivative of the hill is near zero for a very shallow grade and far from zero (that is, more negative) for a steep downhill grade.]
3. Assuming you answered "yes" to question (1): Does the optimal gear choice depend on the grade of the road? (In concrete terms, would you choose different gears for an uphill climb than for a level road or a downhill stretch?) `r mark(2775)`

Using the methods in this chapter, the answers to those three questions let you choose an appropriate form for the speed(gear, grade) function. Then, using methods in Block 5, you can make a few measurements for any given rider and construct a model customized to that rider. `r mark(2780)`

Note that the three questions all have to do with derivatives. An "optimal gear" is a gear at which $\partial_\text{gear} \text{speed}(\text{gear}, \text{grade}) = 0$. That you ride slower the higher the numerical value of the slope means that  $\partial_\text{grade} \text{speed}(\text{gear}, \text{grade}) < 0$. And we know that $\partial_\text{gear} \text{speed}(\text{gear}, \text{grade})$ depends on the grade; that's why there's a different optimal gear at each grade. `r mark(2785)`

## Eight simple shapes

In many modeling situations with a single input, you can get very close to a good modeling function $f(x)$ by selecting one of ***eight simple shapes***, shown in Figure \@ref(fig:eight-simple-shapes). `r mark(2790)`

```{r eight-simple-shapes, echo=FALSE, out.width="40%", fig.show="keep", fig.cap="The ***eight simple shapes***, locally, of functions with one input. (See Chapter @@ref(local-approximations).)"}
g <- makeFun(a + b*x + c*x^2 ~ x, a=-1, b=2, c=1)
slice_plot(-g(x, c=0) ~ x, domain(x=c(-3,1)), size=2  ) %>%
  gf_labs(y="Output", x="Input", title="(A) downward sloping line")
slice_plot(g(x, c=0) ~ x, domain(x=c(-3,1)), size=2  ) %>%
  gf_labs(y="Output", x="Input", title="(B) upward sloping line")
slice_plot(g(x) ~ x, domain(x=c(-3,-1)), size=2) %>%
  gf_labs(y="Output", x="Input", title="(C) downward sloping, concave up; steep then shallow")
slice_plot(g(x) ~ x, domain(x=c(-1,1)), size=2) %>% 
  gf_labs(y="Output", x="Input", title="(D) upward sloping, concave up; shallow then steep")
slice_plot(-g(x) ~ x, domain(x=c(-3,-1)), size=2) %>% 
  gf_labs(y="Output", x="Input", title="(E) upward sloping, concave down; steep then shallow")
slice_plot(-g(x) ~ x, domain(x=c(-1,1)), size=2) %>%
  gf_labs(y="Output", x="Input", title="(F) downward sloping, concave down; shallow then steep")
slice_plot(g(x) ~ x, domain(x=c(-3,1)), size=2) %>%
  gf_labs(y="Output", x="Input", title="(G) local minimum")
slice_plot(-g(x) ~ x, domain(x=c(-3,1)), size=2) %>% 
  gf_labs(y="Output", x="Input", title="(H) local maximum")
```



To choose among these shapes, consider your modeling context: `r mark(2795)`

- is the relationship positive (slopes up) or negative (slopes down)
- is the relationship monotonic or not
- is the relationship concave up, concave down, or neither

Some examples, scenarios where the modeler knows about the derivative and concavity of the relationship being modeled. It's often the case that your knowledge of the system comes in this form. `r mark(2800)`

* The incidence of an out-of-control epidemic versus time is concave up, but shallow-then-steep. As the epidemic is brought under control, the decline is steep-then-shallow and concave up. Over the whole course of an epidemic, there is a maximum incidence. Experience shows that epidemics can have a phase where incidence reaches a local minimum: a decline as people practice social distancing followed by an increase as people become complacent. `r mark(2805)`

* How many minutes can you run as a function of speed? Concave down and shallow-then-steep; you wear out faster if you run at high speed. How far can you walk as a function of time? Steep-then-shallow and concave down; your pace slows as you get tired.

* How does the stew taste as a function of saltiness. The taste improves as the amount of salt increases ... up to a point. Too much salt and the stew is unpalatable.

* The temperature of cooling water or the emission of radioactivity as functions of time are concave up and steep-then-shallow. `r mark(2810)`

*  How much fuel is consumed by an aircraft as a function of distance? For long flights the function is concave up and shallow-then-steep; fuel use increases with distance, but the amount of fuel you have to carry also increases with distance and heavy aircraft use more fuel per mile.

* In micro-economic theory there are ***production functions*** that describe how much of a good is produced at any given price, and ***demand functions*** that describe how much of the good will be purchased as a function of price.  `r mark(2815)`
    - As a rule, production increases with price and demand decreases with price. In the short term, production functions tend to be concave down, since it's hard to squeeze increased production out of existing facilities.  
    - For demand in the short term, functions will be concave up when there is some group of consumers who have no other choice than to buy the product. An example is the consumption of gasoline versus price: it's hard in the short term to find another way to get to work. In the long term, consumption functions can be concave down as consumers find alternatives to the high-priced good. For example, high prices for gasoline may, in the long term, prompt a switch to more efficient cars, hybrids, or electric vehicles. This will push demand down steeply.  `r mark(2820)`

 `r mark(2825)`

## Low-order polynomials


There is a simple, familiar functional form that, by selecting parameters appropriately, can take on each of the eight simple shapes: the ***second-order polynomial***.
$$g(x) \equiv a + b x + c x^2$$
As you know, the graph of $g(x)$ is a parabola. 

- The parabola opens upward if $0 < c$. That's the shape of a ***local minimum***.
- The parabola opens downward if $c < 0$. That's the shape of a ***local maximum***

Consider what happens if $c = 0$. The function becomes simply $a + bx$, the straight-line function. 

- When $0 < b$ the line slopes upward.
- When $b < 0$ the line slopes downward.

With the appropriate choice of parameters, the form $a + bx + cx^2$ is  capable of representing four of the ***eight simple shapes***. What about the remaining four? This is where the idea of ***local*** becomes important. Those remaining four shapes are the sides of parabolas, as in Figure \@ref(fig:four-shapes). `r mark(2830)`

```{r four-shapes, echo=FALSE, fig.cap="Four of the ***eight simple shapes*** correspond to the sides of the parabola. The labels refer to the graphs in Figure @@ref(fig:eight-simple-shapes)."}
f1 <- makeFun(a + b*x + c*x^2 ~ x, a=-2, b=1, c=1)
f2 <- makeFun(a + b*x + c*x^2 ~ x, a=-2, b=1, c=-1)
graph_with_boxes(f1, domain = c(-1.1,0.1), my_letters = c("C", "D"), 
                 intervals = tibble(x = c(-1, -.45), xend=c(-.55, 0)))
graph_with_boxes(f2, domain = c(-.3,1.4), my_letters = c("E", "F"),
                 intervals = tibble(x = c(-.2, .55), xend=c(.45, 1.25)))
```


## The low-order polynomial with two inputs

For functions with two inputs, the low-order polynomial approximation looks like this:

$$g(x, y) \equiv a_0 + a_x x + a_y y + a_{xy} x y + a_{yy} y^2 + a_{xx} x^2$$
In reading this form, note the system being used to name the polynomial's coefficients. First, we've used $a$ as the root name of all the coefficients. Sometimes we might want to compare two or more low-order polynomials, so it's convenient to be able to use $a$ for one, $b$ for another, and so on. `r mark(2835)`

The subscripts on the coefficients describes exactly which term in the polynomial involves each coefficient. For instance, the $a_{yy}$ coefficient applies to the $y^2$ term, while $a_x$ applies to the $x$ term.  `r mark(2840)`

Each of $a_0, a_x,$ $a_y,$ $a_{xy}, a_{yy}$, and $a_{xx}$ will, in the final model, be a constant quantity. Don't be confused by the use of $x$ or $y$ in the name of the coefficients. Each coefficient is a constant and not a function of the inputs. Often, your prior knowledge of the system being modeled will tell you something about one or more of the coefficients, for example, whether it is positive or negative. Finding a precise value is often based on quantitative data about the system.  `r mark(2845)`

It helps to have different names for the various terms. It's not too bad say something like, "the $a_{xy}$ term." (Pronounciation: "a sub x y" or  "a x y") But the proper names are: ***linear terms***, ***quadratic terms***, and ***interaction term***. And a shout out to $a_0$, the ***constant term***. `r mark(2850)`

$$g(x, y) \equiv a_0 + \underbrace{a_x x + a_y y}_\text{linear terms} \ \ \ + 
\underbrace{a_{xy} x y}_\text{interaction term} +\ \ \  \underbrace{a_{yy} y^2 + a_{xx} x^2}_\text{quadratic terms}$$

```{r saddle2, echo=FALSE, fig.keep="hold", fig.cap="A saddle"}
make_gxy <- function(seed=1) {
  set.seed(seed)
  f <- makeFun(a0 + ax*x + ay*y + axy*x*y + axx*x^2 + ayy*y^2 ~ x + y,
               a0 = runif(1, -1, 1), 
               ax = runif(1, -1, 1), ay = runif(1, -1, 1), 
               axy = runif(1, -1, 1), 
               ayy = runif(1, -1, 1), axx = runif(1, -1, 1)
  )
}
show_poly2 <- function(seed=1, domain=list(x=c(-2, 2), y=c(-2, 2))) {
  f <- make_gxy(seed)
  list(P1 = contour_plot(f(x, y) ~ x + y, domain=domain),
  P2 = interactive_plot(f(x, y) ~ x + y, domain=domain))
}


Four <- show_poly2(104)

Four$P1
if (knitr::is_html_output()) {
  Four$P2
} else {
  knitr::include_graphics(normalizePath("www/show_poly2_104.png"))
}
```

::: {.example}
In selecting cadets for pilot training, two criteria are the cadet's demonstrated flying aptitude and the leadership potential of the cadet. Let's assume that the overall merit $M$ of a candidate is a function of flying aptitude $F$ and leadership potential $L$. 

Currently, the merit score is a simple function of the $F$ and $L$ scores: $$M_{current}(F, L) \equiv F + L$$

The general in charge of the training program is not satisfied with the current merit function. "I'm getting too many cadets who are great leaders but poor pilots, and too many pilot hot-shots who are not good leaders.  I would rather have an good pilot who is a good leader than have a great pilot who is a poor leader or a poor pilot who is a great leader." (You might reasonably agree or disagree with this point of view, but the general is in charge.)

The general has tasked you to revise the formula to better match her views about the balance betwen flying ability and leadership potential. 

How should you go about constructing $M_{improved}(F, L)$?

You recognize that $F + L$ is a low-order polynomial: just the linear terms are present without a constant or interaction term or quadratic terms. Low-order polynomials are a good way to approximate any formula locally, so you have decided to follow that route.

Quadratic terms are appropriate when a model needs to feature a locally ***optimal*** level of the of the inputs. But it will never be the case that a lower flying score will be more favored than a higher score, and the same thing for the leadership score. So your model doesn't need quadratic terms. 

That leaves the interaction term as the way forward. Your model will be 
$$M_{improved}(F, L) \equiv d_0 + F + L + d_{12} FL$$
Should $d_{12}$ be positive or negative? 

Imagine a cadet Drew with acceptable and equal F and L scores. Another cadet, Blake, has scores that are $F+\epsilon$ and $L-\epsilon$, where $\epsilon$ might be positive or negative. Under the original formula for merit, Drew and Blake have equal merit. Under the new criteria, Drew should have a higher merit than Blake. In other words:
$$M_{improved}(F, L) - M_{improved}(F+\epsilon, L-\epsilon) > 0$$

Expanding out the left side of the inequality gives
$$d_0 + F + L + d_{12} FL - d_0 - F - \epsilon - L + \epsilon - d_{12} (FL -\epsilon L + \epsilon F -  \epsilon^2)\\
\,\\
= - d_{12}(\epsilon(F-L) + \epsilon^2)$$
Since $F$ and $L$ were assumed equal, this results in 
$$M_{improved}(F, L) - M_{improved}(F+\epsilon, L-\epsilon) = d_{1,2}\, \epsilon^2 > 0$$
Thus, $d_{1,2}$ will have to be positive.
:::


<!-- about shapes of contour lines when zooming in. needs work `rrr insert_calcZ_exercise("XX.XX", "bmdrd", "Exercises/Diff/approx-tan.Rmd")`

Original formulation of flying/leadership/merit
`rrr insert_calcZ_exercise("XX.XX", "slks", "Exercises/Diff/rooster-red.Rmd")`
-->

## Finding coefficients from data

Low-order polynomials are often used for constructing functions from data. In this section, I'll demonstrate briefly how this can be done. The full theory will be introduced in Block 5. 

The data I'll use for the demonstration is a set of physical measurements of height, weight, abdominal circumference, etc. on 252 human subjects. These are contained in the `Body_fat` data frame, shown below. 
```{r echo=FALSE}
if (knitr::is_html_output()) {
  math141Z::Body_fat %>% DT::datatable()
} else {
  knitr::kable(math141Z::Body_fat %>% head(10))
}
```

One of the variables records the body-fat percentage, that is, the fraction of the body's mass that is fat. This is thought to be an indicator of fitness and health, but it is extremely hard to measure and involves weighing the person when they are fully submerged in water. This difficulty motivates the development of a method to approximation body-fat percentage from other, easier to make measurements such as height, weight, and so on.

For the purpose of this demonstration, we'll build a local polynomial model of body-fat percentage as a function of height (in inches) and weight (in pounds). 

The polynomial we choose will omit the quadratic terms. It will contain the constant, linear, and interaction terms only. That is
$$\text{body.fat}(h, w) \equiv c_0 + c_h h + c_w w + c_{hw} h w$$
The process of finding the best coefficients in the polynomial is called ***linear regression***. Without going into the details, we'll use linear regression to build the body-fat model and then display the model function as a contour plot.

```{r bodyfat-mod, fig.cap="A low order polynomial model of body fat percentage as a function of height (inches) and weight (lbs)."}
mod <- lm(bodyfat ~ height + weight + height*weight,
          data = math141Z::Body_fat)
body_fat_fun <- makeFun(mod)
contour_plot(body_fat_fun(height, weight) ~ height + weight,
             domain(weight=c(100, 250), height = c(60, 80))) %>%
  gf_labs(title = "Body fat percentage")
```

That we can build such a model doesn't mean that it's useful for anything. In Block 5 we'll return to the question of how well a model constructed from data represents the real-world relationships that the model attempts to describe.

::: {.todo}
Interpreting the model in terms of partial derivatives and gradients. To increase the body-fat percentage, a person can either lose height or gain weight. The former is impractical. Compare a tall person (say, 75 inches) to a short person (say, 63 inches). Who has to gain more weight to increase the body-fat percentage from 10% to 20%?
:::


::: {.todo}
Example about modeling walking

There's an exercise in DailyDigitals/ 141 DD-35 with some narrative

and the project is in DD-37
:::




`r insert_calcZ_exercise("25.02", "ckslw", "Exercises/Diff/rooster-pink.Rmd")`

`r insert_calcZ_exercise("25.04", "ikdlx", "Exercises/Diff/rooster-violet.Rmd")`




